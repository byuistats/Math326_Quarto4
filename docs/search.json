[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Anova_F-test.html",
    "href": "Anova_F-test.html",
    "title": "ANOVA and the F-Test",
    "section": "",
    "text": "With the effects model defined we will want to test whether the treatment factor(s) has a statistically significant effect on the response variable. In other words we are interested in testing the hypotheses:\n\\[\nH_0: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\ne 0 \\text{ for at least one i}\n\\qquad(1)\\]\nWhere \\(\\alpha_i\\) represents the effect of a factor level.\nAnalysis of variance (ANOVA) is a statistical technique that allows us to simultaneously test all factor level effects at the same time."
  },
  {
    "objectID": "Anova_F-test.html#multiple-t-tests",
    "href": "Anova_F-test.html#multiple-t-tests",
    "title": "ANOVA and the F-Test",
    "section": "Multiple t-tests",
    "text": "Multiple t-tests\nAt this point it is reasonable to ask if we couldn’t arrive at the same conclusion by simply conducting multiple t-tests. For example, you could do a t-test for each factor level to determine if the effect is significantly different from zero. Or you might consider testing each combination of factor level effects to see if they are equal to each other.\nThe multiple t-test approach has a couple of a drawbacks. The first drawback is that it becomes a real burden to run, present and interpret a lot of tests if there are many levels to a factor. If you only have 3 or 4 factor levels and only 1 or 2 factors, conducting many tests may be an annoyance. However, many factor levels and many factor would truly bog down your analysis.\nThe other main drawback of using multiple t-tests is more substantive and has to do with the probability of a Type I error. Suppose the treatment factor in our study has 3 levels. The null hypothesis associated with an ANOVA that tests all factor level effects simultaneously is:\n\\[\nH_0: \\alpha_1 = \\alpha_2 =  \\alpha_3 = 0\n\\]\nTesting at a 0.05 significance level means there is a 0.05 probability we will incorrectly reject this null hypothesis (i.e. commit a Type I error). Conversely, there is 0.95 probability we will NOT commit a Type I error.\nIf we attempt to approach the problem by conducting multiple t-tests, we would test the following set of null hypotheses:\n\\(H_0: \\alpha_1 = 0\\) and \\(H_0: \\alpha_2 = 0\\) and \\(H_0: \\alpha_3 = 0\\).\nWe may conduct each of these tests at the 0.05 significance level. Incorrectly rejecting the null hypothesis on any one of these tests would result in the same Type 1 error as incorrectly rejecting the null hypothesis of our ANOVA test of all the effects simultaneously.\nSo what is the probability of committing a Type 1 error in at least 1 of these 3 tests? The simplest way to find the probability of committing at least one Type 1 error in the 3 tests is to calculate \\(1 – P(\\text{no Type 1 errors in all three tests})\\). As previously stated, the significance level (0.05) of each test represents the probability of a Type 1 error. Therefore, the probability of not committing a Type 1 error on each test is 0.95. If we treat the tests as independent, we can find the probability of NOT committing a Type 1 error in all of the tests by multiplying the probabilities:\n\\[\n0.95 * 0.95 * 0.95 = 0.857\n\\]\nWe can subsequently find \\(1-0.857 = .143\\) is the probability of committing a Type 1 error in at least one of the tests, assuming all the null hypotheses are true. This is often referred to as the family wise error rate. The Type 1 error probability (0.143) in this family of t-tests is almost 3 times higher than the ANOVA Type 1 probability of 0.05.\nIn summary, ANOVA allows us to keep the number of tests manageable and it greatly simplifies how Type 1 error is addressed.\nIf we consider a study with more than 1 factor, there are additional advantages of ANOVA. Unlike a multiple t-test approach, while testing one factor’s effects the ANOVA test can account for the other factors’ impact on the response. In this regard, ANOVA is similar to regression."
  },
  {
    "objectID": "Anova_F-test.html#regression",
    "href": "Anova_F-test.html#regression",
    "title": "ANOVA and the F-Test",
    "section": "Regression",
    "text": "Regression\nIndeed, ANOVA and linear regression are more similar than they are different. ANOVA and linear regression tend to each have their own vocabulary because they were developed under different circumstances. ANOVA was developed to deal with agricultural experiments where the independent variables were primarily categorical. Linear regression tends to be introduced as a tool to analyze data where the independent variables are quantitative. Though the language and output associated with each technique may appear different on the surface, the “math” (i.e. the linear algebra) underlying the hood of the techniques is identical. It is not uncommon to have a study where there are multiple quantitative independent variables and multiple categorical independent variables. Thus, the differences between the two lie more in the problems they tend to be applied to and the vocabulary of the researcher than in any meaningful difference in results."
  },
  {
    "objectID": "Anova_F-test.html#mean-squares-ms",
    "href": "Anova_F-test.html#mean-squares-ms",
    "title": "ANOVA and the F-Test",
    "section": "Mean Squares (MS)",
    "text": "Mean Squares (MS)\nYou can think of Mean Squares (MS) as synonymous with variance. The F statistic is a ratio of variances:\n\\[\nF = \\frac{\\text{Variation between factor levels}}{\\text{Variation within factor levels}} = \\frac{\\text{Mean squares of treatment factor means}}{\\text{Mean squares of residual errors}}\n\\]\nWith this is mind, we can fill in the F column of the ANOVA table for Treatment Factor.\n\n\nTable 2: Blank ANOVA summary table for an experiment with 1 treatment factor\n\n\n\n\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nF\np-value\n\n\n\n\nGrand Mean\n\n\n\n\n\n\n\nTreatment Factor\n\n\n\n\\(\\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}}\\)\n\n\n\nResidual Error\n\n\n\n\n\n\n\nTotal\n\n\n\n\n\n\n\n\n\nTo find the variation between factor level means, calculate the sample variance of factor level means and multiply it by the number of replicates in each factor level. (In the case of unbalanced data where you do not have the same number of replicates in each factor level, weighting by sample size is needed).\nThe Mean Squares of the residual error factor (i.e. Mean Squared Error, MSE) represents the within factor level variation. To calculate it you can find the sample variance within each factor level and then take the mean of those variances. (In the case of unbalanced data where you do not have the same number of replicates in each factor level, you would take a weighted average).\n\n\n\nFigure 4: Data from an experiment with 3 factor levels is shown in two separate panels. Left panel shows variation between factor level means. Right panel shows variation within factor levels.\n\n\nIn Figure 4 data from an experiment with 3 factor levels is shown. The panel on the left shows the factor level means plotted as points and the grand mean as a red line. In this panel we can see the between group variation. As mentioned above, the mean squares for treatment could be computed as the variance of the 3 factor level means, and multiplied by 15 (the number of replicates in each factor level).\nIn the panel on the right, the factor level means are plotted in blue and the deviation from each point to its respective factor level mean is depicted. The mean square error could be computed by finding the sample variance within each group and then taking the mean of those 3 variance estimates.\nThough the above methods work, the ANOVA summary table captures interim steps for an alternative (preferred) algorithm for calculating mean squares. Since Mean Squares is synonymous with variance, now is a good time to review the sample variance formula.\n\\[\ns^2 = \\frac{\\sum{(y_i - \\bar{y})}^2}{n-1}\n\\qquad(2)\\]\nUpon closer examination of Equation 2 you can see that this formula is essentially a mean. In fact, you can think of variance as a mean of squared deviations (a.k.a. errors). Any mean is built using 2 parts:\n\n\nRecall that an effect is defined as a deviation from the mean.\n\nnumerator: a sum or total\ndenominator: the number of pieces of information used to create the sum in the numerator\n\nHere, the numerator is the sum of squares and the denominator is the degrees of freedom.\n\n\n\n\n\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nF\np-value\n\n\n\n\nGrand Mean\n\n\n\n\n\n\n\nTreatment Factor\n\n\n\\(\\frac{SS_\\text{Treatment Factor}}{df_\\text{Treatment Factor}}\\)\n\\(\\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}}\\)\n\n\n\nResidual Error\n\n\n\\(\\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}}\\)\n\n\n\n\nTotal"
  },
  {
    "objectID": "Anova_F-test.html#sum-of-squares-ss",
    "href": "Anova_F-test.html#sum-of-squares-ss",
    "title": "ANOVA and the F-Test",
    "section": "Sum of Squares (SS)",
    "text": "Sum of Squares (SS)\nLet’s talk about the numerator first, this will be the sum of squared deviations, or Sum of Squares for short. The Sum of Squares (SS) is a measure of the total variability in a dataset. A naïve approach to calculating total variability in a dataset is to measure the distance from each value to the mean of the dataset. The problem with this approach is that those distance measures will always sum to zero.\nTo avoid this problem, statisticians square the distances before summing them. This results in a value that summarizes the total amount of spread in the dataset. This quantity, the Sum of Squares, is important and so it has its own column in the ANOVA summary table.\nIn the table below an equation for each factor’s SS is listed using terms from the factor effects model. We’ll walk through the meaning of each of those equations.\n\n\n\n\n\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nF\np-value\n\n\n\n\nGrand Mean\n\n\\(n*\\bar{y}_\\text{..}^2\\)\n\n\n\n\n\nTreatment Factor\n\n\\[ \\sum (\\hat{\\alpha}_i^2*n_i)\\]\n\\(\\frac{SS_\\text{Treatment Factor}}{df_\\text{Treatment Factor}}\\)\n\\(\\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}}\\)\n\n\n\nResidual Error\n\n\\[ \\sum \\hat{\\epsilon}_\\text{ij}^2 \\]\n\\(\\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}}\\)\n\n\n\n\nTotal\n\n\\(\\sum y_\\text{ij}^2\\)\n\n\n\n\n\n\n\n\nA deviation from the mean can be thought of as an effect. That is why the symbols for factor effects are used in the SS column in the ANOVA summary table.\nFirst, let’s review the factor effects model to better understand the equations in the SS column above.\n\\[\ny_\\text{ij} = \\mu + \\alpha_i + \\epsilon_\\text{ij}\n\\]\nWe can walk through each equation in the SS column, one by one.\n\nGrand Mean SS: \\(\\bar{y}_\\text{..}\\) is the grand mean. Its value should be squared and then multiplied by \\(n\\), which is the total number of observations in the study.\nTreatment Factor SS: Recall that \\(\\hat{\\alpha}_i\\) is the estimated effect of each factor level. After squaring each effect, multiply it by the number of observations in that level, \\(n_i\\). Finally, the \\(\\sum\\) symbol means to add all those products together.\nResidual Error SS: $ _ $ is the symbol for a residual. Each residual must be squared and then all those squared residuals are summed together.\nTotal SS: This is the sum of all the other sums of squares. Or it can be found by squaring each observed value and then adding up all those squared observations."
  },
  {
    "objectID": "Anova_F-test.html#degrees-of-freedom",
    "href": "Anova_F-test.html#degrees-of-freedom",
    "title": "ANOVA and the F-Test",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nDegrees of freedom can be thought of as the number of unique pieces of information that contributed to the variance estimate, mean squares.\n\n\n\n\n\n\nDegrees of Freedom\n\n\n\nThe number of unique pieces of information that contributed to the variance estimate.\n\n\nIn our dataset we have a certain number of observations. All those observations can be used to estimate the variance in the dataset. But you will notice in Equation 2 the data has already been used to estimate the grand mean (\\(\\bar{y}\\) estimates \\(\\mu\\)). In other words, before we can estimate the variance we must use the data to estimate the mean. Estimating the mean “uses up” one degree of freedom. This is why the denominator of the sample variance formula divides by \\(n-1\\) instead of by \\(n\\).\nFor additional explanation, consider this simple example. There are three data points and you know that the mean of these 3 data points is 10. The value of the first data point could be any number, it is free to vary. The value of the second data point could also be any number, it is free to vary. The third number’s value is not free to vary. It is constrained by the fact that the mean of the 3 data points must be 10. The values of the first two datapoints will determine the value of the third under the constraint of a known (or estimated) mean.\n\n\nTable 3: Only n-1 values are free to vary when the mean of the values is known\n\n\n\n\n\n\n\n\n\nvalue 1\nvalue 2\nvalue 3\n\nMean of 3 Values\n\n\n\n\na\nb\n\\(3*10 - (a+b)\\)\n->\n10\n\n\nfree to vary\nfree to vary\ndepends on other two values\n\n\n\n\n\n\nHow does this apply to the analysis of variance? Initially you have \\(n\\) observations, or in other words \\(n\\) unique pieces of information that can be used to estimate variance of the dataset. As I try to break the variance into its component pieces, I will also need to reallocate those \\(n\\) pieces of information to each factor (grand mean, treatment factor, residual error) for use in estimating their mean squared error. To paraphrase the law of the conservation of mass, “the number of observations can neither be created nor destroyed”. The sum of degrees of freedom for all the factors must equal the number of observations in the dataset.\nWe will reason through the degrees of freedom calculation for each of the 3 sources in the ANOVA table. Keep in mind, we are using the simplest experiment, just one treatment factor, to illustrate these concepts. In more complex designs, there will be additional factors listed in the “sources” column.\nAs was mentioned, every time we use the data to estimate a parameter we use a degree of freedom. To find the grand mean we average over all the values in the dataset; that uses up one degree of freedom because we have estimated 1 mean.\nWhen calculating the degrees of freedom for the treatment factor you might be tempted to think that the degrees of freedom is equal to the number of factor levels because you have to estimate a mean for each level. But, remember the simple example depicted in figure Table 3. Because I have already estimated the grand mean, the last factor level is is not free to vary and therefore is not estimated directly. The mean of the last factor level will have to be a number that satisfies the constraint that the mean of all the factor level means is the grand mean.\nExplained another way, consider the fact that all the factor level effects must sum to zero. If there are \\(m\\) factor levels, I only need to estimate effects for \\(m-1\\) levels. The last level’s effect is a function of the other factor level effects, it does not need to be estimated and therefore does not need a degree of freedom.\nFinally, consider the residual error factor. The non-technical definition of the term residual means “left over”. The degrees of freedom for the residual error factor is whatever degrees of freedom are left over after calculating degrees of freedom for all other factors.\nIn summary, to estimate the degrees of freedom for a factor, start with its number of levels and then subtract the number of means that need to be calculated in order to calculate the factor’s level effects. This is exactly what the general rule for finding degrees of freedom tells us.\n\n\n\n\n\n\nGeneral rule to find degrees of freedom for a factor\n\n\n\n\\[\n\\text{df} = \\text{number of levels} - \\text{sum of df of outside factors}\n\\]"
  },
  {
    "objectID": "assumptions.html",
    "href": "assumptions.html",
    "title": "ANOVA Assumptions",
    "section": "",
    "text": "For our ANOVA F test results and model predictions to be trusted, certain assumptions, or requirements must be met.1\n\n\nThe terms “requirements” and “assumptions” are often used interchangeably when referring to the set of conditions that must be met for the model to be a valid representation of the data.\nBy way of review, here is the mathematical expression of the model for 1 structural factor. If we incorporated more factors into our study we would need to add additional terms to the model to represent that factor’s effects, as well as any interaction effects.\n\\[\ny_\\text{ij} = \\mu + \\alpha_i + \\epsilon_\\text{ij}\n\\qquad(1)\\]\nWhere\n\n\\(y_\\text{ij}\\) is an observation\n\\(\\mu\\) is the grand mean\n\\(\\alpha_i\\) represents the effect of factor level \\(i\\)\n\\(\\epsilon_\\text{ij}\\) is the residual error for the \\(j^\\text{th}\\) observation in factor level \\(i\\)\n\n\\(\\epsilon_\\text{ij}\\) is a random variable and most of the assumptions are focused on defining the distribution of this random variable. Namely, we assume that each residual comes from the same normal distribution, with mean 0 and standard deviation \\(\\sigma\\). Figure 1 illustrates the same residual distribution visually applied to three distinct factor levels. The assumptions and how to check them are explained in more detail below.\n\n\nCode\nset.seed(15)\ny <- data.frame(yi = rnorm(30,rep(c(12,14,18),each=10),2), g = rep(1:3,each=10)) \n\nplot(yi~g, data=y, pch=16, xaxt='n', xlim=c(0.25,3.75), ylab=expression(y[ik]), xlab=\"\", cex=.8, yaxt='n')\naxis(1, at=c(1,2,3), labels=paste(\"Group\",1:3))\n\nmu <- mean(c(12,14,18))\nmyi <- mean(y$yi)\nmai <- mean(yi ~ g, data=y)\nai <- c(12,14,18)\nyval <- seq(7,23, length.out=100)\n\ndy1 <- dnorm(yval, 12, 2)\ndy2 <- dnorm(yval, 14, 2)\ndy3 <- dnorm(yval, 18, 2)\nlines(dy1+1, yval, col='darkgray')\nlines(rep(1,100), yval, col='darkgray')\n\nlines(dy2+2, yval, col='darkgray')\nlines(rep(2,100), yval, col='darkgray')\n\nlines(dy3+3, yval, col='darkgray')\nlines(rep(3,100), yval, col='darkgray')\n\n#lines(c(.75,3.5), rep(mu, 2), lty=2)\n#text(.65,mu, expression(mu))\n\n#lines(rep(1+.21,2), c(ai[1],mu), lty=2, col='firebrick')\nlines(c(1-.2,1+.21), rep(ai[1],2), lty=2)\ntext(1-.4,ai[1], expression(mu[1]))\n#text(1+.21, (ai[1]+mu)/2, expression(alpha[1]), pos=4, cex=0.8)\n\n#lines(rep(2+.21,2), c(ai[2],mu), lty=2, col='firebrick')\nlines(c(2-.2,2+.21), rep(ai[2],2), lty=2)\ntext(2-.4,ai[2], expression(mu[2]))\n#text(2+.21, (ai[2]+mu)/2, expression(alpha[2]), pos=4, cex=0.8)\n\n#lines(rep(3+.21,2), c(ai[3],mu), lty=2, col='firebrick')\nlines(c(3-.2,3+.21), rep(ai[3],2), lty=2)\ntext(3-.4,ai[3], expression(mu[3]))\n#text(3+.21, (ai[3]+mu)/2, expression(alpha[3]), pos=4, cex=0.8)\n\nlines(rep(3-.1,2), c(ai[3],y$yi[25]), lty=2, col='firebrick')\nlines(c(3-.2,3), rep(y$yi[25],2), lty=2)\n#text(3-.21,y$yi[25], expression(y[3][\",\"][5] == mu[3]+epsilon[3][\",\"][5]), pos=2, cex=0.8)\ntext(3-.1, (y$yi[25]+ai[3])/2, expression(epsilon[3][\",\"][5]), pos=2, cex=0.8)\n\n\n\n\n\nFigure 1: Same distribution can be used to describe the residuals from each factor level"
  },
  {
    "objectID": "assumptions.html#center",
    "href": "assumptions.html#center",
    "title": "ANOVA Assumptions",
    "section": "Center",
    "text": "Center\nThe model assumes the mean of the residuals equals zero. The residual is the distance from an observation to its respective factor level mean, or predicted value. This assumption is the reason calculating a mean of observations makes sense as an estimate of the true mean of a factor level. Each observation is made up of two parts: a true part and some random error. If we have 3 observations all from the same factor level:\n\n\\(y_1 = \\text{true factor level mean} + \\text{error}_1\\)\n\\(y_2 = \\text{true factor level mean} + \\text{error}_2\\)\n\\(y_3 = \\text{true factor level mean} + \\text{error}_3\\)\n\nWe estimate the true mean of the factor level by taking the mean of the 3 values:\n\\[\n\\text{Mean of observations} = \\frac{y_1 + y_2 + y_3}{3} = \\frac{\\text{truth} + \\text{error}_1 + \\text{truth} + \\text{error}_2 + \\text{truth} + \\text{error}_3}{3}\n\\]\nRearranging terms gets:\n\\[\n\\text{Mean of observations} = \\text{truth} + \\frac{\\text{error}_1 + \\text{error}_2 + \\text{error}_3}{3}\n\\]\nSince the mean of the residual errors is assumed zero, the second term goes to zero and the mean of observations is the best estimate of the true value. Of course, the more observations we average over the better our estimate of the truth will be.\nThis requirement does not need to be checked since we are guaranteed this will occur based on how we calculate factor level effects. We saw this when we noticed the level effects of a factor sum to zero."
  },
  {
    "objectID": "assumptions.html#constant-variance",
    "href": "assumptions.html#constant-variance",
    "title": "ANOVA Assumptions",
    "section": "Constant Variance",
    "text": "Constant Variance\nWe express the spread of the distribution of residuals in terms of the variance, \\(\\sigma^2\\). We assume that the variance of residuals is the same regardless of the factor level. Consider our conveyor belt example. All the observations go down the same conveyor belt. The conveyor belt does not split into multiple branches just before the last, random station. All the residuals come from the same distribution.\nIn the F-statistic calculation the denominator is a pooled variance; or in other words, an average of the within factor level variances. When factor level sample sizes are unequal, then the average variance is biased toward the factor level with the largest sample size. Thus, it becomes important to show that the variance estimate within each factor level is (relatively) equal when sample sizes are not equal. The greater disparity in sample sizes, the more important it is to have similar within factor levels variances. (Inflation of Type I error tends to be worse if the smallest group has the largest variance.) The F-distribution used to calculate p-values is based on the assumption of equal variances. When there is non-constant variance, the ratio of between group variance to within group variance no longer follows the F-distribution and the p-value calculations will be off.\nThe simplest, quickest, and most common way to check this assumption is a visual assessment of a residual plot. A residual plot shows the residuals on the y-axis and the factor levels or fitted values on the x-axis. The assumption is satisfied when the vertical spread of the data points within each factor level is roughly the same. This is called homogeneity of variance or homoscedasticity. When the spread is not the same it is called heterogeneity of variance, or heteroscedasticity.\nFigure 2 shows the residual plot in our toothbrush example where the effectiveness of 4 different types of toothbrush were studied.\n\n\nCode\nbf2 <- read_csv(\"data/toothpaste_BF2.csv\")\nbrush_aov <- aov(Plaque~Brush, data = bf2)\nwhich = plot(brush_aov, which = 1)\n\n\n\n\n\nFigure 2: Residual vs. Fitted plot to check constant variance assumption\n\n\n\n\n\n\n\n\n\n\nRed Line in the Residual Plot\n\n\n\nIgnore the red line in the residual plot. It can trick your eyes and draw your attention to the wrong thing. It is not meant to gauge constant variance.\n\n\nThe points in Figure 2 are in 4 vertical groupings corresponding to the factor levels of toothbrush. This is to be expected because the x-axis is fitted values. Each toothbrush has a different fitted, or predicted, plaque value. The group of points on the far left appears less vertically spread out than the group of points on the far right.\nOf course, the groupings will never all have exactly equal variance. How different does the spread in this plot need to be to conclude that the assumption is met or is violated? It is subjective and experience will help you spot trouble in the plot. You can also employ additional methods to help detect non-constant variance.\nAs a rule of thumb, you can check to see if the largest standard deviation is more than double the smallest standard deviation. Table 1 shows summary statistics for the toothbrush example. The smallest standard deviation of 1.7 belongs to the oscillating brush. The largest standard deviation of 3.9 belongs to the ultrasonic brush. Because \\(2*1.74 = 3.48 < 3.90\\), by this rule of thumb the constant variance assumption appears to be violated.\n\n\nCode\nfavstats(Plaque~Brush, data = bf2) |> kable(digits = 2)\n\n\n\n\nTable 1: Summary statistics for each toothbrush\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBrush\nmin\nQ1\nmedian\nQ3\nmax\nmean\nsd\nn\nmissing\n\n\n\n\nManual\n19.12\n22.04\n23.38\n24.01\n26.88\n23.09\n2.60\n6\n0\n\n\nOscillating\n17.62\n18.89\n19.94\n21.29\n22.09\n19.98\n1.74\n6\n0\n\n\nSonic\n18.99\n21.73\n23.20\n23.68\n25.58\n22.67\n2.27\n6\n0\n\n\nUltrasonic\n21.45\n23.62\n24.30\n25.35\n32.74\n25.31\n3.90\n6\n0\n\n\n\n\n\n\nThere are formal hypothesis tests that can help determine if variance is equal across factor levels. One such test is Levene’s test. Actually, Modified Levene’s test (also called Brown-Forsythe test) is usually recommended and is the default in R’s car package. The hypothesis for this test is\n\\[\nH_0: \\sigma_1 = \\sigma_2 = … = \\sigma_i \\\\\n\\] \\[\nH_a: \\text{At least one sigma is different from the rest}\n\\]\nThe details of Levene’s test will not be covered here, but essentially the test runs an ANOVA F-test on the factor level variances to determine if the variances are equal. If the p-value of the test is low and the null is rejected, then you would consider the assumption violated. As the researcher, you are hoping to fail to reject the null hypothesis so that you may continue on with your analysis.\n\n\n\n\n\n\nDon’t Forget to Think\n\n\n\nIt is tempting to turn off your brain and simply run the test or use a rule without looking at the data or thinking of the impact. Do NOT do this. In fact, you can often get by without running this test at all. It is better to consider the sample sizes, outliers, general shapes of the distributions, and effect sizes relative to variance within each factor level. Think about how different the groups of residuals really are rather than blindly trusting a rule.\n\n\n\n\nCode\nleveneTest(brush_aov) |> kable()\n\n\n\n\nTable 2: Levene’s test output for the toothbrush example\n\n\n\nDf\nF value\nPr(>F)\n\n\n\n\ngroup\n3\n0.2498376\n0.8604884\n\n\n\n20\nNA\nNA\n\n\n\n\n\n\nFor the toothbrush example, the p-value of Levene’s F-test in Table 2 is .8605, indicating the constant variance assumption is met. It is not uncommon for this hypothesis test to disagree with the rule of thumb. It appears that one outlier in the upper right portion of Figure 2 is the main cause of the unequal variance. If that point is ignored, the groups do look more alike and the rule of thumb agrees with the Levene’s test.\nThis is not to suggest the point be removed from the analysis; rather, to recognize the impact an outlier can have on the assumptions. This is especially true when the methods of checking the assumption don’t agree.\n\nMore than 1 structural factor\nIf you have more than 1 structural factor, multiple residual plots should be examined, or examine one plot that contains all factor level combinations. Consider the slightly more complicated example where researchers investigated toothpaste brand (name brand vs. off brand), toothbrush type, and their interaction.\nIn this case, the residual vs. fitted plot has 8 different vertical groupings - one for each factor level combination of brush and paste. You should not be concerned about looking at each group individually. Rather, look for overall trends or megaphone shapes in the data. For example, does the spread of the residuals increase as the fitted value increases? Or, does the spread of the residuals decrease as the fitted value decreases?\n\n\nCode\nbrush_aov2 <- aov(Plaque~Brush*Toothpaste, data = bf2)\nwhich = plot(brush_aov2, which = 1)\n\n\n\n\n\nFigure 3: Residual vs. Fitted plot to check constant variance assumption for the 2-factor example\n\n\n\n\nFigure 3 shows a slight megaphone shape. As we move from left to right along the x-axis the spread of the points increases (with the exception of the points at x=24.5). We can use a Levene’s test to help us determine if heterogeneity of variance is a problem. The result is shown in Table 3.\n\n\nCode\nleveneTest(brush_aov2) |> kable()\n\n\n\n\nTable 3: Levene’s test output for the 2-factor example\n\n\n\nDf\nF value\nPr(>F)\n\n\n\n\ngroup\n7\n0.8834329\n0.5409189\n\n\n\n16\nNA\nNA\n\n\n\n\n\n\nWith a p-value of .541 we fail to reject the null hypothesis. It appears the constant variance assumption is met."
  },
  {
    "objectID": "assumptions.html#shape-normal-residual-distribution",
    "href": "assumptions.html#shape-normal-residual-distribution",
    "title": "ANOVA Assumptions",
    "section": "Shape: normal residual distribution",
    "text": "Shape: normal residual distribution\nThe ANOVA model assumes that residuals will follow a (approximately) normal distribution. To check this assumption we use a Q-Q plot.\n\n\nThere are statistical tests for normality as well, but each come with their own set of drawbacks. Due to the robust nature of the F test, a visual assessment is usually sufficient.\nThe “Q” in Q-Q plot stands for quantile. For an explanation of quantiles and their relationship to percentiles go here. There are many variations of Q-Q plots and each software computes it slightly differently. The general concept is to plot two quantities on a scatter plot:\n\nResidual from the model2\nThe value from the standard normal distribution (i.e. Z distribution) associated with the sample quantile.\n\nClick to show/hide detailed explanation of Q-Q plot construction\n\n\nThe Q-Q plot is actually just a scatterplot created from ordered pairs. Each ordered pair consists of a residual from the model (that’s easy to find!) and the quantile from the normal distribution associated with that residual.\nBut how do you find a quantile from the normal distribution? To get this, each residual is converted into a sample quantile, then the theoretical Z score from the normal distribution associated with that quantile is calculated. For example, if I had 20 residuals I would calculate the 1/20 quantile (a.k.a. fifth percentile) from the z-distribution. From Figure 4 (a) I can see the 5th percentile of the Z distribution is -1.645. My first ordered pair on the scatterplot would be the smallest residual and the value -1.645.\n\n\nCode\nxqnorm(.05, return = \"plot\")\n\nxqnorm(.10, return = \"plot\")\n\n\n\n\n\n\n\n\n(a) 5th percentile\n\n\n\n\n\n\n\n(b) 10th percentile\n\n\n\n\nFigure 4: Z-score calculations from desired percentile\n\n\n\nThe next point on the Q-Q plot would be my second smallest residual on the y-axis and the \\(2/20 = .10\\) quantile from the Z distribution on the x-axis. The 0.10 quantile is -1.282 as seen in Figure 4 (b).\nThis process would be repeated for all 20 residuals.\n\n\nIf the sample data is normally distributed then the resulting plot of the two quantities will roughly be a straight line. The residuals will never be exactly normal, of course. Some amount of “wiggle” should be allowed.\nFigure 5 is a Q-Q plot for the toothbrush example.\n\n\nCode\nplot(brush_aov, which = 2)\n\n\n\n\n\nFigure 5: Q-Q plot of residuals for tootbrush 1-factor ANOVA example\n\n\n\n\nIt can be difficult to tell if the line is straight enough. qqPlot from the car package (see Figure 6) adds boundary lines to help you determine if the points are out of bounds3. If sections of the plot are out of bounds the assumption of normally distributed residuals can be considered violated.\n\n\nCode\n#The envelope argument controls whether the region between the lines is shaded or not\ncar::qqPlot(brush_aov, envelope = list(style = \"lines\"))\n\n\n[1] 1 9\n\n\n\n\n\nFigure 6: Boundaries added to Q-Q plot of residuals for tootbrush 1-factor ANOVA example\n\n\n\n\nA point on the far right is clearly out of the dashed boundary. It is not uncommon for 1 or 2 points at either end of the x-axis to stray far from the line. Overall, however, the points in this plot tend to follow the line and stay in bounds. I would conclude that the assumption of normally distributed residuals is met.\n\n\n\n\n\n\nNotation\n\n\n\nSo far we have shown the residuals come from a normal distribution, with mean zero and a standard deviation (sigma). This is expressed mathematically as \\(\\epsilon\\) ~ N( 0, \\(\\sigma\\) )."
  },
  {
    "objectID": "assumptions.html#independent-observations",
    "href": "assumptions.html#independent-observations",
    "title": "ANOVA Assumptions",
    "section": "Independent observations",
    "text": "Independent observations\nIn addition to making assumptions about the distribution of residuals, we also make an assumption regarding individual observations, or realizations, from the distribution of errors. Specifically, we assume each observation from the error distribution is independent of the rest. In other words, the residuals are not correlated with each other in any way.\nThis is violated when something is affecting the response that was not adequately randomized, controlled for, or included in the model. Not adequately accounting for treatment order in time or space is often a culprit. For example, suppose you run an experiment where respondents were given a task to complete under 3 distinct conditions. If you did not randomize the order of the conditions or neglected to account for the fact the same respondent provided 3 observations, you would have violated this assumption.\nSometimes looking at the data can provide a clue this requirement is violated, sometimes it cannot. Looking at the Residual vs. Fitted plot is a good place to start. For example, when a model over predicts all observations in condition 1 and under predicted all observations in condition 3 it may be an indicator that you neglected to address something important (i.e. subject identification, or order of conditions) in your experiment.\nAn order plot can also be useful in detecting a violation of this assumption. The order plot shows each residual on the y-axis and the chronological order in which the observation was made/collected along the x-axis. Figure 7 contains the order plot for our simple toothbrush example, assuming the row number indicates the order in which each observation was actually made.\n\n\nCode\nplot(brush_aov$residuals)\n\n\n\n\n\nFigure 7: Order plot for 1-factor toothbrush example\n\n\n\n\nIt is interesting to see in this plot that the very first observation is a bit of an outlier. Perhaps the technology wasn’t working right or the assistant had not yet learned the correct procedure for measuring percent area with plaque. As the researcher, this is something you would want to dig deeper into. An equally plausible explanation for the outlying value is that the person really did have more plaque. Throwing out the datapoint simply because it doesn’t meet your expectations or messes up your analysis is not good research.\n\n\n\n\n\n\nDanger\n\n\n\nYou should not throw out data points based alone on the fact that they appear anomalous.\n\n\nNo other trends are evident in Figure 7. If patterns/trends are evident, you may have violated the assumption of independent observations. Perhaps a tool lost calibration over time, or subjects/researchers experienced fatigue. Whatever the cause, you will want to investigate, fix the issue, and potentially redo the experiment. It really comes down to your ability/inability to defend the validity of your study in the minds of your audience. Bias in your design or execution will lead to violating this assumption.\nIn many cases, the data will not indicate there is bias unless you know exactly what to look for. These unknown sources of bias are particularly difficult to detect. Planning the study in great detail, thinking critically about your results, being familiar with the protocols of the experiment, and getting help from others to provide fresh perspectives is ultimately the best way to check this assumption and ensure bias does not affect your results."
  },
  {
    "objectID": "assumptions.html#assumptions-summary",
    "href": "assumptions.html#assumptions-summary",
    "title": "ANOVA Assumptions",
    "section": "Assumptions Summary",
    "text": "Assumptions Summary\n\n\n\n\n\n\n\nResidual Assumption\nMethod for Checking\n\n\n\n\nMean is zero\nDoesn’t need to be checked. This will be a direct result of how we create the model.\n\n\nConstant variance across factor levels\n\nRule of thumb comparing standard deviations\nResidual vs. fitted plot\nLevene’s Test\n\n\n\nNormally distributed residuals\nNormal Q-Q plot\n\n\nIndependent of each other\n\nCritical thinking\nOrder plot"
  },
  {
    "objectID": "assumptions.html#what-to-do-if-assumptions-are-violated",
    "href": "assumptions.html#what-to-do-if-assumptions-are-violated",
    "title": "ANOVA Assumptions",
    "section": "What To Do If Assumptions Are Violated?",
    "text": "What To Do If Assumptions Are Violated?\n\nPrinciples For How To Proceed\nYou now have some tools to help assess whether the ANOVA assumptions have been met. It is extremely common in practice to be faced with data that is in the “gray area”, and making this determination is not always easy. There are a couple of principles to keep in mind as you decide whether to proceed with the analysis or try to address potential assumption violations.\nFirst, your p-value and test statistic values will be wrong proportional to the degree your assumptions are violated. For example, a minor violation of the homogeneity of variance assumption slightly degrades the accuracy, or truthfulness, of your F statistic. If the F statistic is quite extreme, then being off a little bit will not change the conclusions of your study.\nIn fact, ANOVA is robust to minor/moderate violations of the assumptions. This is the second principle to keep in mind. This means that you can still obtain reasonably trustworthy results even when there are minor or moderate violations of the assumptions. If the sample size is large and balanced, ANOVA tends to be more robust (especially with regard to the normal distribution of errors assumption). The case where skew is present and data is unbalanced is another story, and becomes particularly problematic if you plan to do one-tailed t-tests of contrasts.\nANOVA’s robustness to the mathematical assumptions does not minimize the adverse impacts of bias in a study.\nThird, take into account the purpose and context of the study in the broader context. If violated assumptions can be easily fixed with a few extra lines of code, there is no reason you should not try to improve the situation. As the remedy becomes more difficult/requires more effort, the cost-benefit analysis of trying something else changes. Think about deadlines, project cost, degree of assumption violation, desired precision, and severity of consequences if a wrong conclusion is reached as you decide how to pursue solutions to violated assumptions.\n\n\nLack of time due to procrastination is not a good reason to violate assumptions.\nRather than simply stating if the assumption is met or not met, it is wise to consider the pros and cons of proceeding with the analysis and then document and explain your decision. Consider sample sizes, effect sizes, outliers, and the degree to which assumptions are met when interpreting your results. ANOVA is just one family of models, there are alternative ways to approach a problem. If the ANOVA model does not seem like a good fit, do not be afraid to ask for help or learn a new technique.\n\n\nRemedial Measures\nThe strategy to address violated assumptions depends on how and which assumptions were violated. But beware, none of the suggested measures below can correct bias in sampling or random assignment.\nIf an outlier or two are the source of trouble, investigate the outlier to ensure it is valid, belongs in the study, and does not represent an error in some way.\nTo address non-normality of residuals you will want to know what the distribution of residuals looks like. If a histogram of residuals reveals a multi-modal distribution, that is often an indicator that there are additional populations (i.e. subgroups) that your model did not take into account. Try to identify what variable is causing the multiple modes (e.g. gender) and include it in your model.\nTransforming the data is a technique that can help with the normal distribution assumption and with heteroscedasticity simultaneously. The transformation is applied to the response variable and then the ANOVA analysis is run as usual with the new, transformed variable as the response. Though the analysis is performed using the transformed variable, you can interpret the results in terms of the original units of the response variable. Groups that differ on the transformed response tend to differ on the untransformed response variable as well.\nKnowing what transformation to apply to the response variable can be a challenge. A square root, log transformation, or taking the reciprocal of the response variable are common transformations to use, especially if the response variable represents a count during a defined interval or a time until something occurs. If the response is a proportion (e.g. proportion of quiz questions answered correctly), this transformation may prove useful: \\(Y_\\text{transformed} = log(\\frac{y}{1-y})\\). If you have the data used to calculate the proportion, each “failure or”success” as it were, a logistic regression may be a more powerful tool than an ANOVA on the summarized percent.4\nThe Box-Cox is a more algorithmic way of choosing a transformation.\nIt is also important to recognize that ANOVA is just one of many analysis tools available5. Kruskal-Wallis is one example of an alternative test with less stringent assumptions. But if its requirements are met, ANOVA offers greater statistical power than Kruskal-Wallis. It can also be difficult to extend some of these alternative tests to more complex designs.\nOne other approach is to emphasize the tests of contrasts and comparisons rather than omnibus F-tests. These more specific tests can handle non-constant variances and non-normal residuals, but at the expense of increased complexity or reduced statistical power. In fact, many researchers skip the omnibus ANOVA F-test and will go directly to testing the specific comparisons that motivated the experiment in the first place."
  },
  {
    "objectID": "BasicFactorial.html",
    "href": "BasicFactorial.html",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "",
    "text": "The experimental designs in this section have 2 key characteristics in common:\nTo assign something completely at random means that each experimental unit has a known and equal chance of being selected for a particular treatment and that no other considerations are taken into account when making treatment assignments. Usually, for balance, the same number of units are assigned to each treatment. For example, if I have 4 treatment and 16 units, I may use a computer to randomly shuffle the units into treatment groups.\nFactorial experiments involve two or more factors that are crossed. Factorial crossing means that each combination of factor levels is considered as a treatment in the study. (A study with just one factor is not technically a factorial design, but we will lump it in with our discussion of factorial experiments her because of the completely random treatment assignment).\nContrast a factorial design with the one-at-a-time approach. In a one-at-a-time approach, if I had two factors I wanted to study I would run two separate experiments to evaluate the effect of each factor on the response one-at-time. Factorial designs have a couple of major advantages over one-factor-at-a-time studies.\nEXAMPLE of BF2???\nIn summary, “factorial” refers to how you determine which treatments will be included in the study, and “completely randomized” refers to how treatments are assigned to subjects."
  },
  {
    "objectID": "BasicFactorial.html#bf1",
    "href": "BasicFactorial.html#bf1",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "BF[1]",
    "text": "BF[1]\nA study with just one factor\n\nOverview\nIn a basic one-way factorial design (BF[1]), only one factor is purposefully varied. Each level of the factor is considered a treatment. Each experimental unit is randomly assigned to exactly one treatment.\n\nFactor structure\nThe factor structure for the model resulting from a completely randomized, one factor with design is:\n\nThe above diagram illustrates a factor with 4 levels, 6 replications at each level.\n\n\nHypotheses and model\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from treatment \\(i\\)\n\\(\\mu\\): the grand mean of the dataset. Also referred to as an overall mean or benchmark.\n\\(\\alpha_i\\): effect of treatment \\(i\\)\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its treatment mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\nAssumptions\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\nEach experimental unit is randomly assigned to only 1 treatment (or factor level)\nThe error term of the model (\\(\\epsilon_{ik}\\)) is normally distributed. This assumption is met when the residuals are normally distributed (as seen in a qq-plot).\nThe population variance of each group is equal. This is often called the homogeneity of variance, or constant variance assumption. This is considered met when each group of residuals in the residual vs. fitted-values plot shows a similar vertical spread.\n\n\n\n\n\nDesign\nIn a one factor design, one factor is purposefully varied and all other factors are controlled in order to isolate the effect of just the factor under study. Each level of the factor is considered a treatment.\nIn a completely randomized design, each experimental unit is randomly assigned to exactly 1 treatment. It is common to keep the number of units assigned to each treatment the same to ensure balance. This can be done by listing all the subjects, then listing the treatments, as seen below:\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n1\n\n\nSubject 2\nA\n2\n\n\nSubject 3\nB\n3\n\n\nSubject 4\nB\n4\n\n\nSubject 5\nC\n5\n\n\nSubject 6\nC\n6\n\n\n\nThen you randomly shuffle the treatment column. (You should also be paying attention to the order in which subjects and treatments are being experimented on as this could be a potential source of bias. In a BF[1], you randomize the order also.) The result might look something like this.\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n4\n\n\nSubject 2\nB\n3\n\n\nSubject 3\nC\n6\n\n\nSubject 4\nC\n5\n\n\nSubject 5\nA\n1\n\n\nSubject 6\nB\n2\n\n\n\nYou may notice in the above example that, even with randomization, treatment C occurs in the last 2 observations. If we were truly concerned about the order we could be more strategic and implement a blocked design to prevent “unlucky” ordering and pairing.\nConsider the following example. An experiment was done to asses different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included: Lecture/Materials (Control) (1), Monitor/Keyboard (2), Head Monitor Display/Joypad (3), and Head Monitor Display/Wearables (4). The response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test).\nTo obtain a balanced design, we will want each treatment to be assigned to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\ntreatment_list <- rep(1:4,4) #This repeats the sequence of 1 to 4, four times\ntreatment_list\n\n [1] 1 2 3 4 1 2 3 4 1 2 3 4 1 2 3 4\n\n\nHere it is reformatted in a easy to read table.\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\nThen we randomly shuffle treatments with subjects to get the following assignments. The R code could look like this\n\nset.seed(17) #only use this if you want the exact same random selection as this example\nsample(treatment_list, 16)\n\n [1] 2 4 1 4 3 1 3 2 2 2 4 3 4 1 3 1\n\n\nWe can see here that subject 1 should get treatment 2. Subject 2 gets treatment 4, Subject 3 gets treatment 1 and so on.\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n2\n\n\nSubject 2\n4\n\n\nSubject 3\n1\n\n\nSubject 4\n4\n\n\nSubject 5\n3\n\n\nSubject 6\n1\n\n\nSubject 7\n3\n\n\nSubject 8\n2\n\n\nSubject 9\n2\n\n\nSubject 10\n2\n\n\nSubject 11\n4\n\n\nSubject 12\n3\n\n\nSubject 13\n4\n\n\nSubject 14\n1\n\n\nSubject 15\n3\n\n\nSubject 16\n1\n\n\n\n\n\n\nDecomposition and Factor Structure\nThis section serves as a bridge between the design and the analysis of an experiment. It is equivalent to doing the analysis by hand. The primary goal is to see how the design decisions impact the analysis; including a deeper understanding of what the numbers in an ANOVA table mean and how they are calculated.\nA factor structure for an experimental design can help provide an effective way to organize and plan for the type of data needed for an experiment. For a basic one-way factorial design, three factors are involved for the experiment: the benchmark (or grand mean), the treatment, and the residual error. For example, an experiment was done to help train people in the procedure to launch a lifeboat. This was a Basic One-way Factorial Design, one where the treatments included: Lecture/Materials (Control) (1), Monitor/Keyboard (2), Head Monitor Display/Joypad (3), and Head Monitor Display/Wearables (4). The students were then given a pre-test before training and a post-test after training and the difference between the two scores was the measurement used from each student in the analysis. Therefore, we have four levels for the treatment with six replicates for each treatment (the actual study used 16 observations per treatment). The diagram below gives the factor structure of the design, and the accompanying mathematical model.\n\nA basic one-way factorial design has three factors: the benchmark, treatment, and residual. The effects of these factors can be summed together to find each observed value.\n\nThe observed values on the left show that there are 24 distinct observations of performance score, represented by the 24 cells - one for each of the observed values.\nThe benchmark represents the grand mean (or overall mean). The single large cell indicates that there is only one grand mean and it is part of every observation.\n\nThe treatment factor involves the four levels of the treatment represented by the four vertically long cells. Each treatment may have a distinct mean (or effect).\nThe residual error represents the difference between the observed value and the predicted value. The predicted value, also called the fitted value, is the sum of the grand mean and treatment effect. Each of the cells represent a distinct value for the residual error.\n\n\nInside vs. Outside Factors\nHaving a factor structure can help us determine the degrees of freedom and the effects of each factor. Before determining the degrees of freedom and the effects of each factor, understanding outside and inside factors is helpful.\nA factor is inside of another factor if all the levels of one factor (the inside factor) completely fits within a second factor (the outside factor).\nYou may find this analogy helpful. Pretend that an outside factor is a box, and the inside factor levels are blocks that fit perfectly within the box.\n\n  \n\nIn our basic one-way factorial design there are three factors: the benchmark, treatment, and residuals. In the picture below, benchmark is represented in red, treatment is drawn in blue, and the residual factor levels are depicted in black.\n\nIn order to understand the relationship between the benchmark and treatment factor, imagine picking up the levels of factor and placing them in the other factor one at a time. We will start with taking the levels of treatment and placing them inside of the benchmark.\n\nIn this picture you can see that one entire level of treatment can fit inside of a single level of benchmark. Even though they may share a boundary line, the level does not cross over and start sharing boundaries with any other level. You can repeat this for the other 3 levels of treatment with the same result. Therefore, we say that treatment is inside of benchmark, which is the same as saying that benchmark is outside of treatment.\nConsider now the relationship between treatment and residual. If we take a level of treatment and overlay it on the residual factor, we can see it does not fit neatly inside one of the levels of residual error. In fact, one level of treatment crosses the boundaries of many of the levels of residual error. Therefore, we cannot say that treatment is inside of residual error.\n\nSince treatment is not inside of residual error, does this necessarily mean that treatment is outside of residual error? We can determine this by taking one level of residual at a time and overlaying it on the treatment factor structure, as is pictured below. It can be seen that one level of residual error does NOT cross any of the treatment level boundaries. Therefore, we can safely say that treatment is indeed outside of residual error; or equivalently that treatment is outside of residual error.\n\nTo clarify a common misunderstanding, consider an experiment where we are looking at the inside vs. outside relationship of two factors: A, and B.\n\nWhen factor A is inside of factor B, we can also say factor B is outside of factor A.\nBut, when factor A is not inside of factor B, this does not necessarily mean that factor A is outside of factor B. Later you will come across designs where the two factors are neither outside nor inside of each other: they are crossed.\n\nIn summary, inside and outside factors for every basic one-way factorial design:\n\nThe benchmark factor is the outside factor for all the other factors (treatment and residual error)\nThe treatment factor is an inside factor to the benchmark factor but an outside factor to the residual error.\nThe residual error is an inside factor for all other factors (the benchmark and treatment factors).\n\n\n\nDegrees of Freedom\nWe can use our understanding of inside and outside factors to determine the degrees of freedom (df) for the benchmark, treatment, and residual errors factors.\nThe general formula for degrees of freedom for any factor in a design is:\n\n\ndf = Total levels of a factor minus the sum of the df of all outside factors\n\n\nAn alternative method of finding degrees of freedom is to count the number of unique pieces of information in a factor.\nGoing back to the lifeboat training example (see example above), we have 24 observations total and four levels of the treatment.\n\nFor benchmark, there is only one level of the factor (shown by the one cell) and there are no outside factors for benchmark. Therefore, the degrees of freedom for benchmark is one. Another way to think of this is that the degrees of freedom represents the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as I know the benchmark value (or better stated, as soon as I estimate the benchmark value) for just one of the observations, I know it for all the observations. Therefore, there is just one degree of freedom.\nFor treatment, there are four levels of the factor (shown by the four vertically long cells for treatment). Benchmark is the only factor outside of treatment. Take the number of levels for treatment (4) and subtract the degrees of freedom for benchmark (1), which yields 4-1 = 3 degrees of freedom for treatment.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the treatment effects really contains. Since all observations from the same treatment will have the same treatment effect applied, we really only need to know 4 pieces of information: the effect of each treatment. But the answer is actually less than that. Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom is 3. As soon as we know 3 of the treatment effects, we can fill in the treatment effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of the factor structure diagram). Both benchmark and treatment are outside factors for the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for benchmark and treatment (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the treatment effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 treatments is 20 observations, or in other words, 20 degrees of freedom.\n\n\nFactor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size for the benchmark, treatment, and residual errors factors. In other words, we can estimate the terms in the one-way ANOVA model.\nThe general formula for effect size for any factor of a design is:\n\n\nEffect size = factor level mean minus the sum of the effects of all outside factors\n\n\nTo demonstrate this, the lifeboat training study will be used; where each column of data comes from a different training method (a.k.a. treatment).\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the benchmark factor and the means for each treatment level.\nFor benchmark, get the mean of all 24 observations. The mean for all the observations is 6.5846. There is only one level for benchmark since, all observations come from the same benchmark. Therefore, this number is placed into each of the cells for the benchmark factor.\n\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. These numbers will be put in the columns associated with each level of the treatment (see below).\n\n\n\nCalculate effects\nFrom here we can calculate the effects for benchmark, treatment and residual errors. We will use the general formula for calculating effect size as stated above.\nFor the benchmark, there is only one level and there are no outside factors. Therefore, the effect due to benchmark is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nFor the treatment factor there are four means, one for each level. To calculate this, take the factor level mean and subtract it from the effect due to benchmark to get the effect for each treatment level. For Control, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the overall, or grand, mean. In a similar way you can find the effect for Monitor/Keyboard 7.8492 - 6.5846 = 1.2645. This means the student performance scores increased by 1.2645 on average in this condition compared to the overall mean. For Head Monitor Display/Joypad, the effect is -0.0058 (6.5789 - 6.5846). For Head Monitor Display/Wearables, the effect is 0.5770 (7.1616 - 6.5846) (see below).\n\nTo calculate the residual error effects we must remember that there are 24 levels of residuals. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for benchmark and the effect for the treatment that particular observation received. For instance, for the observation located in the top left of our dataset the observed value is 4.5614. Subtract the sum of the effects of outside factors (benchmark and treatment). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual errors effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was -0.1875 less than the average for all observations in the control group. In context of the this study, this individual’s performance was lower than his/her peers who received the same type of training.\nWe can repeat the calculation for the first residual in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to benchmark and its respective treatment (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in the table below on the right.\n\n\n\n\nCompleting the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA table enables us to conduct a hypothesis test of the significance of the treatment.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n     \n     \n     \n     \n  \n  \n    Treatment \n    3 \n     \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n     \n     \n     \n     \n  \n  \n    Total \n    24 \n     \n     \n     \n     \n  \n\n\n\n\n\nTo get the sum of squares (SS) for a factor, for each observation the effect for that factor needs to be squared. Then all the squared values are summed up to get the sum of squares.\nFor benchmark, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to benchmark.\n\\[\nSS_\\text{Benchmark} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor has four different effects, one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to treatment. For instance, for the control group, the effect is -1.8358. The value is then squared, and then multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Treatment} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the benchmark, treatment, and residual error factors.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n     \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n     \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWe can now calculate the mean squared error column, or mean square (MS). This mean is calculated by dividing sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation).\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. We can then see more clearly which factor is the a bigger source of variability.\nThe mean square calculations are:\n\\[\nMS_\\text{Benchmark} = \\frac{SS_\\text{Benchmark}}{df_\\text{Benchmark}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Treatment} = \\frac{SS_\\text{Treatment}}{df_\\text{Treatment}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWhen getting an F test statistic, testing for the treatment factor is the primary factor of interest so only the F test statistic for treatment is calculated for the analysis. To get the F test statistic for treatment, take the mean square (MS) due to treatment and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of this as calculating the variance in treatment effect sizes in the numerator and the variance of the distances for an observed value to its respective treatment mean in the denominator. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Treatment} = \\frac{MS_\\text{Treatment}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for treatment is calculated based on the F statistic for treatment and the degrees of freedom for both Treatment and Residual Error. In practice, you would not compute this by hand, but in order to complete the decomposition of variance in a manual way, we will calculate the p-value in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to treatment are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n    2.11 \n    0.131 \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\n\n\n\n\nR Instructions\nThe following stuff would belong in the R code pages instead of here\n\nNumerical Summaries\nIn the following explanations\n\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use as.factor(X) inside the aov(Y ~ as.factor(X),…) command.\nYourDataSet is the name of your data set.\n\nYou can take a tidyverse approach or a mosaic package approach to calculating numerical summaries.\nmosaic package:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\ntidyverse approach:\n\nlibrary(tidyverse)\nYourDataSet %>%\n  Group_by(X) %>%\n  Summarise(MeanY = mean(Y), sdY = sd(Y), sampleSize = n()) \n\n\n\nGraphical Summaries\nTo obtain a boxplot:\nboxplot(Y~X, data = YourDataSet)\nExample Code:\n\n\n\n\n\n\n\n\n\n\nResources\n\nExamples\nLifeboat launch training\nMosquito\n\n\nLinks to outside resources\nPopulate this section yourself with links to good examples, definitions, other sections within this textbook, or anything else you think will be interesting/helpful."
  },
  {
    "objectID": "BasicFactorial.html#bf2",
    "href": "BasicFactorial.html#bf2",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "BF[2]",
    "text": "BF[2]\nA study with exactly two factors used to predict a continuous response variable.\n\nOverview\nLorem Ipsum Overview\n\nHypotheses and model\nHere we would list the model in equation form along with the hypotheses we would want to test\n\n\nAssumptions\nA quick recount of the assumptions associated with the model. If this gets too repetitive maybe we could take it out and put it under broad topics\n\n\nFactor structure image\nThis image would actually probably go at the top somewhere, maybe even by or above the title, as a sort of visual anchor/synopsis as to what this design is all about in terms of its structural factors.\n\n\n\n\nDesign\nThis will explain how random assignment is conducted. It may generally be a short section, especially since I already explained about completely random assignment above. However, it could get more in-depth. For example, in blocking you can talk about the different methods for creating blocks, or for Latin Squares there’s a lot to describe. For partial fractional factorials it could get interesting, etc.\n\n\n\nDecomposition\nIt is what it sounds like: discussion of effect calculation, degree of freedom calculation, and factor structure diagrams. Where do things like notation get defined, and concepts like inside vs. outside factors? Should those go in the broad topics menu?\n\n\n\nR Instruction\nIt is what it sounds like: discussion of effect calculation, degree of freedom calculation, and factor structure diagrams. Where do things like notation get defined, and concepts like inside vs. outside factors? Should those go in the broad topics menu?\n\n\nResources\n\nExamples\nHere we could link to a full walk through example of the anlaysis (similar to the Math325 notebook)\n\n\nLinks to outside resources\nThis section the student would populate with links to good examples, definitions, other sections within this textbook, or anything else"
  },
  {
    "objectID": "BasicFactorial.html#bf3",
    "href": "BasicFactorial.html#bf3",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "BF[3]",
    "text": "BF[3]\nA study with exactly three factors used to predict a continuous response variable.\n\nOverview\nLorem Ipsum Overview\n\nHypotheses and model\nHere we would list the model in equation form along with the hypotheses we would want to test\n\n\nAssumptions\nA quick recount of the assumptions associated with the model. If this gets too repetitive maybe we could take it out and put it under broad topics\n\n\nFactor structure image\nThis image would actually probably go at the top somewhere, maybe even by or above the title, as a sort of visual anchor/synopsis as to what this design is all about in terms of its structural factors.\n\n\n\n\nDesign\nThis will explain how random assignment is conducted. It may generally be a short section, especially since I already explained about completely random assignment above. However, it could get more in-depth. For example, in blocking you can talk about the different methods for creating blocks, or for Latin Squares there’s a lot to describe. For partial fractional factorials it could get interesting, etc.\n\n\n\nDecomposition\nIt is what it sounds like: discussion of effect calculation, degree of freedom calculation, and factor structure diagrams. Where do things like notation get defined, and concepts like inside vs. outside factors? Should those go in the broad topics menu?\n\n\n\nR Instruction\nIt is what it sounds like: discussion of effect calculation, degree of freedom calculation, and factor structure diagrams. Where do things like notation get defined, and concepts like inside vs. outside factors? Should those go in the broad topics menu?\n\n\nResources\n\nExamples\nHere we could link to a full walk through example of the anlaysis (similar to the Math325 notebook)\n\n\nLinks to outside resources\nThis section the student would populate with links to good examples, definitions, other sections within this textbook, or anything else"
  },
  {
    "objectID": "BasicFactorial.html#fractional-factorial-designs",
    "href": "BasicFactorial.html#fractional-factorial-designs",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "Fractional Factorial Designs",
    "text": "Fractional Factorial Designs\nThis would probably not follow a similar structure as other sections\n\nOverview??\nLorem Ipsum Overview\n\n\n\nHow many treatments, design rank\nHere we would list the model in equation form along with the hypotheses we would want to test\n\n\n\nConfounding and a Generating Function\nA quick recount of the assumptions associated with the model. If this gets too repetitive maybe we could take it out and put it under broad topics\n\n\n\nAnything else??\n\n\n\nAdditional resources and links\n\nExamples\nHere we could link to a full walk through example of the anlaysis (similar to the Math325 notebook)\n\n\nLinks to outside resources\nThis section the student would populate with links to good examples, definitions, other sections within this textbook, or anything else\n\nThe decompositions presented in this book are all for balanced designs. Unbalanced designs (where not all treatments have an equal number of observations) use more complicated formulas, but a similar approach/process of decomposition is used."
  },
  {
    "objectID": "BasicFactorial_intro.html",
    "href": "BasicFactorial_intro.html",
    "title": "Basic Factorial Designs Overview",
    "section": "",
    "text": "Basic Factorial designs have some key characteristics in common, notably:\n\nFor studies with more than one factor, factors levels are created by crossing factors1\nTreatments are assigned to subjects (a.k.a. experimental units) completely at random2\n\nTo assign something completely at random means that each experimental unit has a known and equal chance of being selected for a particular treatment and that no other considerations are taken into account when making treatment assignments.\nThe decomposition and formulas presented for each of the specific designs assumes the design is balanced, meaning each factor level combination has the same number of observations. In the case of unbalanced designs, formulas would need to be adjusted to account for the differences. Additional explanation of how to approach analysis for unbalanced data is found under broad topics>unbalanced.\n\n\n\n\nFootnotes\n\n\nFactorial crossing is defined in BF[2] and in the Factor Structure page.↩︎\nOnce the factor level combinations are decided upon using factorial crossing, there are multiple ways to perform the random assignment of experimental units to factor levels. In this book though, all of the BF models will be treated as using completely randomized assignment. Strategies such as blocking and repeated measures are treated as separate designs.↩︎"
  },
  {
    "objectID": "BasicFactorial_quarto.html#overview",
    "href": "BasicFactorial_quarto.html#overview",
    "title": "Basic Factorial",
    "section": "Overview",
    "text": "Overview\nIn a basic one-way factorial design (BF[1]), only one factor is purposefully varied. Each experimental unit is assigned to exactly one factor level. (In the case of an observational study, only one independent factor is under consideration.)\n\nFactor Structure\nThe factor structure for the model resulting from a completely randomized, one factor design is:\n\n\n\n\nFigure 1: Example of BF1 Factor Structure\n\n\n\nFigure 1 illustrates a factor with 4 levels, 6 replications at each level.\n\n\nHypothesis and Model\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from factor level \\(i\\)\n\\(\\mu\\): the grand mean of the data set.\n\\(\\alpha_i\\): effect of factor level \\(i\\)\n\\(\\epsilon_{ij}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its factor level mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\nAssumptions\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nRule of thumb comparing standard deviations\n\\(max(s) < 2*min(s)\\)\n\n\n\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "BasicFactorial_quarto.html#design",
    "href": "BasicFactorial_quarto.html#design",
    "title": "Basic Factorial",
    "section": "Design",
    "text": "Design\nIn a one factor design, one factor is purposely varied and all other factors are controlled in order to isolate the effect of just the factor under study. Each level of the factor is considered a treatment.\nIn a completely randomized design, each experimental unit is randomly assigned to exactly 1 treatment. In this example we expect a balanced design (i.e. each factor level has the same number of observations). This can be done by listing all the subjects, then listing the treatments, as seen below:\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n1\n\n\nSubject 2\nA\n2\n\n\nSubject 3\nB\n3\n\n\nSubject 4\nB\n4\n\n\nSubject 5\nC\n5\n\n\nSubject 6\nC\n6\n\n\n\nThen you randomly shuffle the treatment column. (You should also be paying attention to the order in which subjects and treatments are being experimented on as this could be a potential source of bias. In a BF[1], you randomize the order also.) The result might look something like this.\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n4\n\n\nSubject 2\nB\n3\n\n\nSubject 3\nC\n6\n\n\nSubject 4\nC\n5\n\n\nSubject 5\nA\n1\n\n\nSubject 6\nB\n2\n\n\n\nYou may notice in the above example that, even with randomization, treatment C occurs in the last 2 observations. If we were truly concerned about the order we could be more strategic and implement a blocked design to prevent “unlucky” ordering and pairing.\n\nLifeboat Training Example\nConsider the following example. An experiment was done to assess different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included:\n\nLecture/Materials (Control)\nMonitor/Keyboard\nHead Monitor Display/Joypad, and\nHead Monitor Display/Wearables.\n\nThe response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test). There is just one controlled factor, training method, which has 4 levels: the four training methods. An experimental unit in this study is each of the individuals being trained, 16 in all.\nWe want to assign each treatment to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\n\nCode\n#Repeat the sequence of 1 to 4, four times\nTreatment <- rep(1:4,4) \n\n#Create a sequence from 1 to 16\n#Paste the word \"Subject \" in front of each id #\nSubject <- paste(\"Subject\", seq(1:16), sep = \" \")\n\n#Combine the vector of treatment numbers and Subject ID's into 1 tibble/data frame\nassignment_table <- tibble(Subject, Treatment)\n\n#print the table, pander() makes it look nice\npander(assignment_table) \n\n\n\n\n\n\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\n\n\nThen we randomly shuffle the Treatments column to get the following assignments. Check out the R-code to see how this is done.\n\n\nCode\n#set.seed() allows us to get the same random sample each time\nset.seed(42) \n\n#sample() will randomly select from the Treatment vector 16 times without replacement\n# %>% is called a pipe. It simply takes the output from the command on the left\n# and sends it to the command on the right\ntibble(Subject, sample(Treatment, 16)) %>% pander()\n\n\n\n\n\n\n\n\n\nSubject\nsample(Treatment, 16)\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n1\n\n\nSubject 3\n4\n\n\nSubject 4\n1\n\n\nSubject 5\n2\n\n\nSubject 6\n4\n\n\nSubject 7\n2\n\n\nSubject 8\n2\n\n\nSubject 9\n4\n\n\nSubject 10\n3\n\n\nSubject 11\n3\n\n\nSubject 12\n1\n\n\nSubject 13\n3\n\n\nSubject 14\n4\n\n\nSubject 15\n3\n\n\nSubject 16\n2\n\n\n\n\n\nWe can see here that subject 1 should get treatment 2. Subject 2 gets treatment 4, Subject 3 gets treatment 1, and so on."
  },
  {
    "objectID": "BasicFactorial_quarto.html#decomposition",
    "href": "BasicFactorial_quarto.html#decomposition",
    "title": "Basic Factorial",
    "section": "Decomposition",
    "text": "Decomposition\nThis section serves as a bridge between the design and the analysis of an experiment. It is equivalent to doing the analysis by hand. The primary goal is to see how the design decisions impact the analysis; including a deeper understanding of what the numbers in an ANOVA table mean and how they are calculated.\nThe factor structure diagram of an experimental design is an effective way to organize and plan for the type of data needed for an experiment. Recall that in our lifeboat example there were four levels of training method with six replicates for each (the actual study used 16 observations per treatment). The diagram below gives the factor structure of the design, and the accompanying mathematical model.\n\n\n\n\nExample of BF1 Factor Structure\n\n\n\nA basic one-way factorial design has three analysis factors: the grand mean, treatment, and residual. The effects of these factors can be summed together to find each observed value.\n\nThe observed values on the left show that there are 24 distinct observations of performance score, represented by the 24 cells - one for each of the observed values.\nThe grand mean factor represents the grand mean. The single large cell indicates that there is only one grand mean and it is part of every observation.\nThe treatment factor involves the four levels of the treatment represented by the four vertically long cells. Each treatment may have a distinct mean and effect.\nThe residual error represents the difference between the observed value and the predicted value. The predicted value, also called the fitted value, is the sum of the grand mean and treatment effect. Each of the cells represent a distinct value for the residual error.\n\n\nDegrees of Freedom\nWe can use our understanding of inside vs. outside factors to determine the degrees of freedom (df) for the grand mean, treatment, and residual errors factors. We start with 24 observations - or pieces of information. In other words, we have 24 degrees of freedom that need to be allocated to the 3 factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the lifeboat example, grand mean has one level (shown by the one cell in Figure 1) and there are no factors outside of grand mean. Therefore, its degrees of freedom equals one.\nRemember, the degrees of freedom represent the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as you estimate the grand mean for just one of the observations, you know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for the grand mean effect were also known. Therefore, there is just one unique piece of information in the grand mean factor. Grand mean has just 1 degree of freedom.\nFor treatment factor, there are four levels of the factor (shown by the four vertically long cells for treatment in Figure 1). Grand mean is the only factor outside of treatment. Take the number of levels for treatment factor (4 training methods) and subtract the degrees of freedom for grand mean (1), which yields 4-1 = 3 degrees of freedom for treatment.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the treatment effects really contain. Since all observations from the same treatment will have the same treatment effect applied, we only need to know 4 pieces of information: the effect of each treatment. But the answer is actually less than that. Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom are 3. As soon as we know 3 of the treatment effects, we can fill in the treatment effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of Figure 1). Both grand mean and treatment are outside of the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for grand mean and treatment (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the residual factor effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 treatments is 20 observations, or in other words, 20 degrees of freedom.\n\n\nFactor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size of the grand mean, treatment, and residual errors factors in the lifeboat training study. In other words, we can estimate the terms in the one-way ANOVA model.\n\n\n\n\n\n\nGeneral Rule for Effect Size\n\n\n\nEffect size = factor level mean - the sum of the effects of all outside factors\n\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the grand mean factor and the means for each level of training method.\nTo get the grand mean, average all 24 observations. The mean for all the observations is 6.5846. There is only one level for grand mean so this number is placed into each of the cells for the grand mean factor in Figure 2.\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. In Figure 2 these means are placed in the respective training method column.\n\n\n\n\nFigure 2: Raw data and means for grand mean and training factors\n\n\n\n\n\nCalculate effects\nNow that we have calculated means for each level of each factor, we can move on to calculate the effects of the factor levels. We will use the general formula for calculating effect size.\nFor the grand mean, there is only one level and there are no outside factors. Therefore, the effect due to grand mean is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nThe training method factor has four levels: one for each method. To calculate the effect of a training method, take the training method mean and subtract it from the effect due to the grand mean factor. For the “Control” method, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the grand mean. In a similar way you can find the effect for Monitor/Keyboard \\(7.8492 - 6.5846 = 1.2645\\). This means the student performance scores increased by 1.2645 on average in this training method compared to the grand mean. For Head Monitor Display/Joypad, the effect is \\(6.5789 - 6.5846 = -0.0058\\). For Head Monitor Display/Wearables the effect is \\(7.1616 - 6.5846 = 0.5770\\) (see below).\n\n\n\n\nFigure 3: Training Method Effects\n\n\n\nTo calculate the residual error effects remember that there are 24 levels of the residual error factor. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for grand mean and the effect for whichever training method that particular observation received. For instance, for the observation located in the top left of our data set the value is 4.5614. Subtract the sum of the effects of outside factors (grand mean and training). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual error effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was 0.1875 less than the mean of the control group. This individual’s performance was lower than the mean of his/her peers who received the same type of training.\nWe can repeat the residual calculation for the first observation in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to grand mean and its respective training (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in Figure 4.\n\n\n\n\nFigure 4: Residual Effects\n\n\n\n\n\n\nCompleting the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA summary table contains the information we need for a hypothesis test of a treatment factor.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n     \n     \n     \n     \n  \n  \n    Factor \n    3 \n     \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n     \n     \n     \n     \n  \n  \n    Total \n    24 \n     \n     \n     \n     \n  \n\n\n\n\n\nTo get the sum of squares (SS) for a factor, for each observation the effect for that factor first needs to be squared. Then all the squared values are summed up to get the sum of squares.\nFor grand mean, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to grand mean.\n\\[\nSS_\\text{Grand Mean} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor has four different effects, one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to treatment. For instance, for the control group, the effect is -1.8358. The value is then squared, and then multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Factor} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the grand mean factor, treatment factor, and residual error factor.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    1040.57 \n     \n     \n     \n  \n  \n    Factor \n    3 \n    31.81 \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n     \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWe can now calculate the mean squared error column, or mean square (MS), by dividing the sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total (the sum of squares) into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation). The MS is calculated in this manner for each of the effects.\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. This works when looking at SS, since it is the total variance due to each factor. MS is then the average variability for each effect. We can then see clearly which factor is a bigger source of variability by comparing their mean squares.\nThe mean square calculations are:\n\\[\nMS_\\text{Grand Mean} = \\frac{SS_\\text{Grand Mean}}{df_\\text{Grand Mean}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Factor} = \\frac{SS_\\text{Factor}}{df_\\text{Factor}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Factor \n    3 \n    31.81 \n    10.60 \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nThe treatment factor is the primary factor of interest so the F test statistic is only calculated for that factor. To get the F test statistic for the treatment factor take the mean square (MS) due to treatment factor and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of this as calculating the variance in treatment factor level means in the numerator and the variance of the distances for an observed value to its respective treatment factor level mean in the denominator. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Factor} = \\frac{MS_\\text{Factor}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for the treatment factor is calculated based on the F statistic and the degrees of freedom for both treatment factor and residual error. In practice, statistical software computes all the components of the ANOVA table, including the p-value. To complete the decomposition of variance in a manual way, the p-value is calculated in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to the treatment factor are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Factor \n    3 \n    31.81 \n    10.60 \n    2.11 \n    0.131 \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87"
  },
  {
    "objectID": "BasicFactorial_quarto.html#analysis-in-r",
    "href": "BasicFactorial_quarto.html#analysis-in-r",
    "title": "Basic Factorial",
    "section": "Analysis in R",
    "text": "Analysis in R\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots or scatterplots with the means displayed. Instructions for how to calculate numerical summaries and create these plots in R are found at R Instructions->Descriptive Summaries section of the book.\nYou then create the model using the aov() function. To see results of the F-test you can feed your model into a summary() function.\n\nmyaov <- aov(Y ~ X, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is the user defined name in which the results of the aov() model are stored\nY is the name of a numeric variable in your dataset which represents the quantitative response variable.\nX is the name of a qualitative variable in your dataset. It should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\nYourDataSet is the name of your data set.\n\nExample Code\n\n\n df A name you come up with for your dataset  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv( a command from the tidyverse to read in csv files  “data/toothpaste_BF2.csv” The path to the csv file containing the data  ) Functions always end with a closing parenthesis  plaque_aovA name you come up with for your model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  summary( Give important information about an object. When called on an aov object the default is to print the ANOVA table  plaque_aov  Whatever you named your ANOVA model in the previous line   )  Functions always end with a closing parenthesis  Click to view output Click to View Output. \n\n\n\n\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nWe then interpret the results. Toothbrush appears to be a significant factor. Since the p-value in this case is significant we may be able to look at the graphical summaries to understand which factor level effects are significant. We may also want to do some pairwise tests of the means or contrasts.\nNow that the model is created the assumptions need to be checked. Code and explanation for assumption checking can be found in the Model Diagnostics and Assumptions sections of the book respectively."
  },
  {
    "objectID": "BasicFactorial_quarto.html#resources",
    "href": "BasicFactorial_quarto.html#resources",
    "title": "Basic Factorial",
    "section": "Resources",
    "text": "Resources\n\nExamples\nLifeboat launch training\nMosquito\n\n\nLinks to outside resources\nPopulate this section yourself with links to good examples, definitions, other sections within this textbook, or anything else you think will be interesting/helpful."
  },
  {
    "objectID": "BF.html",
    "href": "BF.html",
    "title": "Basic Factorial",
    "section": "",
    "text": "The experimental designs in this section have 2 key characteristics in common:\nNOT SURE HOW CRITICAL THESE DEFINITIONS WILL BE HERE, DEPENDS ON WHAT BRETT COMES UP WITH. THERE IS ALREADY SOME OVERLAP/REPEATING WITH THE FACTOR STRUCTURE SECTION. BUT REPITITION MAY NOT BE A BAD THING.\nTo assign something completely at random means that each experimental unit has a known and equal chance of being selected for a particular treatment and that no other considerations are taken into account when making treatment assignments.\nFactorial experiments involve two or more factors that are crossed. Full factorial crossing occurs when each combination of factor levels is present in the study. (A study with just one factor is not technically a factorial design, but we will lump it in with our discussion of factorial experiments here because of the completely random treatment assignment).\nContrast a factorial design with the one-at-a-time approach. In a one-at-a-time approach, if I had two factors I wanted to study I would run two separate experiments to evaluate the effect of each factor on the response one-at-time. Factorial designs have a couple of major advantages over one-factor-at-a-time studies.\nIn summary, “factorial” refers to how you determine which fact level combinations will be included in the study, and “completely randomized” refers to how treatments are assigned to subjects."
  },
  {
    "objectID": "BF.html#overview",
    "href": "BF.html#overview",
    "title": "Basic Factorial",
    "section": "Overview",
    "text": "Overview\nIn a basic one-way factorial design (BF[1]), only one factor is purposefully varied. Each experimental unit belongs to exactly one factor level. (In the case of an observational study, only one independent factor is under consideration.)\n\nFactor Structure\nThe factor structure for the model resulting from a completely randomized, one factor design is:\n\n\n\n\nFigure 1: Example of BF1 Factor Structure\n\n\n\nFigure 1 illustrates a factor with 4 levels, 6 replications at each level.\n\n\nHypothesis and Model\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from factor \\(i\\)\n\\(\\mu\\): the grand mean of the data set. Also referred to as an overall mean or benchmark.\n\\(\\alpha_i\\): effect of treatment \\(i\\)\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its treatment mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\nAssumptions\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\nIndividual realizations of the error term (i.e. residuals) are independent of one another. We generally consider this requirement met if each experimental unit is randomly assigned to only 1 factor level. However, the researcher should always be on the look out for violations of this assumption and other bias.\nThe error term of the model (\\(\\epsilon_{ik}\\)) is normally distributed. This assumption is met when the residuals are normally distributed (as seen in a qq-plot).\nThe population variance of each group is equal. This is often called the homogeneity of variance, or constant variance assumption. This is considered met when each group of residuals in the residual vs. fitted-values plot shows a similar vertical spread."
  },
  {
    "objectID": "BF.html#design",
    "href": "BF.html#design",
    "title": "Basic Factorial",
    "section": "Design",
    "text": "Design\nIn a one factor design, one factor is purposefully varied and all other factors are controlled in order to isolate the effect of just the factor under study. Each level of the factor is considered a treatment.\nIn a completely randomized design, each experimental unit is randomly assigned to exactly 1 treatment. It is common to keep the number of units assigned to each treatment the same to ensure balance. This can be done by listing all the subjects, then listing the treatments, as seen below:\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n1\n\n\nSubject 2\nA\n2\n\n\nSubject 3\nB\n3\n\n\nSubject 4\nB\n4\n\n\nSubject 5\nC\n5\n\n\nSubject 6\nC\n6\n\n\n\nThen you randomly shuffle the treatment column. (You should also be paying attention to the order in which subjects and treatments are being experimented on as this could be a potential source of bias. In a BF[1], you randomize the order also.) The result might look something like this.\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n4\n\n\nSubject 2\nB\n3\n\n\nSubject 3\nC\n6\n\n\nSubject 4\nC\n5\n\n\nSubject 5\nA\n1\n\n\nSubject 6\nB\n2\n\n\n\nYou may notice in the above example that, even with randomization, treatment C occurs in the last 2 observations. If we were truly concerned about the order we could be more strategic and implement a blocked design to prevent “unlucky” ordering and pairing.\nConsider the following example. An experiment was done to assess different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included:\n\nLecture/Materials (Control)\nMonitor/Keyboard\nHead Monitor Display/Joypad, and\nHead Monitor Display/Wearables.\n\nThe response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test).\nWe want to assign each treatment to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\n\nCode\n#Repeat the sequence of 1 to 4, four times\nTreatment <- rep(1:4,4) \n\n#Create a sequence from 1 to 16\n#Paste the word \"Subject \" in front of each id #\nSubject <- paste(\"Subject\", seq(1:16), sep = \" \")\n\n#Combine the vector of treatment numbers and Subject ID's into 1 tibble/data frame\nassignment_table <- tibble(Subject, Treatment)\n\n#print the table, pander() makes it look nice\npander(assignment_table) \n\n\n\n\n\n\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\n\n\nThen we randomly shuffle the Treatments column to get the following assignments. Check out the R-code to see how this is done.\n\n\nCode\n#set.seed() allows us to get the same random sample each time\nset.seed(42) \n\n#sample() will randomly select from the Treatment vector 16 times without replacement\n# %>% is called a pipe. It simply takes the output from the command on the left\n# and sends it to the command on the right\ntibble(Subject, sample(Treatment, 16)) %>% pander()\n\n\n\n\n\n\n\n\n\nSubject\nsample(Treatment, 16)\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n1\n\n\nSubject 3\n4\n\n\nSubject 4\n1\n\n\nSubject 5\n2\n\n\nSubject 6\n4\n\n\nSubject 7\n2\n\n\nSubject 8\n2\n\n\nSubject 9\n4\n\n\nSubject 10\n3\n\n\nSubject 11\n3\n\n\nSubject 12\n1\n\n\nSubject 13\n3\n\n\nSubject 14\n4\n\n\nSubject 15\n3\n\n\nSubject 16\n2\n\n\n\n\n\nWe can see here that subject 1 should get treatment 2. Subject 2 gets treatment 4, Subject 3 gets treatment 1, and so on."
  },
  {
    "objectID": "BF.html#decomposition",
    "href": "BF.html#decomposition",
    "title": "Basic Factorial",
    "section": "Decomposition",
    "text": "Decomposition\nThis section serves as a bridge between the design and the analysis of an experiment. It is equivalent to doing the analysis by hand. The primary goal is to see how the design decisions impact the analysis; including a deeper understanding of what the numbers in an ANOVA table mean and how they are calculated.\nThe factor structure diagram of an experimental design is an effective way to organize and plan for the type of data needed for an experiment. Recall that in our lifeboat example there were four levels of training method with six replicates for each (the actual study used 16 observations per treatment). The diagram below gives the factor structure of the design, and the accompanying mathematical model.\n\n\n\n\nExample of BF1 Factor Structure\n\n\n\nA basic one-way factorial design has three analysis factors: the benchmark, treatment, and residual. The effects of these factors can be summed together to find each observed value.\n\nThe observed values on the left show that there are 24 distinct observations of performance score, represented by the 24 cells - one for each of the observed values.\nThe benchmark represents the grand mean (or overall mean). The single large cell indicates that there is only one grand mean and it is part of every observation.\nThe treatment factor involves the four levels of the treatment represented by the four vertically long cells. Each treatment may have a distinct mean (or effect).\nThe residual error represents the difference between the observed value and the predicted value. The predicted value, also called the fitted value, is the sum of the grand mean and treatment effect. Each of the cells represent a distinct value for the residual error.\n\n\nDegrees of Freedom\nWe can use our understanding of inside and outside factors to determine the degrees of freedom (df) for the benchmark, treatment, and residual errors factors. We start with 16 observations - or pieces of information. In other words, we have 16 degrees of freedom that need to be allocated to the 3 factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the lifeboat example, benchmark has one level (shown by the one cell in Figure 1) and there are no outside factors for benchmark. Therefore, the degrees of freedom for benchmark is one.\nRemember, the degrees of freedom represents the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as I estimate the benchmark effect for just one of the observations, I know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for benchmark were also known. Therefore, there is just one unique piece of information in the benchmark factor. Benchmark has just 1 degree of freedom.\nFor treatment factor, there are four levels of the factor (shown by the four vertically long cells for treatment in Figure 1). Benchmark is the only factor outside of treatment. Take the number of levels for treatment factor (4 training methods) and subtract the degrees of freedom for benchmark (1), which yields 4-1 = 3 degrees of freedom for treatment.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the treatment effects really contains. Since all observations from the same treatment will have the same treatment effect applied, we really only need to know 4 pieces of information: the effect of each treatment. But the answer is actually less than that. Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom is 3. As soon as we know 3 of the treatment effects, we can fill in the treatment effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of Figure 1). Both benchmark and treatment are outside factors for the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for benchmark and treatment (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the residual factor effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 treatments is 20 observations, or in other words, 20 degrees of freedom.\n\n\nFactor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size of the benchmark, treatment, and residual errors factors in the lifeboat training study. In other words, we can estimate the terms in the one-way ANOVA model.\n\n\n\n\n\n\nGeneral Rule for Effect Size\n\n\n\nEffect size = factor level mean - the sum of the effects of all outside factors\n\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the benchmark factor and the means for each level of training method.\nFor benchmark, get the mean of all 24 observations. The mean for all the observations is 6.5846. There is only one level for benchmark so this number is placed into each of the cells for the benchmark factor in Figure 2.\n\n\n\n\nFigure 2: Raw data and mean for benchmark factor\n\n\n\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. In Figure 3 these means are placed in the respective training method column.\n\n\n\n\nFigure 3: Raw data and means for benchmark and training factors\n\n\n\n\n\nCalculate effects\nFrom here we can calculate the effects for benchmark, training method and residual errors. We will use the general formula for calculating effect size as stated above.\nFor the benchmark, there is only one level and there are no outside factors. Therefore, the effect due to benchmark is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nThe training method factor has four levels: one for each method. To calculate the effect of a training method, take the training method mean and subtract it from the effect due to benchmark. For the “Control” method, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the grand mean. In a similar way you can find the effect for Monitor/Keyboard \\(7.8492 - 6.5846 = 1.2645\\). This means the student performance scores increased by 1.2645 on average in this training method compared to the grand mean. For Head Monitor Display/Joypad, the effect is \\(6.5789 - 6.5846 = -0.0058\\). For Head Monitor Display/Wearables the effect is \\(7.1616 - 6.5846 = 0.5770\\) (see below).\n\n\n\n\nFigure 4: Training Method Effects\n\n\n\nTo calculate the residual error effects we must remember that there are 24 levels of the residual error factor. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for benchmark and the effect for training method that particular observation received. For instance, for the observation located in the top left of our data set the observed value is 4.5614. Subtract the sum of the effects of outside factors (benchmark and training). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual error effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was 0.1875 less than the mean of the control group. In this case, this individual’s performance was lower than his/her peers who received the same type of training.\nWe can repeat the calculation for the first residual in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to benchmark and its respective training (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in Figure 5.\n\n\n\n\nFigure 5: Residual Effects\n\n\n\n\n\n\nCompleting the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA table enables us to conduct a hypothesis test of the significance of the treatment.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n     \n     \n     \n     \n  \n  \n    Treatment \n    3 \n     \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n     \n     \n     \n     \n  \n  \n    Total \n    24 \n     \n     \n     \n     \n  \n\n\n\n\n\nTo get the sum of squares (SS) for a factor, for each observation the effect for that factor needs to be squared. Then all the squared values are summed up to get the sum of squares.\nFor benchmark, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to benchmark.\n\\[\nSS_\\text{Benchmark} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor has four different effects, one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to treatment. For instance, for the control group, the effect is -1.8358. The value is then squared, and then multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Treatment} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the benchmark, treatment, and residual error factors.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n     \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n     \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWe can now calculate the mean squared error column, or mean square (MS). This mean is calculated by dividing sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation).\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. We can then see more clearly which factor is a bigger source of variability.\nThe mean square calculations are:\n\\[\nMS_\\text{Benchmark} = \\frac{SS_\\text{Benchmark}}{df_\\text{Benchmark}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Treatment} = \\frac{SS_\\text{Treatment}}{df_\\text{Treatment}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWhen getting an F test statistic, testing for the treatment factor is the primary factor of interest so only the F test statistic for treatment is calculated for the analysis. To get the F test statistic for treatment, take the mean square (MS) due to treatment and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of this as calculating the variance in treatment effect sizes in the numerator and the variance of the distances for an observed value to its respective treatment mean in the denominator. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Treatment} = \\frac{MS_\\text{Treatment}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for the treatment factor is calculated based on the F statistic and the degrees of freedom for both Treatment Factor and Residual Error. In practice, you would not compute this by hand, but in order to complete the decomposition of variance in a manual way, we will calculate the p-value in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to treatment are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n    2.11 \n    0.131 \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87"
  },
  {
    "objectID": "BF.html#analysis-in-r",
    "href": "BF.html#analysis-in-r",
    "title": "Basic Factorial",
    "section": "Analysis in R",
    "text": "Analysis in R\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots or scatterplots with the means displayed. Instructions for how to create these plots in R are found at R Instructions->Descriptive Summaries section of the book.\nYou then create the model using the aov() function. To see results of the F-test you can feed your model into a summary() function.\n\nmyaov <- aov(Y ~ X, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is some name you come up with to store the results of the aov() model.\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\nYourDataSet is the name of your data set.\n\nExample Code\n\n\ndfA name you come up with for your dataset <-The assignment operator. The result to the right of it gets stored in an object specified on the left read_csv(a command from the tidyverse to read in csv files “data/toothpaste_BF2.csv”The path to the csv file containing the data )Functions always end with a closing parenthesis plaque_aovA name you come up with for your model <-The assignment operator. The result to the right of it gets stored in an object specified on the left aov(A function to define the model PlaqueThe response, or y, variable in the model. It is numeric. ~The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s). Brush,The independent variable containing the names for the 4 types of toothbrushes. data = dfTell the model to look in the dataset named “df” for Plaque and Brush variables )Functions always end with a closing parenthesis summary(Give important information about an object. When called on an aov object the default is to print the ANOVA table plaque_aovWhatever you named your ANOVA model in the previous line )Functions always end with a closing parenthesisClick to view outputClick to View Output.\n\n\n\n\ndf <- read_csv(\"data/toothpaste_BF2.csv\")\nplaque_aov <- aov(Plaque ~ Brush, data = df)\nsummary(plaque_aov)\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nWe then interpret the results. Since the p-value is significant we may be able to the graphical summaries to understand which factor level effects are significant. We may also want to do some pairwise tests of the means or contrasts.\nNow that the model is created the assumption need to be checked. Code and explanation for assumption checking can be found at R Instructions->Model Assumptions section of the book."
  },
  {
    "objectID": "BF.html#resources",
    "href": "BF.html#resources",
    "title": "Basic Factorial",
    "section": "Resources",
    "text": "Resources\n\nExamples\nLifeboat launch training\nMosquito\n\n\nLinks to outside resources\nPopulate this section yourself with links to good examples, definitions, other sections within this textbook, or anything else you think will be interesting/helpful."
  },
  {
    "objectID": "BF1test.html",
    "href": "BF1test.html",
    "title": "Basic Factorial",
    "section": "",
    "text": "The experimental designs in this section have 2 key characteristics in common:\nNOT SURE HOW CRITICAL THESE DEFINITIONS WILL BE HERE, DEPENDS ON WHAT BRETT COMES UP WITH. THERE IS ALREADY SOME OVERLAP/REPEATING WITH THE FACTOR STRUCTURE SECTION. BUT REPITITION MAY NOT BE A BAD THING.\nTo assign something completely at random means that each experimental unit has a known and equal chance of being selected for a particular treatment and that no other considerations are taken into account when making treatment assignments.\nFactorial experiments involve two or more factors that are crossed. Full factorial crossing occurs when each combination of factor levels is present in the study. (A study with just one factor is not technically a factorial design, but we will lump it in with our discussion of factorial experiments here because of the completely random treatment assignment).\nContrast a factorial design with the one-at-a-time approach. In a one-at-a-time approach, if I had two factors I wanted to study I would run two separate experiments to evaluate the effect of each factor on the response one-at-time. Factorial designs have a couple of major advantages over one-factor-at-a-time studies.\nIn summary, “factorial” refers to how you determine which fact level combinations will be included in the study, and “completely randomized” refers to how treatments are assigned to subjects."
  },
  {
    "objectID": "BF1test.html#overview",
    "href": "BF1test.html#overview",
    "title": "Basic Factorial",
    "section": "Overview",
    "text": "Overview\nIn a basic one-way factorial design (BF[1]), only one factor is purposefully varied. Each experimental unit belongs to exactly one factor level. (In the case of an observational study, only one independent factor is under consideration.)\n\nFactor Structure\nThe factor structure for the model resulting from a completely randomized, one factor design is:\n\n\n\n\nFigure 1: Example of BF1 Factor Structure\n\n\n\nFigure 1 illustrates a factor with 4 levels, 6 replications at each level.\n\n\nHypothesis and Model\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from factor \\(i\\)\n\\(\\mu\\): the grand mean of the data set. Also referred to as an overall mean or benchmark.\n\\(\\alpha_i\\): effect of treatment \\(i\\)\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its treatment mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\nAssumptions\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\nIndividual realizations of the error term (i.e. residuals) are independent of one another. We generally consider this requirement met if each experimental unit is randomly assigned to only 1 factor level. However, the researcher should always be on the look out for violations of this assumption and other bias.\nThe error term of the model (\\(\\epsilon_{ik}\\)) is normally distributed. This assumption is met when the residuals are normally distributed (as seen in a qq-plot).\nThe population variance of each group is equal. This is often called the homogeneity of variance, or constant variance assumption. This is considered met when each group of residuals in the residual vs. fitted-values plot shows a similar vertical spread."
  },
  {
    "objectID": "BF1test.html#design",
    "href": "BF1test.html#design",
    "title": "Basic Factorial",
    "section": "Design",
    "text": "Design\nIn a one factor design, one factor is purposefully varied and all other factors are controlled in order to isolate the effect of just the factor under study. Each level of the factor is considered a treatment.\nIn a completely randomized design, each experimental unit is randomly assigned to exactly 1 treatment. It is common to keep the number of units assigned to each treatment the same to ensure balance. This can be done by listing all the subjects, then listing the treatments, as seen below:\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n1\n\n\nSubject 2\nA\n2\n\n\nSubject 3\nB\n3\n\n\nSubject 4\nB\n4\n\n\nSubject 5\nC\n5\n\n\nSubject 6\nC\n6\n\n\n\nThen you randomly shuffle the treatment column. (You should also be paying attention to the order in which subjects and treatments are being experimented on as this could be a potential source of bias. In a BF[1], you randomize the order also.) The result might look something like this.\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n4\n\n\nSubject 2\nB\n3\n\n\nSubject 3\nC\n6\n\n\nSubject 4\nC\n5\n\n\nSubject 5\nA\n1\n\n\nSubject 6\nB\n2\n\n\n\nYou may notice in the above example that, even with randomization, treatment C occurs in the last 2 observations. If we were truly concerned about the order we could be more strategic and implement a blocked design to prevent “unlucky” ordering and pairing.\nConsider the following example. An experiment was done to assess different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included:\n\nLecture/Materials (Control)\nMonitor/Keyboard\nHead Monitor Display/Joypad, and\nHead Monitor Display/Wearables.\n\nThe response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test).\nWe want to assign each treatment to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\n\nCode\n#Repeat the sequence of 1 to 4, four times\nTreatment <- rep(1:4,4) \n\n#Create a sequence from 1 to 16\n#Paste the word \"Subject \" in front of each id #\nSubject <- paste(\"Subject\", seq(1:16), sep = \" \")\n\n#Combine the vector of treatment numbers and Subject ID's into 1 tibble/data frame\nassignment_table <- tibble(Subject, Treatment)\n\n#print the table, pander() makes it look nice\npander(assignment_table) \n\n\n\n\n\n\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\n\n\nThen we randomly shuffle the Treatments column to get the following assignments. Check out the R-code to see how this is done.\n\n\nCode\n#set.seed() allows us to get the same random sample each time\nset.seed(42) \n\n#sample() will randomly select from the Treatment vector 16 times without replacement\n# %>% is called a pipe. It simply takes the output from the command on the left\n# and sends it to the command on the right\ntibble(Subject, sample(Treatment, 16)) %>% pander()\n\n\n\n\n\n\n\n\n\nSubject\nsample(Treatment, 16)\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n1\n\n\nSubject 3\n4\n\n\nSubject 4\n1\n\n\nSubject 5\n2\n\n\nSubject 6\n4\n\n\nSubject 7\n2\n\n\nSubject 8\n2\n\n\nSubject 9\n4\n\n\nSubject 10\n3\n\n\nSubject 11\n3\n\n\nSubject 12\n1\n\n\nSubject 13\n3\n\n\nSubject 14\n4\n\n\nSubject 15\n3\n\n\nSubject 16\n2\n\n\n\n\n\nWe can see here that subject 1 should get treatment 2. Subject 2 gets treatment 4, Subject 3 gets treatment 1, and so on."
  },
  {
    "objectID": "BF1test.html#decomposition",
    "href": "BF1test.html#decomposition",
    "title": "Basic Factorial",
    "section": "Decomposition",
    "text": "Decomposition\nThis section serves as a bridge between the design and the analysis of an experiment. It is equivalent to doing the analysis by hand. The primary goal is to see how the design decisions impact the analysis; including a deeper understanding of what the numbers in an ANOVA table mean and how they are calculated.\nThe factor structure diagram of an experimental design is an effective way to organize and plan for the type of data needed for an experiment. Recall that in our lifeboat example there were four levels of training method with six replicates for each (the actual study used 16 observations per treatment). The diagram below gives the factor structure of the design, and the accompanying mathematical model.\n\n\n\n\nExample of BF1 Factor Structure\n\n\n\nA basic one-way factorial design has three analysis factors: the benchmark, treatment, and residual. The effects of these factors can be summed together to find each observed value.\n\nThe observed values on the left show that there are 24 distinct observations of performance score, represented by the 24 cells - one for each of the observed values.\nThe benchmark represents the grand mean (or overall mean). The single large cell indicates that there is only one grand mean and it is part of every observation.\nThe treatment factor involves the four levels of the treatment represented by the four vertically long cells. Each treatment may have a distinct mean (or effect).\nThe residual error represents the difference between the observed value and the predicted value. The predicted value, also called the fitted value, is the sum of the grand mean and treatment effect. Each of the cells represent a distinct value for the residual error.\n\n\nDegrees of Freedom\nWe can use our understanding of inside and outside factors to determine the degrees of freedom (df) for the benchmark, treatment, and residual errors factors. We start with 16 observations - or pieces of information. In other words, we have 16 degrees of freedom that need to be allocated to the 3 factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the lifeboat example, benchmark has one level (shown by the one cell in Figure 1) and there are no outside factors for benchmark. Therefore, the degrees of freedom for benchmark is one.\nRemember, the degrees of freedom represents the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as I estimate the benchmark effect for just one of the observations, I know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for benchmark were also known. Therefore, there is just one unique piece of information in the benchmark factor. Benchmark has just 1 degree of freedom.\nFor treatment factor, there are four levels of the factor (shown by the four vertically long cells for treatment in Figure 1). Benchmark is the only factor outside of treatment. Take the number of levels for treatment factor (4 training methods) and subtract the degrees of freedom for benchmark (1), which yields 4-1 = 3 degrees of freedom for treatment.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the treatment effects really contains. Since all observations from the same treatment will have the same treatment effect applied, we really only need to know 4 pieces of information: the effect of each treatment. But the answer is actually less than that. Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom is 3. As soon as we know 3 of the treatment effects, we can fill in the treatment effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of Figure 1). Both benchmark and treatment are outside factors for the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for benchmark and treatment (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the residual factor effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 treatments is 20 observations, or in other words, 20 degrees of freedom.\n\n\nFactor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size of the benchmark, treatment, and residual errors factors in the lifeboat training study. In other words, we can estimate the terms in the one-way ANOVA model.\n\n\n\n\n\n\nGeneral Rule for Effect Size\n\n\n\nEffect size = factor level mean - the sum of the effects of all outside factors\n\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the benchmark factor and the means for each level of training method.\nFor benchmark, get the mean of all 24 observations. The mean for all the observations is 6.5846. There is only one level for benchmark so this number is placed into each of the cells for the benchmark factor in Figure 2.\n\n\n\n\nFigure 2: Raw data and mean for benchmark factor\n\n\n\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. In Figure 3 these means are placed in the respective training method column.\n\n\n\n\nFigure 3: Raw data and means for benchmark and training factors\n\n\n\n\n\nCalculate effects\nFrom here we can calculate the effects for benchmark, training method and residual errors. We will use the general formula for calculating effect size as stated above.\nFor the benchmark, there is only one level and there are no outside factors. Therefore, the effect due to benchmark is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nThe training method factor has four levels: one for each method. To calculate the effect of a training method, take the training method mean and subtract it from the effect due to benchmark. For the “Control” method, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the grand mean. In a similar way you can find the effect for Monitor/Keyboard \\(7.8492 - 6.5846 = 1.2645\\). This means the student performance scores increased by 1.2645 on average in this training method compared to the grand mean. For Head Monitor Display/Joypad, the effect is \\(6.5789 - 6.5846 = -0.0058\\). For Head Monitor Display/Wearables the effect is \\(7.1616 - 6.5846 = 0.5770\\) (see below).\n\n\n\n\nFigure 4: Training Method Effects\n\n\n\nTo calculate the residual error effects we must remember that there are 24 levels of the residual error factor. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for benchmark and the effect for training method that particular observation received. For instance, for the observation located in the top left of our data set the observed value is 4.5614. Subtract the sum of the effects of outside factors (benchmark and training). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual error effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was 0.1875 less than the mean of the control group. In this case, this individual’s performance was lower than his/her peers who received the same type of training.\nWe can repeat the calculation for the first residual in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to benchmark and its respective training (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in Figure 5.\n\n\n\n\nFigure 5: Residual Effects\n\n\n\n\n\n\nCompleting the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA table enables us to conduct a hypothesis test of the significance of the treatment.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n     \n     \n     \n     \n  \n  \n    Treatment \n    3 \n     \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n     \n     \n     \n     \n  \n  \n    Total \n    24 \n     \n     \n     \n     \n  \n\n\n\n\n\nTo get the sum of squares (SS) for a factor, for each observation the effect for that factor needs to be squared. Then all the squared values are summed up to get the sum of squares.\nFor benchmark, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to benchmark.\n\\[\nSS_\\text{Benchmark} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor has four different effects, one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to treatment. For instance, for the control group, the effect is -1.8358. The value is then squared, and then multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Treatment} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the benchmark, treatment, and residual error factors.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n     \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n     \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWe can now calculate the mean squared error column, or mean square (MS). This mean is calculated by dividing sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation).\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. We can then see more clearly which factor is a bigger source of variability.\nThe mean square calculations are:\n\\[\nMS_\\text{Benchmark} = \\frac{SS_\\text{Benchmark}}{df_\\text{Benchmark}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Treatment} = \\frac{SS_\\text{Treatment}}{df_\\text{Treatment}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWhen getting an F test statistic, testing for the treatment factor is the primary factor of interest so only the F test statistic for treatment is calculated for the analysis. To get the F test statistic for treatment, take the mean square (MS) due to treatment and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of this as calculating the variance in treatment effect sizes in the numerator and the variance of the distances for an observed value to its respective treatment mean in the denominator. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Treatment} = \\frac{MS_\\text{Treatment}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for the treatment factor is calculated based on the F statistic and the degrees of freedom for both Treatment Factor and Residual Error. In practice, you would not compute this by hand, but in order to complete the decomposition of variance in a manual way, we will calculate the p-value in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to treatment are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n    2.11 \n    0.131 \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87"
  },
  {
    "objectID": "BF1test.html#analysis-in-r",
    "href": "BF1test.html#analysis-in-r",
    "title": "Basic Factorial",
    "section": "Analysis in R",
    "text": "Analysis in R\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots or scatterplots with the means displayed. Instructions for how to create these plots in R are found at R Instructions->Descriptive Summaries section of the book.\nYou then create the model using the aov() function. To see results of the F-test you can feed your model into a summary() function.\n\nmyaov <- aov(Y ~ X, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is some name you come up with to store the results of the aov() model.\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\nYourDataSet is the name of your data set.\n\nExample Code\n\n\n df A name you come up with for your dataset  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv( a command from the tidyverse to read in csv files  “data/toothpaste_BF2.csv” The path to the csv file containing the data  ) Functions always end with a closing parenthesis  plaque_aovA name you come up with for your model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  summary( Give important information about an object. When called on an aov object the default is to print the ANOVA table  plaque_aov  Whatever you named your ANOVA model in the previous line   )  Functions always end with a closing parenthesis  Click to view output Click to View Output. \n\n\n\n\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nWe then interpret the results. Toothbrush appears to be a significant factor. Since the p-value in this case is significant we may be able to look at the graphical summaries to understand which factor level effects are significant. We may also want to do some pairwise tests of the means or contrasts.\nNow that the model is created the assumption need to be checked. Code and explanation for assumption checking can be found in the R Instructions->Model Assumptions section of the book."
  },
  {
    "objectID": "BF1test.html#resources",
    "href": "BF1test.html#resources",
    "title": "Basic Factorial",
    "section": "Resources",
    "text": "Resources\n\nExamples\nLifeboat launch training\nMosquito\n\n\nLinks to outside resources\nPopulate this section yourself with links to good examples, definitions, other sections within this textbook, or anything else you think will be interesting/helpful."
  },
  {
    "objectID": "bf2.html#overview",
    "href": "bf2.html#overview",
    "title": "BF[2]",
    "section": "Overview",
    "text": "Overview\nFactorial experiments involve two or more factors that are crossed.\n\n\n\n\n\n\nTip\n\n\n\nFull factorial crossing occurs when each combination of factor levels is present in the study.\n\n\nContrast a factorial design with the one-at-a-time approach. In a one-at-a-time approach, if I had two factors I wanted to study I would run two separate experiments. Each experiment would evaluate the effect of just one factor on the response.\nFactorial designs have a couple of major advantages over one-factor-at-a-time studies.\n\nThey are a more efficient use of our time and material: I can get information about both of my factors from just one observation\nPerhaps most importantly, factorial designs allow the researcher to estimate interaction effects. Or in other words, we can observe how one factor’s effect on the response changes for different levels of the other factor.\n\nWe will expand on the simple toothpaste example to illustrate BF[2] concepts. The study is summarized here.\nResearchers wanted to know which of 4 types of toothbrushes was best at reducing plaque: manual (this is the traditional/usual type of brush), oscillating bristles, sonic, and ultrasonic. The response variable is was the percent of teeth surface area covered with plaque. Four teeth (first molar in each quadrant of the mouth) were measured on each person to calculate the total percent area covered. Six subjects were assigned to each type of brush.\nResearchers also wanted to study the effect of name brand tooth paste compared to its generic brand equivalent. This is the second controlled factor in the experiment. It has two levels (name brand and off/generic brand). Twelve subjects were used name brand paste, and a different 12 subjects used the generic brand. Toothpaste brand is crossed with toothbrush type to create a BF[2].\n\nFactor Structure\nBased on the description above, the factor structure for this experiment is displayed in Figure 1:\n\n\n\n\nFigure 1: Factor Structure Diagram\n\n\n\nThere are 3 replicates for each factor level combination of toothbrush and toothpaste brand. Two levels of toothpaste multiplied by 4 levels of toothbrush results in 8 factor level combinations total. These 8 factor level combinations are obtained by overlaying the 2 controlled factor partitions. When the controlled factor brush and paste partitions are overlayed, they cross each other and create new, meaningful partitions. Since there were 24 subjects and the study is balanced, we end up with \\(24\\div 8 = 3\\) replicates in each factor level combination.\n\n\nHypothesis and Model\nEach factor (i.e. meaningful partition of the data) in Figure 1 corresponds to a term in Equation 1:\n\\[\ny_\\text{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_\\text{ij} + \\epsilon_\\text{ijk}\n\\qquad(1)\\]\nWhere\n\n\\(\\alpha\\) is the effect of toothbrush, and \\(i\\) goes from 1 to 4 since there are 4 toothbrush types\n\\(\\beta\\) is the effect of toothpaste, and \\(j\\) is either 1 or 2 since there are 2 levels (Name brand and generic brand).\nThe \\((\\alpha\\beta)_\\text{ij}\\) is called the interaction effect.\n\\(\\epsilon\\) is the residual error term, and \\(k\\) is the replicate count within a factor level combination.\n\nThere are at least three hypotheses to test with this model. A hypothesis for each main effect, and a hypothesis for the interaction effect.\nA hypothesis for toothbrush type: \\(H_0: \\alpha_\\text{i} = 0 \\text{ for all } i\\) \\(H_a: \\alpha_\\text{i} ne 0 \\text{ for some } i\\)\nA hypothesis for toothpaste brand: \\(H_0: \\beta_\\text{j} = 0 \\text{ for all } j\\) \\(H_a: \\beta_\\text{j} ne 0 \\text{ for some } j\\)\nA hypothesis for toothbrush - toothpaste interaction \\(H_0: (\\alpha\\beta)_\\text{ij} = 0 \\text{ for all } ij\\) \\(H_a: (\\alpha\\beta)_\\text{ij} ne 0 \\text{ for some } ij\\)\n\n\nAssumptions\nA two-way ANOVA model may be used to analyze data from a BF[2] design if the following requirements are satisfied. Note that these requirements are identical to the requirements of a BF[1] one-way ANOVA.\n\n\nThe BF[] designation refers to the design of the experiment. The reference to one- or two-way ANOVA refers to the analysis technique applied to the resulting data.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nRule of thumb comparing standard deviations\n\\(max(s) < 2*min(s)\\)\n\n\n\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias\n\n\n\n\n\n\n\n\n\nBalanced vs. Unbalanced Data\n\n\n\nThe formulas and decomposition presented here are for balanced data: the number of replicates at each factor level combination is the same. In the case of unbalanced data with interaction effects, decisions must be made about how to allocate sums of squares. How to deal with this situations, including R code, is explained in the Unbalanced page under Broad Topics."
  },
  {
    "objectID": "contrast.html",
    "href": "contrast.html",
    "title": "Contrasts",
    "section": "",
    "text": "The ANOVA F test is considered an omnibus test, meaning it tests all the factor levels of a factor at once. If the test suggests the null hypothesis should be rejected it seems to give rise to more questions than answers. Specifically, you will want to know which factor levels are significantly different from which other factor levels.\nUsually during the design of an experiment, the researcher has specific comparisons in mind that are of particular interest. For example, they may be interested in comparing treatment effects for two dosing levels. These pre-planned comparisons usually drive the experimental design. When it comes time for analysis, an omnibus F-test test may be skipped entirely in favor of jumping directly to the planned comparisons. Or, if the F-test finds statistical significance, the researcher may follow-up with focused post-hoc tests of specific factor levels.\nWhen one factor level mean is compared to another, it is called a pairwise comparison, or simple contrasts. For example, in our toothbrush experiment we may be interested in comparing the oscillating brush to the control group (manual brush). Or we may be especially interested in comparing sonic to ultra sonic.\nLess commonly, the comparison of interest may involve averages of two or more factor level means. This is most likely to occur when the factor levels lend themselves to natural groupings that may be of particular interest to compare. For example, we may want to compare the mean of the sonic and ultrasonic groups to the mean of the oscillating group. Another example might include a comparison of the average of all the “treatment” toothbrushes vs. the control group (manual). When an average across groups is involved, this is called a complex comparison, or linear contrast.\nWe can represent the null hypotheses of these 4 example contrasts as:\n\n\nThough contrast and comparison are technically synonomous, “comparison” most often refers to simple, pairwise comparisons; and “contrast” refers to complex comparisons.\n\n\n\n\nVenn Diagram\n\n\n\n\\(\\begin{aligned} H_0: \\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\nThe above hypotheses can all be expressed as a sum, where each factor level mean is multiplied by a coefficient. When a factor level is not a part of the hypotheses, it has a coefficient of zero.\n\n\nTable 1: Expanded Hypotheses\n\n\n\n\n\n\nFour Null Hypotheses\nLeft Hand Side of Hypotheses Expressed as a Sum of Means and Coefficients\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(-1*\\mu_\\text{man} + 1*\\mu_\\text{osc} + 0*\\mu_\\text{sonic} + 0*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 0*\\mu_\\text{osc} + 1*\\mu_\\text{sonic} + -1*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 1*\\mu_\\text{osc} + -\\frac{1}{2}*\\mu_\\text{sonic} + -\\frac{1}{2}*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\n\\(1*\\mu_\\text{man} + -\\frac{1}{3}*\\mu_\\text{osc} + -\\frac{1}{3}*\\mu_\\text{sonic} + -\\frac{1}{3}*\\mu_\\text{ultra}\\)\n\n\n\n\nThe contents in the right column of Table 1 are referred to as contrasts. We will use the symbol \\(\\psi\\) to represent the contrast. A contrast is formed by multiplying each factor level mean by a coefficient. Simply put, it is a weighted sum. The above hypotheses are all examples of valid contrasts. To be considered a valid contrast, the only restriction is that the sum of the coefficients must be zero. We will often write coefficients used in a contrast as a set, in curly braces as shown in Table 2. Thinking of a contrast in terms of its set of coefficients is helpful for identifying orthogonality of contrasts. Also, when calculating/testing a contrast with software, you are required to input the set (or vector) of coefficients to define the contrast.\n\n\nTable 2: Contrast Coefficients\n\n\n\n\n\n\n\n\\(H_0\\)\nContrast (\\(\\psi\\)) Tested in \\(H_0\\)\nSet of Contrast Coefficients\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(-1*\\mu_\\text{man} + 1*\\mu_\\text{osc} + 0*\\mu_\\text{sonic} + 0*\\mu_\\text{ultra}\\)\n\\(\\{ -1, 1, 0, 0 \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 0*\\mu_\\text{osc} + 1*\\mu_\\text{sonic} + -1*\\mu_\\text{ultra}\\)\n\\(\\{ 0, 0, 1, -1 \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 1*\\mu_\\text{osc} + -\\frac{1}{2}*\\mu_\\text{sonic} + -\\frac{1}{2}*\\mu_\\text{ultra}\\)\n\\(\\{ 0, 1, -\\frac{1}{2}, -\\frac{1}{2} \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\n\\(1*\\mu_\\text{man} + -\\frac{1}{3}*\\mu_\\text{osc} + -\\frac{1}{3}*\\mu_\\text{sonic} + -\\frac{1}{3}*\\mu_\\text{ultra}\\)\n\\(\\{ 1, -\\frac{1}{3}, -\\frac{1}{3}, -\\frac{1}{3} \\}\\)\n\n\n\n\nThere are an infinite number of contrasts that could be tested. Realistically though, the contrasts that make sense to test are generally obvious and depend on your understanding/context of the experiment. Testing pairwise comparisons (i.e. simple contrasts where the coefficients are either -1, 0, or 1) is quite common; averaging across certain factor level means as part of the comparison is less common, but is still something you should be prepared to do. Contrasts can get quite complicated, especially for experiments with complicated designs. In this class though we will stick to relatively simple situations."
  },
  {
    "objectID": "contrast.html#testing-a-contrast",
    "href": "contrast.html#testing-a-contrast",
    "title": "Contrasts",
    "section": "Testing a Contrast",
    "text": "Testing a Contrast\n\nt-test for Pairwise Comparisons\nPairwise comparisons (i.e. simple contrasts) of means using a t-test is something you are probably familiar with from previous statistics classes. The procedure was most likely called something like, “independent samples t-test of two means”. We can build on that understanding to come up with a more general approach that will allow us to test any contrast.\nRecall, that a t-test for one sample has the general form:\n\\[\nt = \\frac{\\bar{y} - \\mu_0}{s_\\bar{y}}\n\\]\nWhere \\(\\bar{y}\\) is the sample mean, \\(\\mu_0\\) is the value from the null hypothesis, and \\(s_\\bar{y}\\) is the standard error of the mean. We can expand this to test whether a difference of two means is zero, in other words an independent samples t-test of two means. Recall, that in ANOVA we assume constant variance across factor levels. (This is a slightly different assumption, resulting in a slightly different calculation than the independent samples t-tests presented in Math221 and Math3251).\n\n\nStandard error of the mean is equal to standard deviation of the individual observations divided by square root of the sample size, \\(s_\\bar{y} = \\frac{s_y}{\\sqrt{n}}\\). See Math221 text for review.\nIn our toothbrush experiment, if we want to test whether the mean of manual brushes is equal to the mean of oscillating brushes we have for our null hypothesis:\n\\[\nH_0: \\mu_\\text{man} - \\mu_\\text{osc} = 0\n\\]\nWe use a t statistic:\n\\[\nt = \\frac{(\\bar{y}_\\text{man} - \\bar{y}_\\text{osc})}{\\sqrt{s^2_p*(\\frac{1}{n_1} + \\frac{1}{n_2})}}\n\\qquad(1)\\]\nThe difference in the numerator is calculated directly from the contrast (multiplying the set of coefficients by their respective factor level mean). In the denominator, the pooled variance (\\(s^2_p\\)) is identical to the mean squared error from the ANOVA summary table. The degrees of freedom for this test statistic are equivalent to the residual degrees of freedom.\n\n\n\n\n\n\nNote, by using the MSE from the ANOVA summary table we are taking advantage of information about residual errors contained in the observations of sonic and ultrasonic brushes as well as the observations from manual and oscillating. This leads to a better estimate of the size of random error.\n\n\n\nFor our study on toothbrushes we have the model:\n\\[\ny_\\text{ij} = \\mu + \\alpha_i + \\epsilon_\\text{ij}\n\\qquad(2)\\]\nWhere\n\n\\(y_\\text{ij}\\) is an observation\n\\(\\mu\\) is the grand mean\n\\(\\alpha_i\\) represents the effect of factor level \\(i\\)\n\\(\\epsilon_\\text{ij}\\) is the residual error for the \\(j^\\text{th}\\) observation in factor level \\(i\\)\n\nBelow is the table of factor level means and the ANOVA summary table.\n\n\nCode\n```{r}\n#| label: tbl-brush_analysis\n#| message: false\n#| tbl-cap: \"Toothbrush Experiment Results\"\n#| tbl-subcap:\n#| - \"Factor Level Means\"\n#| - \"ANOVA Summary Table\"\n#| layout-ncol: 2\n#| code-fold: true\n\nbf2 <- read_csv(\"data/toothpaste_BF2.csv\") \n\nmeans_tbl <- bf2 |> group_by(Brush) |> summarise(mean = mean(Plaque),\n                                    `sample size` = n())\nmeans_tbl |> pander::pander()\n\n\nbrush_aov <- aov(Plaque~Brush, data = bf2)\nsummary(brush_aov) |> pander::pander()\n\n#These lines store values in variables so that I can write them in\n#the latex equation below programmatically rather than hardcoding them\nmean_man <- means_tbl[[1,2]]\nmean_osc <- means_tbl[[2,2]]\nnsize <- means_tbl[[1,3]]\nmse <- summary(brush_aov)[[1]][2,3] #This gets the number from the summary table\ntstat <- (mean_man - mean_osc)/sqrt(mse*(1/nsize + 1/nsize))\npprob <- pt(q=tstat, df=brush_aov$df.resid, lower.tail=FALSE) * 2\n```\n\n\n\nTable 3: Toothbrush Experiment Results\n\n\n\n\n(a) Factor Level Means\n\n\n\n\n\n\n\nBrush\nmean\nsample size\n\n\n\n\nManual\n23.09\n6\n\n\nOscillating\n19.98\n6\n\n\nSonic\n22.67\n6\n\n\nUltrasonic\n25.31\n6\n\n\n\n\n\n\n(b) ANOVA Summary Table\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(>F)\n\n\n\n\nBrush\n3\n86.31\n28.77\n3.822\n0.02583\n\n\nResiduals\n20\n150.6\n7.528\nNA\nNA\n\n\n\n\n\n\n\nPlugging the values from Table 3 into Equation 1 we can calculate the t statistic:\n\\[\nt = \\frac{ 3.11 }{\\sqrt{ 7.53 * (\\frac{1}{ 6 } + \\frac{1}{ 6 })}} = 1.97\n\\qquad(3)\\]\nA t statistic of 1.97 leads to a p-value of 0.063. Since the p-value is greater than our traditional alpha of 0.05, we fail to reject the null hypothesis of equality. In other words, there is insufficient evidence to claim that the manual brush and the oscillating brush have different mean values for percent area of teeth with plaque.\n\n\nt-test for Any Contrast\nThis same t-test approach can be extended so that we can test any contrast, not just pairwise comparisons. To extend the approach, recognize that the \\(1's\\) in Equation 3 appearing directly above each sample size actually represent the squared coefficient of the contrast (see Table 1). Thus, Equation 1 used to compare two factor level means, is actually just a special case of a more general formula, Equation 4, which allows us to perform a hypothesis test of any contrast. This equation continues with the general structure of a t statistic: the numerator contains a sample estimate of the difference, the denominator is the standard error of that difference.\n\\[\nt = \\frac{\\hat{\\psi}}{s_\\hat{\\psi}} = \\frac{\\hat{\\psi}}{\\sqrt{MSE * \\sum(c^2_j / n_j)}}\n\\qquad(4)\\]\nWhere,\n\n\\(\\hat{\\psi}\\) is an estimate of the contrast, obtained by multiplying each factor level mean by its respective contrast coefficient. For a simple pairwise comparison, it is just the difference in means.\n\\(MSE\\) is the mean squares of residuals obtained from the ANOVA summary table\n\\(c_j\\) is the coefficient for the \\(j^\\text{th}\\) factor level and\n\\(n_j\\) is the sample size of the \\(j^\\text{th}\\) factor level.\n\nThe degrees of freedom for \\(t\\) will be equal to the degrees of freedom for residual error in the ANOVA summary table.\nLet’s use this more general approach in Equation 4 to test the fourth hypothesis contained in Table Table 1. Our alternative hypothesis will be the contrast is not equal to zero. Though you can use directional (i.e. 1-tailed) tests of a contrast, the default is to use a two-tailed alternative hypothesis of “not equal to zero”.\nPlugging the values from Table 3 into Equation 4 we can calculate the t statistic:\nNumerator: \\[\n\\hat{\\psi} = 1 * 23.09 + -\\frac{1}{3} * 19.98 + -\\frac{1}{3} * 22.67 + -\\frac{1}{3} * 25.31 = 0.438\n\\]\nDenominator: \\[\ns_\\hat{\\psi} = \\sqrt{MSE * \\sum(c^2_j / n_j)} = \\sqrt{ 7.53 * \\left( \\frac{1^2}{6} + \\frac{-\\frac{1}{3}^2}{6} + \\frac{-\\frac{1}{3}^2}{6} + \\frac{-\\frac{1}{3}^2}{6} \\right) } = 1.294\n\\]\nt statistic: \\[\nt = \\frac{\\hat{\\psi}}{s_\\hat{\\psi}} = \\frac{0.438}{1.294} = .34\n\\qquad(5)\\]\nA test statistic \\(t_\\text{20} = .34\\) is not large enough to be significant.\n\n\n\n\n\n\nDanger\n\n\n\nActually, it does not make a lot of sense to compare the control group (manual brush) to the average of the other three brushes. For a contrast of the control mean vs. average of the treatments to make sense, the treatments would need to have more commonality. For example, if there were two treatments and both used oscillating toothbrushes: one oscillated in a clockwise fashion and the other oscillated in a counter-clockwise. In that case it would make sense to combine the treatment factor levels since they could be interpreted generally as “oscillating brush”. Then you could compare the average of the oscillating groups against the average of the control group (manual brush).\n\n\n\n\nF-test vs. t-test\nWe could have reached exactly the same conclusions by conducting an appropriate F test for the contrast instead of a t-test2. It can be shown that \\(F = t^2\\). When t is based on the degrees of freedom for residuals, and F has \\(df_\\text{numerator}\\) = 1 and \\(df_\\text{denominator} = df_\\text{residuals}\\) , the two tests given identical p-values and thus lead to the same conclusion.\n\n\nR Instructions\nThis section illustrates just one way to test custom contrasts in R. There are many packages, each with their unique syntax, for computing and testing contrasts. As you work more in the field, you may find another package better suits your needs.\nThere are sets of comparisons (a.k.a. contrasts) that are commonly done in practice. The calculation of these sets can be obtained with simpler code than what is shown here but may require other R packages. In addition, when testing multiple contrasts simultaneously there are potentially other adjustments that should be made. Please read “Multiple Comparisons” to understand what other adjustments to consider as well as the R code for conducting these common sets of comparisons.\n\nCaution, the contrasts() function from the stats package in base R will produce the correct p-value for the test of a contrast, but without extra work will not produce the correct estimate of the contrast itself. For this reason, we illustrate estimating and testing the contrast with the emmeans package, which stands for “estimated marginal means”.\nThe first step is to create the model. Then use the emmeans() command to create a grid of factor level summary statistics, including: means, standard deviations, standard error, degrees of freedom associated with the standard error estimate, and confidence intervals around the mean. Unlike a summarize() or favstats() command, emmeans() has the output structured so that it can easily be used in the next step. Store the grid of means into a new object.\n\nmyaov <- aov(Y ~ X, data = df)\nmymeans <- emmeans(myaov, \"X\")\n\n\nmyaov is some name you come up with to store the results of the aov() model.\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\ndf is the name of your data set.\nmymeans is some name you come up with to store the results of the emmeans() command.\n\nDefine the contrasts your are interested in testing inside the contrast() function, which returns the hypothesis test results. You can also feed the result into a confint() function if you prefer confidence intervals over p-values.\n\ncontrast(brush_means,list(name_of_contrast1 = coefficient vector,\n                       name_of_contrast2 = another coefficient vector))) \n\nname_of_contrast are descriptive names you should give to the contrast to help you remember what it represents. The coefficient vector is how you define the contrast.\nWe will repeat the contrasts we did by hand in the sections above, but this time using R.\nExample Code Using Toothbrush Experiment:\n\n\n df The name you want for your dataset  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv(“../data/toothpaste_BF2.csv”) A tidyverse command to read the data in from the specified path  plaque_aov Name you want for your ANOVA model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  brush_means The name you want for the output of the emmeans command  <- The assignment operator. The result to the right of it gets stored in an object specified on the left   emmeans(  Function to calculate stats about marginal means  plaque_aov, aov model created in previous step  “Brush” Factor for whose levels you want to calculate means  ) Functions always end with a closing parenthesis  contrast_results Name you want to store contrast results in  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  contrast( Function to define and test contrasts  brush_means, Grid of stats about marginal means you named in the previous step list( create a list object, which allows you to pass multiple contrast coefficient vectors  man_v_osc = A descriptive name to help you remember what the contrast represents  c(1,-1,0,0) Vector of coefficients used to define the contrast  , Seperator to allow additional inputs to the list     man_v_others = A descriptive name to help you remember what the contrast represents  c(1,-(1/3),-(1/3),-(1/3)) Vector of coefficients used to define the contrast  ), A list is closed with a parenthesis  adjust = Specify what type of adjustment (if any) to make for multiple testing. Default is “none” if this argument is not included.  “none” Read help at ?summary.emmGrid for other acceptable values  ) Functions always end with a closing parenthesis  contrast_results View the test results stored in this object in the previous step  confint( Function to create confidence intervals around contrasts  contrast_results Name of object where you stored contrasts  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n contrast     estimate   SE df t.ratio p.value\n man_v_osc       3.117 1.58 20   1.967  0.0632\n man_v_others    0.438 1.29 20   0.339  0.7382\n\n\n\n\n contrast     estimate   SE df lower.CL upper.CL\n man_v_osc       3.117 1.58 20   -0.188     6.42\n man_v_others    0.438 1.29 20   -2.260     3.14\n\nConfidence level used: 0.95"
  },
  {
    "objectID": "contrast.html#othogonal-contrast",
    "href": "contrast.html#othogonal-contrast",
    "title": "Contrasts",
    "section": "Othogonal Contrast",
    "text": "Othogonal Contrast\nStay tuned…Under Construction"
  },
  {
    "objectID": "DescribeData.html",
    "href": "DescribeData.html",
    "title": "Describing Data",
    "section": "",
    "text": "In the following explanations\n\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable. It would represent a treatment factor.\nYourDataSet is the name of your data set.\n\nYou can take a tidyverse approach or a mosaic package approach to calculating numerical summaries for each treatment.\n\nmosaic package:tidyverse approach\n\n\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  Month min   Q1 median    Q3 max     mean       sd  n missing\n1     5  56 60.0     66 69.00  81 65.54839 6.854870 31       0\n2     6  65 76.0     78 82.75  93 79.10000 6.598589 30       0\n3     7  73 81.5     84 86.00  92 83.90323 4.315513 31       0\n4     8  72 79.0     82 88.50  97 83.96774 6.585256 31       0\n5     9  63 71.0     76 81.00  93 76.90000 8.355671 30       0\n\n\n\nWhen calculating treatment means for combinations of 2 or more factors you can use + or | to separate the factors. | (read as ‘vertical bar’ or ‘pipe’) has the advantage that in addition to calculating means for every factor level combination, favstats will also output the marginal means for each level of the last factor listed.\nNOTE: unlike it’s use in the aov() command, using the * within favstats does not yield expected results and should NOT be used.\n\nlibrary(mosaic)\nfavstats(Y ~ X + Z, data = YourDataSet) \n#OR\nfavstats(Y ~ X | Z, data = YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  + This allows us to create additional subgroups within ‘am’ for each level of ‘cyl’.  cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  am.cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1    0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2    1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3    0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4    1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5    0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6    1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n\n\n\nNotice that the first column in the output contains the factor level combinations of am and cyl. So, ‘0.4’ is interpreted as level 0 for am and level 4 for cyl. Or in other words, the summary statistics on that row are for automatic tranmission, 4 cylinder engine vehicles. The column label of ‘am.cyl’ indicates which factor is represented on which side of the period. The next example uses the same way of labeling the factor level combinations, but the column label is not as intuitive or helpful.\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  | Referred to as a vertical bar or pipe, this symbol further defines subgroups of the variable on its left, using the values of the variable on its right side   cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to View Output  Click to View Output. \n\n\n\n\n\n  cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1 0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2 1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3 0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4 1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5 0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6 1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n7   4 21.4 22.800  26.00 30.400 33.9 26.66364 4.5098277 11       0\n8   6 17.8 18.650  19.70 21.000 21.4 19.74286 1.4535670  7       0\n9   8 10.4 14.400  15.20 16.250 19.2 15.10000 2.5600481 14       0\n\n\n\n\n\n\nCalculating treatment means for one factor:\n\nlibrary(tidyverse)\nYourDataSet %>%\n  Group_by(X) %>%\n  Summarise(MeanY = mean(Y), sdY = sd(Y), sampleSize = n()) \n\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  airquality airquality is a dataset in R.   %>%  The pipe operator that will send the airquality dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the airquality dataset into “little” datasets, one dataset for each value in the “Month” column.  Month “Month” is a column from the airquality dataset that can be treated as qualitative.  ) Functions must always end with a closing parenthesis.   %>%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  aveTemp =  “AveTemp” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  Temp Temp is a quantitative variable (numeric vector) from the airquality dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\nMonth\naveTemp\n\n\n\n\n5\n65.55\n\n\n6\n79.1\n\n\n7\n83.9\n\n\n8\n83.97\n\n\n9\n76.9\n\n\n\n\n\nNote that R calculated the mean Temp for each month in Month from the airquality dataset.\nMay (5), June (6), July (7), August (8), and September (9), respectively.\nFurther, note that to get the “nicely formatted” table, you would have to use\nlibrary(pander)\nairquality %>% \n  group_by(Month) %>%\n  summarise(aveTemp = mean(Temp)) %>%\n  pander()\n\nTo calculate treatment means for each combination of factor levels of 2 or more factors, simply add the additional variable to the group_by() statement.\nExample code:\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  mpg mtcars is a dataset in preloaded in R.   %>%  The pipe operator that will send the mtcars dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the mtcars dataset into “little” datasets, one dataset for each combination of values in the ‘am’ and ‘cyl’ variables  am, cyl ‘am’ and ‘cyl’ are both columns in mtcars. By listing them both here we are going to get output for each combination of ‘am’ and ‘cyl’ that exists in the dataset  ) Functions must always end with a closing parenthesis.   %>%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  mean_mpg =  “mean_mpg” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  mpg mpg is a quantitative variable (numeric vector) from the mtcars dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n`summarise()` has grouped output by 'am'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\n\n\n\n\nam\ncyl\nmean_mpg\n\n\n\n\n0\n4\n22.9\n\n\n0\n6\n19.12\n\n\n0\n8\n15.05\n\n\n1\n4\n28.07\n\n\n1\n6\n20.57\n\n\n1\n8\n15.4"
  },
  {
    "objectID": "DescribeData.html#graphical-summaries",
    "href": "DescribeData.html#graphical-summaries",
    "title": "Describing Data",
    "section": "Graphical Summaries",
    "text": "Graphical Summaries\n\nBoxplots\n\n\n\n\n\n\n\n\nOverviewR InstructionsExplanation\n\n\n\nGraphical depiction of the five-number summary. Great for comparing the distributions of data across several groups or categories. Provides a quick visual understanding of the location of the median as well as the range of the data. Can be useful in showing outliers. Sample size should be larger than at least five, or computing the five-number summary is not very meaningful.\n\n\n\n\n\nBase R ggplot2 plotly\n\n\n\nTo make a boxplot in R use the function:\nboxplot(object)\nTo make side-by-side boxplots:\nboxplot(object ~ group, data=NameOfYourData, ...)\n\nobject must be quantitative data. R refers to this as a “numeric vector.”\ngroup must be qualitative data. R refers to this as either a “character vector” or a “factor.” However, a “numeric vector” can also act as a qualitative variable.\nNameOfYourData is the name of the dataset containing object and group.\n... implies there are many other options that can be given to the boxplot() function. Type ?boxplot in your R Console for more details.\n\nExample Code\nBasic Single Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  $ The $ allows us to access any variable from the airquality dataset.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.  )\nClosing parenthesis for the function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nMore Useful… Basic Side-by-Side Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Names under each Box\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  names=c(“May”,“June”,“July”,“Aug”,“Sep”) names= is used to tell R what labels to place on the x-axis below each boxplot.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Color and Labels\n\n\n boxplot(Temp ~ Month, data=airquality This code was explained in the previous example code.  ,  The comma is used to separate each additional command to a function.  xlab=“Month of the Year” xlab= stands for “x label.” Use it to specify the text to print on the plot under the x-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  ylab=“Temperature” ylab= stands for “y label.” Use it to specify the text to print on the plot next to the y-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  main=“La Guardia Airport Daily Temperatures” main= stands for the “main label” of the plot, which is placed at the top center of the plot. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  col=“wheat” col= stands for the “color” of the plot. The color name “wheat” is an available color in R. Type colors() in the R Console to see more options. The color name must always be placed in quotes.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a boxplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_boxplot()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_boxplot() causes the ggplot to become a boxplot.\n\n\nExample Code\nBasic Single Boxplot\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the y-axis should become.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot() The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n Side-by-side Boxplot and Color Change\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box in the boxplot.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Labels \n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_histogram()” function causes the ggplot to become a histogram. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.   +  The addition symbol + is used to add further elements to the ggplot.     labs( The “labs” function is used to add labels to the plot, like a main title, x-label and y-label.  title=“La Guardia Airport Daily Mean Temperature”,  The “title=” command allows you to control the main title at the top of the graphic.  x=“Month of the Year”,  The “x=” command allows you to control the x-label of the graphic.  y=“Daily Mean Temperature” The “y=” command allows you to control the y-label of the graphic.  )\nClosing parenthesis for the labs function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nGallery\nSee what past students have done…\nClick to view.\n\nHover to see code.\n \n ggplot(data = mtcars, aes(x = as.factor(cyl), y = mpg, fill=as.factor(cyl))) +  geom_boxplot()  +  stat_summary(fun.y = mean, geom = \"errorbar\", aes(ymax = ..y.., ymin = ..y..),     width = .75, linetype = \"dashed\", color=\"firebrick\") +  theme_light() +  theme(panel.grid.major=element_blank()) +  scale_fill_brewer(palette=\"Dark2\") +  geom_jitter(width=0.1, height=0) +  labs(title = \"Miles Per Gallon Based on Cylinders\",     x=\"Number of Cylinders\",     fill=\"Cylinders\",     y=\"Miles Per Gallon\")   \n \n ggplot(data = ToothGrowth, aes(x = as.factor(dose), y = len, fill=as.factor(dose))) +  geom_boxplot( )  +  facet_wrap(~supp) +  theme_bw() +  scale_fill_manual(values=c(\"#999999\", \"#E69F00\", \"#56B4E9\")) +  geom_jitter(width=0.1, height=0) +  labs(title = \"Tooth Length Based on Doses     According to Supplement Type\",     fill=\"Doses\",     x=\"Dosage Amount(mg)\",     y=\"Tooth Length\" )   \n\n\n\n\n\nTo make a histogram in plotly first load\nlibrary(plotly)\nThen, use the function:\nplot_ly(dataName, y=~columnNameY, x=~columnNameX, type=\"box\")\n\ndataName is the name of a data set\ncolumnNameY must be the name of a column of quantitative data. R refers to this as a “numeric vector.” This will become the y-axis of the plot.\ncolumnNameX must be the name of a column of qualitative data. This will provide the “groups” forming each individual box in the boxplot.\ntype=\"box\" tells the plot_ly(…) function to create a boxplot.\n\nVisit plotly.com/r/box-plots for more details.\n\nExample Code\nHover your mouse over the example codes to learn more. Click on them to see what they create.\nBasic Boxplot\n\n\n plot_ly An R function “plot_ly” from library(plotly) used to create any plotly plot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality,  “airquality” is a dataset. Type “View(airquality)” in R to see it.  y= The y= allows us to declare which column of the data set will become the y-axis of the boxplot. In other words, the quantitative data we are interested in studying for each group.  ~Temp,   “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset. The ~ is required before column names inside all plot_ly(…) commands.  x= The x= allows us to declare which column of the data set will become the x-axis of the boxplot. In other words, the “groups” forming each separate box in the boxplot.  ~as.factor(Month),   since “Month” is a quantitative variable (numeric vector) from the “airquality” dataset we have to change it to a “factor” which forces R to treat it as a qualitative (groups) variable. The ~ is required before column names inside all plot_ly(…) commands.  type=“box” This option tells the plot_ly(…) function what “type” of graph to make. In this case, a boxplot.  )\nClosing parenthesis for the plot_ly function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nChange Color\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”,  This code was explained in the first example code.  fillcolor=“skyblue”,  this changes the fill color of the boxes in the boxplot to the color specified, in this case “skyblue.”  line=list(color=“darkgray”, width=3),  this “list(…)” of options that will be specified will effect the edges of the boxes in the boxplot. We are changing their color to “darkgray” and their width to 3 pixels wide.  marker=list( this “list(…)” of options that will be specified will effect the outlying dots shown in the boxplots beyond the “fences” of each box.  color = “orange”,  this will change the color of the dots to orange.  line = list(,  this opens a list of options to specify for the “lines” around the “markers.”  color = “red”,  this will change the color of the lines around the outlier dots to red.  width = 1 this will change the width of the lines around the outlier dots to 1 pixel.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nAdd Titles\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”, fillcolor=“skyblue”, line=list(color=“darkgray”, width=3), marker = list(color=“orange”, line = list(color=“red”, width=1)))  This code was explained in the above example code.  %>% the pipe operator sends the completed plot_ly(…) code into the layout function.  layout( The layout(…) function is used for specifying details about the axes and their labels.  title=“La Guardia Airport Daily Mean Temperatures” This declares a main title for the top of the graph.  xaxis=list( This declares a list of options to be specified for the xaxis. The same can be done for the yaxis(…).  title=“Month of the Year” This declares a title underneath the x-axis.  ),  Functions always end with a closing parenthesis.  yaxis=list( This declares a list of options to be specified for the y-axis.  title=“Temperature in Degrees F” This declares a title beside the y-axis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding how a boxplot is created is the best way to understand what the boxplot shows.\n\nHow Boxplots are Made\n\nThe five-number summary is computed.\nA box is drawn with one edge located at the first quartile and the opposite edge located at the third quartile.\nThis box is then divided into two boxes by placing another line inside the box at the location of the median.\nThe maximum value and minimum value are marked on the plot.\nWhiskers are drawn from the first quartile out towards the minimum and from the third quartile out towards the maximum.\nIf the minimum or maximum is too far away, then the whisker is ended early.\nAny points beyond the line ending the whisker are marked on the plot as dots. This helps identify possible outliers in the data.\n\n\n\n\n\n\n\n\n\nScatterplot, with Means\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nScatterplots of a catgorical variable on the x axis and quantitative variable on the y axis are sometimes called strip charts, or side-by-side strip charts. When sample sizes are not too big and there are not too many repeated value this type of chart is an excellent way to see the variability in the data without the abstraction of a boxplot. By plotting individual observations you also can see the size of the sample for each factor level. Including factor level means on the plot adds additional insight. The mean of each factor level is often connected with a line for visual impact.\n\n\n\n\nmosaic ggplot2 plotly\n\n\n\nTo make a scatterplot use the function:\nxyplot(y~x, data = mydata)\n\ny is the quantitative response variable, i.e., “numeric vector.”\nx is the independent, explanatory variable\nmydata is the name of the dataset containing y and x.\n\nThis will return a scatterplot regardless of how your x variable is stored in R (numeric, character, factor). This function is flexible and with minimal effort can include averages or make an interaction plot. xyplot() is a part of the lattice package, which is loaded when the mosaic package is loaded.\nNote: plot() from base R will also give a scatterplot, but only if the x variable is quantitative. If x is a character or factor variable the default is to return a boxplot plot.\nExample Code\nBy reading the documentation for the dataset (visible when ?ToothGrowth is run in the console) we can see that our “x” variable, “dose”, is a numeric variable in R. Because of this the x-axis maintains the relative distance of doses on the x-axis.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nIf you start with a numeric x variable, you may or may not want to convert it to a factor variable. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed. Compare the output of the previous example code with this example code. This example code converts our x variable of “dose” to a factor variable.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nTo include the means on the plot and connect them with a line use this code\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  , \nThe “,” is required to start specifying additional commands for the function.  type =\nThe type argument allows you to add different types of lines to the plot. Run ?panel.xyplot() to read more about values for this argument  c( Combines the following values into one vector. This allows me to pass multiple values as one input to “type =”. Useful for if I want to plot something in addition to the default of plotting points.  ‘p’\nThis requests the points to be plotted. It is the default value. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  , \nThe “,” is required to start specifying additional commands for the function.  ‘a’ This requests the average for each factor level to be connected with a line. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a scatterplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_point()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_point() causes the ggplot to become a scatterplot; or in other words to draw points to represent data.\n\n\nExample Code\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n If you start with a numeric x variable, you may or may not want to convert it to a factor variable. You do this by using ‘factor(x)’ instead of just ‘x’ as shown below. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed.\nggplot(ToothGrowth, aes(x = factor(dose), y = len)) +   geom_point(color = \"blue\")\nAdding averages to the plot and connecting them with a line requires a little more effort and is demonstrated in the code below. I also add some more descriptive labels to the chart.\nNote the use of stat_summary to indicate I want to add a layer that plots a numerical summary, not the original data. Some geoms have stat summaries built in to them (like geom_bar or geom_boxplot), but in our case we have to define the summary.\nIn the stat_summary I provide additional arguments to the aesthetics helper function. Defining the aesthetics in ggplot() is like a global definition, all additional layers inherit those aesthetic mappings. Defining them in a geom_* or a stats_* allows you to add to or override what was defined in ggplot() for that layer only. The group aesthetic is required in order to use a line geometry. In this case, group could just as easily have been defined in ggplot(aes()).\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_point( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.   + The addition symbol + is used to add further elements to the ggplot.    stat_summary( This function will calculate a statistical summary to be plotted on the chart  fun = mean, fun is short for function. The summary function I want to apply to my y variable is “mean”.  geom = “line”, The “geom=” argument is used to tell what kind of geometry should be drawn to represent the means. Here we are asking for the means to be connected with a line.  aes( The aes or “aesthetics” function allows you to tell ggplot what variables should be mapped to what visual aspects of the chart; including what the x-axis or y-axis should become. Including it her means the aesthetic will only be applied to this layer.  group = 1 indicates which variable should be grouped by when drawing multiple lines (one line for each factor level). We write the number 1 to indicate there is just 1 group; we are not further splitting the data.  )\nClosing parenthesis for the geom_boxplot function.  )\nClosing parenthesis for the geom_boxplot function.   + The addition symbol + is used to add further elements to the ggplot.    labs( Function to edit labels of the plot  x = “Vitamin C mg/day”, Edit the x-axis label  y = “Length”, Edit the y-axis label  title = “Tooth Growth in Guinea Pigs” Edit the chart title  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nUnder construction.\n\n\n\n\n\n\n\n\n\nInteraction Plot\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nThese plots are used to visualize two categorical factors (mapped to the x-axis and the line color/type) and a quantitative response variable (displayed on the y-axis). A point for each factor level combination mean is plotted, and then points are connected with lines to aid the visual interpretation of the plot. Because they show two factors, they are ideal for two-way ANOVA.\nInteraction plots are a great way to see factor effects. In particular, they can be helpful in understanding the nature of an interaction factor, or detecting the lack thereof. If the line segments in the plot are all (nearly) parallel, this is indicative that no interaction effect exists between the two factors. The more non-parallel the line segments, the more likely a significant interaction effect is present.\nA formal hypothesis test should be conducted to determine the significance of an interaction term, since sometimes the hypothesis test result can run counter to what a quick visual inspection might suggest. When a significant interaction is present, an interaction plot can be a critical part of understanding the nature of the interaction.\nIf there are three factors in a study, multiple interaction plots can be used (one at each value of the third factor) to explore the nature of two-way and three-way interactions. This approach can be extended for analyses involving more than 3 factors. However, interactions involving more than 3 variables are rare in practice. Therefore, if more than 3 factors are present in an analysis, interaction plots are not usually used as an exploratory tool. Instead, statistical tests are used to find significant interactions, and then interaction plots are used to describe the nature of those interactions.\n\n\n\n\nBase R ggplot2 plotly\n\n\n\nTo make a scatterplot use the function:\ninteraction.plot(mydata$factor_x, mydata$factor_line, mydata$response)\n\nmydata is the name of the dataset containing the factors and response.\nfactor_x is factor (or string) variable that will be plotted on the x-axis\nfactor_line is factor (or string) variable that will have different colored/types of lines on the plot\ny is the quantitative response variable, i.e., “numeric vector.”\n\nNote, unlike the other plotting we have done so far, there is no data = argument. Each variable must be specified using the $ notation if it exists inside a dataset. There are many additional arguments to specify colors, line types, legend formatting, etc.\nExample Code\nBy reading the documentation for the dataset (visible when ?ToothGrowth is run in the console) we can see that our “x” variable, “dose”, is a numeric variable in R. Because of this we convert it to a factor variable in the plot command with the factor() command. This changes the nature of dose only within that particular plot, not within the dataset generally.\n\n\n\n interaction.plot( An R function used to create an interaction plot  factor( A function to make a variable categorical.  ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  ) parenthesis to close the factor function  , separate arguments to a function with commas  ToothGrowth Name of the dataset that contains the variables.  $ The $ allows you to refer to a variable in a dataset by name  supp a different line will be drawn for each value of supp  , separate arguments to a function with commas   ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  len name of the response variable in ToothGrowth  , separate arguments to a function with commas ylab= argument to specify y-axis label  “Tooth length” Label for the y-axis must be put in quotes  ,  separate arguments to a function with commas  xlab= argument to specify x-axis label  “Dose (vitamin C mg/day)” Label for the x-axis must be put in quotes  , separate arguments to a function with commas  trace.label= argument to specify the trace label which will appear in the legend  “Delivery Method” Label for the trace factor must be put in quotes  , separate arguments to a function with commas  main= argument to specify the chart title  “Tooth Growth in Guinea Pigs” Chart title must be put in quotes  ) parenthesis to close the interaction.plot function      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\nBecause not all the line segments are parallel, you may begin to suspect an interaction is present. To determine if the interaction is significant you can do a hypothesis test for.\nNote, an easy/slick method for changing the legend position does not (currently) exist for interaction.plot(), though some hacked solutions can be used.\nYou can adjust things like line color, plotting points, etc. as shown in this next example.\n\n\n\n interaction.plot( An R function used to create an interaction plot  factor( A function to make a variable categorical.  ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  ) parenthesis to close the factor function  , separate arguments to a function with commas  ToothGrowth Name of the dataset that contains the variables.  $ The $ allows you to refer to a variable in a dataset by name  supp a different line will be drawn for each value of supp  , separate arguments to a function with commas   ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  len name of the response variable in ToothGrowth  , separate arguments to a function with commas ylab= argument to specify y-axis label  “Tooth length” Label for the y-axis must be put in quotes  ,  separate arguments to a function with commas  xlab= argument to specify x-axis label  “Dose (vitamin C mg/day)” Label for the x-axis must be put in quotes  , separate arguments to a function with commas  trace.label= argument to specify the trace label which will appear in the legend  “Delivery Method” Label for the trace factor must be put in quotes  , separate arguments to a function with commas  main= argument to specify the chart title  “Tooth Growth in Guinea Pigs” Chart title must be put in quotes  , separate arguments to a function with commas  type=\nargument to specify whether lines, points, or both should be plotted  ‘b’ b, in quotes, indicates lines and points should be drawn on the plot  , separate arguments to a function with commas   pch=\nargument to specify shape of the points  16 an integer value from 0 to 25 is expected.   , separate arguments to a function with commas  lty=\nargument to specify line type.   1 1 for a solid line. Line type can be specified with an integer from 0 - 6, or text “solid”.  , separate arguments to a function with commas  col=\nargument to specify colors to be used for different values of the trace factor, supp  c( concatenate function used to create a vector  “darkblue” color to be used for first value of supp. Can be given in name form, integer, or rgb specs  ,\nseparate values in a vector with a comma   “deeppink3” color to be used for first value of supp. Can be given in name form, integer, or rgb specs  ) end the vector with a parenthesis  ) parenthesis to close the interaction.plot function      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make an interaction plot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=factor1, color=factor2, group=factor2, y=response) +\n  stat_summary(fun = mean, geom = \"line\")\n\ndata is the name of your dataset.\nfactor1 is a column of data from your dataset that is a qualitative factor whose values you want to plot along the x-axis.\nfactor2 is a column of data from your dataset that is a qualitative factor. You want to draw a different colored line for each value of this factor.\nresponse is the name of the quantitative response variable in your dataset.\nThe aesthetic helper function aes() is how you tell R which variables you want mapped to which aesthetics (i.e. visual attributes) of your chart. This is actually the input to the mapping= argument, but for conciseness mapping= is usually not typed out.\n\nThe group aesthetic indicates that any summary statistics that are calculated should be calculated separately for each value of factor2. It’s similar to a group_by() statement.\nBecause factor2 is also the value for color, each value of factor2 will be represented with a different color.\n\nstat_summary() does two things:\n\ncalculates a summary statistic. In this case we tell it to calculate the mean for each factor level combination with the fun = mean code. fun stands for “function”.\nindicates we want to connect the means with a line. geom stands for our desired geometry, in this case lines.\n\n\nNote if one of your factor variables is not coded as a factor (e.g. it is numeric), use factor() to convert it to the correct data type.\n\nHere is a basic interaction plot using ggplot2 package. In a later example we will add additional formatting, labels, etc.\n\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function is actually an input to the mapping= argument. It allows you to which variable is mapped to aspects of the chart. This includes things like what the x-axis or y-axis should become.  x= “x=” declares which variable will become the x-axis of the graphic.  factor(dose), factor converts dose, a numeric variable, into a categorical variable  color=supp,  declares that each value of supp will be represented with a different color  group=supp,  declares that each value of supp must be drawn separately. We specify the geometry to be drawn later with geom.  y=len declares which variable will become the y-axis of the graphic.  )) close the aes and ggplot functions with a parenthesis   + The addition symbol is used to add/tweak chart elements.    stat_summary( this adds a layer to the chart that will show summary statistics  fun = mean,  “mean” is the function used to get a summary statistic  geom=“line” The geometry used on the chart will be lines  ) parenthesis to close the stat_summary function      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\nAdd different line types, points for each factor level mean, and improved labelling\nLook at the code below and notice that with the exception of the group aesthetic, a label is applied to each aesthetic mapping. linetype and color have the same label and R is smart enough to therefore combine the legend for these two aesthetic mappings into one legend. If the labels are not identical, each aesthetic will have a unique legend.\n\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function is actually an input to the mapping= argument. It allows you to which variable is mapped to aspects of the chart. This includes things like what the x-axis or y-axis should become.  x= “x=” declares which variable will become the x-axis of the graphic.  factor(dose), factor converts dose, a numeric variable, into a categorical variable  color=supp,  declares that each value of supp will be represented with a different color  group=supp,  declares that each value of supp must be drawn separately. We specify the geometry to be drawn later with geom.  linetype=supp,  declares that each value of supp will be represented with a different line type  y=len declares which variable will become the y-axis of the graphic.  )) close the aes and ggplot functions with a parenthesis   + The addition symbol is used to add/tweak chart elements.    stat_summary( this adds a layer to the chart that will show summary statistics  fun=mean,  “mean” is the function used to get a summary statistic  geom=“line”,  The geometry used on the chart will be lines  size=1 Change the line thickness  ) parenthesis to close the stat_summary function   + The addition symbol is used to add/tweak chart elements.    stat_summary( this adds a layer to the chart that will show summary statistics  fun=mean,  “mean” is the function used to get a summary statistic  geom=“point”,  The geometry used on the chart will be points  size=3 Change the size of the points  ) parenthesis to close the stat_summary function   + The addition symbol is used to add/tweak chart elements.    labs( use this layer to change chart labels  x=“Vitamin C dose (mg/day)”, Put the x-axis label in quotes     y=“Tooth Length”, Put the x-axis label in quotes     title=“Guinea Pig Study”, Put the chart title in quotes     color=“Delivery Method”, Put the color label in quotes     linetype=“Delivery Method” Put the linetype label in quotes  ) Close labs with a parenthesis      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nUnder construction."
  },
  {
    "objectID": "diagnostics.html",
    "href": "diagnostics.html",
    "title": "Model Diagnostics",
    "section": "",
    "text": "A key assumption for ANOVA tests is that the error, or residual term, has a constant variance across all factor levels. This is sometimes call homogeneity of variance, or homoscedasticity.\nWe explain three ways to check the assumption: rule of thumb when comparing standard deviations for each factor level, a visual assessment of the residual vs. fitted plot, and Levene’s test. These methods may not always agree. You should be aware of the underlying data. Understanding why this assumption is important and how it will affect results when violated will help you decide how to proceed after checking these diagnostics. It is also worth noting that the ANOVA F-test is robust in the face of mild to moderate violation of this assumption.\nWe will use the pre-loaded dataset ToothGrowth. To learn more about the dataset, run ?ToothGrowth in the console. len will be our response variable, supp is an independent factor, and dose is the other independent factor. We will analyze this a two-way, basic factorial design. Because dose is stored as a numeric variable, we will convert it to a categorical variable and rename it dose_f before including it in the model. Don’t forget to load the tidyverse in order to use mutate().\n\n\n tg The name you want for your modified dataset  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  ToothGrowth A preloaded dataset in R  |> The result on the left is piped into the first argument of the function on the right  mutate( A tidyverse function to compute a new column for a dataset  dose_f = The name you want to give to the new column  factor( A function to convert a variable from numeric to quantitative  dose A numeric variable in ToothGrowth  )) Functions always end with a closing parenthesis  aov2th A name you come up with for your model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  len The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  dose_f Column in the tg dataset where doese is stored as a factor  * Crosses two factors. Both simple factors and the interaction factor are included in the model   supp variable with 2 levels of delivery method: orange juice or asorbic acid (vc)  , Seperates multiple input arguments to a function.  data = tg Tell the model that the variable names come from the tg dataset  ) Functions always end with a closing parenthesis \n\n\n\n\n\n\n\n\n\n\nA quick rule of thumb to check this assumption is to compare standard deviations across factor levels. If the largest standard deviation is no more than double the smallest standard deviation, then the standard deviations (and the variances) are close enough to be considered equal. Check the R Instructions>Describing Data>Numerical Summaries section of the textbook on how to calculate standard deviations for each factor level.\nIn cases with more than 1 factor, you can compare the standard deviation of each factor level combination (i.e. the interaction factor). Sometimes though, looking at the interaction results in a very small sample size at each level or you may be concerned about a particular factor level of an experimental factor. In that case you may want to apply this rule of thumb to each factor individually. When faced with a situation where the rule of thumb is met for some factors but not for others use your best judgement. An understanding of how a violation may affect your results is critical. You can see that this approach can be tricky to implement, especially as you go beyond studies with just two factors.\n\n\n\nAnother informal approach to checking the constant variance assumption is looking at a residual vs. fitted plot. Similar to the rule of thumb, in situations with more than 1 factor, you can either create a plot that shows all factor level combinations OR look at multiple plots, one for each experimental factor. In order to view this plot, you must first create the ANOVA model. Once the model is created, there are a couple of ways to get a residual vs. fitted plot.\nConstruct the plot manually from vectors within the aov object\nThe plot can be constructed using the vector of residuals and vector of fitted values contained in the aov object.\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\nplot(myaov$fittedvalues, myaov$residuals)\n\nNote: If you want to know all the named items in an R object, you can run names(object). In this case we have an aov object called myaov. To see what it contains we can run names(myaov) in the console.\nExample code:\n\n\n\n plot( Base R function to create a scatterplot  aov2th$  Look in the aov2th object for the item named on the right of the $  fitted.values  This vector, stored in the aov object, contains the fitted, or predicted, values.  , Seperates multiple input arguments to a function  aov2th$ Look in the aov2th object for the item names on the righ tof the $  residuals Vector in the aov object that contains model residuals  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\nNote the resulting plot show 6 vertical groupings, one for each factor level combination. (3 does levels x 2 levels of supp = 6 factor level combinations) ::: {.cell} ::: {.cell-output-display}  ::: :::\n\n\nConstruct the plot with a shortcut\nWhen the function plot() is called on an aov object, 4 diagnostic plots are produced. Instead of viewing all four, chose which ones to see with the which= argument. The first of the four plots is the residual vs. fitted plot.\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\nplot(myaov, which = 1)\n\nExample code:\n\n\n\n plot( Base R function, when fed an aov object it produces 4 diagnostic plots  aov2th,  The aov object for our model  which = Which of the four diagnostic plots do we want  1 The first of the 4 plots is the residual vs. fitted plot  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\nIgnore the red line on the plot. It does not measure variance and so can be distracting. ::: {.cell} ::: {.cell-output-display}  ::: :::\n\n\n\n\n\nLevene’s test is a formal hypothesis test to determine if the variances are equal. In essence, this is an ANOVA F-test comparing sample variances across factor levels (as opposed to comparing sample means). A large p-value for the test indicates there is insufficient evidence to conclude one of the variances is different; and therefore the assumption of constant variance is met.\nThis test comes in handy when there are multiple factors in a study and it is burdensome to informally evaluate all their factor level combinations.\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\ncar::leveneTest(myaov)\n\nExample code:\n\n\n\n car Levene’s test comes from the car package.   :: Allows you to reference functions from the package named on the left without having to load the entire package.  leveneTest( function to run Levene’s test  aov2th name of the aov object to run the test on  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  5  1.7086 0.1484\n      54"
  },
  {
    "objectID": "diagnostics.html#normal-distribution",
    "href": "diagnostics.html#normal-distribution",
    "title": "Model Diagnostics",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nAnother key assumption for ANOVA tests is that the error, or residual, term follows a normal distribution. We use the Q-Q plot to check this assumption. There are two ways to create the Q-Q plot.\nWe will continue to use the aov2th model that was created at the beginning of the Constant Variance section.\nConstruct the Q-Q plot with a shortcut\nWhen the function plot() is called on an aov object, 4 diagnostic plots are produced. Instead of viewing all four, chose which ones to see with the which= argument. The second of the four plots is a normal Q-Q plot.\nExample code:\n\n\n\n plot( Base R function, when fed an aov object it produces 4 diagnostic plots  aov2th,  The aov object for our model  which = Which of the four diagnostic plots do we want  2 The second of the 4 plots is the normal Q-Q plot  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\n\n\n\n\n\nThe advantage of this method is that you can easily get the residual vs. fitted plot and the normal Q-Q plot with one command by providing the which = argument a vector containing the values 1 and 2. (The : is shorthand to create a vector that starts at the value of the left of the : and increments by 1 until reaching the value on the right side of the :.)\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\nplot(myaov, which = 1:2)\n\nThe disadvantage of this method is that it can be difficult to determine if the points follow the line closely enough. To help with this decision, you may prefer to use the Q-Q plot from the car package.\nConstruct the Q-Q plot from the car package\nThe Q-Q plot from the car package provides boundary lines. When points are out of the boundaries that is evidence that the normal residual assumption is violated.\nYou can customize the way the acceptable region for points is designated. The default is shading a region. Below is code to draw dashed-line boundary.\nExample code:\n\n\n\n car qqPlot comes from the car package.   :: Allows you to reference functions from the package named on the left without having to load the entire package.  qqPlot( function to a Q-Q plot from the car package  aov2th, name of the aov object  envelope = Argument to control the formatting for the acceptable region for points  list( There are potentially many arguments to affect the envelope, so they are provided as a list.  style = “filled” shading, boundary “lines”, or none  “lines” designate the acceptable region with lines  )) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\n\n\n\n[1] 32 49"
  },
  {
    "objectID": "diagnostics.html#independent-errors",
    "href": "diagnostics.html#independent-errors",
    "title": "Model Diagnostics",
    "section": "Independent Errors",
    "text": "Independent Errors\nAn order plot can serve as a partial check of the assumption that the residuals are independent. If there are patterns/trends in the plot that may be grounds to say the assumption is violated.\nThe plot assumes that the dataset is sorted in the same order the data was recorded. If the data has been re-sorted or is from an observational study (i.e. the chronology of collection is unknown or irrelevant) the order plot does not make sense as a check of independence.\nExample code:\n\n\n\n plot( A function to plot the data  aov2th Name you gave your model  $ Access a named object within an object  residuals residuals of the model  ) Functions always end with a closing parenthesis  Toggle output Toggle Output."
  },
  {
    "objectID": "effects_model.html",
    "href": "effects_model.html",
    "title": "Effects Model",
    "section": "",
    "text": "In science, statistics, mathematics, etc. we are interested in discovering and describing truth about the world we live in. We can use models to represent a phenomenon or system. The model’s purpose may be to describe and explain something about the way things work and/or to make prediction. An ANOVA model is a model that uses mathematical terms and constructs, in the form of an equation. The ANOVA model quantifies the relationship between factor(s) and a response.\nIf we were able to observe all items in a population we would be able to quantify with exactness how a factor variable is related to a response variable with an ANOVA model. This “true”, or exact quantification of how the two variables relate is called a parameter. However, with rare exceptions, we cannot observe every item in a population. Instead, we must rely on a sample to calculate estimates of the parameter.\nBy the end of this section you should know how to interpret the terms in an ANOVA model (i.e. know what they mean), and also perform the calculations necessary to estimate ANOVA model parameters.\n\n\n\nConsider an experiment conducted to test 4 different types of toothbrushes: manual, oscillating, sonic and ultrasonic. The response variable is percent of area on teeth that has plaque. Twenty-four individuals participate in the experiment, yielding 6 observations per treatment. We will discuss the creation of an ANOVA model using the context of this specific example. In this section and “Calculating Effect Sizes” section we will be referring to estimates of model parameters using this sample data.\nUp to this point we have primarily been interested in calculating means in order to compare toothbrushes. If the mean percent of teeth surface area with plaque was 23.09 for a manual brush, you would not know how that value compares to the other types of brushes.\nA graph or table reporting the other sample means would be necessary to provide context. Figure 1 depicts the data points and the mean for each factor level.\n\n\n\n\n\n\n\n\nFigure 1: Brush means and grand mean\n\n\n\n\nIn an earlier, introductory statistics class you most likely learned how to use sample means in order to test whether populations means for different groups are equal using analysis of variance (ANOVA). This hypothesis test of multiple population means is valid and works when you only have 1 factor. (The factor is the variable that defines the groups.) However, it is limited in its ability to include more factors or more complicated designs.\nThere is another metric we use to compare factor levels: the effect size. Reporting the effect of a factor level has the benefit of providing some context on how that factor level is influencing the response variable relative to other levels of the same factor. Using effect sizes (as opposed to factor level means) allows us to model and test much more complicated scenarios than a simple one factor experiment.1"
  },
  {
    "objectID": "effects_model.html#assembly-line-metaphor",
    "href": "effects_model.html#assembly-line-metaphor",
    "title": "Effects Model",
    "section": "Assembly Line Metaphor",
    "text": "Assembly Line Metaphor\nYou can imagine that each data point in your data set is created by going down an assembly line, much like you would find in a factory that makes cars or appliances. All points start with the grand mean value. As it progresses through the assembly line the data point is altered to reflect the effect of the factor levels it belongs to.\n\n\n\n\n\n\nIn the toothbrush and toothpaste experiment all the points start the assembly line at the same value: the grand mean of the data set. The first station on the line receives the data point and adds or subtracts to it based on the type of brush it is. For example, the value would be added upon if the brush type was “manual” because the mean plaque percentage for the manual type was higher than the grand mean. The next station alters the value depending on which toothpaste was used: off-brand or name brand. After going through each station (one station for each factor) in the assembly line the data point arrives at the last station.\nThe last station is worked by a person who makes random adjustments! Some adjustments will be big, and some will be small; some will be positive, and some will be negative. (In a typical factory this person would be fired. But we would rather have randomness than unknown, systematic adjustments , i.e. bias). These random adjustments are driven by any/all factors that we did not explicitly measure.\nFor example, variability in the experimental unit’s diet, hardness of the water used when brushing, the impact of flossing, outside temperature, and the price of rice in China are all factors that were not taken into account. Effects from these and an infinite number of other factors are all lumped into the residual error factor effects. The effects of factors unrelated to the response should be negligible. Effects from other factors that were sufficiently randomized should usually cancel each other out. The point is that all these factor’s effects show up in one (hopefully small) adjustment at the last station and are referred to as “unexplained variance” (review Sources of Variance).\nThough the adjustments at this last station for residual error are (assumed) random, they do follow a pattern. Namely, the mean of the adjustments is zero and they follow a normal distribution."
  },
  {
    "objectID": "examples/mosquito.html",
    "href": "examples/mosquito.html",
    "title": "Mosquitos",
    "section": "",
    "text": "Code\nlibrary(mosaic)\nlibrary(DT)\nlibrary(pander)\nlibrary(car)\nlibrary(tidyverse)\n\n## Data from original article:\nmosquito <- read_csv(\"../data/mosquito_patch.csv\")"
  },
  {
    "objectID": "examples/mosquito.html#background",
    "href": "examples/mosquito.html#background",
    "title": "Mosquitos",
    "section": "Background",
    "text": "Background\nFive pre-treated patches were compared to to see which material did the best in reducing mosquito human contact for the Armed Forces in India. The five treatments included Odomos(1), Deltamethrin (2), Cyfluthrin(3), D+O(4), C+O(5) Each of the treatments included 30 replicates per treatment\nSource: A. Bhatnagar and V.K. Mehta (2007). “Efficacy of Deltamethrin and Cyfluthrin Impregnated Cloth Over Uniform Against Mosquito Bites,” Medical Journal Armed Forces India, Vol. 63, pp. 120-122"
  },
  {
    "objectID": "examples/mosquito.html#analysis",
    "href": "examples/mosquito.html#analysis",
    "title": "Mosquitos",
    "section": "Analysis",
    "text": "Analysis\nApplying a one-way ANOVA to this study, we have the following model:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\nWhere \\(y_{ij}\\) is the \\(j^{th}\\) observation from treatment \\(i\\)\n\\(\\mu\\) is the grand mean of the dataset.\n\\(\\alpha_i\\) is the effect of the treatment as described in the background.\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. Since there are 30 subjects for each treatment, \\(j\\) ranges from 1 to 30.\nApplying a one-way ANOVA to this study, we have the null hypothesis that the effect of human mosquito contact, represented by α, is equal for each of the factors. This is formally written as follows. \\[ H_0:\\alpha_\\text{Odomos} = \\alpha_\\text{Deltamethrin} = \\alpha_\\text{Cyfluthrin} = \\alpha_\\text{D+O} = \\alpha_\\text{C+O} = 0 \\] The alternative hypothesis states that at least one of the effects due to material is different than zero \\[ H_a: \\text{at least one } \\alpha \\text{ is different than 0} \\] Using these hypotheses will allow for us to address the question whether any of the materials are better at minimizing mosquito-human contact.\n\nHypothesis test\nWe will use a level of significance of α = 0.05 for the analysis.\nFor the analysis, we perform the following one-way ANOVA\n\n\nCode\nmosquito <- mosquito %>% \n   mutate(\n         Treatment = case_when(\n           trt.mosq %in% 1  ~ \"Odomos\",\n           trt.mosq %in% 2  ~ \"Deltamethrin\",\n           trt.mosq %in% 3  ~ \"Cyfluthrin\",\n           trt.mosq %in% 4  ~ \"D+O\",\n           trt.mosq %in% 5  ~ \"C+O\"\n          )\n        )\n\nmosquito.aov <- aov(y.mosq ~ Treatment, data=mosquito)\nsummary(mosquito.aov) %>% pander()\n\n\n\nAnalysis of Variance Model\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(>F)\n\n\n\n\nTreatment\n4\n184.6\n46.16\n4.48\n0.001924\n\n\nResiduals\n145\n1494\n10.3\nNA\nNA\n\n\n\n\n\nThe p-value for this test is significant (p = 0.001924). Based on this result, the null hypothesis is rejected and we have sufficient evidence that at least one of the effects due to material is different for human mosquito contact.\nThe requirements of equal variances for ANOVA is met. This is shown by the residual versus fitted plot, which shows roughly a constant variance within each vertical group of dots. The QQ-plot of residuals on the right shows some non-normality as evidenced by some of the points outside of the dashed line boundaries. However, it is not severe and we will move forward with the analysis.\n\n\nCode\npar(mfrow=c(1,2))\nplot(mosquito.aov, which=1, pch=16)\nqqPlot(mosquito.aov, id=FALSE)\n\n\n\n\n\nThe following plot shows which types of material minimize the human mosquito contact.\n\n\nCode\nboxplot(y.mosq ~ as.factor(Treatment), data=mosquito, main=\"Human Mosquito Contact Based on Type of Material\", xlab =\"Treatment\", ylab = \"Amount of Mosquito Human Contact\")\n\n\n\n\n\nThe averages are illustrated with the blue line in the plot above and the table below shows the means, standard deviations, and sample sizes for each of the five different materials.\n\n\nCode\nfavstats(y.mosq ~ Treatment, data=mosquito) %>% \n  select(Treatment,mean,sd,n) %>% \n  arrange(mean) %>% \n  pander()\n\n\n\n\n\n\n\n\n\n\n\nTreatment\nmean\nsd\nn\n\n\n\n\nC+O\n5.367\n3.068\n30\n\n\nD+O\n6.333\n3.121\n30\n\n\nOdomos\n7.901\n3.366\n30\n\n\nCyfluthrin\n8.033\n3.01\n30\n\n\nDeltamethrin\n8.133\n3.46\n30\n\n\n\n\n\n\n\nPairwise comparisons\nWe now that smallest mean (C+O) must be different than the largest mean (Deltamethrin) because the F-test was significant above. In order to better understand which treatments perform better than which other treatments we will look at all pairwise comparisons and apply Tukey’s correction to the family error rate.\n\n\nCode\n#This code would work, but...\n# TukeyHSD(mosquito.aov, \"Treatment\")\n\n#I want to do this fancy stuff below to sort the output\nTukeyHSD(mosquito.aov, \"Treatment\")$Treatment %>% \n  as_tibble(rownames = \"id\") %>% \n  arrange(`p adj`) %>% #Have to put the column name in back ticks since it has a space\n  pander() \n\n\n\n\n\n\n\n\n\n\n\n\nid\ndiff\nlwr\nupr\np adj\n\n\n\n\nDeltamethrin-C+O\n2.766\n0.4764\n5.056\n0.009359\n\n\nCyfluthrin-C+O\n2.666\n0.3761\n4.955\n0.01367\n\n\nOdomos-C+O\n2.534\n0.2441\n4.823\n0.02204\n\n\nDeltamethrin-D+O\n1.8\n-0.4899\n4.089\n0.1965\n\n\nD+O-Cyfluthrin\n-1.699\n-3.989\n0.5902\n0.2477\n\n\nOdomos-D+O\n1.567\n-0.7222\n3.857\n0.3268\n\n\nD+O-C+O\n0.9663\n-1.323\n3.256\n0.7707\n\n\nOdomos-Deltamethrin\n-0.2323\n-2.522\n2.057\n0.9986\n\n\nOdomos-Cyfluthrin\n-0.132\n-2.422\n2.158\n0.9999\n\n\nDeltamethrin-Cyfluthrin\n0.1003\n-2.189\n2.39\n1\n\n\n\n\n\nC+O is significantly lower than 3 of the treatments at the 0.05 level; and no other treatment has a sample mean lower than C+O’s."
  },
  {
    "objectID": "examples/mosquito.html#interpretation",
    "href": "examples/mosquito.html#interpretation",
    "title": "Mosquitos",
    "section": "Interpretation",
    "text": "Interpretation\nIt appears the the best type of material is the C+O material to minimize the amount of mosquito human contact. The lowest mean came from the C+O material where the average amount of mosquito/human contact was 5.367. With a mean of 6.333, D+O was not significantly different than C+O and could also be an option. Conducting a new experiment that focuses on the difference between C+O and D+O and gives them a larger sample size in order to better detect significant would be reasonable.\nA future study could look into other types of material as well as doing this analysis at different locations throughout the world."
  },
  {
    "objectID": "examples/VirtualTrain.html",
    "href": "examples/VirtualTrain.html",
    "title": "Lifeboat Launch Training Methods",
    "section": "",
    "text": "Code\nlibrary(mosaic)\nlibrary(DT)\nlibrary(pander)\nlibrary(car)\nlibrary(tidyverse)\n\n## Data from original article:\nvirtual <- read.csv(\"../data/virtual_training.csv\", header=TRUE)"
  },
  {
    "objectID": "examples/VirtualTrain.html#background",
    "href": "examples/VirtualTrain.html#background",
    "title": "Lifeboat Launch Training Methods",
    "section": "Background",
    "text": "Background\nAn experiment was done to help train people in the procedure to launch a lifeboat. This was a Completely Randomized Design with 16 subjects per treatment, for a total of 64 subjects. The response variable is the performance on a procedural knowledge test. The treatments included: Lecture/Materials (Control) (1), Monitor/Keyboard (2), Head Monitor Display/Joypad (3), and Head Monitor Display/Wearables (4)\nSource: J.Jung and Y.J. Ahn (2018). “Effects of Interface on Procedural Skill Transfer in Virtual Training: Lifeboat Launching Operation Study,” Computer Animation & Virtual Worlds, Vol. 29, pp. e1812. https://doi.org/10.1002/cav.1812"
  },
  {
    "objectID": "examples/VirtualTrain.html#analysis",
    "href": "examples/VirtualTrain.html#analysis",
    "title": "Lifeboat Launch Training Methods",
    "section": "Analysis",
    "text": "Analysis\nApplying a one-way ANOVA to this study, we have the following model:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\nWhere \\(y_{ij}\\) is the \\(j^{th}\\) observation from treatment \\(i\\)\n\\(\\mu\\) is the grand mean of the dataset. Also referred to as an overall mean or benchmark.\n\\(\\alpha_i\\) is the effect of the training method. 1 = control/lecture, 2 = Monitor/keyboard, 3 = head monitor/joypad, 4 = head monitor/wearables.\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. Since there are 16 subjects for each treatment, \\(j\\) ranges from 1 to 16.\n\nHypothesis Test\nThe null hypothesis is that the effect of all training methods, represented by α, is equal to zero. This is formally written as follows.\n\\[ H_0:\\alpha_\\text{Control} = \\alpha_\\text{Monitor/Keyboard} = \\alpha_\\text{Joypad} = \\alpha_\\text{Wearables} = 0 \\]\nThe alternative hypothesis states that at least one of the effects due to material is different than zero \\[ H_a: \\text{at least one } \\alpha \\text{ is different than 0} \\]\nUsing these hypotheses will allow for us to address the question whether any of the type of training is different to improve test score.\nWe will use a level of significance of α = 0.05 for the analysis.\nFor the analysis, we perform the following one-way ANOVA\n\n\nCode\nvirtual <- virtual %>% \n   mutate(\n         Treatment = case_when(\n           grp.trt %in% 1  ~ \"Control\",\n           grp.trt %in% 2  ~ \"Monitor/Keyboard\",\n           grp.trt %in% 3  ~ \"Joypad\",\n           grp.trt %in% 4  ~ \"Wearables\"\n          )\n        )\n\nvirtual.aov <- aov(procKnow ~ Treatment, data=virtual)\nsummary(virtual.aov) %>% pander()\n\n\n\nAnalysis of Variance Model\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(>F)\n\n\n\n\nTreatment\n3\n65.66\n21.89\n4.941\n0.003931\n\n\nResiduals\n60\n265.8\n4.43\nNA\nNA\n\n\n\n\n\nThe p-value for this test is significant (p = 0.003931). Based on this result, the null hypothesis is rejected and we have sufficient evidence that at least one of the effects due to training is different for post test score.\n\n\nCheck Requirements\nIn order to trust this result, we must verify the requirements for the ANOVA model are met. The requirement of equal variances appears to be met since the residuals versus fitted plot shows roughly a constant variance within each vertical group of dots.\nThe QQ-plot of residuals on the right is used to check whether residuals are normally distributed. There are a few points outside the boundaries that might be a concern for this ANOVA requirement, but generally there are no strong departures from normality and so we consider this requirement to be met also.\n\n\nCode\npar(mfrow=c(1,2))\nplot(virtual.aov, which=1, pch=16)\nqqPlot(virtual.aov, id=FALSE)\n\n\n\n\n\n\n\nTraining method’s effect on test score\nThe following plot shows which types of training increases the post test score.\n\n\nCode\nxyplot(procKnow ~ as.factor(Treatment), data=virtual, type=c(\"p\",\"a\"), main=\"Score based on Type of Training\", xlab =\"Treatment\", ylab = \"Test Score\")\n\n\n\n\n\nThe averages are illustrated with the blue line in the plot above and the table below shows the means, standard deviations, and sample sizes for each of the five different materials.\n\n\nCode\npander(favstats(procKnow ~ Treatment, data=virtual)[,c(\"Treatment\",\"mean\",\"sd\",\"n\")])\n\n\n\n\n\n\n\n\n\n\n\nTreatment\nmean\nsd\nn\n\n\n\n\nControl\n4.931\n1.94\n16\n\n\nJoypad\n6.736\n2.82\n16\n\n\nMonitor/Keyboard\n7.708\n1.43\n16\n\n\nWearables\n6.875\n1.99\n16"
  },
  {
    "objectID": "examples/VirtualTrain.html#interpretation",
    "href": "examples/VirtualTrain.html#interpretation",
    "title": "Lifeboat Launch Training Methods",
    "section": "Interpretation",
    "text": "Interpretation\nIt appears the the best type of training may be the Monitor/Keyboard type training. The highest mean came from the Monitor/Keyboard where the average procedural knowledge post test score was 7.708. The head monitor training methods may perform better on different types of assessments that were not part of this study. A future study could look into other training methods to improve readiness in lifeboat launching."
  },
  {
    "objectID": "experimental_units.html",
    "href": "experimental_units.html",
    "title": "Experimental Units",
    "section": "",
    "text": "The first example will study to see if a specific SAT prep class improves individual’s SAT math scores. Twenty randomly selected students are randomly divided into two groups. One group will take the prep class and the other group will not take the class. In this case the experimental unit is the student because factor level assignments were made for each student. The observational unit is also the student because the math scores are measured for each student.\nThe next example will be slightly, but distinctly different. In this case, we will be applying a new teaching method to a math classroom to see if it improves math scores. Six randomly selected classrooms are randomly divided into 2 groups. One group will be randomly assigned the new teaching method and the other group will be randomly assigned the standard method. Within each classroom there are 25 students and math scores will be taken from each student. In this case, the classrooms are the experimental unit because the factor levels are assigned to each classroom. The students are the observational unit because the scores are measured for each student. The new teaching method will have 75 observations (3 classrooms with 25 students in each). However, the research objectives are concerning the classroom, and assignments of the teaching method are made at the classroom level, so the number of experimental units for each teaching method is just 3 for this analyses. Even though there were many observations, the limited number of experimental units limits the ability to make convincing inference to the broader population. We would like more classrooms involved be be more sure the succes/failure of the new teaching method was not due to a few particularly good/bad teachers. The researcher needs to be aware when this type of sampling is occurring so that a more complex analysis technique can be used to tease out the effect of teachers vs. method - and enhance our ability to make inference. This technique is discussed in further detail with the Nested Factor Designs.\nNow let’s apply this to the toothbrush study. Each person will be assigned to use one type of toothbrush, so person is the experimental unit. The measurements will be taken from teeth, so the observational unit will be tooth. If measurements are taken from multiple teeth, then a more complex design, like the Nested Factor designs should be considered."
  },
  {
    "objectID": "factor_structure.html",
    "href": "factor_structure.html",
    "title": "Factor Structure",
    "section": "",
    "text": "In this section you will learn about factors in context of analyzing results of an experiment:"
  },
  {
    "objectID": "factor_structure.html#inside-and-outside",
    "href": "factor_structure.html#inside-and-outside",
    "title": "Factor Structure",
    "section": "Inside and Outside",
    "text": "Inside and Outside\nThink about our toothbrush example, but ignore toothpaste for a moment. If toothbrush is the only treatment under scrutiny we have three factors in the analysis: the grand mean, toothbrush type, and the residual error.\nRecall that in the simplest version of the toothbrush experiment there were 4 levels of the treatment (toothbrush type), with six replicates for each toothbrush. In the following factor structure diagrams grand mean is represented in red, toothbrush type is drawn in blue, and the residual factor levels are depicted in black.\n\n\n\nA factor is inside of another factor if all the levels of one factor (the inside factor) completely fit within a second factor (the outside factor).\nYou may find this analogy helpful. Pretend that an outside factor is a box, and the inside factor levels are blocks that fit perfectly within the box.\n\n\n\n\n\nTo determine if a factor is inside another factor, imagine picking up the levels of the factor one by one and placing them inside the other factor. If they all fit without crossing the partition lines of a factor,then it is considered inside.\nThis is illustrated with the toothbrush example. We will start by taking the levels of toothbrush and placing them inside of grand mean\n\n\n\n\n\nIn the figure above you can see that one entire level of toothbrush can fit inside of a single level of benchmark. Even though they may share a boundary line, the toothbrush level does not cross over any lines or start sharing boundaries with any other level of benchmark (this is of course impossible since benchmark only has one level). You can repeat this for the other 3 levels of toothbrush with the same result. Therefore, we say that toothbrush is inside of benchmark, which is the same as saying that benchmark is outside of toothbrush.\nConsider now the relationship between toothbrush and residual as shown below. If we take a level of toothbrush and overlay it on the residual factor, we can see it does not fit neatly inside one of the levels of residual error. In fact, one level of toothbrush crosses the boundaries of many of the levels of residual error. Therefore, we cannot say that toothbrush is inside of residual error.\n\n\n\n\n\nSince toothbrush is not inside of residual error, does this necessarily mean that toothbrush is outside of residual error? No! This is something that has to be checked. To determine whether toothbrush is outside of residual we must take the levels of residual error one at a time and overlay them on the toothbrush factor structure, as shown below. You can see that one level of residual error does NOT cross any of the toothbrush level boundaries. Therefore, toothbrush is indeed outside of residual error; or equivalently, residual error is inside of toothbrush.\n\n\n\n\n\nLet’s pause here to clarify a common misunderstanding. Consider an experiment where we are looking at the inside vs. outside relationship of two factors: A and B.\n\nWhen factor A is inside of factor B, we can also say factor B is outside of factor A.\nBut, when factor A is not inside of factor B, this does not necessarily mean that factor A is outside of factor B. There are situations where two factors are neither inside nor outside of each other; they are crossed."
  },
  {
    "objectID": "factor_structure.html#crossed-factors",
    "href": "factor_structure.html#crossed-factors",
    "title": "Factor Structure",
    "section": "Crossed Factors",
    "text": "Crossed Factors\nTwo factors are crossed when their partition lines cross in a way that creates new groups of observations that represent every possible combination of the factor levels. More succinctly stated, factors are crossed when all factor level combinations are present in the study. We see this type of relationship in the toothbrush study with two controlled factors: toothbrush type (4 levels) and toothpaste brand (2 levels). Toothbrush and toothpaste are neither inside nor outside of each other; rather, they are crossed.\n\n\n\n\n\n\n\n\n\n\n\nThe crossing of toothpaste brand and toothbrush created an interaction factor"
  },
  {
    "objectID": "hoveRmd/BF1_R_Instructions.html",
    "href": "hoveRmd/BF1_R_Instructions.html",
    "title": "BF1 R Instructions",
    "section": "",
    "text": "Df Sum Sq Mean Sq F value Pr(>F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "hoveRmd/contrast_R_instructions.html",
    "href": "hoveRmd/contrast_R_instructions.html",
    "title": "Math326 Notebook",
    "section": "",
    "text": "The first step is to create the model. Then use the emmeans() command to create a grid of factor level summary statistics, including: means, standard deviations, standard error, degrees of freedom associated with the standard error estimate, and confidence intervals around the mean. Unlike a summarize() or favstats() command, emmeans() has the output structured so that it can easily be used in the next step. Store the grid of means into a new object.\n\nmyaov <- aov(Y ~ X, data = df)\nmymeans <- emmeans(myaov, \"X\")\n\n\nmyaov is some name you come up with to store the results of the aov() model.\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\ndf is the name of your data set.\nmymeans is some name you come up with to store the results of the emmeans() command.\n\nDefine the contrasts your are interested in testing inside the contrast() function, which returns the hypothesis test results. You can also feed the result into a confint() function if you prefer confidence intervals over p-values.\n\ncontrast(brush_means,list(name_of_contrast1 = coefficient vector,\n                       name_of_contrast2 = another coefficient vector))) \n\nname_of_contrast are descriptive names you should give to the contrast to help you remember what it represents. The coefficient vector is how you define the contrast.\nWe will repeat the contrasts we did by hand in the sections above, but this time using R.\nExample Code Using Toothbrush Experiment:\n\n\n df The name you want for your dataset  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv(“../data/toothpaste_BF2.csv”) A tidyverse command to read the data in from the specified path  plaque_aov Name you want for your ANOVA model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  brush_means The name you want for the output of the emmeans command  <- The assignment operator. The result to the right of it gets stored in an object specified on the left   emmeans(  Function to calculate stats about marginal means  plaque_aov, aov model created in previous step  “Brush” Factor for whose levels you want to calculate means  ) Functions always end with a closing parenthesis  contrast_results Name you want to store contrast results in  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  contrast( Function to define and test contrasts  brush_means, Grid of stats about marginal means you named in the previous step list( create a list object, which allows you to pass multiple contrast coefficient vectors  man_v_osc = A descriptive name to help you remember what the contrast represents  c(1,-1,0,0) Vector of coefficients used to define the contrast  , Seperator to allow additional inputs to the list     man_v_others = A descriptive name to help you remember what the contrast represents  c(1,-(1/3),-(1/3),-(1/3)) Vector of coefficients used to define the contrast  ), A list is closed with a parenthesis  adjust = Specify what type of adjustment (if any) to make for multiple testing. Default is “none” if this argument is not included.  “none” Read help at ?summary.emmGrid for other acceptable values  ) Functions always end with a closing parenthesis  contrast_results View the test results stored in this object in the previous step  confint( Function to create confidence intervals around contrasts  contrast_results Name of object where you stored contrasts  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n contrast     estimate   SE df t.ratio p.value\n man_v_osc       3.117 1.58 20   1.967  0.0632\n man_v_others    0.438 1.29 20   0.339  0.7382\n\n\n\n\n contrast     estimate   SE df lower.CL upper.CL\n man_v_osc       3.117 1.58 20   -0.188     6.42\n man_v_others    0.438 1.29 20   -2.260     3.14\n\nConfidence level used: 0.95"
  },
  {
    "objectID": "hoveRmd/DescribeData_backup.html",
    "href": "hoveRmd/DescribeData_backup.html",
    "title": "Describing Data",
    "section": "",
    "text": "In the following explanations\n\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable. It would represent a treatment factor.\nYourDataSet is the name of your data set.\n\nYou can take a tidyverse approach or a mosaic package approach to calculating numerical summaries for each treatment.\n\nmosaic package:tidyverse approach\n\n\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  Month min   Q1 median    Q3 max     mean       sd  n missing\n1     5  56 60.0     66 69.00  81 65.54839 6.854870 31       0\n2     6  65 76.0     78 82.75  93 79.10000 6.598589 30       0\n3     7  73 81.5     84 86.00  92 83.90323 4.315513 31       0\n4     8  72 79.0     82 88.50  97 83.96774 6.585256 31       0\n5     9  63 71.0     76 81.00  93 76.90000 8.355671 30       0\n\n\n\nWhen calculating treatment means for combinations of 2 or more factors you can use + or | to separate the factors. | (read as ‘vertical bar’ or ‘pipe’) has the advantage that in addition to calculating means for every factor level combination, favstats will also output the marginal means for each level of the last factor listed.\nNOTE: unlike it’s use in the aov() command, using the * within favstats does not yield expected results and should NOT be used.\n\nlibrary(mosaic)\nfavstats(Y ~ X + Z, data = YourDataSet) \n#OR\nfavstats(Y ~ X | Z, data = YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  + This allows us to create additional subgroups within ‘am’ for each level of ‘cyl’.  cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  am.cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1    0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2    1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3    0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4    1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5    0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6    1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n\n\n\nNotice that the first column in the output contains the factor level combinations of am and cyl. So, ‘0.4’ is interpreted as level 0 for am and level 4 for cyl. Or in other words, the summary statistics on that row are for automatic tranmission, 4 cylinder engine vehicles. The column label of ‘am.cyl’ indicates which factor is represented on which side of the period. The next example uses the same way of labeling the factor level combinations, but the column label is not as intuitive or helpful.\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  | Referred to as a vertical bar or pipe, this symbol further defines subgroups of the variable on its left, using the values of the variable on its right side   cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to View Output  Click to View Output. \n\n\n\n\n\n  cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1 0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2 1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3 0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4 1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5 0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6 1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n7   4 21.4 22.800  26.00 30.400 33.9 26.66364 4.5098277 11       0\n8   6 17.8 18.650  19.70 21.000 21.4 19.74286 1.4535670  7       0\n9   8 10.4 14.400  15.20 16.250 19.2 15.10000 2.5600481 14       0\n\n\n\n\n\n\nCalculating treatment means for one factor:\n\nlibrary(tidyverse)\nYourDataSet %>%\n  Group_by(X) %>%\n  Summarise(MeanY = mean(Y), sdY = sd(Y), sampleSize = n()) \n\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  airquality airquality is a dataset in R.   %>%  The pipe operator that will send the airquality dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the airquality dataset into “little” datasets, one dataset for each value in the “Month” column.  Month “Month” is a column from the airquality dataset that can be treated as qualitative.  ) Functions must always end with a closing parenthesis.   %>%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  aveTemp =  “AveTemp” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  Temp Temp is a quantitative variable (numeric vector) from the airquality dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\nMonth\naveTemp\n\n\n\n\n5\n65.55\n\n\n6\n79.1\n\n\n7\n83.9\n\n\n8\n83.97\n\n\n9\n76.9\n\n\n\n\n\nNote that R calculated the mean Temp for each month in Month from the airquality dataset.\nMay (5), June (6), July (7), August (8), and September (9), respectively.\nFurther, note that to get the “nicely formatted” table, you would have to use\nlibrary(pander)\nairquality %>% \n  group_by(Month) %>%\n  summarise(aveTemp = mean(Temp)) %>%\n  pander()\n\nTo calculate treatment means for each combination of factor levels of 2 or more factors, simply add the additional variable to the group_by() statement.\nExample code:\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  mpg mtcars is a dataset in preloaded in R.   %>%  The pipe operator that will send the mtcars dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the mtcars dataset into “little” datasets, one dataset for each combination of values in the ‘am’ and ‘cyl’ variables  am, cyl ‘am’ and ‘cyl’ are both columns in mtcars. By listing them both here we are going to get output for each combination of ‘am’ and ‘cyl’ that exists in the dataset  ) Functions must always end with a closing parenthesis.   %>%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  mean_mpg =  “mean_mpg” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  mpg mpg is a quantitative variable (numeric vector) from the mtcars dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n`summarise()` has grouped output by 'am'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\n\n\n\n\nam\ncyl\nmean_mpg\n\n\n\n\n0\n4\n22.9\n\n\n0\n6\n19.12\n\n\n0\n8\n15.05\n\n\n1\n4\n28.07\n\n\n1\n6\n20.57\n\n\n1\n8\n15.4"
  },
  {
    "objectID": "hoveRmd/DescribeData_backup.html#graphical-summaries",
    "href": "hoveRmd/DescribeData_backup.html#graphical-summaries",
    "title": "Describing Data",
    "section": "Graphical Summaries",
    "text": "Graphical Summaries\n\nBoxplots\n\n\n\n\n\n\n\n\nOverviewR InstructionsExplanation\n\n\n\nGraphical depiction of the five-number summary. Great for comparing the distributions of data across several groups or categories. Provides a quick visual understanding of the location of the median as well as the range of the data. Can be useful in showing outliers. Sample size should be larger than at least five, or computing the five-number summary is not very meaningful.\n\n\n\n\n\nBase R ggplot2 plotly\n\n\n\nTo make a boxplot in R use the function:\nboxplot(object)\nTo make side-by-side boxplots:\nboxplot(object ~ group, data=NameOfYourData, ...)\n\nobject must be quantitative data. R refers to this as a “numeric vector.”\ngroup must be qualitative data. R refers to this as either a “character vector” or a “factor.” However, a “numeric vector” can also act as a qualitative variable.\nNameOfYourData is the name of the dataset containing object and group.\n... implies there are many other options that can be given to the boxplot() function. Type ?boxplot in your R Console for more details.\n\nExample Code\nBasic Single Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  $ The $ allows us to access any variable from the airquality dataset.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.  )\nClosing parenthesis for the function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nMore Useful… Basic Side-by-Side Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Names under each Box\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  names=c(“May”,“June”,“July”,“Aug”,“Sep”) names= is used to tell R what labels to place on the x-axis below each boxplot.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Color and Labels\n\n\n boxplot(Temp ~ Month, data=airquality This code was explained in the previous example code.  ,  The comma is used to separate each additional command to a function.  xlab=“Month of the Year” xlab= stands for “x label.” Use it to specify the text to print on the plot under the x-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  ylab=“Temperature” ylab= stands for “y label.” Use it to specify the text to print on the plot next to the y-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  main=“La Guardia Airport Daily Temperatures” main= stands for the “main label” of the plot, which is placed at the top center of the plot. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  col=“wheat” col= stands for the “color” of the plot. The color name “wheat” is an available color in R. Type colors() in the R Console to see more options. The color name must always be placed in quotes.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a boxplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_boxplot()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_boxplot() causes the ggplot to become a boxplot.\n\n\nExample Code\nBasic Single Boxplot\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the y-axis should become.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot() The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n Side-by-side Boxplot and Color Change\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box in the boxplot.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Labels \n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_histogram()” function causes the ggplot to become a histogram. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.   +  The addition symbol + is used to add further elements to the ggplot.     labs( The “labs” function is used to add labels to the plot, like a main title, x-label and y-label.  title=“La Guardia Airport Daily Mean Temperature”,  The “title=” command allows you to control the main title at the top of the graphic.  x=“Month of the Year”,  The “x=” command allows you to control the x-label of the graphic.  y=“Daily Mean Temperature” The “y=” command allows you to control the y-label of the graphic.  )\nClosing parenthesis for the labs function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nGallery\nSee what past students have done…\nClick to view.\n\nHover to see code.\n \n ggplot(data = mtcars, aes(x = as.factor(cyl), y = mpg, fill=as.factor(cyl))) +  geom_boxplot()  +  stat_summary(fun.y = mean, geom = \"errorbar\", aes(ymax = ..y.., ymin = ..y..),     width = .75, linetype = \"dashed\", color=\"firebrick\") +  theme_light() +  theme(panel.grid.major=element_blank()) +  scale_fill_brewer(palette=\"Dark2\") +  geom_jitter(width=0.1, height=0) +  labs(title = \"Miles Per Gallon Based on Cylinders\",     x=\"Number of Cylinders\",     fill=\"Cylinders\",     y=\"Miles Per Gallon\")   \n \n ggplot(data = ToothGrowth, aes(x = as.factor(dose), y = len, fill=as.factor(dose))) +  geom_boxplot( )  +  facet_wrap(~supp) +  theme_bw() +  scale_fill_manual(values=c(\"#999999\", \"#E69F00\", \"#56B4E9\")) +  geom_jitter(width=0.1, height=0) +  labs(title = \"Tooth Length Based on Doses     According to Supplement Type\",     fill=\"Doses\",     x=\"Dosage Amount(mg)\",     y=\"Tooth Length\" )   \n\n\n\n\n\nTo make a histogram in plotly first load\nlibrary(plotly)\nThen, use the function:\nplot_ly(dataName, y=~columnNameY, x=~columnNameX, type=\"box\")\n\ndataName is the name of a data set\ncolumnNameY must be the name of a column of quantitative data. R refers to this as a “numeric vector.” This will become the y-axis of the plot.\ncolumnNameX must be the name of a column of qualitative data. This will provide the “groups” forming each individual box in the boxplot.\ntype=\"box\" tells the plot_ly(…) function to create a boxplot.\n\nVisit plotly.com/r/box-plots for more details.\n\nExample Code\nHover your mouse over the example codes to learn more. Click on them to see what they create.\nBasic Boxplot\n\n\n plot_ly An R function “plot_ly” from library(plotly) used to create any plotly plot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality,  “airquality” is a dataset. Type “View(airquality)” in R to see it.  y= The y= allows us to declare which column of the data set will become the y-axis of the boxplot. In other words, the quantitative data we are interested in studying for each group.  ~Temp,   “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset. The ~ is required before column names inside all plot_ly(…) commands.  x= The x= allows us to declare which column of the data set will become the x-axis of the boxplot. In other words, the “groups” forming each separate box in the boxplot.  ~as.factor(Month),   since “Month” is a quantitative variable (numeric vector) from the “airquality” dataset we have to change it to a “factor” which forces R to treat it as a qualitative (groups) variable. The ~ is required before column names inside all plot_ly(…) commands.  type=“box” This option tells the plot_ly(…) function what “type” of graph to make. In this case, a boxplot.  )\nClosing parenthesis for the plot_ly function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nChange Color\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”,  This code was explained in the first example code.  fillcolor=“skyblue”,  this changes the fill color of the boxes in the boxplot to the color specified, in this case “skyblue.”  line=list(color=“darkgray”, width=3),  this “list(…)” of options that will be specified will effect the edges of the boxes in the boxplot. We are changing their color to “darkgray” and their width to 3 pixels wide.  marker=list( this “list(…)” of options that will be specified will effect the outlying dots shown in the boxplots beyond the “fences” of each box.  color = “orange”,  this will change the color of the dots to orange.  line = list(,  this opens a list of options to specify for the “lines” around the “markers.”  color = “red”,  this will change the color of the lines around the outlier dots to red.  width = 1 this will change the width of the lines around the outlier dots to 1 pixel.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nAdd Titles\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”, fillcolor=“skyblue”, line=list(color=“darkgray”, width=3), marker = list(color=“orange”, line = list(color=“red”, width=1)))  This code was explained in the above example code.  %>% the pipe operator sends the completed plot_ly(…) code into the layout function.  layout( The layout(…) function is used for specifying details about the axes and their labels.  title=“La Guardia Airport Daily Mean Temperatures” This declares a main title for the top of the graph.  xaxis=list( This declares a list of options to be specified for the xaxis. The same can be done for the yaxis(…).  title=“Month of the Year” This declares a title underneath the x-axis.  ),  Functions always end with a closing parenthesis.  yaxis=list( This declares a list of options to be specified for the y-axis.  title=“Temperature in Degrees F” This declares a title beside the y-axis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding how a boxplot is created is the best way to understand what the boxplot shows.\n\nHow Boxplots are Made\n\nThe five-number summary is computed.\nA box is drawn with one edge located at the first quartile and the opposite edge located at the third quartile.\nThis box is then divided into two boxes by placing another line inside the box at the location of the median.\nThe maximum value and minimum value are marked on the plot.\nWhiskers are drawn from the first quartile out towards the minimum and from the third quartile out towards the maximum.\nIf the minimum or maximum is too far away, then the whisker is ended early.\nAny points beyond the line ending the whisker are marked on the plot as dots. This helps identify possible outliers in the data.\n\n\n\n\n\n\n\n\n\nScatterplot, with Means\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nScatterplots of a catgorical variable on the x axis and quantitative variable on the y axis are sometimes called strip charts, or side-by-side strip charts. When sample sizes are not too big and there are not too many repeated value this type of chart is an excellent way to see the variability in the data without the abstraction of a boxplot. By plotting individual observations you also can see the size of the sample for each factor level. Including factor level means on the plot adds additional insight. The mean of each factor level is often connected with a line for visual impact.\n\n\n\n\nmosaic ggplot2 plotly\n\n\n\nTo make a scatterplot use the function:\nxyplot(y~x, data = mydata)\n\ny is the quantitative response variable, i.e., “numeric vector.”\nx is the independent, explanatory variable\nmydata is the name of the dataset containing y and x.\n\nThis will return a scatterplot regardless of how your x variable is stored in R (numeric, character, factor). This function is flexible and with minimal effort can include averages or make an interaction plot. xyplot() is a part of the lattice package, which is loaded when the mosaic package is loaded.\nNote: plot() from base R will also give a scatterplot, but only if the x variable is quantitative. If x is a character or factor variable the default is to return a boxplot plot.\nExample Code\nBy reading the documentation for the dataset (visible when ?ToothGrowth is run in the console) we can see that our “x” variable, “dose”, is a numeric variable in R. Because of this the x-axis maintains the relative distance of doses on the x-axis.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nIf you start with a numeric x variable, you may or may not want to convert it to a factor variable. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed. Compare the output of the previous example code with this example code. This example code converts our x variable of “dose” to a factor variable.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nTo include the means on the plot and connect them with a line use this code\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  , \nThe “,” is required to start specifying additional commands for the function.  type =\nThe type argument allows you to add different types of lines to the plot. Run ?panel.xyplot() to read more about values for this argument  c( Combines the following values into one vector. This allows me to pass multiple values as one input to “type =”. Useful for if I want to plot something in addition to the default of plotting points.  ‘p’\nThis requests the points to be plotted. It is the default value. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  , \nThe “,” is required to start specifying additional commands for the function.  ‘a’ This requests the average for each factor level to be connected with a line. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a scatterplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_point()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_point() causes the ggplot to become a scatterplot; or in other words to draw points to represent data.\n\n\nExample Code\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n If you start with a numeric x variable, you may or may not want to convert it to a factor variable. You do this by using ‘factor(x)’ instead of just ‘x’ as shown below. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed.\nggplot(ToothGrowth, aes(x = factor(dose), y = len)) +   geom_point(color = \"blue\")\nAdding averages to the plot and connecting them with a line requires a little more effort and is demonstrated in the code below. I also add some more descriptive labels to the chart.\nNote the use of stat_summary to indicate I want to add a layer that plots a numerical summary, not the original data. Some geoms have stat summaries built in to them (like geom_bar or geom_boxplot), but in our case we have to define the summary.\nIn the stat_summary I provide additional arguments to the aesthetics helper function. Defining the aesthetics in ggplot() is like a global definition, all additional layers inherit those aesthetic mappings. Defining them in a geom_* or a stats_* allows you to add to or override what was defined in ggplot() for that layer only. The group aesthetic is required in order to use a line geometry. In this case, group could just as easily have been defined in ggplot(aes()).\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_point( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.   + The addition symbol + is used to add further elements to the ggplot.    stat_summary( This function will calculate a statistical summary to be plotted on the chart  fun = mean, fun is short for function. The summary function I want to apply to my y variable is “mean”.  geom = “line”, The “geom=” argument is used to tell what kind of geometry should be drawn to represent the means. Here we are asking for the means to be connected with a line.  aes( The aes or “aesthetics” function allows you to tell ggplot what variables should be mapped to what visual aspects of the chart; including what the x-axis or y-axis should become. Including it her means the aesthetic will only be applied to this layer.  group = 1 indicates which variable should be grouped by when drawing multiple lines (one line for each factor level). We write the number 1 to indicate there is just 1 group; we are not further splitting the data.  )\nClosing parenthesis for the geom_boxplot function.  )\nClosing parenthesis for the geom_boxplot function.   + The addition symbol + is used to add further elements to the ggplot.    labs( Function to edit labels of the plot  x = “Vitamin C mg/day”, Edit the x-axis label  y = “Length”, Edit the y-axis label  title = “Tooth Growth in Guinea Pigs” Edit the chart title  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nUnder construction.\n\n\n\n\n\n\n\n\n\nInteraction Plot\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nThese plots are used to visualize two categorical factors (mapped to the x-axis and the line color/type) and a quantitative response variable (displayed on the y-axis). A point for each factor level combination mean is plotted, and then points are connected with lines to aid the visual interpretation of the plot. Because they show two factors, they are ideal for two-way ANOVA.\nInteraction plots are a great way to see factor effects. In particular, they can be helpful in understanding the nature of an interaction factor, or detecting the lack thereof. If the line segments in the plot are all (nearly) parallel, this is indicative that no interaction effect exists between the two factors. The more non-parallel the line segments, the more likely a significant interaction effect is present.\nA formal hypothesis test should be conducted to determine the significance of an interaction term, since sometimes the hypothesis test result can run counter to what a quick visual inspection might suggest. When a significant interaction is present, an interaction plot can be a critical part of understanding the nature of the interaction.\nIf there are three factors in a study, multiple interaction plots can be used (one at each value of the third factor) to explore the nature of two-way and three-way interactions. This approach can be extended for analyses involving more than 3 factors. However, interactions involving more than 3 variables are rare in practice. Therefore, if more than 3 factors are present in an analysis, interaction plots are not usually used as an exploratory tool. Instead, statistical tests are used to find significant interactions, and then interaction plots are used to describe the nature of those interactions.\n\n\n\n\nBase R ggplot2 plotly\n\n\n\nTo make a scatterplot use the function:\ninteraction.plot(mydata$factor_x, mydata$factor_line, mydata$response)\n\nmydata is the name of the dataset containing the factors and response.\nfactor_x is factor (or string) variable that will be plotted on the x-axis\nfactor_line is factor (or string) variable that will have different colored/types of lines on the plot\ny is the quantitative response variable, i.e., “numeric vector.”\n\nNote, unlike the other plotting we have done so far, there is no data = argument. Each variable must be specified using the $ notation if it exists inside a dataset. There are many additional arguments to specify colors, line types, legend formatting, etc.\nExample Code\nBy reading the documentation for the dataset (visible when ?ToothGrowth is run in the console) we can see that our “x” variable, “dose”, is a numeric variable in R. Because of this we convert it to a factor variable in the plot command with the factor() command. This changes the nature of dose only within that particular plot, not within the dataset generally.\n\n\n\n interaction.plot( An R function used to create an interaction plot  factor( A function to make a variable categorical.  ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  ) parenthesis to close the factor function  , separate arguments to a function with commas  ToothGrowth Name of the dataset that contains the variables.  $ The $ allows you to refer to a variable in a dataset by name  supp a different line will be drawn for each value of supp  , separate arguments to a function with commas   ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  len name of the response variable in ToothGrowth  , separate arguments to a function with commas ylab= argument to specify y-axis label  “Tooth length” Label for the y-axis must be put in quotes  ,  separate arguments to a function with commas  xlab= argument to specify x-axis label  “Dose (vitamin C mg/day)” Label for the x-axis must be put in quotes  , separate arguments to a function with commas  trace.label= argument to specify the trace label which will appear in the legend  “Delivery Method” Label for the trace factor must be put in quotes  , separate arguments to a function with commas  main= argument to specify the chart title  “Tooth Growth in Guinea Pigs” Chart title must be put in quotes  ) parenthesis to close the interaction.plot function      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\nBecause not all the line segments are parallel, you may begin to suspect an interaction is present. To determine if the interaction is significant you can do a hypothesis test for.\nNote, an easy/slick method for changing the legend position does not (currently) exist for interaction.plot(), though some hacked solutions can be used.\nYou can adjust things like line color, plotting points, etc. as shown in this next example.\n\n\n\n interaction.plot( An R function used to create an interaction plot  factor( A function to make a variable categorical.  ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  ) parenthesis to close the factor function  , separate arguments to a function with commas  ToothGrowth Name of the dataset that contains the variables.  $ The $ allows you to refer to a variable in a dataset by name  supp a different line will be drawn for each value of supp  , separate arguments to a function with commas   ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  len name of the response variable in ToothGrowth  , separate arguments to a function with commas ylab= argument to specify y-axis label  “Tooth length” Label for the y-axis must be put in quotes  ,  separate arguments to a function with commas  xlab= argument to specify x-axis label  “Dose (vitamin C mg/day)” Label for the x-axis must be put in quotes  , separate arguments to a function with commas  trace.label= argument to specify the trace label which will appear in the legend  “Delivery Method” Label for the trace factor must be put in quotes  , separate arguments to a function with commas  main= argument to specify the chart title  “Tooth Growth in Guinea Pigs” Chart title must be put in quotes  , separate arguments to a function with commas  type=\nargument to specify whether lines, points, or both should be plotted  ‘b’ b, in quotes, indicates lines and points should be drawn on the plot  , separate arguments to a function with commas   pch=\nargument to specify shape of the points  16 an integer value from 0 to 25 is expected.   , separate arguments to a function with commas  lty=\nargument to specify line type.   1 1 for a solid line. Line type can be specified with an integer from 0 - 6, or text “solid”.  , separate arguments to a function with commas  col=\nargument to specify colors to be used for different values of the trace factor, supp  c( concatenate function used to create a vector  “darkblue” color to be used for first value of supp. Can be given in name form, integer, or rgb specs  ,\nseparate values in a vector with a comma   “deeppink3” color to be used for first value of supp. Can be given in name form, integer, or rgb specs  ) end the vector with a parenthesis  ) parenthesis to close the interaction.plot function      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make an interaction plot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=factor1, color=factor2, group=factor2, y=response) +\n  stat_summary(fun = mean, geom = \"line\")\n\ndata is the name of your dataset.\nfactor1 is a column of data from your dataset that is a qualitative factor whose values you want to plot along the x-axis.\nfactor2 is a column of data from your dataset that is a qualitative factor. You want to draw a different colored line for each value of this factor.\nresponse is the name of the quantitative response variable in your dataset.\nThe aesthetic helper function aes() is how you tell R which variables you want mapped to which aesthetics (i.e. visual attributes) of your chart. This is actually the input to the mapping= argument, but for conciseness mapping= is usually not typed out.\n\nThe group aesthetic indicates that any summary statistics that are calculated should be calculated separately for each value of factor2. It’s similar to a group_by() statement.\nBecause factor2 is also the value for color, each value of factor2 will be represented with a different color.\n\nstat_summary() does two things:\n\ncalculates a summary statistic. In this case we tell it to calculate the mean for each factor level combination with the fun = mean code. fun stands for “function”.\nindicates we want to connect the means with a line. geom stands for our desired geometry, in this case lines.\n\n\nNote if one of your factor variables is not coded as a factor (e.g. it is numeric), use factor() to convert it to the correct data type.\n\nHere is a basic interaction plot using ggplot2 package. In a later example we will add additional formatting, labels, etc.\n\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function is actually an input to the mapping= argument. It allows you to which variable is mapped to aspects of the chart. This includes things like what the x-axis or y-axis should become.  x= “x=” declares which variable will become the x-axis of the graphic.  factor(dose), factor converts dose, a numeric variable, into a categorical variable  color=supp,  declares that each value of supp will be represented with a different color  group=supp,  declares that each value of supp must be drawn separately. We specify the geometry to be drawn later with geom.  y=len declares which variable will become the y-axis of the graphic.  )) close the aes and ggplot functions with a parenthesis   + The addition symbol is used to add/tweak chart elements.    stat_summary( this adds a layer to the chart that will show summary statistics  fun = mean,  “mean” is the function used to get a summary statistic  geom=“line” The geometry used on the chart will be lines  ) parenthesis to close the stat_summary function      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\nAdd different line types, points for each factor level mean, and improved labelling\nLook at the code below and notice that with the exception of the group aesthetic, a label is applied to each aesthetic mapping. linetype and color have the same label and R is smart enough to therefore combine the legend for these two aesthetic mappings into one legend. If the labels are not identical, each aesthetic will have a unique legend.\n\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function is actually an input to the mapping= argument. It allows you to which variable is mapped to aspects of the chart. This includes things like what the x-axis or y-axis should become.  x= “x=” declares which variable will become the x-axis of the graphic.  factor(dose), factor converts dose, a numeric variable, into a categorical variable  color=supp,  declares that each value of supp will be represented with a different color  group=supp,  declares that each value of supp must be drawn separately. We specify the geometry to be drawn later with geom.  linetype=supp,  declares that each value of supp will be represented with a different line type  y=len declares which variable will become the y-axis of the graphic.  )) close the aes and ggplot functions with a parenthesis   + The addition symbol is used to add/tweak chart elements.    stat_summary( this adds a layer to the chart that will show summary statistics  fun=mean,  “mean” is the function used to get a summary statistic  geom=“line”,  The geometry used on the chart will be lines  size=1 Change the line thickness  ) parenthesis to close the stat_summary function   + The addition symbol is used to add/tweak chart elements.    stat_summary( this adds a layer to the chart that will show summary statistics  fun=mean,  “mean” is the function used to get a summary statistic  geom=“point”,  The geometry used on the chart will be points  size=3 Change the size of the points  ) parenthesis to close the stat_summary function   + The addition symbol is used to add/tweak chart elements.    labs( use this layer to change chart labels  x=“Vitamin C dose (mg/day)”, Put the x-axis label in quotes     y=“Tooth Length”, Put the x-axis label in quotes     title=“Guinea Pig Study”, Put the chart title in quotes     color=“Delivery Method”, Put the color label in quotes     linetype=“Delivery Method” Put the linetype label in quotes  ) Close labs with a parenthesis      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nUnder construction."
  },
  {
    "objectID": "hoveRmd/model_diagnostics.html",
    "href": "hoveRmd/model_diagnostics.html",
    "title": "Model Diagnostics",
    "section": "",
    "text": "A key assumption for ANOVA tests is that the error, or residual term, has a constant variance across all factor levels. This is sometimes call homogeneity of variance, or homoscedasticity.\nWe explain three ways to check the assumption: rule of thumb when comparing standard deviations for each factor level, a visual assessment of the residual vs. fitted plot, and Levene’s test. These methods may not always agree. You should be aware of the underlying data. Understanding why this assumption is important and how it will affect results when violated will help you decide how to proceed after checking these diagnostics. It is also worth noting that the ANOVA F-test is robust in the face of mild to moderate violation of this assumption.\nWe will use the pre-loaded dataset ToothGrowth. To learn more about the dataset, run ?ToothGrowth in the console. len will be our response variable, supp is an independent factor, and dose is the other independent factor. We will analyze this a two-way, basic factorial design. Because dose is stored as a numeric variable, we will convert it to a categorical variable and rename it dose_f before including it in the model. Don’t forget to load the tidyverse in order to use mutate().\n\n\n tg The name you want for your modified dataset  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  ToothGrowth A preloaded dataset in R  |> The result on the left is piped into the first argument of the function on the right  mutate( A tidyverse function to compute a new column for a dataset  dose_f = The name you want to give to the new column  factor( A function to convert a variable from numeric to quantitative  dose A numeric variable in ToothGrowth  )) Functions always end with a closing parenthesis  aov2th A name you come up with for your model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  len The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  dose_f Column in the tg dataset where doese is stored as a factor  * Crosses two factors. Both simple factors and the interaction factor are included in the model   supp variable with 2 levels of delivery method: orange juice or asorbic acid (vc)  , Seperates multiple input arguments to a function.  data = tg Tell the model that the variable names come from the tg dataset  ) Functions always end with a closing parenthesis \n\n\n\n\n\n\n\n\n\n\nA quick rule of thumb to check this assumption is to compare standard deviations across factor levels. If the largest standard deviation is no more than double the smallest standard deviation, then the standard deviations (and the variances) are close enough to be considered equal. Check the R Instructions>Describing Data>Numerical Summaries section of the textbook on how to calculate standard deviations for each factor level.\nIn cases with more than 1 factor, you can compare the standard deviation of each factor level combination (i.e. the interaction factor). Sometimes though, looking at the interaction results in a very small sample size at each level or you may be concerned about a particular factor level of an experimental factor. In that case you may want to apply this rule of thumb to each factor individually. When faced with a situation where the rule of thumb is met for some factors but not for others use your best judgement. An understanding of how a violation may affect your results is critical. You can see that this approach can be tricky to implement, especially as you go beyond studies with just two factors.\n\n\n\nAnother informal approach to checking the constant variance assumption is looking at a residual vs. fitted plot. Similar to the rule of thumb, in situations with more than 1 factor, you can either create a plot that shows all factor level combinations OR look at multiple plots, one for each experimental factor. In order to view this plot, you must first create the ANOVA model. Once the model is created, there are a couple of ways to get a residual vs. fitted plot.\nConstruct the plot manually from vectors within the aov object\nThe plot can be constructed using the vector of residuals and vector of fitted values contained in the aov object.\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\nplot(myaov$fittedvalues, myaov$residuals)\n\nNote: If you want to know all the named items in an R object, you can run names(object). In this case we have an aov object called myaov. To see what it contains we can run names(myaov) in the console.\nExample code:\n\n\n\n plot( Base R function to create a scatterplot  aov2th$  Look in the aov2th object for the item named on the right of the $  fitted.values  This vector, stored in the aov object, contains the fitted, or predicted, values.  , Seperates multiple input arguments to a function  aov2th$ Look in the aov2th object for the item names on the righ tof the $  residuals Vector in the aov object that contains model residuals  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\nNote the resulting plot show 6 vertical groupings, one for each factor level combination. (3 does levels x 2 levels of supp = 6 factor level combinations) ::: {.cell} ::: {.cell-output-display}  ::: :::\n\n\nConstruct the plot with a shortcut\nWhen the function plot() is called on an aov object, 4 diagnostic plots are produced. Instead of viewing all four, chose which ones to see with the which= argument. The first of the four plots is the residual vs. fitted plot.\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\nplot(myaov, which = 1)\n\nExample code:\n\n\n\n plot( Base R function, when fed an aov object it produces 4 diagnostic plots  aov2th,  The aov object for our model  which = Which of the four diagnostic plots do we want  1 The first of the 4 plots is the residual vs. fitted plot  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\nIgnore the red line on the plot. It does not measure variance and so can be distracting. ::: {.cell} ::: {.cell-output-display}  ::: :::\n\n\n\n\n\nLevene’s test is a formal hypothesis test to determine if the variances are equal. In essence, this is an ANOVA F-test comparing sample variances across factor levels (as opposed to comparing sample means). A large p-value for the test indicates there is insufficient evidence to conclude one of the variances is different; and therefore the assumption of constant variance is met.\nThis test comes in handy when there are multiple factors in a study and it is burdensome to informally evaluate all their factor level combinations.\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\ncar::leveneTest(myaov)\n\nExample code:\n\n\n\n car Levene’s test comes from the car package.   :: Allows you to reference functions from the package named on the left without having to load the entire package.  leveneTest( function to run Levene’s test  aov2th name of the aov object to run the test on  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  5  1.7086 0.1484\n      54"
  },
  {
    "objectID": "hoveRmd/model_diagnostics.html#normal-distribution",
    "href": "hoveRmd/model_diagnostics.html#normal-distribution",
    "title": "Model Diagnostics",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nAnother key assumption for ANOVA tests is that the error, or residual, term follows a normal distribution. We use the Q-Q plot to check this assumption. There are two ways to create the Q-Q plot.\nWe will continue to use the aov2th model that was created at the beginning of the Constant Variance section.\nConstruct the Q-Q plot with a shortcut\nWhen the function plot() is called on an aov object, 4 diagnostic plots are produced. Instead of viewing all four, chose which ones to see with the which= argument. The second of the four plots is a normal Q-Q plot.\nExample code:\n\n\n\n plot( Base R function, when fed an aov object it produces 4 diagnostic plots  aov2th,  The aov object for our model  which = Which of the four diagnostic plots do we want  2 The second of the 4 plots is the normal Q-Q plot  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\n\n\n\n\n\nThe advantage of this method is that you can easily get the residual vs. fitted plot and the normal Q-Q plot with one command by providing the which = argument a vector containing the values 1 and 2. (The : is shorthand to create a vector that starts at the value of the left of the : and increments by 1 until reaching the value on the right side of the :.)\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\nplot(myaov, which = 1:2)\n\nThe disadvantage of this method is that it can be difficult to determine if the points follow the line closely enough. To help with this decision, you may prefer to use the Q-Q plot from the car package.\nConstruct the Q-Q plot from the car package\nThe Q-Q plot from the car package provides boundary lines. When points are out of the boundaries that is evidence that the normal residual assumption is violated.\nYou can customize the way the acceptable region for points is designated. The default is shading a region. Below is code to draw dashed-line boundary.\nExample code:\n\n\n\n car qqPlot comes from the car package.   :: Allows you to reference functions from the package named on the left without having to load the entire package.  qqPlot( function to a Q-Q plot from the car package  aov2th, name of the aov object  envelope = Argument to control the formatting for the acceptable region for points  list( There are potentially many arguments to affect the envelope, so they are provided as a list.  style = “filled” shading, boundary “lines”, or none  “lines” designate the acceptable region with lines  )) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\n\n\n\n[1] 32 49"
  },
  {
    "objectID": "hoveRmd/model_diagnostics.html#independent-errors",
    "href": "hoveRmd/model_diagnostics.html#independent-errors",
    "title": "Model Diagnostics",
    "section": "Independent Errors",
    "text": "Independent Errors\nAn order plot can serve as a partial check of the assumption that the residuals are independent. If there are patterns/trends in the plot that may be grounds to say the assumption is violated.\nThe plot assumes that the dataset is sorted in the same order the data was recorded. If the data has been re-sorted or is from an observational study (i.e. the chronology of collection is unknown or irrelevant) the order plot does not make sense as a check of independence.\nExample code:\n\n\n\n plot( A function to plot the data  aov2th Name you gave your model  $ Access a named object within an object  residuals residuals of the model  ) Functions always end with a closing parenthesis  Toggle output Toggle Output."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BYU-Idaho Math326: Design and Analysis of Experiments",
    "section": "",
    "text": "This book is meant to be a starting point for you to learn design and analysis of experiments. You should feel free to edit the Rmarkdown files so that the book becomes your own.\n\n\nUnder Basics of Design the most foundational issues that face each experimenter are described.\nThe Specific Designs section addresses specific designs we will learn about in this course. Each design will have an image next to it representing the diagram of the structural factors. Within each of these designs there are subsections:\n\nOverview contains the model, factor structure and hypotheses\nDesign discusses how the randomization is implemented and why\nDecomposition is a bridge between the design and analysis. It walks through creating an ANOVA table by hand for the given design to allow you to see how the factor structure affects the analysis.\nR instructions provides code illustrating how to run the model\nResources contains worked examples and a space for you to store other links and info\n\nThe section labeled Broad Topics seeks to address topics that are relevant to many experiment designs.\nFinally, a section dedicated to R code that can be used in multiple designs. This includes numerical and graphical data summaries as well as code for model diagnostics/assumption checking.\nYou should add additional topics and designs as you learn more, even after the course is over. The book is meant to be fully customizable and growing to reflect your growing understanding.\n\n\nThis book was specifically designed for the Math326 Design and Analysis of Experiments class at BYU-Idaho, as it stands in 2022. BYU-I follows a 14 week semester. After introducing some foundational principles of experimental design, the recommended sequence follows the general pattern of\n\nIntroduce a specific design: suitability/benefits of the design, explanation of the design, factor structure and decomposition, steps for analysis (including R code)\nDiscuss new topics/complexities/considerations associated with that design located in the Broad Topics list."
  },
  {
    "objectID": "index.html#book-scope",
    "href": "index.html#book-scope",
    "title": "BYU-Idaho Math326: Design and Analysis of Experiments",
    "section": "Book Scope",
    "text": "Book Scope\nThis is an introductory book intended to familiarize students with foundational concepts and vocabulary in the design and analysis of experiments. The designs covered in this book are the most basic and all assume a continuous response variable. Hopefully with this foundation students will be prepared to excel in experimental design and analysis courses in grad school, or be able to extend these principles to more complex designs as practitioners."
  },
  {
    "objectID": "key_principles.html",
    "href": "key_principles.html",
    "title": "Key Principles of Experimentation",
    "section": "",
    "text": "This textbook will explore the necessary steps to consider as you plan and perform an experiment. These steps include:\n\nUnderstand the objectives of your research. What questions should be answered?\n\nDetermine the measurements that will be needed to help answer the questions of interest.\nDetermine which variables, which we will call factors, are the sources of variation in the measurements. Determine which of these factors you will be testing and decide which levels of those factors will be included in the study. Determine which of these factors you will hold constant.\nDetermine how sampling and treatment assignments will be done and then collect the data.\nIdentify the analysis technique that will be applied, including how to test hypotheses\nDescribe the data using numerical and graphical summaries.\nPerform the analysis and make sure that the analysis is appropriate.\nMake conclusions.\n\nThis textbook will further discuss each of these steps in detail and offer examples. Steps 1-4 will be discussed in the “Basics of Design” section. Steps 5, 7, and 8 will be discussed in the “Specific Designs” and “Broad Topics” sections. Step 6 will be discussed in the “R Instructions” section.\nBefore detailing each of these steps, it is important to understand the differences between observational studies and designed experiments. In observational studies the researchers do not control the conditions of the study. The data are collected by observation. In this case, the researchers cannot assign the subjects to the conditions and factors in the study. An example of this would be studying to see if there is a difference in the amount of wind at the three Brigham Young University (BYU) campuses. In this study the factor is campus. The campus factor has 3 levels: BYU, BYU-Idaho, and BYU-Hawaii. The measurement taken would be the average wind speed for a particular day. The researchers cannot assign the particular days to a specific campus. Instead, they may select random days and then collect the data for those days. This data would be collected through observation, not through experimentation.\nDesigned experiments are studies in which the researchers control the conditions in which the study is performed. In designed experiments the researchers assign subjects to levels of a factor. The method used in making those assignments will be discussed further in the “Sampling and Data Collection” section. An example of this would be determining which of four different toothbrush types are better at reducing plaque. The researchers would randomly assign each subject to one of the toothbrush types and then carry out the experiment.\nExperiments have the advantage over observational studies in isolating a factor’s effect on a response, and thereby proving causality. Sometimes however it is not ethical to assign someone to a condition that is of interest, for example you should not assign anyone to experience the effects of smoking - even if you wanted to study the impact of smoking. In some cases, it may be impossible to assign someone to a condition, for example gender. Furthermore, an observational study may be preferred because it may be a more realistic view of how something will truly play out “in the real world”, rather than in a contrived lab experiment.\nAlthough both types of studies can be used to better understand and answer research questions, this textbook will mostly focus on the steps needed to best design an experiment. The toothbrush study just introduced above will be used to help illustrate how to work thru the process of designing an experiment."
  },
  {
    "objectID": "multiple_comparisons.html",
    "href": "multiple_comparisons.html",
    "title": "Multiple Comparison",
    "section": "",
    "text": "In this page, the approach to dealing with multiple contrasts is explained. Specifically, whether and how to adjust the tests of multiple contrasts to account for an inflated family wise error rate. A few techniques are described, with a focus on when to use which technique. Lastly, instructions and example code is provided for carrying out each technique in R.\nIn most good experiments, researchers are interested in more than just one contrast. Conducting multiple tests on the levels of a factor can inflate the family wise Type I error rate, as illustrated in the “Multiple T-tests” section of the ANOVA page. There is considerable disagreement among statisticians about how to approach the issue of multiple tests. The debate primarily focuses on whether to proactively take steps that will mitigate the inflated family wise error rate or not. To further complicate matters, if an adjustment is desired, there are multiple techniques to choose from. An exhaustive presentation of the arguments on either side is not attempted in this text. Though, a few of the key ideas will naturally emerge as the different approaches are discussed.\n\n\nThe terms “contrast” and “comparison” are treated here as synonymous. Comparison is used more often to refer to testing a difference in factor level means. Read Contrasts for more explanation of these terms."
  },
  {
    "objectID": "multiple_comparisons.html#bonferroni",
    "href": "multiple_comparisons.html#bonferroni",
    "title": "Multiple Comparison",
    "section": "Bonferroni",
    "text": "Bonferroni\nThe Bonferroni adjustment is best for a handful of pre-planned contrasts. As the number of contrasts grows, the adjustment quickly becomes too conservative (i.e. makes it too hard to find significance). In that case, other methods may strike a better balance between Type I and Type II errors.\n\n\nType I error occurs when a true hypothesis is rejected. Type II error occurs when a false hypothesis is not rejected.\nIt can be shown that in order to not exceed a desired family wise error rate of \\(\\alpha_\\text{fw}\\), for a set of \\(k\\) contrasts, each individual contrast should be tested at a significance level of \\(\\frac{\\alpha_\\text{fw}}{k}\\). For example, if we desire a family wise error rate of 0.05 and plan to do 5 tests, each individual contrast must have a p-value less than \\(\\frac{0.05}{5} = 0.01\\) to be considered significant. The test itself has not changed, only the benchmark p-value for claiming significance. This adjustment is easy to understand and to calculate."
  },
  {
    "objectID": "multiple_comparisons.html#scheffé",
    "href": "multiple_comparisons.html#scheffé",
    "title": "Multiple Comparison",
    "section": "Scheffé",
    "text": "Scheffé\nUsing experimental results to suggest which contrasts to test is often referred to as “data snooping” or exploratory analysis. For example, you may look at graphical and numerical summaries to see which means (or combinations of means) will be promising to test. The problem with this approach is that you have essentially done a quick, informal test of many differences when you looked at descriptive statistics and plots. In other words, you have already tested the means and combinations of the means in your mind. The Type I error rate of the contrasts will be different (higher) than stated because you are only formally applying the test to those that look significant already.\nScheffé’s method is most useful when many contrasts are tested, especially when going beyond pairwise comparisons of factor level means to test combined factor levels (i.e. complex comparisons). In data exploration, there are theoretically an infinite number of contrasts you could test. This is not a problem for Scheffé’s adjustment because, unlike other adjustment techniques, Scheffé’s adjustment does not depend on the number of comparisons to be made. Rather, it is determined only by the number of factor levels and the number of observations.\nThe F statistic used to test a contrast in Scheffé’s adjustment is related to the omnibus F test for the factor itself, and is given by:\n\\[\nF_\\text{Scheffé} = (k-1)*F\n\\]\nWhere \\(F\\) is the statistic for the F test of the factor as usual. \\(k\\) is the number of levels in that factor. \\(F_\\text{Scheffé}\\) has \\(df_\\text{numerator} = k-1\\) and \\(df_\\text{denominator} = df_\\text{residual}\\). Scheffé’s test output is often in terms of a t test. Recall that the t statistic is simply the square root of the F statistic.\nIf you are interested in only a specific set of hypotheses (all pairwise comparisons, or all treatment levels vs. control, or all levels compared to the “best” level, etc.) there may be another adjustment technique that will provide better statistical power. Two of which are mentioned below."
  },
  {
    "objectID": "multiple_comparisons.html#methods-designed-for-all-pairwise-comparisons",
    "href": "multiple_comparisons.html#methods-designed-for-all-pairwise-comparisons",
    "title": "Multiple Comparison",
    "section": "Methods Designed for All Pairwise Comparisons",
    "text": "Methods Designed for All Pairwise Comparisons\nWhether it is an exploratory analysis or a pre-planned set of contrasts, many researchers want to test all factor level means against each other. This is usually referred to as testing all pairwise comparisons. Because this situation is so common, two approaches are described below.\n\nTukey’s HSD\nIf a multiple comparison adjustment is desired for testing all pairwise comparisons, a standard approach is to apply Tukey’s Honest Significant Difference (HSD) technique. Occasionally, in the case of few factor levels, Bonferroni’s adjustment may result in more significant findings. If that is the case, use Bonferroni’s correction instead.\nThe calculation for this test is based on the distribution of \\(Q\\). The test statistic \\(Q\\) is sometimes called the studentized range distribution. “Range” is a reference to the numerator where the difference between a maximum and a minimum is calculated. “Studentized” because we are dividing by the estimated standard error, a technique for standardizing famously employed by Student’s (a.k.a. William Gossett) t test. \\(Q\\) is calculated as:\n\\[\nQ = \\frac{max(T_i) - min(T_i)}{\\sqrt{\\frac{MSE}{n}}}\n\\qquad(1)\\]\n\n\\(MSE\\) is an estimate of the random error variance\n\\(n\\) is the number of replicates at each factor level. For unequal sample sizes the formula changes somewhat and the result of this test may have a lower Type I error rate than claimed\nThe observations for each level are generated by a different random variable: \\(k\\) variables total, one for each level. Each random variable is normally distributed with mean zero and standard deviation estimated by the denominator of Equation 1. \\(max(T_i)\\) is the maximum value of the \\(k\\) random variables, \\(min(T_i)\\) is the minimum.\nThe distribution of \\(Q\\) will depend on the number of treatments being compared, \\(k\\), and the number of degrees of freedom for error.\n\n\n\nFisher’s LSD\nMaking adjustments for multiple contrasts is a conservative approach, meaning it is more difficult to claim significance compared to when no adjustment is made. Though these adjustments prevent understating the probability of Type I error, they increase the probability of Type II error for each individual contrast. In exploratory analysis where you are looking for hints of what to study further, a Type II error may be a greater concern than Type I.\nFor example, consider a screening study intended to narrow down the number of factors studied in a future experiment. In this case, accidentally ruling out something early on that actually does have a significant impact on the response is more egregious than letting a non-significant factor through to the next experiment where it’s non-significance will be discovered.\nFisher’s Least Significant Difference (LSD) employs no adjustment at all to the pairwise comparisons. However, before proceeding to test pairwise comparisons, the F test for the factor must be significant. Using the less powerful F test as a gatekeeper to the more powerful pairwise t tests serves as a partial protection against extreme Type I errors inflation.\nIn summary, Fisher’s LSD is a two step process. First, verify the F test for the factor is significant. Second, if it is, proceed with all pairwise comparisons without any adjustment. Fisher’s LSD tends to be used in studies where many factors are present, especially screening/exploratory studies."
  },
  {
    "objectID": "multiple_comparisons.html#bonferonni",
    "href": "multiple_comparisons.html#bonferonni",
    "title": "Multiple Comparison",
    "section": "Bonferonni",
    "text": "Bonferonni\nThere are two ways to implement the Bonferroni adjustment illustrated below using the contrasts that were tested in the R Instructions section of the Contrast page.\n\n\nSee R instructions for Fisher’s LSD for a shortcut to apply Bonferroni adjustment to all pairwise comparisons.\n\nRecalculate an Alpha Level by Hand\nFirst, the Bonferroni adjustment is shown using output provided for a test of contrasts without adjustment. The code and output from the R Instructions section of the Contrast page is provided again here for convenience. These two contrasts test the mean of the manual brush against the oscillating brush mean, as well as the manual brush mean against the mean of all the other brushes combined.\n\n\nCode\nbrush_means <- emmeans(plaque_aov, \"Brush\")\ncontrast_results <- contrast(brush_means,\n                             list(man_v_osc = c(1,-1,0,0),\n                                  man_v_others = c(1,-(1/3),-(1/3),-(1/3))), \n                             adjust=\"none\")\n\n#kable commands are for formatting the output\ncontrast_results |> \n  kable(digits = 2) |> \n  kable_styling(full_width = TRUE)\n\n\n\n \n  \n    contrast \n    estimate \n    SE \n    df \n    t.ratio \n    p.value \n  \n \n\n  \n    man_v_osc \n    3.12 \n    1.58 \n    20 \n    1.97 \n    0.06 \n  \n  \n    man_v_others \n    0.44 \n    1.29 \n    20 \n    0.34 \n    0.74 \n  \n\n\n\n\n\n\nA new alpha level against which to compare the p-values can be calculated by hand. Since there are two tests, if the intent was to keep the family wise error rate of 0.05, the alpha level for each individual test is \\(\\frac{0.05}{2} = 0.025\\). To be considered significant, the contrast’s p-value must be less than 0.025.\nman_v_osc has a p-value of 0.06; man_v_others has a p-value of 0.74. Since neither contrast has a p-value less than 0.025 we conclude that the contrasts are not statistically significant.\n\n\nMake the Adjustment in R\nSecond, the Bonferroni adjustment is applied by changing the value of the adjust = argument in the contrast() function from “none” to “bon”.\n\n\nCode\nbon_results <- contrast(brush_means,\n                        list(man_v_osc = c(1,-1,0,0),\n                             man_v_others = c(1,-(1/3),-(1/3),-(1/3))), \n                        adjust=\"bon\")\n\n#kable commands are for formatting the output\nbon_results |> \n  kable(digits = 2) |> \n  kable_styling(full_width = TRUE)\n\n\n\n \n  \n    contrast \n    estimate \n    SE \n    df \n    t.ratio \n    p.value \n  \n \n\n  \n    man_v_osc \n    3.12 \n    1.58 \n    20 \n    1.97 \n    0.13 \n  \n  \n    man_v_others \n    0.44 \n    1.29 \n    20 \n    0.34 \n    1.00 \n  \n\n\n\n\n\n\nIn these results the p-values have simply been multiplied by 2 because there were 2 contrasts in the set being tested. Each test can be compared to our desired family wise error rate as usual. Since each test has a p-value greater than 0.05 we conclude that the contrasts are not statistically significant.\nNote, for man_v_others the p-value is capped at 1.00 since a p-value cannot exceed 1.00."
  },
  {
    "objectID": "multiple_comparisons.html#scheffé-1",
    "href": "multiple_comparisons.html#scheffé-1",
    "title": "Multiple Comparison",
    "section": "Scheffé",
    "text": "Scheffé\nSimilar to how the Bonferroni adjustment was applied, to apply a Scheffé adjustment, change the value of the adjust = argument in the contrast() function from “none” to “scheffe”.\n\n\nCode\ncontrast(brush_means, \n         list(man_v_osc = c(1,-1,0,0),\n              man_v_others = c(1,-(1/3),-(1/3),-(1/3))),\n         adjust=\"scheffe\") |> \n\n  #kable commands are for formatting the output\n  kable(digits = 2) |> \n  kable_styling(full_width = TRUE)\n\n\n\n \n  \n    contrast \n    estimate \n    SE \n    df \n    t.ratio \n    p.value \n  \n \n\n  \n    man_v_osc \n    3.12 \n    1.58 \n    20 \n    1.97 \n    0.17 \n  \n  \n    man_v_others \n    0.44 \n    1.29 \n    20 \n    0.34 \n    0.94 \n  \n\n\n\n\n\n Each contrast’s p-value can be compared to our desired family wise error rate of 0.05. Since each test has a p-value greater than 0.05 we conclude that the contrasts are not statistically significant. Notice the p-values with Scheffé’s adjustment are higher than the p-values with Bonferroni’s adjustment. This will always be the case if the number of contrasts being tested is small."
  },
  {
    "objectID": "multiple_comparisons.html#tukey",
    "href": "multiple_comparisons.html#tukey",
    "title": "Multiple Comparison",
    "section": "Tukey",
    "text": "Tukey\nIn our toothbrush example, if we want to compare each factor level mean to the other we can apply Tukey’s HSD adjustment using a base R function. The arguments to the function are the name of the model and the name of the factor whose means should be tested. Notice the emmeans grid does not have to be created and the contrast coefficients do not explicitly need to be input. The output provides an estimate of each pairwise comparison, as well as adjusted simultaneous confidence intervals and p-values.\n\n\nCode\nTukeyHSD(plaque_aov, \"Brush\") |> pander()\n\n\n\nBrush:\n\n\n\n\n\n\n\n\n\n\n \ndiff\nlwr\nupr\np adj\n\n\n\n\nOscillating-Manual\n-3.117\n-7.55\n1.317\n0.2332\n\n\nSonic-Manual\n-0.4183\n-4.852\n4.015\n0.9933\n\n\nUltrasonic-Manual\n2.22\n-2.214\n6.654\n0.5129\n\n\nSonic-Oscillating\n2.698\n-1.735\n7.132\n0.348\n\n\nUltrasonic-Oscillating\n5.337\n0.9029\n9.77\n0.01487\n\n\nUltrasonic-Sonic\n2.638\n-1.795\n7.072\n0.367\n\n\n\n\n\n\n\nWith a p-value of 0.01, only the Ultrasonic-Oscillating contrast is significant. This significance is driven by the large difference in means between the two levels, Ultrasonic’s mean is 5.337 higher than Oscillating. All other pairwise comparisons have p-values greater than 0.05 and so are not considered significant."
  },
  {
    "objectID": "multiple_comparisons.html#sec-fisher",
    "href": "multiple_comparisons.html#sec-fisher",
    "title": "Multiple Comparison",
    "section": "Fisher",
    "text": "Fisher\nFirst, look at the ANOVA summary table to see if the F test for brush is significant.\n\n\nCode\nsummary(plaque_aov)\n\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThe p-value for Brush is significant at the 0.05 level. You can then proceed with an unadjusted test of all pairwise comparisons for the Brush factor. The syntax for this function is a bit different. You do not have to create the model first.\nIt requires the response vector as the first argument, the factor vector as the 2nd argument, and an adjustment for multiple comparisons (if any) as the 3rd argument.\n\n\nCode\npairwise.t.test(df$Plaque, df$Brush, p.adjust.method = \"none\") |> \n  pander()\n\n\n\nmethod: t tests with pooled SD\n\ndata.name: df\\(Plaque and df\\)Brush\np.value:\n\n\n\n\n\n\n\n\n\n \nManual\nOscillating\nSonic\n\n\n\n\nOscillating\n0.06315\nNA\nNA\n\n\nSonic\n0.7944\n0.104\nNA\n\n\nUltrasonic\n0.1764\n0.003052\n0.1114\n\n\n\np.adjust.method: none\n\n\n\n\n\n The output is a triangular matrix of p-values. The p-value for Ultrasonic vs. Oscillating is 0.0031 and is the only significant pairwise comparison at the 0.05 level; though Oscillating vs. Manual is close, with a p-value of 0.0632.\n\n\n\n\n\n\nNote\n\n\n\nThe pairwise.t.test() can receive “bon” as an input to the p.adjust.method = argument, which will perform all pairwise comparisons and apply the Bonferroni adjustment. When the number of factor levels is small Bonferroni is preferred over the Tukey’s HSD because it provides more statistical power."
  },
  {
    "objectID": "randomization.html",
    "href": "randomization.html",
    "title": "Randomization: Sampling and Assignment",
    "section": "",
    "text": "Randomization\nThe best way to minimize bias is to choose the sample randomly from the population. When results are based on a random sample, the conclusions can be generalized to the population. Random samples are accomplished by allowing each member of the population the same probability of being selected in the sample.\nAfter the random sample is selected, units should be randomly assigned to factor levels. The exact way in which this randomization takes place will depend upon the experiment’s design. “Completely at random” and “blocking” are two examples of random assignment strategies that will be addressed as we learn about specific designs.\nAnother randomization to consider is the order in which the experimental runs will occur. Performing all the runs for one level and then moving to the next level can introduce a time or order related bias that could be confounded with the factor. Randomizing the order will remove this bias and possible confounding. Good advice to follow is “control what you can, and randomize the rest”1.\n\n\n\n\n\n\nRandomization\n\n\n\nRandomization should occur in at least two parts of an experiment:\n\nthe selection of experimental units from the population and\nthe random assignment of those units to the factor levels.\n\nThere may be other parts of the experiment where randomization should be applied to protect against bias.\n\n\n\n\nReplication\nMultiple observations are needed within each factor level so that the variability can be estimated for each level. This variability makes up the unexplained variation, as mentioned earlier. Replication is when an experimental run is conducted under the same conditions (same factor levels), but with different experimental units. The number of replicates is the number of experimental units that are assigned to a specific factor level, or combination of levels from multiple factors. More replication leads to a better (smaller) estimate of unexplained variation.\nReplication is different than repeated measures. Repeated measures are when multiple measurements are taken within the same experimental run / experimental unit. The material in which repeated measures are taken are the observational units, as was discussed in a previous section. In our study method example, in the Experimental Units section, each student is considered a repeated measure.\nStatistical power will increase as more replicates are taken. The question of how many replicates are needed for a study is an important question that will not be covered in this class. There are statistical algorithms that estimate the statistical power for a specific design given the number of replicates. The R package pwr is a good resource for power calculations for various statistical tests, including analysis of variance.\n\n\nToothbrush Example\nNow let’s apply each of these concepts to the example toothbrush study. A random selection of 40 possible participants should be taken from the population. Our population may be limited to those people who live near the testing location. It might also be limited to adults. Next, they are randomly assigned a toothbrush. There are 4 toothbrush types, 10 people assigned to each type. At the end of the study, the order in which their data will be collected will also be randomized. Because there are 10 participants in each group, there are 10 replicates in this study. Repeated measures will be used by collecting percent of surface area with plaque for the first molar in each of the four quadrants of the mouth for each participant.\n\n\n\n\n\nFootnotes\n\n\nCobb, G.W. Introduction to Design and Analysis of Experiments. Wiley, 2014.↩︎"
  },
  {
    "objectID": "referencing_other_file.html",
    "href": "referencing_other_file.html",
    "title": "referencing another file",
    "section": "",
    "text": "library(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nDP Example code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output."
  },
  {
    "objectID": "research_objectives.html",
    "href": "research_objectives.html",
    "title": "Research Objectives",
    "section": "",
    "text": "Specific: Define your desired outcomes. These outcomes need to be concisely written. They should be written in a way to reduce confusion. Refine these outcomes as you consider the next steps along the SMART process.\nMeasurable: Objectives will be better understood and accomplished when they are measurable. Designed experiments require the collection of data to determine how objectives are met. The population of the study should be considered, so that the collected data are representative of that population. The collected data need to be appropriate and able to answer the questions posed by the objectives. Some concepts, like happiness, depression, or engagement are not directly measurable. Ensure that whatever is measured in the study can adequately address research objectives. In other words, your study needs to have validity. Validity is the degree a study or a measure actually represents what it claims to represent. The validity of a study may be affected by the quality of the sample and/or the choice of response variable. It is discussed more in the Response Variable page.\nAchievable: Realistic expectations need to be considered when determining objectives. Studies are more effective when the number of objectives is limited and well-focused. Time, resources, and budget need to be strongly considered when creating achievable objectives.\nRelevant: Be careful to make sure that your objectives are relevant to your research and overall goals. Review the literature available concerning your research to help drive your objectives towards relevant outcomes that will be appreciated by others in that research area.\nTime-based: Create a schedule for the main elements of the experiment to keep your research on track. This can be done by defining inch-stones (small tasks and deadlines) and milestones (major tasks and deadlines).\nNow, we’ll apply the SMART process to the toothbrush study example.\n\nSpecific: The research objectives for this study will be 1) determining how well each toothbrush type reduces plaque and 2) determining if there are any significant differences in plaque reduction between these toothbrush types.\nMeasure: Plaque coverage over teeth, measured as a percent of surface area, is measurable with the use of plaque staining dye, an oral camera, and software.\nAchievable: There are only two objectives mentioned in the research objectives, both of which can be answered with the defined measure, keeping this study simple and focused.\nRelevant: Considering that the purpose of our research may be to determine which toothbrush to use, this study should be relevant to those that brush their teeth.\nTime-based: Three inch-stones along the schedule will help us keep on track: 1) find the subjects to be used in the study; 2) collect the data, which would include a 2-month brushing window before collecting the data; and 3) analyze the data. The milestone would be the final report."
  },
  {
    "objectID": "response_variable.html",
    "href": "response_variable.html",
    "title": "The Response Variable",
    "section": "",
    "text": "Measurement Scales\nWhen defining a response variable, it is important to understand measurement scales. The four possible measurement scales are: nominal, ordinal, interval, and ratio. These four scales will now be discussed further and are listed in order of least information provided (nominal) to most information provided (ratio).\n\nData that are represented by labelled categories would be considered nominal. Nominal categories have no quantitative value and have no particular order. Gender and color are examples of nominal measurements. A dichotomous (having two categories) variable is a common nominal measurement scale. Analysis of variance, the common analytical technique used throughout this textbook, is not appropriate when the response variable is nominal.\nAn ordinal variable is similar to the nominal variable, except that the categories fall in a significant and meaningful order. A likert scale is a commonly used ordinal measurement. A simple example of likert, ordinal scale would be “bad”, “good”, and “great”. There is an obvious order, however, the distances between the categories are not quantitative. This means that the distance between “bad” and “good” can’t be quantitatively determined and it is not known if that difference is similar to or different than the distance between “good” and “great”. Analysis of variance is generally not appropriate when the response variable is ordinal, especially when the researcher is not comfortable in calculating a mean across the ordinal values.\nInterval measurements are quantitative with a meaningful notion of distance between values, however zero does not have a true zero value. An example of an interval variable is temperature, measured in Fahrenheit. Time is also an interval variable when there is no zero-point defined. Analysis of variance is generally appropriate when the response variable is interval.\nRatio measurements are also quantitative with a meaningful notion of distance between values and zero does have a true zero value. Most quantitative measurements are on a ratio scale. Examples of ratio variables include distance, length, weight, and height. Analysis of variance is generally appropriate when the response variable is ratio. All response variables used in this textbook will be quantitative, either interval or ratio.\n\nThe example toothbrush study, explained previously, wanted to determine if there were differences in plaque build-up when considering 4 different toothbrush types. Plaque build-up is a ratio scale measurement and would be the response variable for this study.\nAn example of a nominal scale to measure plaque build-up would be recording a “yes” if plaque was present, or “no” if plaque wasn’t present. This is a simple response variable, but not very informative. An improvement on this would be to classify each amount of plaque build-up into one of five groups: “no plaque”, “very little plaque”, “moderate plaque”, “heavy plaque”, and “complete plaque”. This would be an ordinal scale, and while it has more information than the nominal scale, it still is vaguely informative and not appropriate for analysis of variance.\nThe best measurement would be quantitative, either interval or ratio. By using red dye indicating the presence of plaque, an oral camera, and software, the percentage of the tooth area covered in plaque could be determined. This response variable would be a ratio scale and would provide much better information than the nominal or ordinal scales. When possible, it is best to have a response variable that is quantitative (interval or ratio).\n\n\nValidity\nA response variable needs to have a high degree of validity. Validity is the degree a study or a measure actually represents what it claims to represent. There are various types of validity (internal, external, construct, etc.) and various methods for checking validity, but we will talk about validity in general terms. How your response variable is defined can greatly affect its validity.\nFor example, if the response variable for an experiment was a person’s arithmetic skills we would need to carefully decide how that could be measured. If the questions used to assess the skills focused too heavily on addition and ignored subtraction, multiplication and division it may not be considered valid.\nAs another example, consider how validity of a measure (i.e. a survey question) may change when translated or applied to another culture. In some countries, socioeconomic status may be measured in number of lightbulbs in the home but for more developed countries that may not be a good measure. In some cultures frequency of reading the Holy Bible could be a measure of religiosity, but in other cultures that would have poor validity as a measure of religiosity.\nThe above examples deal with a latent (not directly observable) response such as arithmetic skills or religiosity. But validity should be a key consideration in all cases, even with observable responses. Converting your response variable into a measure of change, a rate, or a percentage may drastically change its validity.\nFor example, an experiment was conducted to study the effectiveness of different therapies at reducing pain. Rather than measure a patient’s pain after receiving the therapy, researchers can improve the validity by measuring pain before and after therapy. They can then define the response as the difference in pain rating. If pain after therapy is the response it may actually be reflecting a patients sensitivity to pain. By defining the response measure as the difference in pain ratings we can more accurately assess the therapy’s effectiveness.\nYou can take it one step further and convert the change into a percent change. A percent change is a great way to account for differences in the items/people in your study. In our toothbrush study, the effectiveness of a toothbrush is measured in terms of the area of the teeth with plaque. Since total teeth surface area varies from person to person, researchers decided to use the more valid response measure of percent of surface area with plaque.\nAs a final example, think back on the COVID pandemic. When comparing the severity of a COVID outbreak across different states, looking at the total number of COVID deaths can be a helpful measure. However, since states like California, New York and Texas have larger populations to begin with, a more valid measure might be to look at the deaths per 100,000 residents, a rate.\nWhen working with rates and percentages there are a couple of pitfalls to be aware of. First, if the quantity you are calculating a percent from is small, the percentage can be highly variable. For example, when comparing the effectiveness of a public health policy like mask wearing at reducing deaths due to COVID we could consider percent change as our variable. However, if the locale had only a couple of deaths to start with, then any change from that number will look extreme in percentage terms.\nSimpson’s Paradox1 is another phenomenon to be aware of when working with percentages. This occurs when the marginal percentages (or means) are different than the overall percentages. In other words, when the trend observed in small groups is different, even reversed, than the trend observed when all the data is looked at together.\n\n\nReliability\nReliability and validity are often discussed together. Reliability is a key characteristic of a response variable. High reliability means the measure will give the same value as a response if it is used in identical conditions. A measure that has a lot of random noise is not desirable. One source of noise in the response measure is variability in the Experimental Units. A response measure’s reliability can be improved by using homogeneous experimental units. However, uniformity in experimental units should not be pursued at the expense of a sample’s representativeness. Or in other words, the validity of a measure should not be sacrificed to increase its reliability.\n\n\n\n\n\n\nFootnotes\n\n\nMore reading about Simpson’s Paradox can be found here and here↩︎"
  },
  {
    "objectID": "sources_of_variances.html",
    "href": "sources_of_variances.html",
    "title": "Sources of Variation - Factors and Conditions",
    "section": "",
    "text": "Types of Variance\nAnalysis of variance, which is the statistical technique used in this course to analyze the data from an experiment, is just that, an analysis of the variances. There are three types of variance identified in an analysis of variance:\n\nthe total variation (the sum of the next two types: explained variations and unexplained variation),\nthe explained variation, of which each factor in the experimental design has a component,\nthe unexplained variation, usually one component consisting of variation due to random and unknown elements of the experimental design\n\nThe total variation is the variation that exists in the data measurements. This variance does not consider any knowledge about factors from the experimental design. It only measures the variance in the data values. The total variation is made up of two general variance components, the explained variation and the unexplained variation.\nThe degree to which the response variable changes in connection with a change in a controlled factor’s levels is called explained variance. If the value of the response varies substantially from one factor level to the next, then that factor is said to have a large explained variance. Or in other words, variability in the response can largely be explained by variation in the factor. If the explained variation is small for a factor, then the factor has little correlation with the response.\nThe unexplained variation considers all the variability in the response that is not explained by the controlled factors in the analysis. This variation is due to factors that are not known, not measured, and not controlled. If sufficient randomization has taken place in the experiment we generally assume that unexplained variation behaves randomly, without bias.\nWhen the unexplained variation is small, it makes the effect of the controlled factors easier to see. When the unexplained variation is large, it makes the effect of the controlled factors difficult to see. Therefore, it is important to identify the factors that can influence the data measurements. Once these factors are identified, there are two recommended courses of action: incorporate them into the study by measuring or controlling them, or deliberately hold them constant so they are not contributing more variability to the unexplained variation.\n\n\nSummary Table\n\n\n\n\n\n\n\nTypes of Factors\nRelationship to Variance\n\n\n\n\nControlled\nEnables calculation of explained variance\n\n\nHeld constant\nReduces total variance\n\n\nNot controlled, but measured\nCan reduce unexplained variance\n\n\nNot controlled, not measured\nSource of unexplained variance"
  },
  {
    "objectID": "testqmd.html",
    "href": "testqmd.html",
    "title": "Describing Data",
    "section": "",
    "text": "A section to reference another file\n\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nDP Example code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\nNew section\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output."
  },
  {
    "objectID": "testrmd.html",
    "href": "testrmd.html",
    "title": "Describing Data",
    "section": "",
    "text": "library(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nDP Example code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#overview",
    "href": "BasicFactorial_quarto_boat.html#overview",
    "title": "Basic Factorial",
    "section": "Overview",
    "text": "Overview\nIn a basic one-way factorial design (BF[1]), only one factor is purposefully varied. Each experimental unit is assigned to exactly one factor level. (In the case of an observational study, only one independent factor is under consideration.)\n\nFactor Structure\nThe factor structure for the model resulting from a completely randomized, one factor design is:\n\n\n\n\nFigure 1: Example of BF1 Factor Structure\n\n\n\nFigure 1 illustrates a factor with 4 levels, 6 replications at each level.\n\n\nHypothesis and Model\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from factor level \\(i\\)\n\\(\\mu\\): the grand mean of the data set.\n\\(\\alpha_i\\): effect of factor level \\(i\\)\n\\(\\epsilon_{ij}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its factor level mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\nAssumptions\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nRule of thumb comparing standard deviations\n\\(max(s) < 2*min(s)\\)\n\n\n\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#design",
    "href": "BasicFactorial_quarto_boat.html#design",
    "title": "Basic Factorial",
    "section": "Design",
    "text": "Design\nIn a one factor design, one factor is purposely varied and all other factors are controlled in order to isolate the effect of just the factor under study. Each level of the factor is considered a treatment.\nIn a completely randomized design, each experimental unit is randomly assigned to exactly 1 factor level. In this example we expect a balanced design (i.e. each factor level has the same number of observations) because the number of observations is a perfect multiple of the number of factor levels. To make random assignments, start by listing all the subjects, then listing the treatments, as seen below:\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n1\n\n\nSubject 2\nA\n2\n\n\nSubject 3\nB\n3\n\n\nSubject 4\nB\n4\n\n\nSubject 5\nC\n5\n\n\nSubject 6\nC\n6\n\n\n\nThen you randomly shuffle the treatment column. (You should also be paying attention to the order in which subjects and treatments are being experimented on as this could be a potential source of bias. In a BF[1], if it makes sense to do, you randomize the order also.) The result might look something like this.\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n4\n\n\nSubject 2\nB\n3\n\n\nSubject 3\nC\n6\n\n\nSubject 4\nC\n5\n\n\nSubject 5\nA\n1\n\n\nSubject 6\nB\n2\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nYou may notice in the above example that, even with randomization, treatment C occurs in the last 2 observations. If we were truly concerned about the order we could be more strategic and implement a blocked design to prevent “unlucky” ordering and pairing.\n\n\n\nLifeboat Training Example\nConsider the following example. An experiment was done to assess different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included:\n\nLecture/Materials (Control)\nMonitor/Keyboard\nHead Monitor Display/Joypad, and\nHead Monitor Display/Wearables.\n\nThe response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test). There is just one controlled factor, training method, which has 4 levels: the four training methods. An experimental unit in this study is each of the individuals being trained, 16 in all.\nWe want to assign each treatment to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\n\nCode\n#Repeat the sequence of 1 to 4, four times\nTreatment <- rep(1:4,4) \n\n#Create a sequence from 1 to 16\n#Paste the word \"Subject \" in front of each id #\nSubject <- paste(\"Subject\", seq(1:16), sep = \" \")\n\n#Combine the vector of treatment numbers and Subject ID's into 1 tibble/data frame\nassignment_table <- tibble(Subject, Treatment)\n\n#print the table, pander() makes it look nice\npander(assignment_table) \n\n\n\n\n\n\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\n\n\nThen we randomly shuffle the brush and paste column to get the following assignments. Check out the R-code to see how this is done.\n\n\nCode\n#set.seed() allows us to get the same random sample each time\nset.seed(42) \n\n#sample() will randomly select from the Treatment vector 16 times without replacement\n# %>% is called a pipe. It simply takes the output from the command on the left\n# and sends it to the command on the right\ntibble(Subject, sample(Treatment, 16)) %>% pander()\n\n\n\n\n\n\n\n\n\nSubject\nsample(Treatment, 16)\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n1\n\n\nSubject 3\n4\n\n\nSubject 4\n1\n\n\nSubject 5\n2\n\n\nSubject 6\n4\n\n\nSubject 7\n2\n\n\nSubject 8\n2\n\n\nSubject 9\n4\n\n\nSubject 10\n3\n\n\nSubject 11\n3\n\n\nSubject 12\n1\n\n\nSubject 13\n3\n\n\nSubject 14\n4\n\n\nSubject 15\n3\n\n\nSubject 16\n2\n\n\n\n\n\nWe can see here that subject 1 should get treatment 2. Subject 2 gets treatment 4, Subject 3 gets treatment 1, and so on."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#decomposition",
    "href": "BasicFactorial_quarto_boat.html#decomposition",
    "title": "Basic Factorial",
    "section": "Decomposition",
    "text": "Decomposition\nThis section serves as a bridge between the design and the analysis of an experiment. It is equivalent to doing the analysis by hand. The primary goal is to see how the design decisions impact the analysis; including a deeper understanding of what the numbers in an ANOVA table mean and how they are calculated.\nThe factor structure diagram of an experimental design is an effective way to organize and plan for the type of data needed for an experiment. Recall that in our lifeboat example there were four levels of training method with six replicates for each (the actual study used 16 observations per treatment). The diagram below gives the factor structure of the design, and the accompanying mathematical model.\n\n\n\n\nExample of BF1 Factor Structure\n\n\n\nA basic one-way factorial design has three analysis factors: the grand mean, treatment, and residual. The effects of these factors can be summed together to find each observed value.\n\nThe observed values on the left show that there are 24 distinct observations of performance score, represented by the 24 cells - one for each of the observed values.\nThe grand mean factor represents the grand mean. The single large cell indicates that there is only one grand mean and it is part of every observation.\nThe treatment factor involves the four methods of training, represented by the four vertically long cells. Each factor level may have a distinct mean and effect.\nThe residual error represents the difference between the observed value and the predicted value. The predicted value, also called the fitted value, is the sum of the grand mean and factor level effect. Each of the cells represent a distinct value for the residual error.\n\n\nDegrees of Freedom\nWe can use our understanding of inside vs. outside factors to determine the degrees of freedom (df) for the grand mean, treatment, and residual errors factors. We start with 24 observations - or pieces of information. In other words, we have 24 degrees of freedom that need to be allocated to the 3 factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf\\(_\\text{factor}\\) = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the lifeboat example, grand mean has one level (shown by the one cell in Figure 1) and there are no factors outside of grand mean. Therefore, its degrees of freedom equals one.\nRemember, the degrees of freedom represent the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as you estimate the grand mean for just one of the observations, you know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for the grand mean effect were also known. Therefore, there is just one unique piece of information in the grand mean factor. Grand mean has just 1 degree of freedom.\nFor treatment factor, there are four levels of the factor (shown by the four vertically long cells for treatment factor in Figure 1). Grand mean is the only factor outside of training method. Take the number of levels for training method (4) and subtract the degrees of freedom for grand mean (1), which yields 4-1 = 3 degrees of freedom for training method.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the training method effects really contain. Since all observations from the same training method will have the same effect, we only need to know 4 pieces of information: the effect of each training method. But the answer is actually less than that! Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom are 3. As soon as we know 3 of the effects for training method, we can fill in the training method effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of Figure 1). Both grand mean and training method are outside of the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for grand mean and training method (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the residual factor effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 levels of training method is 20 observations, or in other words, 20 degrees of freedom.\n\n\nFactor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size of the grand mean, training methods, and residual errors factors in the lifeboat training study. In other words, we can estimate the terms in the one-way ANOVA model.\n\n\n\n\n\n\nGeneral Rule for Effect Size\n\n\n\nEffect size = factor level mean - the sum of the effects of all outside factors\n\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the grand mean factor and the means for each level of training method.\nTo get the grand mean, average all 24 observations. The mean for all the observations is 6.5846. There is only one level for grand mean so this number is placed into each of the cells for the grand mean factor in Figure 2.\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. In Figure 2 these means are placed in the respective training method column.\nWe do not need to calculate means for residual error factor because for two reasons. First, there is only one observation per level of residual error, so the mean is the observation itself. Second, nothing is inside of residual error. It is the last step in the process and its mean is not needed to calculate factor effects.\n\n\n\n\nFigure 2: Raw data and means for grand mean and training factors\n\n\n\n\n\nCalculate effects\nNow that we have calculated means for each level of each factor, we can move on to calculate the effects of the factor levels. We will use the general formula for calculating effect size.\nFor the grand mean, there is only one level and there are no outside factors. Therefore, the effect due to grand mean is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nThe training method factor has four levels: one for each method. To calculate the effect of a training method, take the training method mean and subtract it from the effect due to the grand mean factor. For the “Control” method, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the grand mean. In a similar way you can find the effect for Monitor/Keyboard \\(7.8492 - 6.5846 = 1.2645\\). This means the student performance scores increased by 1.2645 on average in this training method compared to the grand mean. For Head Monitor Display/Joypad, the effect is \\(6.5789 - 6.5846 = -0.0058\\). For Head Monitor Display/Wearables the effect is \\(7.1616 - 6.5846 = 0.5770\\) (see below).\n\n\n\n\nFigure 3: Training Method Effects\n\n\n\nTo calculate the residual error effects remember that there are 24 levels of the residual error factor. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for grand mean and the effect for whichever training method that particular observation received. For instance, for the observation located in the top left of our data set the value is 4.5614. Subtract the sum of the effects of outside factors (grand mean and training). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual error effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was 0.1875 less than the mean of the control group. This individual’s performance was lower than the mean of his/her peers who received the same type of training.\nWe can repeat the residual calculation for the first observation in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to grand mean and its respective training (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in Figure 4.\n\n\n\n\nFigure 4: Residual Effects\n\n\n\n\n\n\nCompleting the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA summary table contains the information we need for a hypothesis test of a treatment factor.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n     \n     \n     \n     \n  \n  \n    Factor \n    3 \n     \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n     \n     \n     \n     \n  \n  \n    Total \n    24 \n     \n     \n     \n     \n  \n\n\n\n\n\nTo get the sum of squares (SS) for a factor, for each observation the effect for that factor first needs to be squared. Then all the squared values are summed up to get the sum of squares.\nFor grand mean, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to grand mean.\n\\[\nSS_\\text{Grand Mean} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor, training method, has four different effects: one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to training method For instance, for the control group, the effect is -1.8358. The value is then squared, and then multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Factor} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the grand mean factor, treatment factor, and residual error factor.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    1040.57 \n     \n     \n     \n  \n  \n    Factor \n    3 \n    31.81 \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n     \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWe can now calculate the mean squared error column, or mean square (MS), by dividing the sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total (the sum of squares) into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation). The MS is calculated in this manner for each of the effects.\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. This works when looking at SS, since it is the total variance due to each factor. MS is then the average variability for each effect. We can then see clearly which factor is a bigger source of variability by comparing their mean squares.\nThe mean square calculations are:\n\\[\nMS_\\text{Grand Mean} = \\frac{SS_\\text{Grand Mean}}{df_\\text{Grand Mean}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Factor} = \\frac{SS_\\text{Factor}}{df_\\text{Factor}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Factor \n    3 \n    31.81 \n    10.60 \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nThe treatment factor, in this case training method, is the primary factor of interest so the F test statistic is only calculated for that factor. To get the F test statistic for the treatment factor take the mean square (MS) due to treatment factor and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of this as calculating the variance in treatment means for the numerator and the variance of the distances for an observed value to its respective treatment mean in the denominator. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Factor} = \\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for the treatment factor is calculated based on the F statistic and the degrees of freedom for both treatment factor and residual error. In practice, statistical software computes all the components of the ANOVA table, including the p-value. To complete the decomposition of variance in a manual way, the p-value is calculated in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to the treatment factor are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Factor \n    3 \n    31.81 \n    10.60 \n    2.11 \n    0.131 \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87"
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#analysis-in-r",
    "href": "BasicFactorial_quarto_boat.html#analysis-in-r",
    "title": "Basic Factorial",
    "section": "Analysis in R",
    "text": "Analysis in R\nWe will illustrate the R code using the lifeboat launch training example with just 6 observations per training method.\n\nDescribe the Data\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots or scatterplots with the means displayed.\nInteractive code and additional explanations of numerical summaries and plots in R are found at R Instructions->Descriptive Summaries section of the book.\n\nNumerical Summaries\n\n\n\nAfter loading required packages, we will read in the data and do some wrangling.\n\n\nCode\n## Reduced data to match decomposition example\nvirtual <- read_csv(\"data/virtual_training_redux.csv\") \n\n#A bit of data wrangling\nvirtual <- virtual |>\n   mutate(\n         Treatment = case_when(\n           grp.trt %in% 1  ~ \"Control\",\n           grp.trt %in% 2  ~ \"Monitor/Keyboard\",\n           grp.trt %in% 3  ~ \"Joypad\",\n           grp.trt %in% 4  ~ \"Wearables\"\n          )\n        )\n\n\nWe then calculate summary statistics for each level of training method, in Table 1. Monitor/Keyboard has the highest mean (7.16) and median (8.33). It appears to be the best training method. Our ANOVA will seek to know if differences between training methods are statistically significant.\n\n\nCode\nfavstats(procKnow~Treatment, data = virtual) |> \n  kable(digits = 2) |> \n  kable_styling(full_width = TRUE)\n\n\n\nTable 1:  Numerical Summary \n \n  \n    Treatment \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    Control \n    0.33 \n    4.64 \n    5.25 \n    6.24 \n    6.66 \n    4.75 \n    2.32 \n    6 \n    0 \n  \n  \n    Joypad \n    1.88 \n    6.25 \n    6.61 \n    8.25 \n    9.45 \n    6.58 \n    2.65 \n    6 \n    0 \n  \n  \n    Monitor/Keyboard \n    5.45 \n    6.78 \n    8.33 \n    8.78 \n    9.78 \n    7.85 \n    1.65 \n    6 \n    0 \n  \n  \n    Wearables \n    4.94 \n    5.21 \n    7.03 \n    8.91 \n    9.83 \n    7.16 \n    2.22 \n    6 \n    0 \n  \n\n\n\n\n\n\n\n\nGraphical Summaries\nYou should also visualize the data. Since there are only six data point, a scatter plot may be preferred over a boxplot.\n\n\nCode\nggplot(data = virtual, \n       mapping = aes(x=Treatment, y = procKnow, group = 1)) +\n  geom_point() +\n  stat_summary(fun = mean, \n               geom= \"line\") +\n  labs(x = \"Training Method\", y = \"Process Knowledge Test Score\",\n       title = \"Process Knowledge Scores by Training Method\",\n       subtitle = \"Group Means Connected with a Line\")\n\n\n\n\n\nFigure 5: Graphical Summary\n\n\n\n\nThis plot reinforces the conclusion that Monitor/Keyboard tends to have higher scores. The outliers in the Control and Joypad method also become very apparent.\n\n\n\nCreate the Model\nYou then create the model using the aov() function. To see results of the F-test you can feed your model into a summary() function.\n\nmyaov <- aov(Y ~ X, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is the user defined name in which the results of the aov() model are stored\nY is the name of a numeric variable in your dataset which represents the quantitative response variable.\nX is the name of a qualitative variable in your dataset. It should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\nYourDataSet is the name of your data set.\n\nExample Code\n\n\n method_aovA name you come up with for your model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  procKnow The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Treatment, The independent variable containing the names for the 4 training methods  data = virtual Tell the model to look in the dataset named “virtual” for procKnow and Treatment variables  ) Functions always end with a closing parenthesis  summary( Give important information about an object. When called on an aov object the default is to print the ANOVA summary table  method_aov  Whatever you named your ANOVA model in the previous line   )  Functions always end with a closing parenthesis  Click to toggle output Click to toggle output. \n\n\n\n\n\n            Df Sum Sq Mean Sq F value Pr(>F)\nTreatment    3  31.81  10.604   2.111  0.131\nResiduals   20 100.49   5.024               \n\n\n\nWe then interpret the results. Training method does not appear to be a significant factor since the p-value (0.131) is higher than our significance level of 0.05. Therefore, we cannot conclude that one training method results in a better mean test score than another.\n\n\nCheck assumptions\nNow that the model is created the assumptions need to be checked. Interactive code and additional explanation for assumption checking can be found in the Model Diagnostics and Assumptions sections of the book respectively.\nBelow, we find that all assumptions of our lifeboat training method model are met and we can trust the hypothesis test that was just conducted.\n\nConstant Variance\nWe first check to see if the levels of training method have constant variance. The points in Figure 5 have similar spread, with the exception of the particularly low outlier scores in the Control and Joypad groups. Furthermore, in Table 1 we see that the largest standard deviation (2.65 for Joypad) is not more than double the smallest standard deviation (1.65 for Monitor/Keyboard). Therefore, the assumption of constant variance appears to be met.\n\n\nNormally Distributed Residuals\nA QQ-plot of the residuals is shown in Figure 6. Since none of the points are outside of the boundary it is safe to conclude that residuals are normally distributed.\n\n\n\n\n\nCode\ncar::qqPlot(method_aov$residuals)\n\n\n[1] 13  6\n\n\n\n\n\nFigure 6: QQplot of Model Residuals\n\n\n\n\n\n\nIndependent Observations\nNothing about the study suggests a lack of independence among the residuals. The data was obtained second hand. If possible, you should ask the principal researcher more about how the data was collected. For our purposes, we will assume the row number in the dataset does not represent the order in which the data was originally collected. Therefore, an order plot would not be helpful in detecting order bias. Thus, based on everything we know about the study, we have no reason to suspect the independent residuals assumption is violated."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#resources",
    "href": "BasicFactorial_quarto_boat.html#resources",
    "title": "Basic Factorial",
    "section": "Resources",
    "text": "Resources\n\nExamples\nLifeboat launch training with a full dataset\nMosquito\n\n\nLinks to outside resources\nPopulate this section yourself with links to good examples, definitions, other sections within this textbook, or anything else you think will be interesting/helpful."
  },
  {
    "objectID": "hoveRmd/BF1_R_Instructions_boat.html",
    "href": "hoveRmd/BF1_R_Instructions_boat.html",
    "title": "BF1 R Instructions",
    "section": "",
    "text": "Df Sum Sq Mean Sq F value Pr(>F)\nTreatment    3  31.81  10.604   2.111  0.131\nResiduals   20 100.49   5.024"
  },
  {
    "objectID": "bf2.html#interaction-effect",
    "href": "bf2.html#interaction-effect",
    "title": "BF[2]",
    "section": "Interaction Effect",
    "text": "Interaction Effect\nThe purpose of this section is to define an interaction, introduce interaction graphs, explain how to interpret interaction graphs to detect interactions, and provide helpful hints in working with interactions.\nThe terms in Equation 1 that represent the marginal effects of the controlled factors in the experiment are referred to as main effects. In this case \\(\\alpha\\) and \\(\\beta\\) are the main effects for toothbrush and toothpaste respectively.\nThe factor created by crossing toothbrush and toothpaste is called an interaction factor, and its term in the model, \\(\\alpha \\beta\\), is called an interaction effect.\nCompared to a BF[1], the novel piece of a BF[2] is the interaction factor. This factor allows us to estimate the interaction effect, which is the effect of belonging to a particular factor level combination. Stated another way, the interaction effect is the additional change in the response (positive or negative) when the two factor levels happen together, beyond the effect of each factor level in isolation.\nBMOVE THIS PARAGRAPH TO DECOMPOSITION SOMEHWERE?? There is an old saying, “the whole is greater than the sum of its parts”. In a way, the interaction effect is the measure of how much greater. After summing the effects of each controlled factor, the remaining distance to the mean of the observations belonging to a particular combination of factor levels is the interaction effect.\n\n\n\n\n\n\nTip\n\n\n\nWhen an interaction is present this means that a factor level’s effect on the response depends on the value of another factor.\n\n\nWe will discuss interactions at a conceptual level before dealing with numbers and the nuts and bolts of calculations. To facilitate this conceptual discussion we will step away from the toothbrush example and use an example for which you have not yet seen any data. We will return to toothbrushes and toothpaste at the end of the conceptual explanation.\n\nConceptual Understanding\nThe concept behind an interaction should feel quite familiar. It is something we deal with everyday and is very common in science. You may have experienced an interaction effect in something as simple as your daily commute:\n\nConsider a factor to indicate which route you take to work. Route has two levels: using the main roads and using back roads. The time to reach your destination is the response. During rush hour, the main roads are clogged with traffic and result in a longer commute time than taking the back roads. However, in non-rush hour times, the main roads result in a faster commute time. Thus, the effect of taking main roads depends on whether you are traveling during rush hour or not.\n\nThe effect of route was reversed for different levels of rush hour. Not all interactions work this way. Some interactions increase/decrease the magnitude of an effect without completely changing its direction. We can tweak the situation of the commute time example to illustrate this:\n\nDuring non-rush hour periods, on average back roads result in a commute time that is 5 minutes faster than main roads. During rush hour periods however, the benefit of taking back rounds compared to main roads increases to 15 minutes. Thus, the size of the effect of back roads increased (is amplified) for rush hour compared to non-rush hour.\n\nThe above descriptions cover just two possible outcomes for this commute time experiment. It may be helpful to visualize the possible outcome scenarios for this two factor (route and rush hour) study. This can effectively be done with an interaction plot. An interaction plot shows the means for each factor level combination and usually connects the means from the same factor level with a line to help the reader visually group means and detect effects.\nFigure 2 shows four possible outcomes of the traffic study where NO interaction is present. The upper left panel of the plot shows a situation where there are no main effects or interactions apparent. The mean is the same regardless of the factor level combination. The upper right panel of the plot shows a large route effect but no effect due to rush hour. This can be seen because the commute time for back roads is high but commute time for main roads is low; however, for a given route there is no difference in the mean for rush hour vs. not rush hour.\nThe bottom left panel shows a non-zero effect for the rush hour factor, as seen by the sizable difference between the levels of rush hour within a route. However, the flat lines indicate that the mean commute time for route is not changing and therefore route has no effect on commute time. Lastly, the bottom right panel is a situation where both main effects appear to be present - but there is still no interaction apparent.\n\n\nR code instructions to create interaction plots are at the bottom of the R Instructions>Descriptive Summaries page.\n\n\n\n\n\n\n\n\nFigure 2: Scenarios with NO Interaction Present\n\n\n\n\nThe line segments within each graph of Figure 2 are parallel (or coincide), which is a visual indicator that no interaction is present.\n\n\n\n\n\n\nTip\n\n\n\nFactors with no interaction will have (nearly) parallel line segments in the interaction plot.\n\n\nSo what does an interaction plot look like when there is an interaction present? The key things to notice is that the line segments in the plot are not parallel. Figure 3 contains 3 examples of interaction plots that show the presence of an potential interaction.\n\n\n\n\n\n\n\n\nFigure 3: Scenarios Indicative of an Interaction\n\n\n\n\nPanel A of Figure 3 illustrates an example where the effect of Route reverses, depending on the value for Rush Hour. In Panel B, the effect of Rush Hour is much greater when using main roads than for back roads. In Panel C, main roads take longer regardless of time of day, but the effect of switching from back roads to main roads is much larger during rush hour than in non-rush hour times.\nThere are a few key points to remember when working with interactions.\nLastly, exercise caution when interpreting a main effect if an interaction is present. The definition of an interaction is that a factor level’s effect changes for different values of the other factor. Therefore, it does not make sense to interpret the hypothesis test of a controlled factor if it is part of a significant interaction. Instead, get in the habit of describing the nature of the interaction.\nTo illustrate the danger of interpreting main effect hypothesis tests when the interaction is significant consider Panel A of Figure 3. If the hypothesis test for Route had a large p-value, it is tempting to say there is insufficient evidence that Route has an effect on commute time. However, the interaction plot shows quite the opposite. Route has an important effect on the response, since the level of Route drastically changes the impact of Rush Hour on commute times. Even though the mean commute time for “back” and “main” may be similar in this scenario, Route is indirectly having an effect on commute time through its interaction with Rush Hour.\nConversely, imagine a scenario where Route’s main effect had a small p-value and the Route - Rush Hour interaction was also significant. If the interaction is like that depicted in Panel C of Figure 3, simply stating that Route is a significant factor does not tell the whole story. The effect of Route in during rush hour is large and may be significant (steep blue line), but the effect of Route in non-rush hour times may not be large enough to reach significance (the nearly flat red line).\n\n\n\n\n\n\nWhich of these two sentences do you like better??\n\n\n\nWhen a significant interaction is present, do not interpret the hypothesis tests of its main effects without providing additional information.\nIn the case of a significant interaction, do not interpret its main effect hypothesis tests without providing additional information.\n\n\nSecond, don’t rely on interaction plots alone to detect the presence/absence of interactions. Though interaction plots are a a helpful tool, they do not adequately show the repsonse variability in each factor level combination. In other words, even when line segments are not parallel a hypothesis test is still needed to determine if an interaction is real or just due to random error. Furthermore, two lines may look nearly parallel but could actually represent a significant interaction.\nLastly, beware of a common mistake that students make. Students commonly state an interaction means that the level of one factor affects the values of another factor. This is a lie from Satan! The key misunderstanding here is thinking that the value of one factor affects the other factor. In reality, it is the factor’s effect on the response that changes for different levels of the other factor. The two factors do not affect each other."
  },
  {
    "objectID": "bf2.html",
    "href": "bf2.html",
    "title": "BF[2]",
    "section": "",
    "text": "When researchers want to study the effects of two factors on the same response variable a factorial design can be considered. Factorial experiments involve two or more factors that are crossed.\n\n\n\n\n\n\nTip\n\n\n\nFull factorial crossing occurs when each combination of factor levels is present in the study.\n\n\nCompare a factorial design with the one-at-a-time approach. In a one-at-a-time approach, each factor would be investigated in a separate experiment. Each experiment would evaluate the effect of just one factor on the response.\nFactorial designs are a way to simultaneously study the effects of multiple factors using just one experiment. Factorial designs have a couple of major advantages over one-factor-at-a-time studies.\n\nThey are a more efficient use of our time and material: I can get information about both of my factors from just one observation\nThey allow the random error to be allocated across a greater number of factors, thereby reducing unexplained variance (i.e. mean square error) and increasing the statistical power of the F-test.\nThey allow the estimation of interaction effects. Or in other words, we can observe how one factor’s effect on the response changes for different levels of the other factor.\n\nWe will expand on the simple toothpaste example to illustrate BF[2] concepts. The study is summarized here.\nResearchers wanted to know which of 4 types of toothbrushes was best at reducing plaque: manual (this is the traditional/usual type of brush), oscillating bristles, sonic, and ultrasonic. The response variable is was the percent of teeth surface area covered with plaque. Four teeth (first molar in each quadrant of the mouth) were measured on each person to calculate the total percent area covered. Six subjects were assigned to each type of brush.\nResearchers also wanted to study the effect of name brand tooth paste compared to its off brand equivalent. This is the second controlled factor in the experiment. It has two levels (name brand and off brand). Twelve subjects used name brand paste, and a different 12 subjects used the off brand. Toothpaste brand is crossed with toothbrush type to create a BF[2].\n\n\nBased on the description above, the factor structure for this experiment is displayed in Figure 1:\n\n\n\n\nFigure 1: Factor Structure Diagram\n\n\n\nThere are 3 replicates for each factor level combination of toothbrush and toothpaste brand. Two levels of toothpaste multiplied by 4 levels of toothbrush results in 8 factor level combinations total. These 8 factor level combinations are obtained by overlaying the 2 controlled factor partitions. When the controlled factor brush and paste partitions are overlayed, they cross each other and create new, meaningful partitions. Since there were 24 subjects and the study is balanced, we end up with \\(24\\div 8 = 3\\) replicates in each factor level combination.\n\n\n\nEach factor (i.e. meaningful partition of the data) in Figure 1 corresponds to a term in Equation 1:\n\\[\ny_\\text{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_\\text{ij} + \\epsilon_\\text{ijk}\n\\qquad(1)\\]\nWhere\n\n\\(\\alpha\\) is the effect of toothbrush, and \\(i\\) goes from 1 to 4 since there are 4 toothbrush types\n\\(\\beta\\) is the effect of toothpaste, and \\(j\\) is either 1 or 2 since there are 2 levels (Name brand and off brand).\nThe \\((\\alpha\\beta)_\\text{ij}\\) is called the interaction effect.\n\\(\\epsilon\\) is the residual error term, and \\(k\\) is the replicate count within a factor level combination.\n\nThere are at least three hypotheses to test with this model. A hypothesis for each main effect, and a hypothesis for the interaction effect.\nA hypothesis for the main effect of toothbrush type:\n\\[H_0: \\alpha_\\text{i} = 0 \\text{ for all } i\\]\n\\[H_a: \\alpha_\\text{i} \\ne 0 \\text{ for some } i\\]\nA hypothesis for the main effect of toothpaste brand:\n\\[H_0: \\beta_\\text{j} = 0 \\text{ for all } j\\]\n\\[H_a: \\beta_\\text{j} \\ne 0 \\text{ for some } j\\]\nA hypothesis for the interaction of toothbrush and toothpaste.\n\\[\nH_0: (\\alpha\\beta)_\\text{ij} = 0 \\text{ for all } ij\n\\] \\[\nH_a: (\\alpha\\beta)_\\text{ij} \\ne 0 \\text{ for some } ij\n\\]\nWhen the interaction term is not significant a predicted value for an observation can be obtained by simply adding the grand mean to the main effects \\(\\hat{\\alpha}_i\\) and \\(\\hat{\\beta}_j\\). This is equivalent to treating the effect of \\((\\alpha\\beta)_\\text{ij} = 0\\) for all values of \\(i\\) and \\(j\\).\nWhen the interaction effect is significant reject the null hypothesis and accept the alternative hypothesis: at least one factor level combination has a none zero effect.\n\n\n\nA two-way ANOVA model may be used to analyze data from a BF[2] design if the following requirements are satisfied. Note that these requirements are identical to the requirements of a BF[1] one-way ANOVA.\n\n\nThe BF[] designation refers to the design of the experiment. The reference to one- or two-way ANOVA refers to the analysis technique applied to the resulting data.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nRule of thumb comparing standard deviations\n\\(max(s) < 2*min(s)\\)\n\n\n\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "bf2.html#decomposition",
    "href": "bf2.html#decomposition",
    "title": "BF[2]",
    "section": "Decomposition",
    "text": "Decomposition\nSo far, we have been discussing the concept of interaction without doing any calculation or using specific numbers. Let’s return to our BF[2] experiment using toothbrush type and toothpaste brand as independent factors, and percent plaque coverage as the response. We will use this data to show how to calculate interaction effects, as well as main effects.\nWe will then continue on to complete the decomposition of variance and preform an F-test.\nAs was just mentioned, there are 2 controlled factors: toothbrush type (4 levels) and toothpaste brand (2 levels). A third factor, the interaction, is obtained by crossing the two controlled factors. In terms of the factor diagram, factors are crossed by overlaying the partition lines for the two factors to create new partitions that are also meaningful (see Factor Structure for a review). Figure 4 shows the 3 structural factors for a BF[2].\n\n\n\nFigure 4: 3 structural factors\n\n\nTo get a full structure diagram, as shown in Figure 5 we must also include the universal factors for the grand mean and residuals.\n\n\n\nFigure 5: Factor Structure Diagram\n\n\nEach factor in the diagram corresponds to a term in Equation 2:\n\\[\ny_\\text{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_\\text{ij} + \\epsilon_\\text{ijk}\n\\qquad(2)\\]\nWhere\n\n\\(\\alpha\\) is the effect of toothbrush, and \\(i\\) goes from 1 to 4 since there are 4 toothbrush types\n\\(\\beta\\) is the effect of toothpaste, and \\(j\\) is either 1 or 2 since there are 2 levels (Name brand and off brand).\nThe \\((\\alpha\\beta)_\\text{ij}\\) is called the interaction effect.\n\\(\\epsilon\\) is the residual error term, and \\(k\\) is the replicate count within a factor level combination.\n\nA decomposition of the data allows is how we estimate these model parameters.\n\n\n\n\n\n\nBalanced vs. Unbalanced Data\n\n\n\nThe formulas and decomposition presented here are for balanced data, where the number of replicates at each factor level combination is the same. In the case of unbalanced data with interaction effects, decisions must be made about how to allocate sums of squares. How to deal with this situation, including R code, is explained in the Unbalanced page under Broad Topics.\n\n\n\nFactor Effects\nHow can an interaction affect be estimated? Like all factor effects, its estimate is calculated using the general rule.\n\n\n\n\n\n\nGeneral Rule for Calculating Factor Level Effect\n\n\n\nFactor level effect = mean of the factor level - Sum(effects of all outside factors)\n\n\nFrom the general rule we can see that before we estimate the interaction effect we first need to estimate the outside factor effects (i.e. main effects). Factor level means need to be calculated in order to calculate estimated effects.\nIt is also important to recall that the grand mean factor is outside of all other factors, while the residual error factor is inside of all other factors.\n\nFactor Level Means\nFigure Figure 6 shows our data set with partition lines for structural factors in place. We will now proceed to calculate the factor level means for each factor.\n\n\n\nFigure 6: Full data set with partitions\n\n\nThe grand mean is the mean of all the observations:\n\\[\n\\hat{\\mu} = \\bar{y}_\\cdots = \\frac{19.12 + 18.56 + 25.58 + 24.39 + 24.21 + ... + 23.42}{24} = 22.76\n\\]\nNow find the mean for each level of toothbrush type.\n\\[\n\\bar{y}_\\text{manual} = \\bar{y}_{1\\cdot\\cdot} = \\frac{19.12 + 24.21 + 26.88 + 21.6 + 23.4 + 23.35}{6} = 23.10\n\\] \\[\n\\bar{y}_\\text{oscillating} = \\bar{y}_{2\\cdot\\cdot} = \\frac{18.56 + 20.00 + 19.87 + 22.09 + 17.62 + 21.72}{6} = 19.98\n\\] \\[\n\\bar{y}_\\text{sonic} = \\bar{y}_{3\\cdot\\cdot} = \\frac{25.58 + 23.31 + 18.99 + 23.09 + 23.81 + 21.27}{6} = 22.68\n\\] \\[\n\\bar{y}_\\text{ultrasonic} = \\bar{y}_{4\\cdot\\cdot} = \\frac{24.39 + 21.45 + 32.74 + 24.21 + 25.67 + 23.42}{6} = 25.31\n\\]\nNow find the mean for each level of toothpaste brand.\n\\[\n\\bar{y}_\\text{name brand} = \\bar{y}_{\\cdot 1 \\cdot} = \\frac{19.12 + 18.56 + \\cdots + 18.99 + 32.74}{12} = 22.93\n\\] \\[\n\\bar{y}_\\text{off brand} = \\bar{y}_{\\cdot 2 \\cdot} = \\frac{21.60 + 22.09 + \\cdots + 21.27 + 23.42}{12} = 22.60\n\\]\nThere are 8 different combinations of toothbrush type and toothpaste, so the interaction factor has 8 levels total. We calculate a mean for each one, but will only show the calculation for the first 3.\n\\[\n\\bar{y}_\\text{manual and name brand} = \\bar{y}_{11\\cdot} = \\frac{19.12 + 24.21 + 26.88}{3} = 23.40\n\\] \\[\n\\bar{y}_\\text{manual and off brand} = \\bar{y}_{12\\cdot} = \\frac{21.60 + 23.40 + 23.35}{3} = 22.78\n\\] \\[\n\\bar{y}_\\text{oscillating and name brand} = \\bar{y}_{21\\cdot} = \\frac{18.56 + 20.00 + 19.87}{3} = 19.48\n\\]\nThe means for the residual error factor levels is the observed value itself since there is just 1 observation per level. Therefore, there are no calculations to show.\nFigure 7 displays all the factor level means inside the factor structure.\n\n\n\n\nFigure 7: Factor level means\n\n\n\n\n\n\nDegrees of Freedom\n\n\nCompleting the ANOVA Table"
  },
  {
    "objectID": "bf2.html#design",
    "href": "bf2.html#design",
    "title": "BF[2]",
    "section": "Design",
    "text": "Design"
  },
  {
    "objectID": "bf2.html#appendix",
    "href": "bf2.html#appendix",
    "title": "BF[2]",
    "section": "Appendix",
    "text": "Appendix\n\nNotation for Estimated Effects\nHere are symbolic representations for the estimated effects in the BF[2] model, as shown in Equation 1.\n\\[\n\\hat{\\alpha}_i = \\bar{y}_{i \\cdot \\cdot} - \\bar{y}_{\\cdots}\n\\] \\[\n\\hat{\\beta}_j = \\bar{y}_{\\cdot j \\cdot} - \\bar{y}_{\\cdots}\n\\] \\[\n\\begin{align}\n\\hat{\\alpha}\\hat{\\beta}_{ij} & = \\bar{y}_{i j \\cdot} - (\\bar{y}_{\\cdot \\cdot \\cdot} + \\hat{\\alpha}_i  + \\hat{\\beta}_j ) \\\\\n&= \\bar{y}_{i j \\cdot} - (\\bar{y}_{\\cdot \\cdot \\cdot} + (\\bar{y}_{i \\cdot \\cdot} - \\bar{y}_{\\cdot \\cdot \\cdot})  + (\\bar{y}_{\\cdot j \\cdot} - \\bar{y}_{\\cdot \\cdot \\cdot}) ) \\\\\n& = \\bar{y}_{i j \\cdot} - (\\bar{y}_{i \\cdot \\cdot} + \\bar{y}_{\\cdot j \\cdot} - \\bar{y}_{\\cdot \\cdot \\cdot})\n\\end{align}\n\\]\n\n\nUnreplicated or Single Observation per Cell\nWhat can be done in the case of an experiment where there is only one observation per factor level combination?\nUnder construction."
  },
  {
    "objectID": "bf2.html#conceptual-understanding",
    "href": "bf2.html#conceptual-understanding",
    "title": "BF[2]",
    "section": "Conceptual Understanding",
    "text": "Conceptual Understanding\nThe concept behind an interaction should feel quite familiar. It is something we deal with everyday and is very common in science. You may have experienced an interaction effect in something as simple as your daily commute:\n\nConsider a factor to indicate which route you take to work. Route has two levels: using the main roads and using back roads. The time to reach your destination is the response. During rush hour, the main roads are clogged with traffic and result in a longer commute time than taking the back roads. However, in non-rush hour times, the main roads result in a faster commute time. Thus, the effect of taking main roads depends on whether you are traveling during rush hour or not.\n\nThe effect of route was reversed for different levels of rush hour. Not all interactions work this way. Some interactions increase/decrease the magnitude of an effect without completely changing its direction. We can tweak the situation of the commute time example to illustrate this:\n\nDuring non-rush hour periods, on average back roads result in a commute time that is 5 minutes faster than main roads. During rush hour periods however, the benefit of taking back rounds compared to main roads increases to 15 minutes. Thus, the size of the effect of back roads increased (is amplified) for rush hour compared to non-rush hour.\n\nThe above descriptions cover just two possible outcomes for this commute time experiment. It may be helpful to visualize the possible outcome scenarios for this two factor (route and rush hour) study. This can effectively be done with an interaction plot. An interaction plot shows the means for each factor level combination and usually connects the means from the same factor level with a line to help the reader visually group means and detect effects.\nFigure 2 shows four possible outcomes of the traffic study where NO interaction is present. The upper left panel of the plot shows a situation where there are no main effects or interactions apparent. The mean is the same regardless of the factor level combination. The upper right panel of the plot shows a large route effect but no effect due to rush hour. This can be seen because the commute time for back roads is high but commute time for main roads is low; however, for a given route there is no difference in the mean for rush hour vs. not rush hour.\nThe bottom left panel shows a non-zero effect for the rush hour factor, as seen by the sizable difference between the levels of rush hour within a route. However, the flat lines indicate that the mean commute time for route is not changing and therefore route has no effect on commute time. Lastly, the bottom right panel is a situation where both main effects appear to be present - but there is still no interaction apparent.\n\n\nR code instructions to create interaction plots are at the bottom of the R Instructions>Descriptive Summaries page.\n\n\n\n\n\n\n\n\nFigure 2: Scenarios with NO Interaction Present\n\n\n\n\nThe line segments within each graph of Figure 2 are parallel (or coincide), which is a visual indicator that no interaction is present.\n\n\n\n\n\n\nTip\n\n\n\nFactors with no interaction will have (nearly) parallel line segments in the interaction plot.\n\n\nSo what does an interaction plot look like when there is an interaction present? The key things to notice is that the line segments in the plot are not parallel. Figure 3 contains 3 examples of interaction plots that show the presence of an potential interaction.\n\n\n\n\n\n\n\n\nFigure 3: Scenarios Indicative of an Interaction\n\n\n\n\nPanel A of Figure 3 illustrates an example where the effect of Route reverses, depending on the value for Rush Hour. In Panel B, the effect of Rush Hour is much greater when using main roads than for back roads. In Panel C, main roads take longer regardless of time of day, but the effect of switching from back roads to main roads is much larger during rush hour than in non-rush hour times.\nThere are a few key points to remember when working with interactions.\nLastly, exercise caution when interpreting a main effect if an interaction is present. The definition of an interaction is that a factor level’s effect changes for different values of the other factor. Therefore, it does not make sense to interpret the hypothesis test of a controlled factor if it is part of a significant interaction. Instead, get in the habit of describing the nature of the interaction.\nTo illustrate the danger of interpreting main effect hypothesis tests when the interaction is significant consider Panel A of Figure 3. If the hypothesis test for Route had a large p-value, it is tempting to say there is insufficient evidence that Route has an effect on commute time. However, the interaction plot shows quite the opposite. Route has an important effect on the response, since the level of Route drastically changes the impact of Rush Hour on commute times. Even though the mean commute time for “back” and “main” may be similar in this scenario, Route is indirectly having an effect on commute time through its interaction with Rush Hour.\nConversely, imagine a scenario where Route’s main effect had a small p-value and the Route - Rush Hour interaction was also significant. If the interaction is like that depicted in Panel C of Figure 3, simply stating that Route is a significant factor does not tell the whole story. The effect of Route in during rush hour is large and may be significant (steep blue line), but the effect of Route in non-rush hour times may not be large enough to reach significance (the nearly flat red line).\n\n\n\n\n\n\nWhich of these two sentences do you like better??\n\n\n\nWhen a significant interaction is present, do not interpret the hypothesis tests of its main effects without providing additional information.\nIn the case of a significant interaction, do not interpret its main effect hypothesis tests without providing additional information.\n\n\nSecond, don’t rely on interaction plots alone to detect the presence/absence of interactions. Though interaction plots are a a helpful tool, they do not adequately show the repsonse variability in each factor level combination. In other words, even when line segments are not parallel a hypothesis test is still needed to determine if an interaction is real or just due to random error. Furthermore, two lines may look nearly parallel but could actually represent a significant interaction.\nLastly, beware of a common mistake that students make. Students commonly state an interaction means that the level of one factor affects the values of another factor. This is a lie from Satan! The key misunderstanding here is thinking that the value of one factor affects the other factor. In reality, it is the factor’s effect on the response that changes for different levels of the other factor. The two factors do not affect each other."
  },
  {
    "objectID": "bf2.html#factor-effects",
    "href": "bf2.html#factor-effects",
    "title": "BF[2]",
    "section": "Factor Effects",
    "text": "Factor Effects\nHow can an interaction affect be estimated? Like all factor effects, its estimate is calculated using the general rule.\n\n\n\n\n\n\nGeneral Rule for Calculating Factor Level Effect\n\n\n\nFactor level effect = mean of the factor level - Sum(effects of all outside factors)\n\n\nFrom the general rule we can see that before we estimate the interaction effect we first need to estimate the outside factor effects (i.e. main effects). Factor level means need to be calculated in order to calculate estimated effects.\nIt is also important to recall that the grand mean factor is outside of all other factors, while the residual error factor is inside of all other factors.\n\nFactor Level Means\nFigure Figure 6 shows our data set with partition lines for structural factors in place. We will now proceed to calculate the factor level means for each factor.\n\n\n\nFigure 6: Full data set with partitions\n\n\nThe grand mean is the mean of all the observations:\n\\[\n\\hat{\\mu} = \\bar{y}_\\cdots = \\frac{19.12 + 18.56 + 25.58 + 24.39 + 24.21 + ... + 23.42}{24} = 22.76\n\\]\nNow find the mean for each level of toothbrush type.\n\\[\n\\bar{y}_\\text{manual} = \\bar{y}_{1\\cdot\\cdot} = \\frac{19.12 + 24.21 + 26.88 + 21.6 + 23.4 + 23.35}{6} = 23.10\n\\] \\[\n\\bar{y}_\\text{oscillating} = \\bar{y}_{2\\cdot\\cdot} = \\frac{18.56 + 20.00 + 19.87 + 22.09 + 17.62 + 21.72}{6} = 19.98\n\\] \\[\n\\bar{y}_\\text{sonic} = \\bar{y}_{3\\cdot\\cdot} = \\frac{25.58 + 23.31 + 18.99 + 23.09 + 23.81 + 21.27}{6} = 22.68\n\\] \\[\n\\bar{y}_\\text{ultrasonic} = \\bar{y}_{4\\cdot\\cdot} = \\frac{24.39 + 21.45 + 32.74 + 24.21 + 25.67 + 23.42}{6} = 25.31\n\\]\nNow find the mean for each level of toothpaste brand.\n\\[\n\\bar{y}_\\text{name brand} = \\bar{y}_{\\cdot 1 \\cdot} = \\frac{19.12 + 18.56 + \\cdots + 18.99 + 32.74}{12} = 22.93\n\\] \\[\n\\bar{y}_\\text{off brand} = \\bar{y}_{\\cdot 2 \\cdot} = \\frac{21.60 + 22.09 + \\cdots + 21.27 + 23.42}{12} = 22.60\n\\]\nThere are 8 different combinations of toothbrush type and toothpaste, so the interaction factor has 8 levels total. We calculate a mean for each one, but will only show the calculation for the first 3.\n\\[\n\\bar{y}_\\text{manual and name brand} = \\bar{y}_{11\\cdot} = \\frac{19.12 + 24.21 + 26.88}{3} = 23.40\n\\] \\[\n\\bar{y}_\\text{manual and off brand} = \\bar{y}_{12\\cdot} = \\frac{21.60 + 23.40 + 23.35}{3} = 22.78\n\\] \\[\n\\bar{y}_\\text{oscillating and name brand} = \\bar{y}_{21\\cdot} = \\frac{18.56 + 20.00 + 19.87}{3} = 19.48\n\\]\nThe means for the residual error factor levels is the observed value itself since there is just 1 observation per level. Therefore, there are no calculations to show.\nFigure 7 displays all the factor level means inside the factor structure.\n\n\n\n\nFigure 7: Factor level means\n\n\n\n\n\nFactor level effects\n\nGrand mean effect\nNow that we have calculated means for each level of each factor, we can move on to calculate the effects of the factor levels.1\nFor the grand mean, there is only one level and there are no outside factors. Therefore, the effect due to grand mean is 22.76 (equivalent to its mean) and this affect is applied to all 24 observations.\n\n\nToothbrush effects\nThe toothbrush factor has four levels: one for each brush type. We will use the general rule for calculating factor level effects. To calculate the effect of a toothbrush, take the toothbrush mean and subtract it from the grand mean factor’s effect. For the manual brush, this looks like:\n\\[\n23.09 - 22.76 = 0.33\n\\]\nUsing the manual brush has the effect of increasing a person’s plaque area percentage by 0.33 percentage points on average compared to the grand mean. In a similar way2 you can find the effect for the oscillating brush \\(19.98 - 22.76 = -2.79\\). This means the amount of plaque decreased by 2.79 on average with this brush compared to the grand mean. For a sonic toothbrush, the effect is \\(22.68 - 22.76 = -0.09\\). For an ultrasonic brush the effect is \\(25.31 - 22.76 = 2.55\\).\n\n\nIt is interesting to note that the factor effects for brush type are the same, whether toothpaste brand is included in the anlaysis or not.\n\n\nToothpaste effects\nCalculating the effects for the second controlled factor in the experiment follows a similar pattern and also uses the general rule for calculating effect sizes. Remember that toothbrush is not outside or inside of toothpaste, rather the two factors are crossed. To calculate the effect of using the name brand toothpaste, take the name brand mean and subtract it from the grand mean factor’s effect:\n\\[\n22.93 - 22.76 = 0.16\n\\]\nA similar calculation is performed for off the brand toothpaste.\n\\[\n22.60 - 22.76 = -0.16\n\\]\nWith only two levels, it becomes obvious that the effects of a factor’s levels will always sum to zero. You may want to go back to the toothbrush level effects and verify this is true.\n\n\nInteraction effects\nThe general rule says that effects of outside factors must be subtracted from the factor level mean. We pause to review the relationship of the other factors to the interaction factor to determine if they are inside, outside, or crossed with each other.\n\n\n\n\n\nInteraction inside of toothbrush\n\n\nFigure 8: ?(caption)\n\n\n\n\n\n\n\nInteraction inside of toothpaste\n\n\nFigure 9: ?(caption)\n\n\nIn Figure 8 you can see that each level of the interaction will fit nicely within a level of toothbrush, this means toothbrush is outside of interaction (equivalently, interaction is inside of toothbrush). The same holds true for the relationship of toothpaste brand and interaction, as shown in Figure 9.\nTherefore, to calculate the interaction effect for using an ultrasonic brush with name brand toothpaste we will subtract the effects of the grand mean factor, ultrasonic brush, and name brand paste from the “ultrasonic, name brand” level mean.\n\\[\n26.19 - (22.76 + 2.55 + 0.16) = .15\n\\]\nLet’s take a deeper look to understand why this works. It can be helpful to remember our assembly line analogy. We will walk through this assembly line, showing a graph to illustrate how the effects are added at each station.\nAn observation from the “ultrasonic brush, name brand paste” group starts with the grand mean value of 22.76. The observation belongs to the ultrasonic group, where plaque tends to be higher, specifically 2.55 higher on average (2.55 is the effect of ultrasonic). Figure 10 show the starting point of the grand mean and the addition of the brush effect.\n\n\n\n\n\n\n\n\nFigure 10: Grand mean + brush effect\n\n\n\n\nAt the next step, because the observation belongs to the Name Brand Toothpaste group we would tack on an additional 0.16 of plaque coverage, as shown in Figure 11.\n\n\n\n\n\nFigure 11: Grand mean + brush effect + paste effect\n\n\n\n\nWhat we haven’t accounted for yet is the fact that the ultrasonic brush and name brand toothpaste have appeared together. If the interaction is significant then we can expect a synergistic effect (in either direction) and will need to add/subtract more to the response. Otherwise, the interaction effects will be small (relative to the error variance).\nThere is an old saying, “the whole is greater than the sum of its parts”. In a way, the interaction effect is the measure of how much greater. Figure 12 shows that after summing the main effects of each controlled factor, the remaining distance to the mean of the factor level combination is the interaction effect.\n\n\n\n\n\nFigure 12: Interaction effect is remaining distance to factor level mean\n\n\n\n\nWe calculated this above using the general rule and found the distance to be 0.15.\nInstead of 3 separate charts as above, should I use this chart where all 3 are combined into 1 graphic to show the progression?? I spent way too long on this already, so let me know what you would change above these charts. Might as well get them right.\n\n##| label: fig-int-step\n#| fig-cap: \n#|   - \"Grand mean + brush effect... \"\n#|   - \" + paste effect ... \"\n#|   - \" + interaction\"\n##| fig-subcap: \n##|    - \"Grand mean + brush effect...\"\n##|    - \"... + paste effect ...\"\n##|    - \" ... + interaction effect\"\n\n\n#### Plot 1\nxaxis_limits <- c(3.25, 4.75)\nplot(Plaque~brush_num, data=bf1, col = \"gray\", pch=1, xaxt='n',xlim = xaxis_limits, ylab= \"% Teeth Area with Plaque\", xlab=\"\",  main=\"Grand mean + brush effect...\")\n\n#Replot the points of the ultra, name group in brighter color\npoints(y = highlight$Plaque, x = highlight$brush_num, pch = 16, col = \"purple\")\n\n#Add axis labels\naxis(1, at=c(1,2,3,4), labels=c(\"Manual\", \"Oscillating\", \"Sonic\", \"Ultrasonic\"))\n\n#Add grand mean line\nlines(xaxis_limits, rep(grandmean, 2), lty=1)\ntext(4.5,grandmean-.5, \"Grand mean\")\n\n#Puts the dashed group mean line for ultrasonic\n\n#text(4-.4,mu[4,2], expression(bar(y)[ultra]), cex = 1.2)\n\n#Ultrasonic effect line and text\nlines(rep(4-.2,2), c(mu[4,2], grandmean), lty=3, col = \"cornflowerblue\") #vertical line\nlines(c(4-.2,4 -.05), rep(mu[4,2],2), lty=2, col = \"cornflowerblue\") #horizontal line\ntext(4-.25, mean(c(mu[[4,2]], grandmean)), expression(hat(alpha)[ultra]== 2.55), col = \"cornflowerblue\",\n     pos=2, cex = 1.2)\n\n########## Plot 2 ############\nxaxis_limits <- c(3.25, 4.75)\nplot(Plaque~brush_num, data=bf1, col = \"gray\", pch=1, xaxt='n',xlim = xaxis_limits, ylab= \"% Teeth Area with Plaque\", xlab=\"\",  main=\"... + paste effect...\",\n     sub = \"Points in 'ultrasonic, name brand' group in purple\")\n\n#Replot the points of the ultra, name group in brighter color\npoints(y = highlight$Plaque, x = highlight$brush_num, pch = 16, col = \"purple\")\n\n#Add axis labels\naxis(1, at=c(1,2,3,4), labels=c(\"Manual\", \"Oscillating\", \"Sonic\", \"Ultrasonic\"))\n\n#Add grand mean line\nlines(xaxis_limits, rep(grandmean, 2), lty=1)\ntext(4.5,grandmean-.5, \"Grand mean\")\n\n#Puts the dashed group mean line for ultrasonic\n\n#text(4-.4,mu[4,2], expression(bar(y)[ultra]), cex = 1.2)\n\n#Ultrasonic effect line and text\nlines(rep(4-.2,2), c(mu[4,2], grandmean), lty=3, col = \"cornflowerblue\") #vertical line\nlines(c(4-.2,4 -.05), rep(mu[4,2],2), lty=2, col = \"cornflowerblue\") #horizontal line\ntext(4-.25, mean(c(mu[[4,2]], grandmean)), expression(hat(alpha)[ultra]== 2.55), col = \"cornflowerblue\",\n     pos=2, cex = 1.2)\n\n#Name Brand Effect line with text\nlines(rep(4 - .05,2), c(mu[4,2] + .16, mu[4,2]), lty=3, col = \"darkgreen\") #vertical line\nlines(c(4 - .05, 4+.1), rep((mu[4,2] + .16),2), lty = 2, col = \"darkgreen\") #horizontal line\ntext(4 - 0.25, mu[[4,2]] + 0.16, expression(hat(beta)[Name] == 0.16), col = \"darkgreen\", pos=2)\n\n########## Plot 3 ############\nxaxis_limits <- c(3.25, 4.75)\nplot(Plaque~brush_num, data=bf1, col = \"gray\", pch=1, xaxt='n',xlim = xaxis_limits, ylab= \"% Teeth Area with Plaque\", xlab=\"\",  main=\"...+ interaction\")\n\n#Replot the points of the ultra, name group in brighter color\npoints(y = highlight$Plaque, x = highlight$brush_num, pch = 16, col = \"purple\")\n\n#Add axis labels\naxis(1, at=c(1,2,3,4), labels=c(\"Manual\", \"Oscillating\", \"Sonic\", \"Ultrasonic\"))\n\n#Add grand mean line\nlines(xaxis_limits, rep(grandmean, 2), lty=1)\ntext(4.5,grandmean-.5, \"Grand mean\")\n\n#Puts the dashed group mean line for ultrasonic\n\n#text(4-.4,mu[4,2], expression(bar(y)[ultra]), cex = 1.2)\n\n#Ultrasonic effect line and text\nlines(rep(4-.2,2), c(mu[4,2], grandmean), lty=3, col = \"cornflowerblue\") #vertical line\nlines(c(4-.2,4 -.05), rep(mu[4,2],2), lty=2, col = \"cornflowerblue\") #horizontal line\ntext(4-.25, mean(c(mu[[4,2]], grandmean)), expression(hat(alpha)[ultra]== 2.55), col = \"cornflowerblue\",\n     pos=2, cex = 1.2)\n\n#Name Brand Effect line with text\nlines(rep(4 - .05,2), c(mu[4,2] + .16, mu[4,2]), lty=3, col = \"darkgreen\") #vertical line\nlines(c(4 - .05, 4+.1), rep((mu[4,2] + .16),2), lty = 2, col = \"darkgreen\") #horizontal line\ntext(4 - 0.25, mu[[4,2]] + 0.16, expression(hat(beta)[Name] == 0.16), col = \"darkgreen\", pos=2)\n\n#Interaction Mean line\nlines(c(4 - .2, 4+.2), rep(26.19,2), lty = 2, col = \"purple\") #bigger horizontal line\nlines(rep(4 + .1, 2), c(mu[4,2] + .16, 26.19), lty = 3, col = \"purple\") #vertical line\ntext( 4 + .2, 26.19, TeX(r'($\\bar{y}_{Ultra,Name}$)'), col = \"purple\", pos = 4)\n\n#Name Brand Effect line with text\ntext(4 -.25, 27, TeX(r'($\\hat{alpha} \\hat{beta}_{Ultra,Name} = ?$)'), col = \"purple\", pos = 2)\nlines(c(4-.2, 4+.1), c(27, 25.83), col = \"red\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor each observation, Figure 13 displays all the factor level effects that are summed to obtain that observation.\n\n\n\n\nFigure 13: Factor level effects"
  },
  {
    "objectID": "bf2.html#assumptions-1",
    "href": "bf2.html#assumptions-1",
    "title": "BF[2]",
    "section": "Assumptions",
    "text": "Assumptions"
  },
  {
    "objectID": "bf2.html#degrees-of-freedom",
    "href": "bf2.html#degrees-of-freedom",
    "title": "BF[2]",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nWe can use our understanding of inside vs. outside factors to determine the degrees of freedom (df) for the grand mean, treatment factors, interaction and residual errors. We start with 24 observations - or pieces of information. In other words, we have 24 degrees of freedom that need to be allocated to the factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf\\(_\\text{factor}\\) = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the toothbrush and toothpaste example, grand mean has one level and there are no factors outside of grand mean. Therefore, its degrees of freedom equals one. This will always be the case.\nRemember, the degrees of freedom represent the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as you estimate the grand mean for just one of the observations, you know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for the grand mean effect were also known. Therefore, there is just one unique piece of information in the grand mean factor. Grand mean has just 1 degree of freedom.\nIn this case there are two controlled factors, or treatment factors: toothbrush and toothpaste. For toothbrush there are four levels of the factor. Grand mean is the only factor outside of toothbrush. Take the number of levels for toothbrush (4) and subtract the degrees of freedom for grand mean (1), which yields 4-1 = 3 degrees of freedom.\n\n\nThe degrees of freedom for toothbrush is it the same here as it was for the BF[1].\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information. Upon examining the factor for toothbrush in Figure 13 you can see there are 4 unique numbers. We know the effects for toothbrush must sum to zero, so the 4th effect is not free to vary. As soon as I know the effect for 3 of the brushes, I can fill in all the effects for the toothbrush factor.\nA similar approach is taken for toothpaste. Here it is even more obvious that the effects for toothpaste sum to zero. After estimating the toothbrush effect for one observation, I can fill in the toothpaste effects for all the other observations. Therefore, the degrees of freedom for toothpaste is 1.\nUsing the general rule, I know there are 2 levels for toothpaste and grand mean is the only outside factor. Since grand mean has 1 degree of freedom, I get \\(2-1 = 1\\) degree of freedom for toothpaste.\nNow we must calculate degrees of freedom for the interaction term. Take a closer look at the interaction effects in Figure 13. You can see that the numbers repeat within each cell. There are 8 cells total. You can also see that the effects inside a column of values sum to zero, as do the values in a row. Therefore, I really only need to know a value in 3 of the cells of the interaction factor before I can fill in the effects for all the other cells in that factor.\nThis is in perfect harmony with an application of the general rule. The interaction factor has 8 factor levels. Factors outside of the interaction include: grand mean (1 df), toothbrush (3 df), and toothpaste (1 df). Applying the general rule with these values yields \\(8 - (1 + 3 + 1) = 3\\) degrees of freedom for the interaction factor.\nPerhaps the easiest way to find the degrees of freedom for an interaction that is created by crossing two other factors is to multiply the degrees of freedom of the two other factors. In this case, toothbrush and toothpaste are crossed, so you would get \\(3*1 = 3\\), which matches the answer found using other methods.\nFinally, the residual degrees of freedom can be found using the general rule. Since the residual error factor is inside of all other factors, this is the same as finding how many degrees of freedom are leftover after calculating degrees of freedom for all other factors. In this example, there were 24 observations total, so we subtract the degrees of freedom for the other factors from 24. This returns \\(24 - (1+3+1+3) = 16\\) degrees of freedom for residuals.\nThe other approach to finding the degrees of freedom for residuals is to group the residuals by the smallest structural factor partitions (in this case the interaction). Inside each of those partitions the residuals sum to zero. For example, applying the interaction partition to residuals gives the values \\(-4.28\\), \\(0.81\\), and \\(3.48\\). Since we know the 3 residuals sum to zero in each partition, we only need to know 2 values per partition in order to fill in the third residual effect. With 8 partitions applied to the residuals, we have \\(2x8 = 16\\) degrees of freedom for residual error."
  },
  {
    "objectID": "bf2.html#completing-the-anova-table",
    "href": "bf2.html#completing-the-anova-table",
    "title": "BF[2]",
    "section": "Completing the ANOVA Table",
    "text": "Completing the ANOVA Table\nNow that we have calculated degrees of freedom and effects for each factor , we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. A completed ANOVA summary table contains the information we need for a hypothesis test of the main effects (for controlled factors) and their interaction.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n     \n     \n     \n     \n  \n  \n    Brush \n    3 \n     \n     \n     \n     \n  \n  \n    Toothpaste \n    1 \n     \n     \n     \n     \n  \n  \n    Brush:Toothpaste \n    3 \n     \n     \n     \n     \n  \n  \n    Residual Error \n    16 \n     \n     \n     \n     \n  \n  \n    Total \n    24 \n     \n     \n     \n     \n  \n\n\n\n\n\nTo get the sum of squares (SS) of a factor, each value displayed in that particular factor first needs to be squared. Figure 13 shows the effects, while Figure 14 shows the squared effects.\n\n\n\n\n\n\n\n\nFigure 14: Squared factor level effects\n\n\nThen, for each factor, all the squared values are summed up to get the sum of squares. The total sum of squares is obtained by summing the squared observations as shown in Equation 3. This represents the total variability in the dataset that will then be allocated or partitioned to the various factors, starting with the grand mean.\n\\[\nSS_\\text{total} = 365.6 + 344.5 + 654.3 + ... + 452.4 + 548.2  = 12,674.30\n\\qquad(3)\\]\nFor grand mean, the squared effect of 518.2 is listed 24 times, once for each observation. Summing the squared effects gets:\n\\[\nSS_\\text{Grand Mean} = 518.2* 24 = 12,437.43\n\\]\n\n\n\n\n\n\nNote\n\n\n\nThe rounded numbers are displayed throughout this section, but all calculations are done using the unrounded numbers.\n\n\nThe toothbrush factor has four different effects: one for each level of the factor. For each effect, the squared value is multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to toothbrush.\n\\[\nSS_\\text{toothbrush} = 6*(0.11) + 6*(7.77) + 6*(0.01) + 6*(6.50) = 86.31\n\\qquad(4)\\] \nThe sum of squares is similarly calculated for toothpaste brand (Equation 5) and brush by paste interaction (Equation 4).\n\\[\nSS_\\text{toothpaste} = 12*(0.03) + 12*(0.03) = 0.62\n\\qquad(5)\\] \\[\nSS_\\text{brush x paste} = 3*(0.02) + 3*(0.44) + 3*(0.04) + 3*(0.52) +3*(0.02) + 3*(0.44) + 3*(0.04) + 3*(0.52)  = 6.12\n\\]\nThe effect for the residual error factor has 24 unique values. The squared residuals are summed together in Equation 6.\n\\[\nSS_\\text{residual} = 18.35 + 0.84 + 8.72 + ... + 2.11 + 1.03  = 143.82\n\\qquad(6)\\]\nYou can check that the sums of squares (SS) has been allocated to the factors correctly by adding up the SS for each factor and verifying that it also equals the result found in Equation 3.\nPutting this information into the ANOVA table gets us the result shown in Table 1.\n\n\n\nTable 1:  Sums of squares \n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    12437.43 \n     \n     \n     \n  \n  \n    Brush \n    3 \n    86.31 \n     \n     \n     \n  \n  \n    Toothpaste \n    1 \n    0.62 \n     \n     \n     \n  \n  \n    Brush:Toothpaste \n    3 \n    6.12 \n     \n     \n     \n  \n  \n    Residual Error \n    16 \n    143.82 \n     \n     \n     \n  \n  \n    Total \n    24 \n    12674.30 \n     \n     \n     \n  \n\n\n\n\n\n\nRecall that SS is a measure of total variability. Of the three structural factors (brush, toothpaste, and their interaction) it is clear to see that brush is contributing the most variability. Some of the difference in SS may be due to difference in number of levels for each factor. Adding levels to factor will naturally increase variability attributed to that factor. We will convert this total variability (sum of squares) into a mean variability (mean square) measure to properly account for differences in number of factor levels. This allows us to compare the factors’ variability on a standardized scale.\nTo calculate a mean square (MS), simply divide SS by degrees of freedom for a factor. The mean square calculations are:\n\\[\nMS_\\text{Grand Mean} = \\frac{SS_\\text{Grand Mean}}{df_\\text{Grand Mean}} = \\frac{12437.43}{1} = 12437.43\n\\]\n\n\\[\nMS_\\text{Brush} = \\frac{SS_\\text{Brush}}{df_\\text{Brush}} = \\frac{86.31}{3} = 28.77\n\\]\n\n\\[\nMS_\\text{Toothpaste} = \\frac{SS_\\text{Toothpaste}}{df_\\text{Toothpaste}} = \\frac{0.62}{1} = 0.62\n\\]\n\n\\[\nMS_\\text{Brush:Toothpaste} = \\frac{SS_\\text{Brush:Toothpaste}}{df_\\text{Brush:Toothpaste}} = \\frac{6.12}{3} = 2.04\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{143.82}{16} = 8.99\n\\]\n\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    12437.43 \n    12437.43 \n     \n     \n  \n  \n    Brush \n    3 \n    86.31 \n    28.77 \n     \n     \n  \n  \n    Toothpaste \n    1 \n    0.62 \n    0.62 \n     \n     \n  \n  \n    Brush:Toothpaste \n    3 \n    6.12 \n    2.04 \n     \n     \n  \n  \n    Residual Error \n    16 \n    143.82 \n    8.99 \n     \n     \n  \n  \n    Total \n    24 \n    12674.30 \n     \n     \n     \n  \n\n\n\n\n\nFor each structural factor in the design there are a set of hypothesis we want to test using the F statistic.\nSpecifically, we will want to test whether toothbrush type has an effect on plaque coverage, whether toothpaste brand has an effect on plaque coverage, and whether the interaction between brush and paste has an effect on plaque coverage.\nMore specifically, for each factor we test whether the factor level effects are all equal to zero. We can express the hypotheses mathematically using the terms of Equation 2.\nA hypothesis for the main effect of toothbrush type:\n\\[H_0: \\alpha_\\text{i} = 0 \\text{ for all } i\\]\n\\[H_a: \\alpha_\\text{i} \\ne 0 \\text{ for some } i\\]\nA hypothesis for the main effect of toothpaste brand:\n\\[H_0: \\beta_\\text{j} = 0 \\text{ for all } j\\]\n\\[H_a: \\beta_\\text{j} \\ne 0 \\text{ for some } j\\]\nA hypothesis for the interaction of toothbrush and toothpaste.\n\\[\nH_0: (\\alpha\\beta)_\\text{ij} = 0 \\text{ for all } ij\n\\] \\[\nH_a: (\\alpha\\beta)_\\text{ij} \\ne 0 \\text{ for some } ij\n\\]\nTo test these hypotheses we need to compare the mean square (MS) for a factor to the mean square for residual error (abbreviated as MSE). The MSE is the estimate of unexplained, random error. If a factor’s MS is similar in size to the MSE, the variance in that factor may just be random error; and the effect of the factor levels are zero. On the other hand, if the variability in the factor, as measured by its MS, is much larger than the random error observed in the experiment (represented by MSE), then it is reasonable to believe the factor levels have a non-trivial contribution to the variability. In other words, the factor has a significant effect on the response.\nThe F statistic is a ratio of these two errors and is obtained by dividing the factor’s mean square (MS) by the MSE. The F statistic calculations are\n\n\\(F_\\text{brush} = 28.77/8.99 = 3.20\\)\n\\(F_\\text{toothpaste} = 0.62/8.99 = 0.07\\)\n\\(F_\\text{brush:toothpaste} = 2.04 / 8.99 = .23\\)\n\nThis F statistic follows a well defined distribution, called the F distribution. The F distribution is defined by two values for degrees of freedom3:\n\nthe numerator degrees of freedom, which is the degrees of freedom for the factor being tested\nthe denominator degrees of freedom, which is the degrees of freedom for residual error\n\nThe area under this distribution curve to the right of our F statistic is called the p-value. The p-value represents the probability of getting an F statistic at least as large as the one obtained, assuming the null hypothesis (of no effect) is true.\nThe F statistic, numerator degrees of freedom, and denominator degrees of freedom are the 3 required inputs to calculate a p-value. P-values can be obtained manually using the applet mentioned above, the f.dist.rt()4 function in excel or the pf() function in R5. Usually though, R will show p-values as part of the standard output of the ANOVA model/table and it is recommended you stick to those values when reporting answers.\nThe completed ANOVA table for this BF[2] toothbrush and toothpaste example is shown in\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    12437.43 \n    12437.43 \n     \n     \n  \n  \n    Brush \n    3 \n    86.31 \n    28.77 \n    3.20 \n    0.051 \n  \n  \n    Toothpaste \n    1 \n    0.62 \n    0.62 \n    0.07 \n    0.800 \n  \n  \n    Brush:Toothpaste \n    3 \n    6.12 \n    2.04 \n    0.23 \n    0.876 \n  \n  \n    Residual Error \n    16 \n    143.82 \n    8.99 \n     \n     \n  \n  \n    Total \n    24 \n    12674.30 \n     \n     \n     \n  \n\n\n\n\n\nBecause the p-value for the interaction (p-value = 0.876) is much higher than any traditional level of significance threshold we might have chosen (0.01, 0.05, or 0.1), we fail to reject the null hypothesis. There is insufficient evidence to say the interaction effect has an effect on plaque coverage. Because the interaction is NOT significant, we can proceed to interpret the main effects test results.\n\n\n\n\n\n\nSignificant Interaction Effects\n\n\n\nIf the interaction effect is significant, great caution should be taken when interpreting the hypothesis test results for the factors involved in the interaction; it may not be valid to interpret the hypothesis test results. Instead, if the interaction is significant, it is better to describe the nature of the interaction with graphs, numbers, and words.\n\n\nToothpaste’s p-value is high (p-value = 0.8), indicating no evidence that toothpaste brand has an effect on plaque coverage. The p-value for brush is marginally significant (p-value = 0.051). When (in)significance is borderline, rather than making bold statements based on a small amount of (in)significance, it is helpful to dig a little deeper. Consider things like sample size, effect size (practical significance), outliers, and how closely assumptions are met. After weighing those considerations carefully, take a stance and state your belief about the role of the factor on the response. Explain your rationale, then keep an open mind and stay curious."
  },
  {
    "objectID": "bf2.html#describe-the-data",
    "href": "bf2.html#describe-the-data",
    "title": "BF[2]",
    "section": "Describe the Data",
    "text": "Describe the Data\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots, scatterplots, and/or interaction plots with the means displayed.\nInteractive code and additional explanations of numerical summaries and plots in R are found at R Instructions->Descriptive Summaries section of the book.\n\nNumerical Summaries\n\n\n\nAfter loading required packages, we will read in the data and do some wrangling.\n\n\nCode\nbf2 <- read_csv(\"data/toothpaste_BF2.csv\") \n\n\nWe then calculate summary statistics for each factor level separately.\n\n\nCode\n#Descriptive stats for levels of Brush\nfavstats(Plaque~Brush, data = bf2) |> \n  kable(digits = 2) |> \n  kable_styling(full_width = TRUE)\n\n#Descriptive stats for levels of Toothpaste\nfavstats(Plaque~Toothpaste, data = bf2) |> \n  kable(digits = 2) |> \n  kable_styling(full_width = TRUE)\n\n\n\nTable 2: Numerical Summary for Each Factor\n\n\n\n(a) Brush \n \n  \n    Brush \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    Manual \n    19.12 \n    22.04 \n    23.38 \n    24.01 \n    26.88 \n    23.09 \n    2.60 \n    6 \n    0 \n  \n  \n    Oscillating \n    17.62 \n    18.89 \n    19.94 \n    21.29 \n    22.09 \n    19.98 \n    1.74 \n    6 \n    0 \n  \n  \n    Sonic \n    18.99 \n    21.73 \n    23.20 \n    23.68 \n    25.58 \n    22.67 \n    2.27 \n    6 \n    0 \n  \n  \n    Ultrasonic \n    21.45 \n    23.62 \n    24.30 \n    25.35 \n    32.74 \n    25.31 \n    3.90 \n    6 \n    0 \n  \n\n\n\n\n\n\n\n(b) Toothpaste \n \n  \n    Toothpaste \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    NameBrand \n    18.56 \n    19.68 \n    22.38 \n    24.69 \n    32.74 \n    22.92 \n    4.18 \n    12 \n    0 \n  \n  \n    OffBrand \n    17.62 \n    21.69 \n    23.22 \n    23.52 \n    25.67 \n    22.60 \n    2.00 \n    12 \n    0 \n  \n\n\n\n\n\n\n\nIn Table 2 (a) we see that the oscillating brush has lowest mean plaque (19.98). Table 2 (b) shows the mean plaque for the two types of toothpaste is very close, 22.92 for Name Brand and 22.60 for Off Brand.\nYou can also look at descriptive statistics for factor level combinations. This is only advisable if there is sufficient sample size at each combination and the number of combinations is manageable. Table 3 shows what that looks like for our current example. Due to the many combinations, it is a bit difficult to interpret the output. Furthermore, using a 5 number summary on a sample size of 3 observations is not advisable so some of the summary statistics have been dropped.\nThe combination of Oscillating with Name Brand has the lowest mean (19.48) and the lowest standard deviation (0.80).\n\n\nCode\nfavstats(Plaque~Brush+Toothpaste, data = bf2) |> \n  select(Brush.Toothpaste, mean, sd, n) |> \n  kable(digits = 2) |> \n  kable_styling(full_width = FALSE)\n\n\n\nTable 3:  Numerical Summary \n \n  \n    Brush.Toothpaste \n    mean \n    sd \n    n \n  \n \n\n  \n    Manual.NameBrand \n    23.40 \n    3.94 \n    3 \n  \n  \n    Oscillating.NameBrand \n    19.48 \n    0.80 \n    3 \n  \n  \n    Sonic.NameBrand \n    22.63 \n    3.35 \n    3 \n  \n  \n    Ultrasonic.NameBrand \n    26.19 \n    5.86 \n    3 \n  \n  \n    Manual.OffBrand \n    22.78 \n    1.03 \n    3 \n  \n  \n    Oscillating.OffBrand \n    20.48 \n    2.48 \n    3 \n  \n  \n    Sonic.OffBrand \n    22.72 \n    1.31 \n    3 \n  \n  \n    Ultrasonic.OffBrand \n    24.43 \n    1.14 \n    3 \n  \n\n\n\n\n\n\n\n\nGraphical Summaries\nGraphs are also valuable tools to help you get to know your data. Since there are only 3 observation in each factor level combination, a dotplot/scatterplot is more appropriate than a boxplot. This is shown in Figure 15\n\n\nCode\n#Note, I have to turn Brush into a factor because it started out as a character variable\ndotplot(Plaque~factor(Brush)|factor(Toothpaste), data = bf2, \n        xlab = \"\")\n\n\n\n\n\nFigure 15: Graphical Summary\n\n\n\n\nYou could also gain insight about the main effects by cutting the data by each factor separately, as shown in Figure 16.\n\n\n\n\n\n\n\n(a) Brush\n\n\n\n\n\n\n\n(b) Toothpaste\n\n\n\n\nFigure 16: Data cut by one factor at a time\n\n\nFinally, an interaction plot is ideal for investigating a BF[2]. The plot only shows factor level means. Therefore, it does not give a good sense of the underlying distribution of data and should not be used as the only visual assessment of your data. However, it is extremely good at providing insight into possible interactions.\nIn Figure 17 the lines are not parallel. In fact, they cross twice. Though this seems to suggest an interaction is present, our ability to claim an interaction exists will depend on the results of a hypothesis test. The hypothesis test is greatly influenced by sample size and the variability at each of the factor level means presented in the plot.\n\n\n\n\n\nFigure 17: Interaction plot for Brush vs. Toothpaste"
  },
  {
    "objectID": "bf2.html#create-the-model",
    "href": "bf2.html#create-the-model",
    "title": "BF[2]",
    "section": "Create the Model",
    "text": "Create the Model\nYou then create the model using the aov() function. To see results of the F-test you can feed your model into a summary() or anova() function.\n\n\nWhen called on a model created with aov(), summary() and anova() functions give the same output with some slight differences in formatting. The summary() function is more general; it can take linear regression models created with 'lm() as inputs, for example. The output provided by summary() will change based on the type of object it is called on. This is discussed in more detailed at the bottom of the Unbalanced page.\n\nmyaov <- aov(Y ~ X1*X2, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is the user defined name in which the results of the aov() model are stored\nY is the name of a numeric variable in your dataset which represents the quantitative response variable.\nX1 and X2 are names of qualitative variables in your dataset. They should have class(X) equal to factor or character. If that is not the case, use factor(X) inside the aov(Y ~ factor(X1)*...) command.\nYourDataSet is the name of your data set.\n\nThe * in the code above is a shortcut for writing out the whole model. It can be read as, “include each term by itself, and all possible interaction terms”. The long way of writing out the model uses a colon, :, to define interaction terms and is shown below. When writing it this way each term must be explicitly stated.\n\nmyaov <- aov(Y ~ X1+X2+X1:X2, data=YourDataSet)\nsummary(myaov)\n\nBelow are the results for the full BF[2] model using the toothbrush and toothpaste example. You should notice that these results match what we got when we performed the decomposition manually to build the ANOVA summary table. Even though the interaction plot showed crossing lines, we see the interaction between Brush and Toothpaste is not significant (p-value = .8763). This means we can interpret the hypothesis tests for each of the main effects.\nToothpaste is not significant (p-value = .7966) and Brush is marginally significant (p-value = .0517, which is close to the traditional alpha level of 0.05). Our exploratory analysis showed that oscillating brush resulted in the lowest amount of plaque and the ultrasonic brush resulted in the highest plaque measure.\n\n\nCode\nbf2_aov <- aov(Plaque~Brush*Toothpaste,data=bf2)\nsummary(bf2_aov)\n\n\n                 Df Sum Sq Mean Sq F value Pr(>F)  \nBrush             3  86.31  28.769   3.201 0.0517 .\nToothpaste        1   0.62   0.618   0.069 0.7966  \nBrush:Toothpaste  3   6.12   2.040   0.227 0.8763  \nResiduals        16 143.82   8.989                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn order to trust these hypothesis test results we need to verify that the assumptions are met."
  },
  {
    "objectID": "bf2.html#check-assumptions",
    "href": "bf2.html#check-assumptions",
    "title": "BF[2]",
    "section": "Check Assumptions",
    "text": "Check Assumptions\nFor a more detailed explanation of the code, output, and theory behind these assumptions visit the Assumptions page.\n\nConstant Variance\nThere needs to be constant variance across the factor levels. There are multiple ways to verify this assumption is met. First, we can check the residual plot.\n\n\nCode\nplot(bf2_aov, which = 1)\n\n\n\n\n\nFigure 18: Checking constant variance\n\n\n\n\nIn Figure 18 there are 8 distinct vertical groupings of points, one for each factor level combination. Each factor level combination had 3 observations, and so also has 3 residuals. There does seem to be a slight trend for points with larger predicted values to be more spread out. On the far left of the plot the points appear closer together, as you move to the right the points tend to be more spread out (thought not always). This phenomenon raises the concern that the assumption of constant variance across factor level combinations may be violated.\nWe will further investigate the assumption by looking at other measures of constant variance. We can use the rule of thumb that the largest standard deviation should not be more than double the smallest standard deviation. In Table 3 we saw that the largest standard deviation (5.86) belonged to the ultrasonic brush with name brand paste. It’s standard deviation is much more than double the smallest standard deviation, 0.80, which belongs to the oscillating brush with name brand paste. This stands as further evidence that the requirement has been violated.\nStudents often wonder if they should be comparing the standard deviations for factor level combinations as we just did above, or if they should be comparing the standard deviations between the levels of a single factor one-at-a-time, which are shown in Table 2. In this case, and in many cases both approaches lead you to the same conclusion. In situations where the two approaches do not agree you should use your best judgement.\n\n\nNormally Distributed Residuals\nWe check the assumption that residuals are normally distributed in Figure 19. Most of the points are in the shaded region. Row 1 of the dataset appears in the upper right corner, far away from the boundaries. A couple of other points are very close, but just outside of the boundary. Due to the robust nature of ANOVA, the mild violation of this assumption is not a concern.\n\n\nCode\ncar::qqPlot(bf2_aov$residuals)\n\n\n[1] 1 5\n\n\n\n\n\nFigure 19: Checking normality of residuals\n\n\n\n\n\n\nIndependent Residuals\nThe dataset we are analyzing does not include information about the order in which the data was collected. In fact, it may be there were multiple teams of researchers collecting the data simultaneously and there is no specific order. From what we know, there is no reason to think there is a potential order bias. Nevertheless, the order plot in Figure 20 can be used to investigate trends in residuals by row number in the dataset. This plot does not show any patterns or trends. The assumption of independent residuals seems to be satisfied.\n\n\nCode\nplot(bf2_aov$residuals)\n\n\n\n\n\nFigure 20: Checking independent residuals assumption\n\n\n\n\n\n\nAssumptions Summary\nOf most concern was the violation of the constant variance assumption because it was the assumption that was most violated. Even so, its violation was not severe and the dataset is balanced, adding to the robustness of the ANOVA test to assumption violations. For these reasons, this situation would not normally be concerning enough to stop the analysis. However, since the F-test for toothbrush is such a close call, mild-moderate assumption violations may cause the p-value of the test to be slightly off. Even after attempting various transformations of the response variable, Plaque, the degree to which assumptions are met does not improve (in fact, in some cases it gets worse).\nRather than fuss about the whether F-test assumptions are met or not, you can recognize the F-test for Brush is close enough to merit further investigation. In this case, it is recommended to proceed with contrasts/pairwise tests of toothbrush type which do not require constant variance. (You should be aware of what assumption are required for those tests and be sure to check them).\n\n\nCode\ncar::qqPlot(bf2_aov$residuals)\n\n\n[1] 1 5\n\n\n\n\n\nFigure 21: All pairwise comparisons\n\n\n\n\nIn Figure 21 the results for all pairwise comparisons with Tukey’s HSD adjustment for multiple comparisons are displayed. Only the Ultrasonic-Oscillating comparison is significantly different, with a p-value of .03. Therefore, we can state that the ultrasonic brush performs significantly worse than the oscillating brush at plaque reduction."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html",
    "href": "BasicFactorial_quarto_boat.html",
    "title": "BF[1]",
    "section": "",
    "text": "In a basic one-way factorial design (BF[1]), only one factor is purposefully varied.1 Each experimental unit is assigned to exactly one factor level. (In the case of an observational study, only one independent factor is under consideration.)\n\n\nThe factor structure for the model resulting from a completely randomized, one factor design is:\n\n\n\n\nFigure 1: Example of BF1 Factor Structure\n\n\n\nFigure 1 illustrates a factor with 4 levels, 6 replications at each level.\n\n\n\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from factor level \\(i\\)\n\\(\\mu\\): the grand mean of the data set.\n\\(\\alpha_i\\): effect of factor level \\(i\\)\n\\(\\epsilon_{ij}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its factor level mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\n\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nRule of thumb comparing standard deviations\n\\(max(s) < 2*min(s)\\)\n\n\n\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#lifeboat-training-example",
    "href": "BasicFactorial_quarto_boat.html#lifeboat-training-example",
    "title": "BF[1]",
    "section": "Lifeboat Training Example",
    "text": "Lifeboat Training Example\nConsider the following example. An experiment was done to assess different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included:\n\nLecture/Materials (Control)\nMonitor/Keyboard\nHead Monitor Display/Joypad, and\nHead Monitor Display/Wearables.\n\nThe response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test). There is just one controlled factor, training method, which has 4 levels: the four training methods. An experimental unit in this study is each of the individuals being trained, 16 in all.\nWe want to assign each treatment to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\n\nCode\n#Repeat the sequence of 1 to 4, four times\nTreatment <- rep(1:4,4) \n\n#Create a sequence from 1 to 16\n#Paste the word \"Subject \" in front of each id #\nSubject <- paste(\"Subject\", seq(1:16), sep = \" \")\n\n#Combine the vector of treatment numbers and Subject ID's into 1 tibble/data frame\nassignment_table <- tibble(Subject, Treatment)\n\n#print the table, pander() makes it look nice\npander(assignment_table) \n\n\n\n\n\n\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\n\n\nThen we randomly shuffle the brush and paste column to get the following assignments. Check out the R-code to see how this is done.\n\n\nCode\n#set.seed() allows us to get the same random sample each time\nset.seed(42) \n\n#sample() will randomly select from the Treatment vector 16 times without replacement\n# %>% is called a pipe. It simply takes the output from the command on the left\n# and sends it to the command on the right\ntibble(Subject, sample(Treatment, 16)) %>% pander()\n\n\n\n\n\n\n\n\n\nSubject\nsample(Treatment, 16)\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n1\n\n\nSubject 3\n4\n\n\nSubject 4\n1\n\n\nSubject 5\n2\n\n\nSubject 6\n4\n\n\nSubject 7\n2\n\n\nSubject 8\n2\n\n\nSubject 9\n4\n\n\nSubject 10\n3\n\n\nSubject 11\n3\n\n\nSubject 12\n1\n\n\nSubject 13\n3\n\n\nSubject 14\n4\n\n\nSubject 15\n3\n\n\nSubject 16\n2\n\n\n\n\n\nWe can see here that subject 1 should get treatment 2. Subject 2 gets treatment 4, Subject 3 gets treatment 1, and so on."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#degrees-of-freedom",
    "href": "BasicFactorial_quarto_boat.html#degrees-of-freedom",
    "title": "BF[1]",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nWe can use our understanding of inside vs. outside factors to determine the degrees of freedom (df) for the grand mean, treatment, and residual errors factors. We start with 24 observations - or pieces of information. In other words, we have 24 degrees of freedom that need to be allocated to the 3 factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf\\(_\\text{factor}\\) = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the lifeboat example, grand mean has one level (shown by the one cell in Figure 1) and there are no factors outside of grand mean. Therefore, its degrees of freedom equals one.\nRemember, the degrees of freedom represent the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as you estimate the grand mean for just one of the observations, you know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for the grand mean effect were also known. Therefore, there is just one unique piece of information in the grand mean factor. Grand mean has just 1 degree of freedom.\nFor treatment factor, there are four levels of the factor (shown by the four vertically long cells for treatment factor in Figure 1). Grand mean is the only factor outside of training method. Take the number of levels for training method (4) and subtract the degrees of freedom for grand mean (1), which yields 4-1 = 3 degrees of freedom for training method.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the training method effects really contain. Since all observations from the same training method will have the same effect, we only need to know 4 pieces of information: the effect of each training method. But the answer is actually less than that! Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom are 3. As soon as we know 3 of the effects for training method, we can fill in the training method effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of Figure 1). Both grand mean and training method are outside of the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for grand mean and training method (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the residual factor effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 levels of training method is 20 observations, or in other words, 20 degrees of freedom."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#factor-effects",
    "href": "BasicFactorial_quarto_boat.html#factor-effects",
    "title": "BF[1]",
    "section": "Factor Effects",
    "text": "Factor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size of the grand mean, training methods, and residual errors factors in the lifeboat training study. In other words, we can estimate the terms in the one-way ANOVA model.\n\n\n\n\n\n\nGeneral Rule for Effect Size\n\n\n\nEffect size = factor level mean - the sum of the effects of all outside factors\n\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the grand mean factor and the means for each level of training method.\nTo get the grand mean, average all 24 observations. The mean for all the observations is 6.5846. There is only one level for grand mean so this number is placed into each of the cells for the grand mean factor in Figure 2.\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. In Figure 2 these means are placed in the respective training method column.\nWe do not need to calculate means for residual error factor because for two reasons. First, there is only one observation per level of residual error, so the mean is the observation itself. Second, nothing is inside of residual error. It is the last step in the process and its mean is not needed to calculate factor effects.\n\n\n\n\nFigure 2: Raw data and means for grand mean and training factors\n\n\n\n\n\nCalculate effects\nNow that we have calculated means for each level of each factor, we can move on to calculate the effects of the factor levels. We will use the general formula for calculating effect size.\nFor the grand mean, there is only one level and there are no outside factors. Therefore, the effect due to grand mean is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nThe training method factor has four levels: one for each method. To calculate the effect of a training method, take the training method mean and subtract it from the effect due to the grand mean factor. For the “Control” method, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the grand mean. In a similar way you can find the effect for Monitor/Keyboard \\(7.8492 - 6.5846 = 1.2645\\). This means the student performance scores increased by 1.2645 on average in this training method compared to the grand mean. For Head Monitor Display/Joypad, the effect is \\(6.5789 - 6.5846 = -0.0058\\). For Head Monitor Display/Wearables the effect is \\(7.1616 - 6.5846 = 0.5770\\) (see below).\n\n\n\n\nFigure 3: Training Method Effects\n\n\n\nTo calculate the residual error effects remember that there are 24 levels of the residual error factor. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for grand mean and the effect for whichever training method that particular observation received. For instance, for the observation located in the top left of our data set the value is 4.5614. Subtract the sum of the effects of outside factors (grand mean and training). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual error effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was 0.1875 less than the mean of the control group. This individual’s performance was lower than the mean of his/her peers who received the same type of training.\nWe can repeat the residual calculation for the first observation in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to grand mean and its respective training (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in Figure 4.\n\n\n\n\nFigure 4: Residual Effects"
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#completing-the-anova-table",
    "href": "BasicFactorial_quarto_boat.html#completing-the-anova-table",
    "title": "BF[1]",
    "section": "Completing the ANOVA table",
    "text": "Completing the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA summary table contains the information we need for a hypothesis test of a treatment factor.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n     \n     \n     \n     \n  \n  \n    Factor \n    3 \n     \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n     \n     \n     \n     \n  \n  \n    Total \n    24 \n     \n     \n     \n     \n  \n\n\n\n\n\nTo get the sum of squares (SS) for a factor, for each observation the effect for that factor first needs to be squared. Then all the squared values are summed up to get the sum of squares.\nFor grand mean, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to grand mean.\n\\[\nSS_\\text{Grand Mean} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor, training method, has four different effects: one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to training method. For instance, for the control group, the effect is -1.8358. The value is then squared, and then multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Factor} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the grand mean factor, treatment factor, and residual error factor.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    1040.57 \n     \n     \n     \n  \n  \n    Factor \n    3 \n    31.81 \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n     \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWe can now calculate the mean squared error column, or mean square (MS), by dividing the sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total (the sum of squares) into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation). The MS is calculated in this manner for each of the effects.\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. This works when looking at SS, since it is the total variance due to each factor. MS is then the average variability for each effect. We can then see clearly which factor is a bigger source of variability by comparing their mean squares.\nThe mean square calculations are:\n\\[\nMS_\\text{Grand Mean} = \\frac{SS_\\text{Grand Mean}}{df_\\text{Grand Mean}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Factor} = \\frac{SS_\\text{Factor}}{df_\\text{Factor}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Factor \n    3 \n    31.81 \n    10.60 \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nThe treatment factor, in this case training method, is the primary factor of interest so the F test statistic is only calculated for that factor. To get the F test statistic for the treatment factor take the mean square (MS) due to treatment factor and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of this as calculating the variance in treatment means for the numerator and the variance of the distances for an observed value to its respective treatment mean in the denominator. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Factor} = \\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for the treatment factor is calculated based on the F statistic and the degrees of freedom for both treatment factor and residual error. In practice, statistical software computes all the components of the ANOVA table, including the p-value. To complete the decomposition of variance in a manual way, the p-value is calculated in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to the treatment factor are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Factor \n    3 \n    31.81 \n    10.60 \n    2.11 \n    0.131 \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87"
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#describe-the-data",
    "href": "BasicFactorial_quarto_boat.html#describe-the-data",
    "title": "BF[1]",
    "section": "Describe the Data",
    "text": "Describe the Data\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots or scatterplots with the means displayed.\nInteractive code and additional explanations of numerical summaries and plots in R are found at R Instructions->Descriptive Summaries section of the book.\n\nNumerical Summaries\n\n\n\nAfter loading required packages, we will read in the data and do some wrangling.\n\n\nCode\n## Reduced data to match decomposition example\nvirtual <- read_csv(\"data/virtual_training_redux.csv\") \n\n#A bit of data wrangling\nvirtual <- virtual |>\n   mutate(\n         Treatment = case_when(\n           grp.trt %in% 1  ~ \"Control\",\n           grp.trt %in% 2  ~ \"Monitor/Keyboard\",\n           grp.trt %in% 3  ~ \"Joypad\",\n           grp.trt %in% 4  ~ \"Wearables\"\n          )\n        )\n\n\nWe then calculate summary statistics for each level of training method, in Table 1. Monitor/Keyboard has the highest mean (7.16) and median (8.33). It appears to be the best training method. Our ANOVA will seek to know if differences between training methods are statistically significant.\n\n\nCode\nfavstats(procKnow~Treatment, data = virtual) |> \n  kable(digits = 2) |> \n  kable_styling(full_width = TRUE)\n\n\n\nTable 1:  Numerical Summary \n \n  \n    Treatment \n    min \n    Q1 \n    median \n    Q3 \n    max \n    mean \n    sd \n    n \n    missing \n  \n \n\n  \n    Control \n    0.33 \n    4.64 \n    5.25 \n    6.24 \n    6.66 \n    4.75 \n    2.32 \n    6 \n    0 \n  \n  \n    Joypad \n    1.88 \n    6.25 \n    6.61 \n    8.25 \n    9.45 \n    6.58 \n    2.65 \n    6 \n    0 \n  \n  \n    Monitor/Keyboard \n    5.45 \n    6.78 \n    8.33 \n    8.78 \n    9.78 \n    7.85 \n    1.65 \n    6 \n    0 \n  \n  \n    Wearables \n    4.94 \n    5.21 \n    7.03 \n    8.91 \n    9.83 \n    7.16 \n    2.22 \n    6 \n    0 \n  \n\n\n\n\n\n\n\n\nGraphical Summaries\nYou should also visualize the data. Since there are only six data point, a scatter plot may be preferred over a boxplot.\n\n\nCode\nggplot(data = virtual, \n       mapping = aes(x=Treatment, y = procKnow, group = 1)) +\n  geom_point() +\n  stat_summary(fun = mean, \n               geom= \"line\") +\n  labs(x = \"Training Method\", y = \"Process Knowledge Test Score\",\n       title = \"Process Knowledge Scores by Training Method\",\n       subtitle = \"Group Means Connected with a Line\")\n\n\n\n\n\nFigure 5: Graphical Summary\n\n\n\n\nThis plot reinforces the conclusion that Monitor/Keyboard tends to have higher scores. The outliers in the Control and Joypad method also become very apparent."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#create-the-model",
    "href": "BasicFactorial_quarto_boat.html#create-the-model",
    "title": "BF[1]",
    "section": "Create the Model",
    "text": "Create the Model\nYou then create the model using the aov() function. To see results of the F-test you can feed your model into a summary() function.\n\nmyaov <- aov(Y ~ X, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is the user defined name in which the results of the aov() model are stored\nY is the name of a numeric variable in your dataset which represents the quantitative response variable.\nX is the name of a qualitative variable in your dataset. It should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\nYourDataSet is the name of your data set.\n\nExample Code\n\n\n method_aovA name you come up with for your model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  procKnow The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Treatment, The independent variable containing the names for the 4 training methods  data = virtual Tell the model to look in the dataset named “virtual” for procKnow and Treatment variables  ) Functions always end with a closing parenthesis  summary( Give important information about an object. When called on an aov object the default is to print the ANOVA summary table  method_aov  Whatever you named your ANOVA model in the previous line   )  Functions always end with a closing parenthesis  Click to toggle output Click to toggle output. \n\n\n\n\n\n            Df Sum Sq Mean Sq F value Pr(>F)\nTreatment    3  31.81  10.604   2.111  0.131\nResiduals   20 100.49   5.024               \n\n\n\nWe then interpret the results. Training method does not appear to be a significant factor since the p-value (0.131) is higher than our significance level of 0.05. Therefore, we cannot conclude that one training method results in a better mean test score than another."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#check-assumptions",
    "href": "BasicFactorial_quarto_boat.html#check-assumptions",
    "title": "BF[1]",
    "section": "Check assumptions",
    "text": "Check assumptions\nNow that the model is created the assumptions need to be checked. Interactive code and additional explanation for assumption checking can be found in the Model Diagnostics and Assumptions sections of the book respectively.\nBelow, we find that all assumptions of our lifeboat training method model are met and we can trust the hypothesis test that was just conducted.\n\nConstant Variance\nWe first check to see if the levels of training method have constant variance. The points in Figure 5 have similar spread, with the exception of the particularly low outlier scores in the Control and Joypad groups. Furthermore, in Table 1 we see that the largest standard deviation (2.65 for Joypad) is not more than double the smallest standard deviation (1.65 for Monitor/Keyboard). Therefore, the assumption of constant variance appears to be met.\n\n\nNormally Distributed Residuals\nA QQ-plot of the residuals is shown in Figure 6. Since none of the points are outside of the boundary it is safe to conclude that residuals are normally distributed.\n\n\n\n\n\nCode\ncar::qqPlot(method_aov$residuals)\n\n\n[1] 13  6\n\n\n\n\n\nFigure 6: QQplot of Model Residuals\n\n\n\n\n\n\nIndependent Residuals\nNothing about the study suggests a lack of independence among the residuals. The data was obtained second hand. If possible, you should ask the principal researcher more about how the data was collected. For our purposes, we will assume the row number in the dataset does not represent the order in which the data was originally collected. Therefore, an order plot would not be helpful in detecting order bias. Thus, based on everything we know about the study, we have no reason to suspect the independent residuals assumption is violated."
  },
  {
    "objectID": "unbalanced.html",
    "href": "unbalanced.html",
    "title": "Analysis of Unbalanced Data",
    "section": "",
    "text": "A balanced dataset is one in which there are an equal number of replicates for each and every factor level combination. Unbalanced datasets are those that have an unequal number of replicates in at least one factor level combination. In reality, it is more common to have unbalanced data than balanced data. This is particularly true for observational studies. Therefore, it is critical to learn how to analyze unbalanced data.\nThe formulas for unbalanced data are more complicated than when the data is balanced. This is not an issue since we will let computers do the calculations. The bigger issue deals with the fact that unbalanced datasets often result in correlated factor effects. Due to the equal number of replicates, factors in a balanced dataset are orthogonal. Factors in an unbalanced dataset are not guaranteed this desirable property.1\n\n\nFigure 1 is a graphical depiction of an unbalanced dataset for two factors A and B, each with 2 levels, coded as -1 and 1. You can see that each factor level combination appears an equal number of times2.\n\n\n\n\n\nFigure 1: Balanced, orthogonal data\n\n\n\n\nThe correlation of these two columns of 1’s and -1’s is zero.\n\n\n\n\n\nWe are measuring the correlation of the coded factors with each other. We have not even bothered to define the response variable in these examples, since it is irrelevant to the discussion.\nNow consider Figure 2, where there are fewer observations for the A=1, B=-1 combination, and more observations for A=1, B=1.\n\n\n\n\n\nFigure 2: Unbalanced, non-orthogonal data\n\n\n\n\nThe correlation between the two factors is NOT zero.\n\n\n\nThe issue with correlated factors is that their effects on the response are also confounded. When the response varies it cannot be determined how much of the variation in the response is due to factor A and how much was due to factor B."
  },
  {
    "objectID": "unbalanced.html#type-i-1",
    "href": "unbalanced.html#type-i-1",
    "title": "Analysis of Unbalanced Data",
    "section": "Type I",
    "text": "Type I\nFor an example of when Type I may be useful we do not need to look any further than the plant study we have been using all along on this page. Say our research question aims to test the effectiveness of thinning after accounting for the plant’s initial size our hypothesis matches a Type I approach. The research question specifies the order in which we want to consider the factors. Since Type I ANOVA is dependent on the order in which factors are specified in the model, we are able to incorporate the desired order from our research question into the analysis."
  },
  {
    "objectID": "unbalanced.html#type-ii-1",
    "href": "unbalanced.html#type-ii-1",
    "title": "Analysis of Unbalanced Data",
    "section": "Type II",
    "text": "Type II\nYou may want to use a Type II ANOVA if the disparity in sample sizes reflects a similar disparity in population size. Perhaps your end goal is to apply the treatment to all members of the population and you want any difference observed in the study to be present in the population. In that case, Type II may be the best choice. This will be more common in observational studies.\nFor example, a web developer randomly assigns website visitors to one of two website designs. Design A is evenly split between males and females, but Design B receives many more males than females. In this case, the lopsided nature of the gender distribution may accurately reflect the population of website visitors being predominantly male.\nThe test of the main effects for gender and website design will be influenced by sample sizes. Say we conclude that people tend to buy more products when presented with website A. This conclusion will be influenced more heavily by males since males represented a larger proportion of the sample. But in this case that’s okay because males also represent a larger part of our target audience (website visitors)."
  },
  {
    "objectID": "unbalanced.html#type-iii-1",
    "href": "unbalanced.html#type-iii-1",
    "title": "Analysis of Unbalanced Data",
    "section": "Type III",
    "text": "Type III\nLet’s continue with the website design and gender study mentioned above. Now, instead of taking the role of a business owner, we assume the role of a cognitive psychologist. We are not interested in trying to maximize profits for a target market. Rather, we are interested in knowing how individuals respond to the two different site designs. The fact that we partnered with a website with predominantly male clientele is incidental. We want to arrive at conclusions that will be useful in explaining/predicting behavior of an individual.\nIf we use Type II ANOVA the result of the significance test will be confounded with the fact that males account for a larger portion of the sample. A Type III ANOVA will not weight by sample size and will treat the estimated means of males and females equally. Thus our results can be used to predict an individual’s behavior based on their gender and website design. Our findings can now be used by other websites with a different clientele (e.g. predominantly female) to correctly predict/explain individual’s actions."
  },
  {
    "objectID": "unbalanced.html#summary-vs.-anova",
    "href": "unbalanced.html#summary-vs.-anova",
    "title": "Analysis of Unbalanced Data",
    "section": "summary() vs. anova",
    "text": "summary() vs. anova\nMany students are in the habit of using summary() to evaluate model hypothesis tests. When called on an aov object (i.e. an object created using the aov() command), summary()’ behavior is to produce a Type I ANOVA table.\nHowever, when called on an lm() object, summary() does not produce an ANOVA table at all. The default output is to print factor coeffcients, standard deviations, and t-test results (t statistic and p-value). The p-value from the t-tests are equal to the p-values from a Type III ANOVA applied to the same model.\n\n\nlm() is usually preferred over aov() if there are 1 or more numeric independent variables in the model.\nTo get a ANOVA table for an lm() object you can call car::Anova() or anova() on it, depending on the what type you desire."
  },
  {
    "objectID": "unbalanced.html#summary",
    "href": "unbalanced.html#summary",
    "title": "Analysis of Unbalanced Data",
    "section": "summary()",
    "text": "summary()\nMany students are in the habit of using summary() to evaluate model hypothesis tests. When called on an aov object (i.e. an object created using the aov() command), summary()’ prints a Type I ANOVA table.\nHowever, when called on an lm() object, summary() does not print an ANOVA table at all. The default output is to print variable coefficients, standard deviations, and t-test results (t statistic and p-value). If the object has an independent, categorical factor variable a t-test will be conducted for the factor levels. (Actually, all but 1 factor level will be tested. The missing factor level is considered the reference level and is included in the intercept). If there are only two factor levels, the p-value from the t-test of that factor will be equal to the p-values from a Type III ANOVA applied to the same model.\n\n\nlm() is usually preferred over aov() if there are 1 or more numeric independent variables in the model.\nTo get a ANOVA table and the F-tests for a factor’s overall significance you can call car::Anova() or anova() on an lm() object."
  }
]