[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Anova_F-test.html",
    "href": "Anova_F-test.html",
    "title": "ANOVA and the F-Test",
    "section": "",
    "text": "With the effects model defined we will want to test whether the treatment factor(s) has a statistically significant effect on the response variable. In other words we are interested in testing the hypotheses:\n\\[\nH_0: \\alpha_1 = \\alpha_2 = ... = 0\n\\\\\n\\newline\n\\\\\nH_a: \\alpha_i \\ne 0 \\text{ for at least one i}\n\\qquad(1)\\]\nWhere \\(\\alpha_i\\) represents the effect of a factor level.\nAnalysis of variance (ANOVA) is a statistical technique that allows us to simultaneously test all factor level effects at the same time."
  },
  {
    "objectID": "Anova_F-test.html#multiple-t-tests",
    "href": "Anova_F-test.html#multiple-t-tests",
    "title": "ANOVA and the F-Test",
    "section": "Multiple t-tests",
    "text": "Multiple t-tests\nAt this point it is reasonable to ask if we couldn’t arrive at the same conclusion by simply conducting multiple t-tests. For example, you could do a t-test for each factor level to determine if the effect is significantly different from zero. Or you might consider testing each combination of factor level effects to see if they are equal.\nThe multiple t-test approach has a couple of a drawbacks. The first drawback becomes apparent if you have many factor levels. If you only have 3 or 4 factor levels conducting many tests may be only a minor annoyance. However, if there are many factor levels it becomes a real burden to run, present and interpret so many tests.\nThe other main drawback of using multiple t-tests is more substantive and has to do with the probability of a Type I error. Suppose the treatment factor in our study has 3 levels. The null hypothesis associated with an ANOVA that tests all factor level effects simultaneously is:\n\\[\nH_0: \\alpha_1 = \\alpha_2 =  \\alpha_3 = 0\n\\]\nTesting at a 0.05 significance level means there is a 0.05 probability we will incorrectly reject this null hypothesis (i.e. commit a Type I error). Conversely, there is 0.95 probability we will NOT commit a Type I error.\nIf we attempt to approach the problem by conducting multiple t-tests, we would test the following set of null hypotheses:\n\\(H_0: \\alpha_1 = 0\\) and \\(H_0: \\alpha_2 = 0\\) and \\(H_0: \\alpha_3 = 0\\).\nWe may conduct each of these tests at the 0.05 significance level. Incorrectly rejecting the null hypothesis on any one of these tests would result in the same Type 1 error as incorrectly rejecting the null hypothesis of our ANOVA test of all the effects simultaneously.\nSo what is the probability of committing a Type 1 error in at least 1 of these 3 independent tests? The simplest way to find the probability of committing a Type 1 error in at least one of 3 tests is to calculate \\(1 – P(\\text{no Type 1 errors in all three tests})\\). As previously stated, the significance level (0.05) of each test represents the probability of a Type 1 error. Therefore, the probability of not committing a Type 1 error on each test is 0.95. If we treat the tests as independent, we can find the probability of NOT committing a Type 1 error in all of the tests by multiplying the probabilities:\n\\[\n0.95 * 0.95 * 0.95 = 0.857\n\\]\nWe can subsequently find \\(1-0.857 = .143\\) is the probability of committing a Type 1 error in at least one of the tests, assuming all the null hypotheses are true. This is often referred to as the family wise error rate. The Type 1 error probability (0.143) in this family of t-tests is almost 3 times higher than the ANOVA Type 1 probability of 0.05.\nIn summary, ANOVA allows us to keep the number of tests manageable and it greatly simplifies how Type 1 error is addressed. If we consider a study with more than 1 factor, the advantages of ANOVA increase. ANOVA is a more powerful test because, unlike a multiple t-test approach, while testing one factor’s effects it can account for the other factors’ impact on the response. In this regard, ANOVA is similar to regression."
  },
  {
    "objectID": "Anova_F-test.html#regression",
    "href": "Anova_F-test.html#regression",
    "title": "ANOVA and the F-Test",
    "section": "Regression",
    "text": "Regression\nIndeed, ANOVA and linear regression are more similar than they are different. ANOVA and linear regression tend to each have their own vocabulary because they were developed under different circumstances. ANOVA was developed to deal with agricultural experiments where the independent variables were primarily categorical. Linear regression tends to be introduced as a tool to analyze data where the independent variables are quantitative. Though the language and output associated with each technique may appear different on the surface, the “math” (i.e. the linear algebra) underlying the hood of the techniques is identical. It is not uncommon to have a study where there are multiple quantitative independent variables and multiple categorical independent variables. Thus, the differences between the two lie more in the problems they tend to be applied to and the vocabulary of the researcher than in any meaningful difference in results."
  },
  {
    "objectID": "Anova_F-test.html#mean-squares-ms",
    "href": "Anova_F-test.html#mean-squares-ms",
    "title": "ANOVA and the F-Test",
    "section": "Mean Squares (MS)",
    "text": "Mean Squares (MS)\nYou can think of Mean Squares (MS) as synonymous with variance. The F statistic is a ratio of variances:\n\\[\nF = \\frac{\\text{Variation between factor levels}}{\\text{Variation within factor levels}} = \\frac{\\text{Mean squares of treatment factor means}}{\\text{Mean squares of residual errors}}\n\\]\nWith this is mind, we can fill in the F column of the ANOVA table for Treatment Factor.\n\n\nTable 2: Blank ANOVA summary table for an experiment with 1 treatment factor\n\n\n\n\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nF\np-value\n\n\n\n\nBenchmark\n\n\n\n\n\n\n\nTreatment Factor\n\n\n\n\\(\\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}}\\)\n\n\n\nResidual Error\n\n\n\n\n\n\n\nTotal\n\n\n\n\n\n\n\n\n\nTo find the variation between factor level means, calculate the sample variance of factor level means and multiply it by the number of replicates in each factor level. (In the case of unbalanced data where you do not have the same number of replicates in each factor level, weighting by sample size is needed).\nThe Mean Squares of the residual error factor (i.e. Mean Squared Error, MSE) represents the within factor level variation. To calculate it you can find the sample variance within each factor level and then take the mean of those variances. (In the case of unbalanced data where you do not have the same number of replicates in each factor level, you would take a weighted average).\n\n\n\nFigure 4: Data from an experiment with 3 factor levels is shown in two separate panels. Left panel shows variation between factor level means. Right panel shows variation within factor levels.\n\n\nIn Figure 4 data from an experiment with 3 factor levels is shown. The panel on the left shows the factor level means plotted as points and the grand mean as a read line. In the panel on the right, the factor level means are plotted in blue and the deviation from each point to its respective factor level mean is depicted. From the panel on the left we can see the between group variation. As mentioned above, the mean squares for treatment could be computed as the variance of the 3 factor level means, and multiplied by 15 (the number of replicates in each factor level). The mean square error could be computed by finding the sample variance within each group and then taking the mean of those 3 variance estimates.\nThough the above methods work, the ANOVA summary table captures interim steps for an alternative (preferred) algorithm for calculating mean squares. Since Mean Squares is synonymous with variance, now is a good time to review the sample variance formula.\n\\[\ns^2 = \\frac{\\sum{(y_i - \\bar{y})}^2}{n-1}\n\\qquad(2)\\]\nUpon closer examination of Equation 2 you can see that this formula is essentially a mean. In fact, you can think of variance as a mean of squared deviations (a.k.a. errors). Any mean is built using 2 parts:\n\n\nRecall that an effect is defined as a deviation from the mean.\n\nnumerator: a sum or total\ndenominator: the number of pieces of information used to create the sum in the numerator\n\nHere, the numerator is the sum of squares and the denominator is the degrees of freedom.\n\n\n\n\n\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nF\np-value\n\n\n\n\nBenchmark\n\n\n\n\n\n\n\nTreatment Factor\n\n\n\\(\\frac{SS_\\text{Treatment Factor}}{df_\\text{Treatment Factor}}\\)\n\\(\\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}}\\)\n\n\n\nResidual Error\n\n\n\\(\\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}}\\)\n\n\n\n\nTotal"
  },
  {
    "objectID": "Anova_F-test.html#sum-of-squares-ss",
    "href": "Anova_F-test.html#sum-of-squares-ss",
    "title": "ANOVA and the F-Test",
    "section": "Sum of Squares (SS)",
    "text": "Sum of Squares (SS)\nLet’s talk about the numerator first, this will be the sum of squared deviations, or Sum of Squares for short. The Sum of Squares is a measure of the total variability in a dataset. A naïve approach to calculating total variability in a dataset is to measure the distance from each value to the mean of the dataset. The problem with this approach is that those distance measures will always sum to zero.\n\n\nDon’t believe me? Go ahead and test it out. Pick some numbers and find their mean. Then calculate each number’s distance from the mean (keeping track of negative versus positive distances) and add them up. You will always end up with a sum of zero.\nTo avoid this problem, statisticians square the distances before summing them. This results in a value that summarizes the total amount of spread in the dataset. This quantity, the Sum of Squares, is important and so it has its own column in the ANOVA summary table.\n\n\n\n\n\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nF\np-value\n\n\n\n\nBenchmark\n\n\\(n*\\bar{y}_\\text{..}^2\\)\n\n\n\n\n\nTreatment Factor\n\n\\[ \\sum \\hat{\\alpha}_i^2*n_i\\]\n\\(\\frac{SS_\\text{Treatment Factor}}{df_\\text{Treatment Factor}}\\)\n\\(\\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}}\\)\n\n\n\nResidual Error\n\n\\[ \\sum \\hat{\\epsilon}_\\text{ij}^2 \\]\n\\(\\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}}\\)\n\n\n\n\nTotal\n\n\\(y_\\text{ij}^2\\)"
  },
  {
    "objectID": "Anova_F-test.html#degrees-of-freedom",
    "href": "Anova_F-test.html#degrees-of-freedom",
    "title": "ANOVA and the F-Test",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nIn short, you can think of degrees of freedom as the number of unique pieces of information that contributed to the variance estimate.\n\n\n\n\n\n\nDegrees of Freedom\n\n\n\nThe number of unique pieces of information that contributed to the variance estimate.\n\n\nIn our dataset we have a certain number of observations. All those observations can be used to estimate the variance in the dataset. But you will notice in Equation 2 the data has already been used to estimate the grand mean (\\(\\bar{y}\\) estimates \\(\\mu\\)). In other words, before we can estimate the variance we must use the data to estimate the mean. Estimating the mean “uses up” one degree of freedom. This is why the denominator of the sample variance formula divides by \\(n-1\\) instead of by \\(n\\).\nFor additional explanation, consider this simple example. I have three data points and I know that the mean of these 3 data points is 10. The value of the first data point could be any number, it is free to vary. The value of the second data point could be any number also, it is free to vary. The third number’s value is not free to vary. It is constrained by the fact that the mean of the 3 data points must be 10. The values of the first two datapoints will determine the value of the third under the constraint of a known (or estimated) mean.\n\n\nTable 3: Only n-1 values are free to vary when the mean of the values is known\n\n\n\n\n\n\n\n\n\nvalue 1\nvalue 2\nvalue 3\n\nMean of 3 Values\n\n\n\n\na\nb\n\\(3*10 - (a+b)\\)\n->\n10\n\n\nfree to vary\nfree to vary\ndepends on other two values\n\n\n\n\n\n\nHow does this apply to the analysis of variance? Well, initially I have \\(n\\) observations, or in other words \\(n\\) unique pieces of information that can be used to estimate variance of the dataset. As I try to break the variance into its component pieces, I will also need to reallocate those \\(n\\) pieces of information to each factor (benchmark, treatment factor, residual error) for use in estimating their mean squared error. To paraphrase the law of the conservation of mass, “the amount of information can neither be created nor destroyed”.\nWe will reason through the degrees of freedom calculation for each of the 3 sources in the ANOVA table. Keep in mind, we are using the simplest experiment, just one treatment factor, to illustrate these concepts. In more complex designs, there will be additional factors listed in the “sources” column.\nAs was mentioned, every time we use the data to estimate a parameter we use a degree of freedom. To find the benchmark effect we take all the values and estimate the grand mean; that uses up one degree of freedom because we have estimated 1 mean.\nWhen calculating the degrees of freedom for the treatment factor you might be tempted to think that the degrees of freedom is equal to the number of factor levels because you have to estimate a mean for each level. But, remember the simple example depicted in figure Table 3. Because I have already estimated the grand mean (benchmark), the last factor level is is not free to vary and so is not estimated directly. The mean of the last factor level will have to be a number that satisfies the constraint that the mean of all the factor level means is the grand mean.\nExplained another way, consider the fact that all the factor level effects must sum to zero. If there are \\(m\\) factor levels, I only need to estimate effects for \\(m-1\\) levels. The last level’s effect is a function of the other factor level effects, it does not need to be estimated and therefore does not need a degree of freedom.\nFinally, consider the residual error factor. The non-technical definition of the term residual means “left over”. The degrees of freedom for the residual error factor is whatever degrees of freedom are left over.\nIn summary, to estimate the degrees of freedom for a factor, I start with the total number of observations and then subtract the number of means that need to be calculated in order to calculate the factor’s level effects. This is exactly what the general rule for finding degrees of freedom tells us.\n\n\n\n\n\n\nGeneral rule to find degrees of freedom for a factor\n\n\n\n\\[\n\\text{df} = \\text{number of levels} - \\text{sum of df of outside factors}\n\\]"
  },
  {
    "objectID": "BasicFactorial.html",
    "href": "BasicFactorial.html",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "",
    "text": "The experimental designs in this section have 2 key characteristics in common:\nTo assign something completely at random means that each experimental unit has a known and equal chance of being selected for a particular treatment and that no other considerations are taken into account when making treatment assignments. Usually, for balance, the same number of units are assigned to each treatment. For example, if I have 4 treatment and 16 units, I may use a computer to randomly shuffle the units into treatment groups.\nFactorial experiments involve two or more factors that are crossed. Factorial crossing means that each combination of factor levels is considered as a treatment in the study. (A study with just one factor is not technically a factorial design, but we will lump it in with our discussion of factorial experiments her because of the completely random treatment assignment).\nContrast a factorial design with the one-at-a-time approach. In a one-at-a-time approach, if I had two factors I wanted to study I would run two separate experiments to evaluate the effect of each factor on the response one-at-time. Factorial designs have a couple of major advantages over one-factor-at-a-time studies.\nEXAMPLE of BF2???\nIn summary, “factorial” refers to how you determine which treatments will be included in the study, and “completely randomized” refers to how treatments are assigned to subjects."
  },
  {
    "objectID": "BasicFactorial.html#bf1",
    "href": "BasicFactorial.html#bf1",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "BF[1]",
    "text": "BF[1]\nA study with just one factor\n\nOverview\nIn a basic one-way factorial design (BF[1]), only one factor is purposefully varied. Each level of the factor is considered a treatment. Each experimental unit is randomly assigned to exactly one treatment.\n\nFactor structure\nThe factor structure for the model resulting from a completely randomized, one factor with design is:\n\nThe above diagram illustrates a factor with 4 levels, 6 replications at each level.\n\n\nHypotheses and model\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from treatment \\(i\\)\n\\(\\mu\\): the grand mean of the dataset. Also referred to as an overall mean or benchmark.\n\\(\\alpha_i\\): effect of treatment \\(i\\)\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its treatment mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\nAssumptions\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\nEach experimental unit is randomly assigned to only 1 treatment (or factor level)\nThe error term of the model (\\(\\epsilon_{ik}\\)) is normally distributed. This assumption is met when the residuals are normally distributed (as seen in a qq-plot).\nThe population variance of each group is equal. This is often called the homogeneity of variance, or constant variance assumption. This is considered met when each group of residuals in the residual vs. fitted-values plot shows a similar vertical spread.\n\n\n\n\n\nDesign\nIn a one factor design, one factor is purposefully varied and all other factors are controlled in order to isolate the effect of just the factor under study. Each level of the factor is considered a treatment.\nIn a completely randomized design, each experimental unit is randomly assigned to exactly 1 treatment. It is common to keep the number of units assigned to each treatment the same to ensure balance. This can be done by listing all the subjects, then listing the treatments, as seen below:\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n1\n\n\nSubject 2\nA\n2\n\n\nSubject 3\nB\n3\n\n\nSubject 4\nB\n4\n\n\nSubject 5\nC\n5\n\n\nSubject 6\nC\n6\n\n\n\nThen you randomly shuffle the treatment column. (You should also be paying attention to the order in which subjects and treatments are being experimented on as this could be a potential source of bias. In a BF[1], you randomize the order also.) The result might look something like this.\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n4\n\n\nSubject 2\nB\n3\n\n\nSubject 3\nC\n6\n\n\nSubject 4\nC\n5\n\n\nSubject 5\nA\n1\n\n\nSubject 6\nB\n2\n\n\n\nYou may notice in the above example that, even with randomization, treatment C occurs in the last 2 observations. If we were truly concerned about the order we could be more strategic and implement a blocked design to prevent “unlucky” ordering and pairing.\nConsider the following example. An experiment was done to asses different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included: Lecture/Materials (Control) (1), Monitor/Keyboard (2), Head Monitor Display/Joypad (3), and Head Monitor Display/Wearables (4). The response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test).\nTo obtain a balanced design, we will want each treatment to be assigned to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\ntreatment_list <- rep(1:4,4) #This repeats the sequence of 1 to 4, four times\ntreatment_list\n\n [1] 1 2 3 4 1 2 3 4 1 2 3 4 1 2 3 4\n\n\nHere it is reformatted in a easy to read table.\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\nThen we randomly shuffle treatments with subjects to get the following assignments. The R code could look like this\n\nset.seed(17) #only use this if you want the exact same random selection as this example\nsample(treatment_list, 16)\n\n [1] 2 4 1 4 3 1 3 2 2 2 4 3 4 1 3 1\n\n\nWe can see here that subject 1 should get treatment 2. Subject 2 gets treatment 4, Subject 3 gets treatment 1 and so on.\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n2\n\n\nSubject 2\n4\n\n\nSubject 3\n1\n\n\nSubject 4\n4\n\n\nSubject 5\n3\n\n\nSubject 6\n1\n\n\nSubject 7\n3\n\n\nSubject 8\n2\n\n\nSubject 9\n2\n\n\nSubject 10\n2\n\n\nSubject 11\n4\n\n\nSubject 12\n3\n\n\nSubject 13\n4\n\n\nSubject 14\n1\n\n\nSubject 15\n3\n\n\nSubject 16\n1\n\n\n\n\n\n\nDecomposition and Factor Structure\nThis section serves as a bridge between the design and the analysis of an experiment. It is equivalent to doing the analysis by hand. The primary goal is to see how the design decisions impact the analysis; including a deeper understanding of what the numbers in an ANOVA table mean and how they are calculated.\nA factor structure for an experimental design can help provide an effective way to organize and plan for the type of data needed for an experiment. For a basic one-way factorial design, three factors are involved for the experiment: the benchmark (or grand mean), the treatment, and the residual error. For example, an experiment was done to help train people in the procedure to launch a lifeboat. This was a Basic One-way Factorial Design, one where the treatments included: Lecture/Materials (Control) (1), Monitor/Keyboard (2), Head Monitor Display/Joypad (3), and Head Monitor Display/Wearables (4). The students were then given a pre-test before training and a post-test after training and the difference between the two scores was the measurement used from each student in the analysis. Therefore, we have four levels for the treatment with six replicates for each treatment (the actual study used 16 observations per treatment). The diagram below gives the factor structure of the design, and the accompanying mathematical model.\n\nA basic one-way factorial design has three factors: the benchmark, treatment, and residual. The effects of these factors can be summed together to find each observed value.\n\nThe observed values on the left show that there are 24 distinct observations of performance score, represented by the 24 cells - one for each of the observed values.\nThe benchmark represents the grand mean (or overall mean). The single large cell indicates that there is only one grand mean and it is part of every observation.\n\nThe treatment factor involves the four levels of the treatment represented by the four vertically long cells. Each treatment may have a distinct mean (or effect).\nThe residual error represents the difference between the observed value and the predicted value. The predicted value, also called the fitted value, is the sum of the grand mean and treatment effect. Each of the cells represent a distinct value for the residual error.\n\n\nInside vs. Outside Factors\nHaving a factor structure can help us determine the degrees of freedom and the effects of each factor. Before determining the degrees of freedom and the effects of each factor, understanding outside and inside factors is helpful.\nA factor is inside of another factor if all the levels of one factor (the inside factor) completely fits within a second factor (the outside factor).\nYou may find this analogy helpful. Pretend that an outside factor is a box, and the inside factor levels are blocks that fit perfectly within the box.\n\n  \n\nIn our basic one-way factorial design there are three factors: the benchmark, treatment, and residuals. In the picture below, benchmark is represented in red, treatment is drawn in blue, and the residual factor levels are depicted in black.\n\nIn order to understand the relationship between the benchmark and treatment factor, imagine picking up the levels of factor and placing them in the other factor one at a time. We will start with taking the levels of treatment and placing them inside of the benchmark.\n\nIn this picture you can see that one entire level of treatment can fit inside of a single level of benchmark. Even though they may share a boundary line, the level does not cross over and start sharing boundaries with any other level. You can repeat this for the other 3 levels of treatment with the same result. Therefore, we say that treatment is inside of benchmark, which is the same as saying that benchmark is outside of treatment.\nConsider now the relationship between treatment and residual. If we take a level of treatment and overlay it on the residual factor, we can see it does not fit neatly inside one of the levels of residual error. In fact, one level of treatment crosses the boundaries of many of the levels of residual error. Therefore, we cannot say that treatment is inside of residual error.\n\nSince treatment is not inside of residual error, does this necessarily mean that treatment is outside of residual error? We can determine this by taking one level of residual at a time and overlaying it on the treatment factor structure, as is pictured below. It can be seen that one level of residual error does NOT cross any of the treatment level boundaries. Therefore, we can safely say that treatment is indeed outside of residual error; or equivalently that treatment is outside of residual error.\n\nTo clarify a common misunderstanding, consider an experiment where we are looking at the inside vs. outside relationship of two factors: A, and B.\n\nWhen factor A is inside of factor B, we can also say factor B is outside of factor A.\nBut, when factor A is not inside of factor B, this does not necessarily mean that factor A is outside of factor B. Later you will come across designs where the two factors are neither outside nor inside of each other: they are crossed.\n\nIn summary, inside and outside factors for every basic one-way factorial design:\n\nThe benchmark factor is the outside factor for all the other factors (treatment and residual error)\nThe treatment factor is an inside factor to the benchmark factor but an outside factor to the residual error.\nThe residual error is an inside factor for all other factors (the benchmark and treatment factors).\n\n\n\nDegrees of Freedom\nWe can use our understanding of inside and outside factors to determine the degrees of freedom (df) for the benchmark, treatment, and residual errors factors.\nThe general formula for degrees of freedom for any factor in a design is:\n\n\ndf = Total levels of a factor minus the sum of the df of all outside factors\n\n\nAn alternative method of finding degrees of freedom is to count the number of unique pieces of information in a factor.\nGoing back to the lifeboat training example (see example above), we have 24 observations total and four levels of the treatment.\n\nFor benchmark, there is only one level of the factor (shown by the one cell) and there are no outside factors for benchmark. Therefore, the degrees of freedom for benchmark is one. Another way to think of this is that the degrees of freedom represents the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as I know the benchmark value (or better stated, as soon as I estimate the benchmark value) for just one of the observations, I know it for all the observations. Therefore, there is just one degree of freedom.\nFor treatment, there are four levels of the factor (shown by the four vertically long cells for treatment). Benchmark is the only factor outside of treatment. Take the number of levels for treatment (4) and subtract the degrees of freedom for benchmark (1), which yields 4-1 = 3 degrees of freedom for treatment.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the treatment effects really contains. Since all observations from the same treatment will have the same treatment effect applied, we really only need to know 4 pieces of information: the effect of each treatment. But the answer is actually less than that. Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom is 3. As soon as we know 3 of the treatment effects, we can fill in the treatment effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of the factor structure diagram). Both benchmark and treatment are outside factors for the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for benchmark and treatment (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the treatment effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 treatments is 20 observations, or in other words, 20 degrees of freedom.\n\n\nFactor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size for the benchmark, treatment, and residual errors factors. In other words, we can estimate the terms in the one-way ANOVA model.\nThe general formula for effect size for any factor of a design is:\n\n\nEffect size = factor level mean minus the sum of the effects of all outside factors\n\n\nTo demonstrate this, the lifeboat training study will be used; where each column of data comes from a different training method (a.k.a. treatment).\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the benchmark factor and the means for each treatment level.\nFor benchmark, get the mean of all 24 observations. The mean for all the observations is 6.5846. There is only one level for benchmark since, all observations come from the same benchmark. Therefore, this number is placed into each of the cells for the benchmark factor.\n\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. These numbers will be put in the columns associated with each level of the treatment (see below).\n\n\n\nCalculate effects\nFrom here we can calculate the effects for benchmark, treatment and residual errors. We will use the general formula for calculating effect size as stated above.\nFor the benchmark, there is only one level and there are no outside factors. Therefore, the effect due to benchmark is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nFor the treatment factor there are four means, one for each level. To calculate this, take the factor level mean and subtract it from the effect due to benchmark to get the effect for each treatment level. For Control, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the overall, or grand, mean. In a similar way you can find the effect for Monitor/Keyboard 7.8492 - 6.5846 = 1.2645. This means the student performance scores increased by 1.2645 on average in this condition compared to the overall mean. For Head Monitor Display/Joypad, the effect is -0.0058 (6.5789 - 6.5846). For Head Monitor Display/Wearables, the effect is 0.5770 (7.1616 - 6.5846) (see below).\n\nTo calculate the residual error effects we must remember that there are 24 levels of residuals. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for benchmark and the effect for the treatment that particular observation received. For instance, for the observation located in the top left of our dataset the observed value is 4.5614. Subtract the sum of the effects of outside factors (benchmark and treatment). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual errors effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was -0.1875 less than the average for all observations in the control group. In context of the this study, this individual’s performance was lower than his/her peers who received the same type of training.\nWe can repeat the calculation for the first residual in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to benchmark and its respective treatment (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in the table below on the right.\n\n\n\n\nCompleting the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA table enables us to conduct a hypothesis test of the significance of the treatment.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n     \n     \n     \n     \n  \n  \n    Treatment \n    3 \n     \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n     \n     \n     \n     \n  \n  \n    Total \n    24 \n     \n     \n     \n     \n  \n\n\n\n\n\nTo get the sum of squares (SS) for a factor, for each observation the effect for that factor needs to be squared. Then all the squared values are summed up to get the sum of squares.\nFor benchmark, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to benchmark.\n\\[\nSS_\\text{Benchmark} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor has four different effects, one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to treatment. For instance, for the control group, the effect is -1.8358. The value is then squared, and then multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Treatment} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the benchmark, treatment, and residual error factors.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n     \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n     \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWe can now calculate the mean squared error column, or mean square (MS). This mean is calculated by dividing sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation).\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. We can then see more clearly which factor is the a bigger source of variability.\nThe mean square calculations are:\n\\[\nMS_\\text{Benchmark} = \\frac{SS_\\text{Benchmark}}{df_\\text{Benchmark}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Treatment} = \\frac{SS_\\text{Treatment}}{df_\\text{Treatment}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWhen getting an F test statistic, testing for the treatment factor is the primary factor of interest so only the F test statistic for treatment is calculated for the analysis. To get the F test statistic for treatment, take the mean square (MS) due to treatment and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of this as calculating the variance in treatment effect sizes in the numerator and the variance of the distances for an observed value to its respective treatment mean in the denominator. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Treatment} = \\frac{MS_\\text{Treatment}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for treatment is calculated based on the F statistic for treatment and the degrees of freedom for both Treatment and Residual Error. In practice, you would not compute this by hand, but in order to complete the decomposition of variance in a manual way, we will calculate the p-value in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to treatment are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n    2.11 \n    0.131 \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\n\n\n\n\nR Instructions\nThe following stuff would belong in the R code pages instead of here\n\nNumerical Summaries\nIn the following explanations\n\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use as.factor(X) inside the aov(Y ~ as.factor(X),…) command.\nYourDataSet is the name of your data set.\n\nYou can take a tidyverse approach or a mosaic package approach to calculating numerical summaries.\nmosaic package:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\ntidyverse approach:\n\nlibrary(tidyverse)\nYourDataSet %>%\n  Group_by(X) %>%\n  Summarise(MeanY = mean(Y), sdY = sd(Y), sampleSize = n()) \n\n\n\nGraphical Summaries\nTo obtain a boxplot:\nboxplot(Y~X, data = YourDataSet)\nExample Code:\n\n\n\n\n\n\n\n\n\n\nResources\n\nExamples\nLifeboat launch training\nMosquito\n\n\nLinks to outside resources\nPopulate this section yourself with links to good examples, definitions, other sections within this textbook, or anything else you think will be interesting/helpful."
  },
  {
    "objectID": "BasicFactorial.html#bf2",
    "href": "BasicFactorial.html#bf2",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "BF[2]",
    "text": "BF[2]\nA study with exactly two factors used to predict a continuous response variable.\n\nOverview\nLorem Ipsum Overview\n\nHypotheses and model\nHere we would list the model in equation form along with the hypotheses we would want to test\n\n\nAssumptions\nA quick recount of the assumptions associated with the model. If this gets too repetitive maybe we could take it out and put it under broad topics\n\n\nFactor structure image\nThis image would actually probably go at the top somewhere, maybe even by or above the title, as a sort of visual anchor/synopsis as to what this design is all about in terms of its structural factors.\n\n\n\n\nDesign\nThis will explain how random assignment is conducted. It may generally be a short section, especially since I already explained about completely random assignment above. However, it could get more in-depth. For example, in blocking you can talk about the different methods for creating blocks, or for Latin Squares there’s a lot to describe. For partial fractional factorials it could get interesting, etc.\n\n\n\nDecomposition\nIt is what it sounds like: discussion of effect calculation, degree of freedom calculation, and factor structure diagrams. Where do things like notation get defined, and concepts like inside vs. outside factors? Should those go in the broad topics menu?\n\n\n\nR Instruction\nIt is what it sounds like: discussion of effect calculation, degree of freedom calculation, and factor structure diagrams. Where do things like notation get defined, and concepts like inside vs. outside factors? Should those go in the broad topics menu?\n\n\nResources\n\nExamples\nHere we could link to a full walk through example of the anlaysis (similar to the Math325 notebook)\n\n\nLinks to outside resources\nThis section the student would populate with links to good examples, definitions, other sections within this textbook, or anything else"
  },
  {
    "objectID": "BasicFactorial.html#bf3",
    "href": "BasicFactorial.html#bf3",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "BF[3]",
    "text": "BF[3]\nA study with exactly three factors used to predict a continuous response variable.\n\nOverview\nLorem Ipsum Overview\n\nHypotheses and model\nHere we would list the model in equation form along with the hypotheses we would want to test\n\n\nAssumptions\nA quick recount of the assumptions associated with the model. If this gets too repetitive maybe we could take it out and put it under broad topics\n\n\nFactor structure image\nThis image would actually probably go at the top somewhere, maybe even by or above the title, as a sort of visual anchor/synopsis as to what this design is all about in terms of its structural factors.\n\n\n\n\nDesign\nThis will explain how random assignment is conducted. It may generally be a short section, especially since I already explained about completely random assignment above. However, it could get more in-depth. For example, in blocking you can talk about the different methods for creating blocks, or for Latin Squares there’s a lot to describe. For partial fractional factorials it could get interesting, etc.\n\n\n\nDecomposition\nIt is what it sounds like: discussion of effect calculation, degree of freedom calculation, and factor structure diagrams. Where do things like notation get defined, and concepts like inside vs. outside factors? Should those go in the broad topics menu?\n\n\n\nR Instruction\nIt is what it sounds like: discussion of effect calculation, degree of freedom calculation, and factor structure diagrams. Where do things like notation get defined, and concepts like inside vs. outside factors? Should those go in the broad topics menu?\n\n\nResources\n\nExamples\nHere we could link to a full walk through example of the anlaysis (similar to the Math325 notebook)\n\n\nLinks to outside resources\nThis section the student would populate with links to good examples, definitions, other sections within this textbook, or anything else"
  },
  {
    "objectID": "BasicFactorial.html#fractional-factorial-designs",
    "href": "BasicFactorial.html#fractional-factorial-designs",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "Fractional Factorial Designs",
    "text": "Fractional Factorial Designs\nThis would probably not follow a similar structure as other sections\n\nOverview??\nLorem Ipsum Overview\n\n\n\nHow many treatments, design rank\nHere we would list the model in equation form along with the hypotheses we would want to test\n\n\n\nConfounding and a Generating Function\nA quick recount of the assumptions associated with the model. If this gets too repetitive maybe we could take it out and put it under broad topics\n\n\n\nAnything else??\n\n\n\nAdditional resources and links\n\nExamples\nHere we could link to a full walk through example of the anlaysis (similar to the Math325 notebook)\n\n\nLinks to outside resources\nThis section the student would populate with links to good examples, definitions, other sections within this textbook, or anything else\n\nThe decompositions presented in this book are all for balanced designs. Unbalanced designs (where not all treatments have an equal number of observations) use more complicated formulas, but a similar approach/process of decomposition is used."
  },
  {
    "objectID": "BasicFactorial_quarto.html",
    "href": "BasicFactorial_quarto.html",
    "title": "Basic Factorial",
    "section": "",
    "text": "The experimental designs in this section have 2 key characteristics in common:\n\nConditions are assigned to subjects (a.k.a. experimental units) completely at random\nA consistent method of checking requirements and factor relationships (What I’m trying to get at is that there is no nesting/blocking/random factors and so the MSE is always calculated the same. But I’m not sure if that will make sense to students this early in the semester.)\n\nNOT SURE HOW CRITICAL THESE DEFINITIONS WILL BE HERE, DEPENDS ON WHAT BRETT COMES UP WITH. THERE IS ALREADY SOME OVERLAP/REPEATING WITH THE FACTOR STRUCTURE SECTION. BUT REPITITION MAY NOT BE A BAD THING.\nTo assign something completely at random means that each experimental unit has a known and equal chance of being selected for a particular treatment and that no other considerations are taken into account when making treatment assignments.\nFactorial experiments involve two or more factors that are crossed. Full factorial crossing occurs when each combination of factor levels is present in the study. (A study with just one factor is not technically a factorial design, but we will lump it in with our discussion of factorial experiments here because of the completely random treatment assignment).\nContrast a factorial design with the one-at-a-time approach. In a one-at-a-time approach, if I had two factors I wanted to study I would run two separate experiments to evaluate the effect of each factor on the response one-at-time. Factorial designs have a couple of major advantages over one-factor-at-a-time studies.\n\nThey are a more efficient use of our time and material: I can get information about both of my factors from just one observation\nPerhaps most importantly, factorial designs allow the researcher to estimate interaction effects. Or in other words, we can observe how one factor’s effect on the response variable changes for different levels of the other factor.\n\nIn summary, “factorial” refers to how you determine which fact level combinations will be included in the study, and “completely randomized” refers to how treatments are assigned to subjects.\n\n\n\n\n\n\nBalanced vs. Unbalanced Data\n\n\n\nI feel like we need a disclaimer or caveat somewhere in the book to explain that the formulas presented here only work for balanced designs. A similar approach is used for unbalanced data, but the formulas would need to be adjusted to weight the groups according to their size. Maybe the disclaimer belongs here, maybe in the effects model or anova sections. Or maybe it has it’s own “broad topic”…?\n\n\n\n\nBF[1]\nA study with just one factor that is varied in the design.\n\nOverviewDesignDecompositionAnalysis in RResources\n\n\nIn a basic one-way factorial design (BF[1]), only one factor is purposefully varied. Each experimental unit belongs to exactly one factor level. (In the case of an observational study, only one independent factor is under consideration.)\n\nFactor Structure\nThe factor structure for the model resulting from a completely randomized, one factor design is:\n\n\n\n\nFigure 1: Example of BF1 Factor Structure\n\n\n\nFigure 1 illustrates a factor with 4 levels, 6 replications at each level.\n\n\nHypothesis and Model\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from factor \\(i\\)\n\\(\\mu\\): the grand mean of the data set. Also referred to as an overall mean or benchmark.\n\\(\\alpha_i\\): effect of treatment \\(i\\)\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its treatment mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\nAssumptions\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\nIndividual realizations of the error term (i.e. residuals) are independent of one another. We generally consider this requirement met if each experimental unit is randomly assigned to only 1 factor level. However, the researcher should always be on the look out for violations of this assumption and other bias.\nThe error term of the model (\\(\\epsilon_{ik}\\)) is normally distributed. This assumption is met when the residuals are normally distributed (as seen in a qq-plot).\nThe population variance of each group is equal. This is often called the homogeneity of variance, or constant variance assumption. This is considered met when each group of residuals in the residual vs. fitted-values plot shows a similar vertical spread.\n\n\n\n\n\nIn a one factor design, one factor is purposefully varied and all other factors are controlled in order to isolate the effect of just the factor under study. Each level of the factor is considered a treatment.\nIn a completely randomized design, each experimental unit is randomly assigned to exactly 1 treatment. It is common to keep the number of units assigned to each treatment the same to ensure balance. This can be done by listing all the subjects, then listing the treatments, as seen below:\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n1\n\n\nSubject 2\nA\n2\n\n\nSubject 3\nB\n3\n\n\nSubject 4\nB\n4\n\n\nSubject 5\nC\n5\n\n\nSubject 6\nC\n6\n\n\n\nThen you randomly shuffle the treatment column. (You should also be paying attention to the order in which subjects and treatments are being experimented on as this could be a potential source of bias. In a BF[1], you randomize the order also.) The result might look something like this.\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n4\n\n\nSubject 2\nB\n3\n\n\nSubject 3\nC\n6\n\n\nSubject 4\nC\n5\n\n\nSubject 5\nA\n1\n\n\nSubject 6\nB\n2\n\n\n\nYou may notice in the above example that, even with randomization, treatment C occurs in the last 2 observations. If we were truly concerned about the order we could be more strategic and implement a blocked design to prevent “unlucky” ordering and pairing.\nConsider the following example. An experiment was done to asses different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included:\n\nLecture/Materials (Control)\nMonitor/Keyboard\nHead Monitor Display/Joypad, and\nHead Monitor Display/Wearables.\n\nThe response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test).\nWe want to assign each treatment to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\n\nCode\n#Repeat the sequence of 1 to 4, four times\nTreatment <- rep(1:4,4) \n\n#Create a sequence from 1 to 16\n#Paste the word \"Subject \" in front of each id #\nSubject <- paste(\"Subject\", seq(1:16), sep = \" \")\n\n#Combine the vector of treatment numbers and Subject ID's into 1 tibble/data frame\nassignment_table <- tibble(Subject, Treatment)\n\n#print the table, pander() makes it look nice\npander(assignment_table) \n\n\n\n\n\n\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\n\n\nThen we randomly shuffle the Treatments column to get the following assignments. Check out the R-code to see how this is done.\n\n\nCode\n#set.seed() allows us to get the same random sample each time\nset.seed(42) \n\n#sample() will randomly select from the Treatment vector 16 times without replacement\n# %>% is called a pipe. It simply takes the output from the command on the left\n# and sends it to the command on the right\ntibble(Subject, sample(Treatment, 16)) %>% pander()\n\n\n\n\n\n\n\n\n\nSubject\nsample(Treatment, 16)\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n1\n\n\nSubject 3\n4\n\n\nSubject 4\n1\n\n\nSubject 5\n2\n\n\nSubject 6\n4\n\n\nSubject 7\n2\n\n\nSubject 8\n2\n\n\nSubject 9\n4\n\n\nSubject 10\n3\n\n\nSubject 11\n3\n\n\nSubject 12\n1\n\n\nSubject 13\n3\n\n\nSubject 14\n4\n\n\nSubject 15\n3\n\n\nSubject 16\n2\n\n\n\n\n\nWe can see here that subject 1 should get treatment 2. Subject 2 gets treatment 4, Subject 3 gets treatment 1, and so on.\n\n\n\nThis section serves as a bridge between the design and the analysis of an experiment. It is equivalent to doing the analysis by hand. The primary goal is to see how the design decisions impact the analysis; including a deeper understanding of what the numbers in an ANOVA table mean and how they are calculated.\nThe factor structure diagram of an experimental design is an effective way to organize and plan for the type of data needed for an experiment. Recall that in our lifeboat example there were four levels of training method with six replicates for each (the actual study used 16 observations per treatment). The diagram below gives the factor structure of the design, and the accompanying mathematical model.\n\n\n\n\nExample of BF1 Factor Structure\n\n\n\nA basic one-way factorial design has three analysis factors: the benchmark, treatment, and residual. The effects of these factors can be summed together to find each observed value.\n\nThe observed values on the left show that there are 24 distinct observations of performance score, represented by the 24 cells - one for each of the observed values.\nThe benchmark represents the grand mean (or overall mean). The single large cell indicates that there is only one grand mean and it is part of every observation.\nThe treatment factor involves the four levels of the treatment represented by the four vertically long cells. Each treatment may have a distinct mean (or effect).\nThe residual error represents the difference between the observed value and the predicted value. The predicted value, also called the fitted value, is the sum of the grand mean and treatment effect. Each of the cells represent a distinct value for the residual error.\n\n\nDegrees of Freedom\nWe can use our understanding of inside and outside factors to determine the degrees of freedom (df) for the benchmark, treatment, and residual errors factors. We start with 16 observations - or pieces of information. In other words, we have 16 degrees of freedom that need to be allocated to the 3 factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the lifeboat example, benchmark has one level (shown by the one cell in Figure 1) and there are no outside factors for benchmark. Therefore, the degrees of freedom for benchmark is one.\nRemember, the degrees of freedom represents the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as I estimate the benchmark effect for just one of the observations, I know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for benchmark were also known. Therefore, there is just one unique piece of information in the benchmark factor. Benchmark has just 1 degree of freedom.\nFor treatment factor, there are four levels of the factor (shown by the four vertically long cells for treatment in Figure 1). Benchmark is the only factor outside of treatment. Take the number of levels for treatment factor (4 training methods) and subtract the degrees of freedom for benchmark (1), which yields 4-1 = 3 degrees of freedom for treatment.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the treatment effects really contains. Since all observations from the same treatment will have the same treatment effect applied, we really only need to know 4 pieces of information: the effect of each treatment. But the answer is actually less than that. Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom is 3. As soon as we know 3 of the treatment effects, we can fill in the treatment effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of Figure 1). Both benchmark and treatment are outside factors for the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for benchmark and treatment (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the residual factor effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 treatments is 20 observations, or in other words, 20 degrees of freedom.\n\n\nFactor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size of the benchmark, treatment, and residual errors factors in the lifeboat training study. In other words, we can estimate the terms in the one-way ANOVA model.\n\n\n\n\n\n\nGeneral Rule for Effect Size\n\n\n\nEffect size = factor level mean - the sum of the effects of all outside factors\n\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the benchmark factor and the means for each level of training method.\nFor benchmark, get the mean of all 24 observations. The mean for all the observations is 6.5846. There is only one level for benchmark so this number is placed into each of the cells for the benchmark factor in Figure 2.\n\n\n\n\nFigure 2: Raw data and mean for benchmark factor\n\n\n\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. In Figure 3 these means are placed in the respective training method column.\n\n\n\n\nFigure 3: Raw data and means for benchmark and training factors\n\n\n\n\n\nCalculate effects\nFrom here we can calculate the effects for benchmark, training method and residual errors. We will use the general formula for calculating effect size as stated above.\nFor the benchmark, there is only one level and there are no outside factors. Therefore, the effect due to benchmark is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nThe training method factor has four levels: one for each method. To calculate the effect of a training method, take the training method mean and subtract it from the effect due to benchmark. For the “Control” method, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the grand mean. In a similar way you can find the effect for Monitor/Keyboard \\(7.8492 - 6.5846 = 1.2645\\). This means the student performance scores increased by 1.2645 on average in this training method compared to the grand mean. For Head Monitor Display/Joypad, the effect is \\(6.5789 - 6.5846 = -0.0058\\). For Head Monitor Display/Wearables the effect is \\(7.1616 - 6.5846 = 0.5770\\) (see below).\n\n\n\n\nFigure 4: Training Method Effects\n\n\n\nTo calculate the residual error effects we must remember that there are 24 levels of the residual error factor. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for benchmark and the effect for training method that particular observation received. For instance, for the observation located in the top left of our data set the observed value is 4.5614. Subtract the sum of the effects of outside factors (benchmark and training). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual error effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was 0.1875 less than the mean of the control group. In this case, this individual’s performance was lower than his/her peers who received the same type of training.\nWe can repeat the calculation for the first residual in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to benchmark and its respective training (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in Figure 5.\n\n\n\n\nFigure 5: Residual Effects\n\n\n\n\n\nCompleting the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA table enables us to conduct a hypothesis test of the significance of the treatment.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n     \n     \n     \n     \n  \n  \n    Treatment \n    3 \n     \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n     \n     \n     \n     \n  \n  \n    Total \n    24 \n     \n     \n     \n     \n  \n\n\n\n\n\nTo get the sum of squares (SS) for a factor, for each observation the effect for that factor needs to be squared. Then all the squared values are summed up to get the sum of squares.\nFor benchmark, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to benchmark.\n\\[\nSS_\\text{Benchmark} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor has four different effects, one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to treatment. For instance, for the control group, the effect is -1.8358. The value is then squared, and then multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Treatment} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the benchmark, treatment, and residual error factors.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n     \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n     \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWe can now calculate the mean squared error column, or mean square (MS). This mean is calculated by dividing sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation).\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. We can then see more clearly which factor is a bigger source of variability.\nThe mean square calculations are:\n\\[\nMS_\\text{Benchmark} = \\frac{SS_\\text{Benchmark}}{df_\\text{Benchmark}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Treatment} = \\frac{SS_\\text{Treatment}}{df_\\text{Treatment}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWhen getting an F test statistic, testing for the treatment factor is the primary factor of interest so only the F test statistic for treatment is calculated for the analysis. To get the F test statistic for treatment, take the mean square (MS) due to treatment and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of this as calculating the variance in treatment effect sizes in the numerator and the variance of the distances for an observed value to its respective treatment mean in the denominator. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Treatment} = \\frac{MS_\\text{Treatment}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for the treatment factor is calculated based on the F statistic and the degrees of freedom for both Treatment Factor and Residual Error. In practice, you would not compute this by hand, but in order to complete the decomposition of variance in a manual way, we will calculate the p-value in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to treatment are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n    2.11 \n    0.131 \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\n\n\n\n\nNumerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots or mean plots (i.e. a scatterplot of the data with the means also plotted, and sometimes connected with a line). Instructions for how to create these plots in R are found at R Instructions->Descriptive Summaries section of the book.\n\n\n\nExamples\nLifeboat launch training\nMosquito\n\n\nLinks to outside resources\nPopulate this section yourself with links to good examples, definitions, other sections within this textbook, or anything else you think will be interesting/helpful."
  },
  {
    "objectID": "DescribeData.html",
    "href": "DescribeData.html",
    "title": "Describing Data",
    "section": "",
    "text": "In the following explanations\n\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable. It would represent a treatment factor.\nYourDataSet is the name of your data set.\n\nYou can take a tidyverse approach or a mosaic package approach to calculating numerical summaries for each treatment.\n\nmosaic package:tidyverse approach\n\n\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  Month min   Q1 median    Q3 max     mean       sd  n missing\n1     5  56 60.0     66 69.00  81 65.54839 6.854870 31       0\n2     6  65 76.0     78 82.75  93 79.10000 6.598589 30       0\n3     7  73 81.5     84 86.00  92 83.90323 4.315513 31       0\n4     8  72 79.0     82 88.50  97 83.96774 6.585256 31       0\n5     9  63 71.0     76 81.00  93 76.90000 8.355671 30       0\n\n\n\nWhen calculating treatment means for combinations of 2 or more factors you can use + or | to separate the factors. | (read as ‘vertical bar’ or ‘pipe’) has the advantage that in addition to calculating means for every factor level combination, favstats will also output the marginal means for each level of the last factor listed.\nNOTE: unlike it’s use in the aov() command, using the * within favstats does not yield expected results and should NOT be used.\n\nlibrary(mosaic)\nfavstats(Y ~ X + Z, data = YourDataSet) \n#OR\nfavstats(Y ~ X | Z, data = YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  + This allows us to create additional subgroups within ‘am’ for each level of ‘cyl’.  cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  am.cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1    0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2    1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3    0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4    1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5    0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6    1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n\n\n\nNotice that the first column in the output contains the factor level combinations of am and cyl. So, ‘0.4’ is interpreted as level 0 for am and level 4 for cyl. Or in other words, the summary statistics on that row are for automatic tranmission, 4 cylinder engine vehicles. The column label of ‘am.cyl’ indicates which factor is represented on which side of the period. The next example uses the same way of labeling the factor level combinations, but the column label is not as intuitive or helpful.\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  | Referred to as a vertical bar or pipe, this symbol further defines subgroups of the variable on its left, using the values of the variable on its right side   cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to View Output  Click to View Output. \n\n\n\n\n\n  cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1 0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2 1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3 0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4 1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5 0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6 1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n7   4 21.4 22.800  26.00 30.400 33.9 26.66364 4.5098277 11       0\n8   6 17.8 18.650  19.70 21.000 21.4 19.74286 1.4535670  7       0\n9   8 10.4 14.400  15.20 16.250 19.2 15.10000 2.5600481 14       0\n\n\n\n\n\n\nCalculating treatment means for one factor:\n\nlibrary(tidyverse)\nYourDataSet %>%\n  Group_by(X) %>%\n  Summarise(MeanY = mean(Y), sdY = sd(Y), sampleSize = n()) \n\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  airquality airquality is a dataset in R.   %>%  The pipe operator that will send the airquality dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the airquality dataset into “little” datasets, one dataset for each value in the “Month” column.  Month “Month” is a column from the airquality dataset that can be treated as qualitative.  ) Functions must always end with a closing parenthesis.   %>%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  aveTemp =  “AveTemp” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  Temp Temp is a quantitative variable (numeric vector) from the airquality dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\nMonth\naveTemp\n\n\n\n\n5\n65.55\n\n\n6\n79.1\n\n\n7\n83.9\n\n\n8\n83.97\n\n\n9\n76.9\n\n\n\n\n\nNote that R calculated the mean Temp for each month in Month from the airquality dataset.\nMay (5), June (6), July (7), August (8), and September (9), respectively.\nFurther, note that to get the “nicely formatted” table, you would have to use\nlibrary(pander)\nairquality %>% \n  group_by(Month) %>%\n  summarise(aveTemp = mean(Temp)) %>%\n  pander()\n\nTo calculate treatment means for each combination of factor levels of 2 or more factors, simply add the additional variable to the group_by() statement.\nExample code:\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  mpg mtcars is a dataset in preloaded in R.   %>%  The pipe operator that will send the mtcars dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the mtcars dataset into “little” datasets, one dataset for each combination of values in the ‘am’ and ‘cyl’ variables  am, cyl ‘am’ and ‘cyl’ are both columns in mtcars. By listing them both here we are going to get output for each combination of ‘am’ and ‘cyl’ that exists in the dataset  ) Functions must always end with a closing parenthesis.   %>%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  mean_mpg =  “mean_mpg” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  mpg mpg is a quantitative variable (numeric vector) from the mtcars dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n`summarise()` has grouped output by 'am'. You can override using the `.groups` argument.\n\n\n\n\n\n\n\n\n\n\nam\ncyl\nmean_mpg\n\n\n\n\n0\n4\n22.9\n\n\n0\n6\n19.12\n\n\n0\n8\n15.05\n\n\n1\n4\n28.07\n\n\n1\n6\n20.57\n\n\n1\n8\n15.4"
  },
  {
    "objectID": "DescribeData.html#graphical-summaries",
    "href": "DescribeData.html#graphical-summaries",
    "title": "Describing Data",
    "section": "Graphical Summaries",
    "text": "Graphical Summaries\n\nBoxplots\n\n\n\n\n\n\n\n\nOverviewR InstructionsExplanation\n\n\n\nGraphical depiction of the five-number summary. Great for comparing the distributions of data across several groups or categories. Provides a quick visual understanding of the location of the median as well as the range of the data. Can be useful in showing outliers. Sample size should be larger than at least five, or computing the five-number summary is not very meaningful.\n\n\n\n\n\n\nBase R ggplot2 plotly\n\n\n\nTo make a boxplot in R use the function:\nboxplot(object)\nTo make side-by-side boxplots:\nboxplot(object ~ group, data=NameOfYourData, ...)\n\nobject must be quantitative data. R refers to this as a “numeric vector.”\ngroup must be qualitative data. R refers to this as either a “character vector” or a “factor.” However, a “numeric vector” can also act as a qualitative variable.\nNameOfYourData is the name of the dataset containing object and group.\n... implies there are many other options that can be given to the boxplot() function. Type ?boxplot in your R Console for more details.\n\nExample Code\nBasic Single Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  $ The $ allows us to access any variable from the airquality dataset.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.  )\nClosing parenthesis for the function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nMore Useful… Basic Side-by-Side Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Names under each Box\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  names=c(“May”,“June”,“July”,“Aug”,“Sep”) names= is used to tell R what labels to place on the x-axis below each boxplot.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Color and Labels\n\n\n boxplot(Temp ~ Month, data=airquality This code was explained in the previous example code.  ,  The comma is used to separate each additional command to a function.  xlab=“Month of the Year” xlab= stands for “x label.” Use it to specify the text to print on the plot under the x-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  ylab=“Temperature” ylab= stands for “y label.” Use it to specify the text to print on the plot next to the y-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  main=“La Guardia Airport Daily Temperatures” main= stands for the “main label” of the plot, which is placed at the top center of the plot. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  col=“wheat” col= stands for the “color” of the plot. The color name “wheat” is an available color in R. Type colors() in the R Console to see more options. The color name must always be placed in quotes.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a boxplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_boxplot()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_boxplot() causes the ggplot to become a boxplot.\n\n\nExample Code\nBasic Single Boxplot\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the y-axis should become.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot() The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n Side-by-side Boxplot and Color Change\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box in the boxplot.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Labels \n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_histogram()” function causes the ggplot to become a histogram. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.   +  The addition symbol + is used to add further elements to the ggplot.     labs( The “labs” function is used to add labels to the plot, like a main title, x-label and y-label.  title=“La Guardia Airport Daily Mean Temperature”,  The “title=” command allows you to control the main title at the top of the graphic.  x=“Month of the Year”,  The “x=” command allows you to control the x-label of the graphic.  y=“Daily Mean Temperature” The “y=” command allows you to control the y-label of the graphic.  )\nClosing parenthesis for the labs function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nGallery\nSee what past students have done…\nClick to view.\n\nHover to see code.\n \n ggplot(data = mtcars, aes(x = as.factor(cyl), y = mpg, fill=as.factor(cyl))) +  geom_boxplot()  +  stat_summary(fun.y = mean, geom = \"errorbar\", aes(ymax = ..y.., ymin = ..y..),     width = .75, linetype = \"dashed\", color=\"firebrick\") +  theme_light() +  theme(panel.grid.major=element_blank()) +  scale_fill_brewer(palette=\"Dark2\") +  geom_jitter(width=0.1, height=0) +  labs(title = \"Miles Per Gallon Based on Cylinders\",     x=\"Number of Cylinders\",     fill=\"Cylinders\",     y=\"Miles Per Gallon\")   \n \n ggplot(data = ToothGrowth, aes(x = as.factor(dose), y = len, fill=as.factor(dose))) +  geom_boxplot( )  +  facet_wrap(~supp) +  theme_bw() +  scale_fill_manual(values=c(\"#999999\", \"#E69F00\", \"#56B4E9\")) +  geom_jitter(width=0.1, height=0) +  labs(title = \"Tooth Length Based on Doses     According to Supplement Type\",     fill=\"Doses\",     x=\"Dosage Amount(mg)\",     y=\"Tooth Length\" )   \n\n\n\n\n\nTo make a histogram in plotly first load\nlibrary(plotly)\nThen, use the function:\nplot_ly(dataName, y=~columnNameY, x=~columnNameX, type=\"box\")\n\ndataName is the name of a data set\ncolumnNameY must be the name of a column of quantitative data. R refers to this as a “numeric vector.” This will become the y-axis of the plot.\ncolumnNameX must be the name of a column of qualitative data. This will provide the “groups” forming each individual box in the boxplot.\ntype=\"box\" tells the plot_ly(…) function to create a boxplot.\n\nVisit plotly.com/r/box-plots for more details.\n\nExample Code\nHover your mouse over the example codes to learn more. Click on them to see what they create.\nBasic Boxplot\n\n\n plot_ly An R function “plot_ly” from library(plotly) used to create any plotly plot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality,  “airquality” is a dataset. Type “View(airquality)” in R to see it.  y= The y= allows us to declare which column of the data set will become the y-axis of the boxplot. In other words, the quantitative data we are interested in studying for each group.  ~Temp,   “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset. The ~ is required before column names inside all plot_ly(…) commands.  x= The x= allows us to declare which column of the data set will become the x-axis of the boxplot. In other words, the “groups” forming each separate box in the boxplot.  ~as.factor(Month),   since “Month” is a quantitative variable (numeric vector) from the “airquality” dataset we have to change it to a “factor” which forces R to treat it as a qualitative (groups) variable. The ~ is required before column names inside all plot_ly(…) commands.  type=“box” This option tells the plot_ly(…) function what “type” of graph to make. In this case, a boxplot.  )\nClosing parenthesis for the plot_ly function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nChange Color\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”,  This code was explained in the first example code.  fillcolor=“skyblue”,  this changes the fill color of the boxes in the boxplot to the color specified, in this case “skyblue.”  line=list(color=“darkgray”, width=3),  this “list(…)” of options that will be specified will effect the edges of the boxes in the boxplot. We are changing their color to “darkgray” and their width to 3 pixels wide.  marker=list( this “list(…)” of options that will be specified will effect the outlying dots shown in the boxplots beyond the “fences” of each box.  color = “orange”,  this will change the color of the dots to orange.  line = list(,  this opens a list of options to specify for the “lines” around the “markers.”  color = “red”,  this will change the color of the lines around the outlier dots to red.  width = 1 this will change the width of the lines around the outlier dots to 1 pixel.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nAdd Titles\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”, fillcolor=“skyblue”, line=list(color=“darkgray”, width=3), marker = list(color=“orange”, line = list(color=“red”, width=1)))  This code was explained in the above example code.  %>% the pipe operator sends the completed plot_ly(…) code into the layout function.  layout( The layout(…) function is used for specifying details about the axes and their labels.  title=“La Guardia Airport Daily Mean Temperatures” This declares a main title for the top of the graph.  xaxis=list( This declares a list of options to be specified for the xaxis. The same can be done for the yaxis(…).  title=“Month of the Year” This declares a title underneath the x-axis.  ),  Functions always end with a closing parenthesis.  yaxis=list( This declares a list of options to be specified for the y-axis.  title=“Temperature in Degrees F” This declares a title beside the y-axis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding how a boxplot is created is the best way to understand what the boxplot shows.\n\nHow Boxplots are Made\n\nThe five-number summary is computed.\nA box is drawn with one edge located at the first quartile and the opposite edge located at the third quartile.\nThis box is then divided into two boxes by placing another line inside the box at the location of the median.\nThe maximum value and minimum value are marked on the plot.\nWhiskers are drawn from the first quartile out towards the minimum and from the third quartile out towards the maximum.\nIf the minimum or maximum is too far away, then the whisker is ended early.\nAny points beyond the line ending the whisker are marked on the plot as dots. This helps identify possible outliers in the data.\n\n\n\n\n\n\n\n\n\nScatterplot, with Means\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nScatterplots of a catgorical variable on the x axis and quantitative variable on the y axis are sometimes called strip charts, or side-by-side strip charts. When sample sizes are not too big and there are not too many repeated value this type of chart is an excellent way to see the variability in the data without the abstraction of a boxplot. By plotting individual observations you also can see the size of the sample for each factor level. Including factor level means on the plot adds additional insight. The mean of each factor level is often connected with a line for visual impact.\n\n\n\n\nmosaic ggplot2 plotly\n\n\n\nTo make a scatterplot use the function:\nxyplot(y~x, data = mydata)\n\ny is the quantitative response variable, i.e., “numeric vector.”\nx is the independent, explanatory variable\nmy is the name of the dataset containing y and x.\n\nThis will return a scatterplot regardless of how your x variable is stored in R (numeric, character, factor). This function is flexible and with minimal effort can include averages or make an interaction plot. xyplot() is a part of the lattice package, which is loaded when the mosaic package is loaded.\nNote: plot() from base R will also give a scatterplot, but only if the x variable is quantitative. If x is a character or factor variable the default is to return a boxplot plot.\nExample Code\nBy reading the documentation for the dataset (visible when ?ToothGrowth is run in the console) we can see that our “x” variable, “dose”, is a numeric variable in R. Because of this the x-axis maintains the relative distance of doses on the x-axis.\nBy reading the documentation for the dataset (visible when ?ToothGrowth is run in the console) we can see that our “x” variable, “dose”, is a numeric variable in R. Because of this the x-axis maintains the relative distance of doses on the x-axis.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nIf you start with a numeric x variable, you may or may not want to convert it to a factor variable. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed. Compare the output of the previous example code with this example code. This example code converts our x variable of “dose” to a factor variable.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nTo include the means on the plot and connect them with a line use this code\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  , \nThe “,” is required to start specifying additional commands for the function.  type =\nThe type argument allows you to add different types of lines to the plot. Run ?panel.xyplot() to read more about values for this argument  c( Combines the following values into one vector. This allows me to pass multiple values as one input to “type =”. Useful for if I want to plot something in addition to the default of plotting points.  ‘p’\nThis requests the points to be plotted. It is the default value. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  , \nThe “,” is required to start specifying additional commands for the function.  ‘a’ This requests the average for each factor level to be connected with a line. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a scatterplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_point()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_point() causes the ggplot to become a scatterplot; or in other words to draw points to represent data.\n\n\nExample Code\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n If you start with a numeric x variable, you may or may not want to convert it to a factor variable. You do this by using ‘factor(x)’ instead of just ‘x’ as shown below. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed.\nggplot(ToothGrowth, aes(x = factor(dose), y = len)) +   geom_point(color = \"blue\")\nAdding averages to the plot and connecting them with a line requires a little more effort and is demonstrated in the code below. I also add some more descriptive labels to the chart.\nNote the use of stat_summary to indicate I want to add a layer that plots a numerical summary, not the original data. Some geoms have stat summaries built in to them (like geom_bar or geom_boxplot), but in our case we have to define the summary.\nIn the stat_summary I provide additional arguments to the aesthetics helper function. Defining the aesthetics in ggplot() is like a global definition, all additional layers inherit those aesthetic mappings. Defining them in a geom_* or a stats_* allows you to add to or override what was defined in ggplot() for that layer only. The group aesthetic is required in order to use a line geometry. In this case, group could just as easily have been defined in ggplot(aes()).\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_point( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.   +  The addition symbol + is used to add further elements to the ggplot.    stat_summary( This function will calculate a statistical summary to be plotted on the chart  fun = mean, fun is short for function. The summary function I want to apply to my y variable is “mean”.  geom = “line”, The “geom=” argument is used to tell what kind of geometry should be drawn to represent the means. Here we are asking for the means to be connected with a line.  aes( The aes or “aesthetics” function allows you to tell ggplot what variables should be mapped to what visual aspects of the chart; including what the x-axis or y-axis should become. Including it her means the aesthetic will only be applied to this layer.  group = 1 indicates which variable should be grouped by when drawing multiple lines (one line for each factor level). We write the number 1 to indicate there is just 1 group; we are not further splitting the data.  )\nClosing parenthesis for the geom_boxplot function.  )\nClosing parenthesis for the geom_boxplot function.   +  The addition symbol + is used to add further elements to the ggplot.    labs( Function to edit labels of the plot  x = “Vitamin C mg/day”, Edit the x-axis label  y = “Length”, Edit the y-axis label  title = “Tooth Growth in Guinea Pigs” Edit the chart title  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nUnder construction.\n\n\n\n\n\n\n\n\nInteraction Plot\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nUnder construction\n\n\n\n\nmosaic ggplot2 plotly\n\nUnder construction"
  },
  {
    "objectID": "effects_model.html",
    "href": "effects_model.html",
    "title": "Effects Model",
    "section": "",
    "text": "Consider an experiment conducted to test 4 different types of toothbrushes: manual, oscillating, sonic and ultrasonic. The response variable is percent of area on teeth that has plaque. Twenty-four individuals participate in the experiment, yielding 6 observations per treatment. Up to this point we have primarily been interested in calculating means in order to compare toothbrushes. If I simply reported that the mean of percent area with plaque was 23.09 for a manual brush, you would not know how that value compares to the other types of brushes.\nA graph or table reporting the other means would be necessary to provide context. Figure 1 depicts the data points and mean for each factor level.\nIn an earlier, introductory statistics class you most likely learned how to test whether these means are equal using analysis of variance (ANOVA). This approach of testing means is valid and works when you only have 1 factor. However, it is limited in its ability to include more factors or more complicated designs.\nThere is another metric we use to compare factor levels: the effect size. Reporting the effect of a factor level has the benefit of providing some context on how that factor level is influencing the response variable relative to other levels of the same factor. Using effect sizes (as opposed to factor level means) allows us to model and test much more complicated scenarios than a simple one factor experiment..(Footnote with an explanation about cell means model??)"
  },
  {
    "objectID": "effects_model.html#assembly-line-metaphor",
    "href": "effects_model.html#assembly-line-metaphor",
    "title": "Effects Model",
    "section": "Assembly Line Metaphor",
    "text": "Assembly Line Metaphor\nYou can imagine that each data point in your data set is created by going down an assembly line, much like you would find in a factory that makes cars or appliances. All points start with the benchmark value. As it progresses through the assembly line the data point is altered to reflect the effect of the factor levels it belongs to.\n\n\n\n\n\n\nIn the toothbrush and toothpaste experiment all the points start the assembly line at the same value: the benchmark value, or the grand mean of the data set. The first station on the line receives the data point and adds to it because the instructions say “manual”. The next station alters the value depending what the instructions for that data point say: off-brand or name brand. After going through each station (one station for each factor) in the assembly line the data point arrives at the last station.\nThe last station is worked by a person who makes random adjustments! Some adjustments will be big, and some will be small; some will be positive, and some will be negative. (In a typical factory this person would be fired. But we would rather have randomness than unknown systematic adjustments). Though the adjustments at this last station for residual error are random, they do follow a pattern. Namely, the errors average out to zero and they follow a normal distribution."
  },
  {
    "objectID": "examples/mosquito.html",
    "href": "examples/mosquito.html",
    "title": "Mosquitos",
    "section": "",
    "text": "library(mosaic)\nlibrary(DT)\nlibrary(pander)\nlibrary(car)\nlibrary(tidyverse)\n\n## Data from original article:\nmosquito <- read_csv(\"../data/mosquito_patch.csv\")"
  },
  {
    "objectID": "examples/mosquito.html#background",
    "href": "examples/mosquito.html#background",
    "title": "Mosquitos",
    "section": "Background",
    "text": "Background\nFive pre-treated patches were compared to to see which material did the best in reducing mosquito human contact for the Armed Forces in India. The five treatments included Odomos(1), Deltamethrin (2), Cyfluthrin(3), D+O(4), C+O(5) Each of the treatments included 30 replicates per treatment\nSource: A. Bhatnagar and V.K. Mehta (2007). “Efficacy of Deltamethrin and Cyfluthrin Impregnated Cloth Over Uniform Against Mosquito Bites,” Medical Journal Armed Forces India, Vol. 63, pp. 120-122"
  },
  {
    "objectID": "examples/mosquito.html#analysis",
    "href": "examples/mosquito.html#analysis",
    "title": "Mosquitos",
    "section": "Analysis",
    "text": "Analysis\nApplying a one-way ANOVA to this study, we have the following model:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\nWhere \\(y_{ij}\\) is the \\(j^{th}\\) observation from treatment \\(i\\)\n\\(\\mu\\) is the grand mean of the dataset. Also referred to as an overall mean or benchmark.\n\\(\\alpha_i\\) is the effect of the treatment as described in the background.\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. Since there are 30 subjects for each treatment, \\(j\\) ranges from 1 to 30.\nApplying a one-way ANOVA to this study, we have the null hypothesis that the effect of human mosquito contact, represented by α, is equal for each of the factors. This is formally written as follows. \\[ H_0:\\alpha_\\text{Odomos} = \\alpha_\\text{Deltamethrin} = \\alpha_\\text{Cyfluthrin} = \\alpha_\\text{D+O} = \\alpha_\\text{C+O} = 0 \\] The alternative hypothesis states that at least one of the effects due to material is different than zero \\[ H_a: \\text{at least one } \\alpha \\text{ is different than 0} \\] Using these hypotheses will allow for us to address the question whether any of the materials are better at minimizing mosquito-human contact.\n\nHypothesis test\nWe will use a level of significance of α = 0.05 for the analysis.\nFor the analysis, we perform the following one-way ANOVA\n\nmosquito <- mosquito %>% \n   mutate(\n         Treatment = case_when(\n           trt.mosq %in% 1  ~ \"Odomos\",\n           trt.mosq %in% 2  ~ \"Deltamethrin\",\n           trt.mosq %in% 3  ~ \"Cyfluthrin\",\n           trt.mosq %in% 4  ~ \"D+O\",\n           trt.mosq %in% 5  ~ \"C+O\"\n          )\n        )\n\nmosquito.aov <- aov(y.mosq ~ Treatment, data=mosquito)\nsummary(mosquito.aov) %>% pander()\n\n\nAnalysis of Variance Model\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(>F)\n\n\n\n\nTreatment\n4\n184.6\n46.16\n4.48\n0.001924\n\n\nResiduals\n145\n1494\n10.3\nNA\nNA\n\n\n\n\n\nThe p-value for this test is significant (p = 0.001924). Based on this result, the null hypothesis is rejected and we have sufficient evidence that at least one of the effects due to material is different for human mosquito contact.\nThe requirements of equal variances for ANOVA is met. This is shown by the residual versus fitted plot, which shows roughly a constant variance within each vertical group of dots. The QQ-plot of residuals on the right shows some non-normality as evidenced by some of the points outside of the dashed line boundaries. However, it is not severe and we will move forward with the analysis.\n\npar(mfrow=c(1,2))\nplot(mosquito.aov, which=1, pch=16)\nqqPlot(mosquito.aov, id=FALSE)\n\n\n\n\nThe following plot shows which types of material minimize the human mosquito contact.\n\nboxplot(y.mosq ~ as.factor(Treatment), data=mosquito, main=\"Human Mosquito Contact Based on Type of Material\", xlab =\"Treatment\", ylab = \"Amount of Mosquito Human Contact\")\n\n\n\n\nThe averages are illustrated with the blue line in the plot above and the table below shows the means, standard deviations, and sample sizes for each of the five different materials. ::: {.cell}\nfavstats(y.mosq ~ Treatment, data=mosquito) %>% \n  select(Treatment,mean,sd,n) %>% \n  arrange(mean) %>% \n  pander()\n\n\n\n\n\n\n\n\n\n\nTreatment\nmean\nsd\nn\n\n\n\n\nC+O\n5.367\n3.068\n30\n\n\nD+O\n6.333\n3.121\n30\n\n\nOdomos\n7.901\n3.366\n30\n\n\nCyfluthrin\n8.033\n3.01\n30\n\n\nDeltamethrin\n8.133\n3.46\n30\n\n\n\n\n:::\n\n\nPairwise comparisons\nWe now that smallest mean (C+O) must be different than the largest mean (Deltamethrin) because the F-test was significant above. In order to better understand which treatments perform better than which other treatments we will look at all pairwise comparisons and apply Tukey’s correction to the family error rate.\n\n#This code would work, but...\n# TukeyHSD(mosquito.aov, \"Treatment\")\n\n#I want to do this fancy stuff below to sort the output\nTukeyHSD(mosquito.aov, \"Treatment\")$Treatment %>% \n  as_tibble(rownames = \"id\") %>% \n  arrange(`p adj`) %>% #Have to put the column name in back ticks since it has a space\n  pander() \n\n\n\n\n\n\n\n\n\n\n\nid\ndiff\nlwr\nupr\np adj\n\n\n\n\nDeltamethrin-C+O\n2.766\n0.4764\n5.056\n0.009359\n\n\nCyfluthrin-C+O\n2.666\n0.3761\n4.955\n0.01367\n\n\nOdomos-C+O\n2.534\n0.2441\n4.823\n0.02204\n\n\nDeltamethrin-D+O\n1.8\n-0.4899\n4.089\n0.1965\n\n\nD+O-Cyfluthrin\n-1.699\n-3.989\n0.5902\n0.2477\n\n\nOdomos-D+O\n1.567\n-0.7222\n3.857\n0.3268\n\n\nD+O-C+O\n0.9663\n-1.323\n3.256\n0.7707\n\n\nOdomos-Deltamethrin\n-0.2323\n-2.522\n2.057\n0.9986\n\n\nOdomos-Cyfluthrin\n-0.132\n-2.422\n2.158\n0.9999\n\n\nDeltamethrin-Cyfluthrin\n0.1003\n-2.189\n2.39\n1\n\n\n\n\n\nC+O is significantly lower than 3 of the treatments at the 0.05 level; and no other treatment has a sample mean lower than C+O’s."
  },
  {
    "objectID": "examples/mosquito.html#interpretation",
    "href": "examples/mosquito.html#interpretation",
    "title": "Mosquitos",
    "section": "Interpretation",
    "text": "Interpretation\nIt appears the the best type of material is the C+O material to minimize the amount of mosquito human contact. The lowest mean came from the C+O material where the average amount of mosquito/human contact was 5.367. With a mean of 6.333, D+O was not significantly different than C+O and could also be an option. Conducting a new experiment that focuses on the difference between C+O and D+O and gives them a larger sample size in order to better detect significant would be reasonable.\nA future study could look into other types of material as well as doing this analysis at different locations throughout the world."
  },
  {
    "objectID": "examples/VirtualTrain.html",
    "href": "examples/VirtualTrain.html",
    "title": "Lifeboat Launch Training Methods",
    "section": "",
    "text": "library(mosaic)\nlibrary(DT)\nlibrary(pander)\nlibrary(car)\nlibrary(tidyverse)\n\n## Data from original article:\nvirtual <- read.csv(\"../data/virtual_training.csv\", header=TRUE)"
  },
  {
    "objectID": "examples/VirtualTrain.html#background",
    "href": "examples/VirtualTrain.html#background",
    "title": "Lifeboat Launch Training Methods",
    "section": "Background",
    "text": "Background\nAn experiment was done to help train people in the procedure to launch a lifeboat. This was a Completely Randomized Design with 16 subjects per treatment, for a total of 64 subjects. The response variable is the performance on a procedural knowledge test. The treatments included: Lecture/Materials (Control) (1), Monitor/Keyboard (2), Head Monitor Display/Joypad (3), and Head Monitor Display/Wearables (4)\nSource: J.Jung and Y.J. Ahn (2018). “Effects of Interface on Procedural Skill Transfer in Virtual Training: Lifeboat Launching Operation Study,” Computer Animation & Virtual Worlds, Vol. 29, pp. e1812. https://doi.org/10.1002/cav.1812"
  },
  {
    "objectID": "examples/VirtualTrain.html#analysis",
    "href": "examples/VirtualTrain.html#analysis",
    "title": "Lifeboat Launch Training Methods",
    "section": "Analysis",
    "text": "Analysis\nApplying a one-way ANOVA to this study, we have the following model:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\nWhere \\(y_{ij}\\) is the \\(j^{th}\\) observation from treatment \\(i\\)\n\\(\\mu\\) is the grand mean of the dataset. Also referred to as an overall mean or benchmark.\n\\(\\alpha_i\\) is the effect of the training method. 1 = control/lecture, 2 = Monitor/keyboard, 3 = head monitor/joypad, 4 = head monitor/wearables.\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. Since there are 16 subjects for each treatment, \\(j\\) ranges from 1 to 16.\n\nHypothesis Test\nThe null hypothesis is that the effect of all training methods, represented by α, is equal to zero. This is formally written as follows.\n\\[ H_0:\\alpha_\\text{Control} = \\alpha_\\text{Monitor/Keyboard} = \\alpha_\\text{Joypad} = \\alpha_\\text{Wearables} = 0 \\]\nThe alternative hypothesis states that at least one of the effects due to material is different than zero \\[ H_a: \\text{at least one } \\alpha \\text{ is different than 0} \\]\nUsing these hypotheses will allow for us to address the question whether any of the type of training is different to improve test score.\nWe will use a level of significance of α = 0.05 for the analysis.\nFor the analysis, we perform the following one-way ANOVA\n\nvirtual <- virtual %>% \n   mutate(\n         Treatment = case_when(\n           grp.trt %in% 1  ~ \"Control\",\n           grp.trt %in% 2  ~ \"Monitor/Keyboard\",\n           grp.trt %in% 3  ~ \"Joypad\",\n           grp.trt %in% 4  ~ \"Wearables\"\n          )\n        )\n\nvirtual.aov <- aov(procKnow ~ Treatment, data=virtual)\nsummary(virtual.aov) %>% pander()\n\n\nAnalysis of Variance Model\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(>F)\n\n\n\n\nTreatment\n3\n65.66\n21.89\n4.941\n0.003931\n\n\nResiduals\n60\n265.8\n4.43\nNA\nNA\n\n\n\n\n\nThe p-value for this test is significant (p = 0.003931). Based on this result, the null hypothesis is rejected and we have sufficient evidence that at least one of the effects due to training is different for post test score.\n\n\nCheck Requirements\nIn order to trust this result, we must verify the requirements for the ANOVA model are met. The requirement of equal variances appears to be met since the residuals versus fitted plot shows roughly a constant variance within each vertical group of dots.\nThe QQ-plot of residuals on the right is used to check whether residuals are normally distributed. There are a few points outside the boundaries that might be a concern for this ANOVA requirement, but generally there are no strong departures from normality and so we consider this requirement to be met also.\n\npar(mfrow=c(1,2))\nplot(virtual.aov, which=1, pch=16)\nqqPlot(virtual.aov, id=FALSE)\n\n\n\n\n\n\nTraining method’s effect on test score\nThe following plot shows which types of training increases the post test score. ::: {.cell}\nxyplot(procKnow ~ as.factor(Treatment), data=virtual, type=c(\"p\",\"a\"), main=\"Score based on Type of Training\", xlab =\"Treatment\", ylab = \"Test Score\")\n\n\n\n:::\nThe averages are illustrated with the blue line in the plot above and the table below shows the means, standard deviations, and sample sizes for each of the five different materials. ::: {.cell}\npander(favstats(procKnow ~ Treatment, data=virtual)[,c(\"Treatment\",\"mean\",\"sd\",\"n\")])\n\n\n\n\n\n\n\n\n\n\nTreatment\nmean\nsd\nn\n\n\n\n\nControl\n4.931\n1.94\n16\n\n\nJoypad\n6.736\n2.82\n16\n\n\nMonitor/Keyboard\n7.708\n1.43\n16\n\n\nWearables\n6.875\n1.99\n16\n\n\n\n\n:::"
  },
  {
    "objectID": "examples/VirtualTrain.html#interpretation",
    "href": "examples/VirtualTrain.html#interpretation",
    "title": "Lifeboat Launch Training Methods",
    "section": "Interpretation",
    "text": "Interpretation\nIt appears the the best type of training may be the Monitor/Keyboard type training. The highest mean came from the Monitor/Keyboard where the average procedural knowledge post test score was 7.708. The head monitor training methods may perform better on different types of assessments that were not part of this study. A future study could look into other training methods to improve readiness in lifeboat launching."
  },
  {
    "objectID": "factor_structure.html",
    "href": "factor_structure.html",
    "title": "Factor Structure",
    "section": "",
    "text": "In this section you will learn factors in context of analyzing results of an experiment:"
  },
  {
    "objectID": "factor_structure.html#inside-and-outside",
    "href": "factor_structure.html#inside-and-outside",
    "title": "Factor Structure",
    "section": "Inside and Outside",
    "text": "Inside and Outside\nThink about our toothbrush example, but ignore toothpaste for a moment. If toothbrush is the only treatment under scrutiny we have three factors in the analysis: the benchmark (or grand mean), toothbrush type, and the residual error.\nRecall that in the simplest version of the toothbrush experiment there were 4 levels of the treatment (toothbrush type), with six replicates for each toothbrush. In the following factor structure diagrams benchmark is represented in red, toothbrush type is drawn in blue, and the residual factor levels are depicted in black.\n\n\n\nA factor is inside of another factor if all the levels of one factor (the inside factor) completely fit within a second factor (the outside factor).\nYou may find this analogy helpful. Pretend that an outside factor is a box, and the inside factor levels are blocks that fit perfectly within the box.\n\n\n\n\n\nTo determine if a factor is inside another factor, imagine picking up the levels of the factor one by one and placing them inside the other factor. If they all fit without crossing the partition lines of a factor,then it is considered inside.\nThis is illustrated with the toothbrush example. We will start by taking the levels of toothbrush and placing them inside of benchmark.\n\n\n\n\n\nIn the figure above you can see that one entire level of toothbrush can fit inside of a single level of benchmark. Even though they may share a boundary line, the toothbrush level does not cross over any lines or start sharing boundaries with any other level of benchmark (this is of course impossible since benchmark only has one level). You can repeat this for the other 3 levels of toothbrush with the same result. Therefore, we say that toothbrush is inside of benchmark, which is the same as saying that benchmark is outside of toothbrush.\nConsider now the relationship between toothbrush and residual as shown below. If we take a level of toothbrush and overlay it on the residual factor, we can see it does not fit neatly inside one of the levels of residual error. In fact, one level of toothbrush crosses the boundaries of many of the levels of residual error. Therefore, we cannot say that toothbrush is inside of residual error.\n\n\n\n\n\nSince toothbrush is not inside of residual error, does this necessarily mean that toothbrush is outside of residual error? No! This is something that has to be checked. To determine whether toothbrush is outside of residual we must take the levels of residual error one at a time and overlay them on the toothbrush factor structure, as shown below. You can see that one level of residual error does NOT cross any of the toothbrush level boundaries. Therefore, toothbrush is indeed outside of residual error; or equivalently, residual error is inside of toothbrush.\n\n\n\n\n\nLet’s pause here to clarify a common misunderstanding, consider an experiment where we are looking at the inside vs. outside relationship of two factors: A, and B.\n\nWhen factor A is inside of factor B, we can also say factor B is outside of factor A.\nBut, when factor A is not inside of factor B, this does not necessarily mean that factor A is outside of factor B. There are situations where two factors are neither inside nor outside of each other; they are crossed."
  },
  {
    "objectID": "factor_structure.html#crossed-factors",
    "href": "factor_structure.html#crossed-factors",
    "title": "Factor Structure",
    "section": "Crossed Factors",
    "text": "Crossed Factors\nTwo factors are crossed when their partition lines cross in a way that creates new groups of observations that represent every possible combination of the factor levels. More succinctly stated, factors are crossed when all factor level combinations are present in the study. We saw this in the toothbrush study when brand of toothpaste was included in the experiment. Toothbrush and toothpaste are neither inside nor outside of each other; rather, they are crossed.\n\n\n\n\n\n\n\n\n\n\n\nThe crossing of toothpaste brand and toothbrush created an interaction factor"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BYU-Idaho Math326: Design and Analysis of Experiments",
    "section": "",
    "text": "This book is meant to be a starting point for you to learn design and analysis of experiments. You should feel free to edit the Rmarkdown files so that the book becomes your own.\n\n\nUnder Principles of Experiments the most foundational issues that face each experimenter are described.\nThe Specific Designs section addresses specific designs we will learn about in this course. Each design will have an image next to it representing the diagram of the structural factors. Within each of these designs there are subsections:\n\nOverview contains the model, factor structure and hypotheses\nDesign discusses how the randomization is implemented and why\nDecomposition is a bridge between the design and analysis. It walks through creating an ANOVA table by hand for the given design to allow you to see how the factor structure affects the analysis.\nR instructions provides interactive code illustrating how to run the model\nResources contains worked examples and a space for you to store other links and info\n\nThe section labeled Broad Topics seeks to address topics that are relevant to many experiment designs.\nFinally, a section dedicated to R code that can be used in multiple designs. This includes numerical and graphical data summaries as well as code for model diagnostics/assumption checking.\nYou should add additional topics and designs as you learn more, even after the course is over. The book is meant to be fully customizable and growing to reflect your growing understanding.\n\n\nThis book was specifically designed for the Math326 Design and Analysis of Experiments class at BYU-Idaho, as it stands in 2022. BYU-I follows a 14 week semester. After introducing some foundational principles of experimental design, the recommended sequence follows the general pattern of\n\nIntroduce a specific design: suitability/benefits of the design, explanation of the design, factor structure and decomposition, steps for analysis (including R code)\nDiscuss new topics/complexities/considerations associated with that design located in the Broad Topics list."
  },
  {
    "objectID": "index.html#book-scope",
    "href": "index.html#book-scope",
    "title": "BYU-Idaho Math326: Design and Analysis of Experiments",
    "section": "Book Scope",
    "text": "Book Scope\nThis is an introductory book intended to familiarize students with foundational concepts and vocabulary in the design and analysis of experiments. The designs covered in this book are the most basic and all assume a continuous response variable. Hopefully with this foundation students will be prepared to excel in experimental design and analysis courses in grad school, or be able to extend these principles to more complex designs as practitioners."
  }
]