[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Anova_F-test.html",
    "href": "Anova_F-test.html",
    "title": "ANOVA and the F-Test",
    "section": "",
    "text": "With the effects model defined we will want to test whether the treatment factor(s) has a statistically significant effect on the response variable. In other words we are interested in testing the hypotheses:\n\\[\nH_0: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\ne 0 \\text{ for at least one i}\n\\qquad(1)\\]\nWhere \\(\\alpha_i\\) represents the effect of a factor level.\nAnalysis of variance (ANOVA) is a statistical technique that allows us to simultaneously test all factor level effects at the same time."
  },
  {
    "objectID": "Anova_F-test.html#multiple-t-tests",
    "href": "Anova_F-test.html#multiple-t-tests",
    "title": "ANOVA and the F-Test",
    "section": "Multiple t-tests",
    "text": "Multiple t-tests\nAt this point it is reasonable to ask if we couldn’t arrive at the same conclusion by simply conducting multiple t-tests. For example, you could do a t-test for each factor level to determine if the effect is significantly different from zero. Or you might consider testing each combination of factor level effects to see if they are equal to each other.\nThe multiple t-test approach has a couple of a drawbacks. The first drawback is that it becomes a real burden to run, present and interpret a lot of tests if there are many levels to a factor. If you only have 3 or 4 factor levels and only 1 or 2 factors, conducting many tests may be an annoyance. However, many factor levels and many factor would truly bog down your analysis.\nThe other main drawback of using multiple t-tests is more substantive and has to do with the probability of a Type I error. Suppose the treatment factor in our study has 3 levels. The null hypothesis associated with an ANOVA that tests all factor level effects simultaneously is:\n\\[\nH_0: \\alpha_1 = \\alpha_2 =  \\alpha_3 = 0\n\\]\nTesting at a 0.05 significance level means there is a 0.05 probability we will incorrectly reject this null hypothesis (i.e. commit a Type I error). Conversely, there is 0.95 probability we will NOT commit a Type I error.\nIf we attempt to approach the problem by conducting multiple t-tests, we would test the following set of null hypotheses:\n\\(H_0: \\alpha_1 = 0\\) and \\(H_0: \\alpha_2 = 0\\) and \\(H_0: \\alpha_3 = 0\\).\nWe may conduct each of these tests at the 0.05 significance level. Incorrectly rejecting the null hypothesis on any one of these tests would result in the same Type 1 error as incorrectly rejecting the null hypothesis of our ANOVA test of all the effects simultaneously.\nSo what is the probability of committing a Type 1 error in at least 1 of these 3 tests? The simplest way to find the probability of committing a Type 1 error in at least one of 3 tests is to calculate \\(1 – P(\\text{no Type 1 errors in all three tests})\\). As previously stated, the significance level (0.05) of each test represents the probability of a Type 1 error. Therefore, the probability of not committing a Type 1 error on each test is 0.95. If we treat the tests as independent, we can find the probability of NOT committing a Type 1 error in all of the tests by multiplying the probabilities:\n\\[\n0.95 * 0.95 * 0.95 = 0.857\n\\]\nWe can subsequently find \\(1-0.857 = .143\\) is the probability of committing a Type 1 error in at least one of the tests, assuming all the null hypotheses are true. This is often referred to as the family wise error rate. The Type 1 error probability (0.143) in this family of t-tests is almost 3 times higher than the ANOVA Type 1 probability of 0.05.\nIn summary, ANOVA allows us to keep the number of tests manageable and it greatly simplifies how Type 1 error is addressed.\nIf we consider a study with more than 1 factor, there are additional advantages of ANOVA. Unlike a multiple t-test approach, while testing one factor’s effects the ANOVA test can account for the other factors’ impact on the response. In this regard, ANOVA is similar to regression."
  },
  {
    "objectID": "Anova_F-test.html#regression",
    "href": "Anova_F-test.html#regression",
    "title": "ANOVA and the F-Test",
    "section": "Regression",
    "text": "Regression\nIndeed, ANOVA and linear regression are more similar than they are different. ANOVA and linear regression tend to each have their own vocabulary because they were developed under different circumstances. ANOVA was developed to deal with agricultural experiments where the independent variables were primarily categorical. Linear regression tends to be introduced as a tool to analyze data where the independent variables are quantitative. Though the language and output associated with each technique may appear different on the surface, the “math” (i.e. the linear algebra) underlying the hood of the techniques is identical. It is not uncommon to have a study where there are multiple quantitative independent variables and multiple categorical independent variables. Thus, the differences between the two lie more in the problems they tend to be applied to and the vocabulary of the researcher than in any meaningful difference in results."
  },
  {
    "objectID": "Anova_F-test.html#mean-squares-ms",
    "href": "Anova_F-test.html#mean-squares-ms",
    "title": "ANOVA and the F-Test",
    "section": "Mean Squares (MS)",
    "text": "Mean Squares (MS)\nYou can think of Mean Squares (MS) as synonymous with variance. The F statistic is a ratio of variances:\n\\[\nF = \\frac{\\text{Variation between factor levels}}{\\text{Variation within factor levels}} = \\frac{\\text{Mean squares of treatment factor means}}{\\text{Mean squares of residual errors}}\n\\]\nWith this is mind, we can fill in the F column of the ANOVA table for Treatment Factor.\n\n\nTable 2: Blank ANOVA summary table for an experiment with 1 treatment factor\n\n\n\n\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nF\np-value\n\n\n\n\nGrand Mean\n\n\n\n\n\n\n\nTreatment Factor\n\n\n\n\\(\\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}}\\)\n\n\n\nResidual Error\n\n\n\n\n\n\n\nTotal\n\n\n\n\n\n\n\n\n\nTo find the variation between factor level means, calculate the sample variance of factor level means and multiply it by the number of replicates in each factor level. (In the case of unbalanced data where you do not have the same number of replicates in each factor level, weighting by sample size is needed).\nThe Mean Squares of the residual error factor (i.e. Mean Squared Error, MSE) represents the within factor level variation. To calculate it you can find the sample variance within each factor level and then take the mean of those variances. (In the case of unbalanced data where you do not have the same number of replicates in each factor level, you would take a weighted average).\n\n\n\nFigure 4: Data from an experiment with 3 factor levels is shown in two separate panels. Left panel shows variation between factor level means. Right panel shows variation within factor levels.\n\n\nIn Figure 4 data from an experiment with 3 factor levels is shown. The panel on the left shows the factor level means plotted as points and the grand mean as a red line. In this panel we can see the between group variation. As mentioned above, the mean squares for treatment could be computed as the variance of the 3 factor level means, and multiplied by 15 (the number of replicates in each factor level).\nIn the panel on the right, the factor level means are plotted in blue and the deviation from each point to its respective factor level mean is depicted. The mean square error could be computed by finding the sample variance within each group and then taking the mean of those 3 variance estimates.\nThough the above methods work, the ANOVA summary table captures interim steps for an alternative (preferred) algorithm for calculating mean squares. Since Mean Squares is synonymous with variance, now is a good time to review the sample variance formula.\n\\[\ns^2 = \\frac{\\sum{(y_i - \\bar{y})}^2}{n-1}\n\\qquad(2)\\]\nUpon closer examination of Equation 2 you can see that this formula is essentially a mean. In fact, you can think of variance as a mean of squared deviations (a.k.a. errors). Any mean is built using 2 parts:\n\n\nRecall that an effect is defined as a deviation from the mean.\n\nnumerator: a sum or total\ndenominator: the number of pieces of information used to create the sum in the numerator\n\nHere, the numerator is the sum of squares and the denominator is the degrees of freedom.\n\n\n\n\n\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nF\np-value\n\n\n\n\nGrand Mean\n\n\n\n\n\n\n\nTreatment Factor\n\n\n\\(\\frac{SS_\\text{Treatment Factor}}{df_\\text{Treatment Factor}}\\)\n\\(\\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}}\\)\n\n\n\nResidual Error\n\n\n\\(\\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}}\\)\n\n\n\n\nTotal"
  },
  {
    "objectID": "Anova_F-test.html#sum-of-squares-ss",
    "href": "Anova_F-test.html#sum-of-squares-ss",
    "title": "ANOVA and the F-Test",
    "section": "Sum of Squares (SS)",
    "text": "Sum of Squares (SS)\nLet’s talk about the numerator first, this will be the sum of squared deviations, or Sum of Squares for short. The Sum of Squares is a measure of the total variability in a dataset. A naïve approach to calculating total variability in a dataset is to measure the distance from each value to the mean of the dataset. The problem with this approach is that those distance measures will always sum to zero.\nTo avoid this problem, statisticians square the distances before summing them. This results in a value that summarizes the total amount of spread in the dataset. This quantity, the Sum of Squares, is important and so it has its own column in the ANOVA summary table.\n\n\n\n\n\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nF\np-value\n\n\n\n\nGrand Mean\n\n\\(n*\\bar{y}_\\text{..}^2\\)\n\n\n\n\n\nTreatment Factor\n\n\\[ \\sum \\hat{\\alpha}_i^2*n_i\\]\n\\(\\frac{SS_\\text{Treatment Factor}}{df_\\text{Treatment Factor}}\\)\n\\(\\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}}\\)\n\n\n\nResidual Error\n\n\\[ \\sum \\hat{\\epsilon}_\\text{ij}^2 \\]\n\\(\\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}}\\)\n\n\n\n\nTotal\n\n\\(y_\\text{ij}^2\\)\n\n\n\n\n\n\n\n\nA deviation from the mean can be thought of as an effect. That is why the symbols for factor effects are used in the SS column in the ANOVA summary table."
  },
  {
    "objectID": "Anova_F-test.html#degrees-of-freedom",
    "href": "Anova_F-test.html#degrees-of-freedom",
    "title": "ANOVA and the F-Test",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nDegrees of freedom can be thought of as the number of unique pieces of information that contributed to the variance estimate, mean squares.\n\n\n\n\n\n\nDegrees of Freedom\n\n\n\nThe number of unique pieces of information that contributed to the variance estimate.\n\n\nIn our dataset we have a certain number of observations. All those observations can be used to estimate the variance in the dataset. But you will notice in Equation 2 the data has already been used to estimate the grand mean (\\(\\bar{y}\\) estimates \\(\\mu\\)). In other words, before we can estimate the variance we must use the data to estimate the mean. Estimating the mean “uses up” one degree of freedom. This is why the denominator of the sample variance formula divides by \\(n-1\\) instead of by \\(n\\).\nFor additional explanation, consider this simple example. There are three data points and you know that the mean of these 3 data points is 10. The value of the first data point could be any number, it is free to vary. The value of the second data point could also be any number, it is free to vary. The third number’s value is not free to vary. It is constrained by the fact that the mean of the 3 data points must be 10. The values of the first two datapoints will determine the value of the third under the constraint of a known (or estimated) mean.\n\n\nTable 3: Only n-1 values are free to vary when the mean of the values is known\n\n\n\n\n\n\n\n\n\nvalue 1\nvalue 2\nvalue 3\n\nMean of 3 Values\n\n\n\n\na\nb\n\\(3*10 - (a+b)\\)\n->\n10\n\n\nfree to vary\nfree to vary\ndepends on other two values\n\n\n\n\n\n\nHow does this apply to the analysis of variance? Initially you have \\(n\\) observations, or in other words \\(n\\) unique pieces of information that can be used to estimate variance of the dataset. As I try to break the variance into its component pieces, I will also need to reallocate those \\(n\\) pieces of information to each factor (grand mean, treatment factor, residual error) for use in estimating their mean squared error. To paraphrase the law of the conservation of mass, “the number of observations can neither be created nor destroyed”. The sum of degrees of freedom for all the factors must equal the number of observations in the dataset.\nWe will reason through the degrees of freedom calculation for each of the 3 sources in the ANOVA table. Keep in mind, we are using the simplest experiment, just one treatment factor, to illustrate these concepts. In more complex designs, there will be additional factors listed in the “sources” column.\nAs was mentioned, every time we use the data to estimate a parameter we use a degree of freedom. To find the grand mean we average over all the values in the dataset; that uses up one degree of freedom because we have estimated 1 mean.\nWhen calculating the degrees of freedom for the treatment factor you might be tempted to think that the degrees of freedom is equal to the number of factor levels because you have to estimate a mean for each level. But, remember the simple example depicted in figure Table 3. Because I have already estimated the grand mean, the last factor level is is not free to vary and therefore is not estimated directly. The mean of the last factor level will have to be a number that satisfies the constraint that the mean of all the factor level means is the grand mean.\nExplained another way, consider the fact that all the factor level effects must sum to zero. If there are \\(m\\) factor levels, I only need to estimate effects for \\(m-1\\) levels. The last level’s effect is a function of the other factor level effects, it does not need to be estimated and therefore does not need a degree of freedom.\nFinally, consider the residual error factor. The non-technical definition of the term residual means “left over”. The degrees of freedom for the residual error factor is whatever degrees of freedom are left over after calculating degrees of freedom for all other factors.\nIn summary, to estimate the degrees of freedom for a factor, start with its number of levels and then subtract the number of means that need to be calculated in order to calculate the factor’s level effects. This is exactly what the general rule for finding degrees of freedom tells us.\n\n\n\n\n\n\nGeneral rule to find degrees of freedom for a factor\n\n\n\n\\[\n\\text{df} = \\text{number of levels} - \\text{sum of df of outside factors}\n\\]"
  },
  {
    "objectID": "assumptions.html",
    "href": "assumptions.html",
    "title": "ANOVA Assumptions",
    "section": "",
    "text": "For our ANOVA F test results and model predictions to be trusted, certain assumptions, or requirements must be met.1\n\n\nThe terms “requirements” and “assumptions” are often used interchangeably when referring to the set of conditions that must be met for the model to be a valid representation of the data.\nBy way of review, here is the mathematical expression of the model for 1 structural factor. If we incorporated more factors into our study we would need to add additional terms to the model to represent that factor’s effects, as well as any interaction effects.\n\\[\ny_\\text{ij} = \\mu + \\alpha_i + \\epsilon_\\text{ij}\n\\qquad(1)\\]\nWhere\n\n\\(y_\\text{ij}\\) is an observation\n\\(\\mu\\) is the grand mean\n\\(\\alpha_i\\) represents the effect of factor level \\(i\\)\n\\(\\epsilon_\\text{ij}\\) is the residual error for the \\(j^\\text{th}\\) observation in factor level \\(i\\)\n\n\\(\\epsilon_\\text{ij}\\) is a random variable and most of the assumptions are focused on defining the distribution of this random variable. Namely, we assume that each residual comes from the same normal distribution, with mean 0 and standard deviation \\(\\sigma\\). Figure 1 illustrates the same residual distribution visually applied to three distinct factor levels. The assumptions and how to check them are explained in more detail below.\n\n\nCode\nset.seed(15)\ny <- data.frame(yi = rnorm(30,rep(c(12,14,18),each=10),2), g = rep(1:3,each=10)) \n\nplot(yi~g, data=y, pch=16, xaxt='n', xlim=c(0.25,3.75), ylab=expression(y[ik]), xlab=\"\", cex=.8, yaxt='n')\naxis(1, at=c(1,2,3), labels=paste(\"Group\",1:3))\n\nmu <- mean(c(12,14,18))\nmyi <- mean(y$yi)\nmai <- mean(yi ~ g, data=y)\nai <- c(12,14,18)\nyval <- seq(7,23, length.out=100)\n\ndy1 <- dnorm(yval, 12, 2)\ndy2 <- dnorm(yval, 14, 2)\ndy3 <- dnorm(yval, 18, 2)\nlines(dy1+1, yval, col='darkgray')\nlines(rep(1,100), yval, col='darkgray')\n\nlines(dy2+2, yval, col='darkgray')\nlines(rep(2,100), yval, col='darkgray')\n\nlines(dy3+3, yval, col='darkgray')\nlines(rep(3,100), yval, col='darkgray')\n\n#lines(c(.75,3.5), rep(mu, 2), lty=2)\n#text(.65,mu, expression(mu))\n\n#lines(rep(1+.21,2), c(ai[1],mu), lty=2, col='firebrick')\nlines(c(1-.2,1+.21), rep(ai[1],2), lty=2)\ntext(1-.4,ai[1], expression(mu[1]))\n#text(1+.21, (ai[1]+mu)/2, expression(alpha[1]), pos=4, cex=0.8)\n\n#lines(rep(2+.21,2), c(ai[2],mu), lty=2, col='firebrick')\nlines(c(2-.2,2+.21), rep(ai[2],2), lty=2)\ntext(2-.4,ai[2], expression(mu[2]))\n#text(2+.21, (ai[2]+mu)/2, expression(alpha[2]), pos=4, cex=0.8)\n\n#lines(rep(3+.21,2), c(ai[3],mu), lty=2, col='firebrick')\nlines(c(3-.2,3+.21), rep(ai[3],2), lty=2)\ntext(3-.4,ai[3], expression(mu[3]))\n#text(3+.21, (ai[3]+mu)/2, expression(alpha[3]), pos=4, cex=0.8)\n\nlines(rep(3-.1,2), c(ai[3],y$yi[25]), lty=2, col='firebrick')\nlines(c(3-.2,3), rep(y$yi[25],2), lty=2)\n#text(3-.21,y$yi[25], expression(y[3][\",\"][5] == mu[3]+epsilon[3][\",\"][5]), pos=2, cex=0.8)\ntext(3-.1, (y$yi[25]+ai[3])/2, expression(epsilon[3][\",\"][5]), pos=2, cex=0.8)\n\n\n\n\n\nFigure 1: Same distribution can be used to describe the residuals from each factor level"
  },
  {
    "objectID": "assumptions.html#center",
    "href": "assumptions.html#center",
    "title": "ANOVA Assumptions",
    "section": "Center",
    "text": "Center\nThe model assumes the mean of the residuals equals zero. The residual is the distance from an observation to its respective factor level mean, or predicted value. This assumption is the reason calculating a mean of observations makes sense as an estimate of the true mean of a factor level. Each observation is made up of two parts: a true part and some random error. If we have 3 observations all from the same factor level:\n\n\\(y_1 = \\text{true factor level mean} + \\text{error}_1\\)\n\\(y_2 = \\text{true factor level mean} + \\text{error}_2\\)\n\\(y_3 = \\text{true factor level mean} + \\text{error}_3\\)\n\nWe estimate the true mean of the factor level by taking the mean of the 3 values:\n\\[\n\\text{Mean of observations} = \\frac{y_1 + y_2 + y_3}{3} = \\frac{\\text{truth} + \\text{error}_1 + \\text{truth} + \\text{error}_2 + \\text{truth} + \\text{error}_3}{3}\n\\]\nRearranging terms gets:\n\\[\n\\text{Mean of observations} = \\text{truth} + \\frac{\\text{error}_1 + \\text{error}_2 + \\text{error}_3}{3}\n\\]\nSince the mean of the residual errors is assumed zero, the second term goes to zero and the mean of observations is the best estimate of the true value. Of course, the more observations we average over the better our estimate of the truth will be.\nThis requirement does not need to be checked since we are guaranteed this will occur based on how we calculate factor level effects. We saw this when we noticed the level effects of a factor sum to zero."
  },
  {
    "objectID": "assumptions.html#constant-variance",
    "href": "assumptions.html#constant-variance",
    "title": "ANOVA Assumptions",
    "section": "Constant Variance",
    "text": "Constant Variance\nWe express the spread of the distribution of residuals in terms of the variance, \\(\\sigma^2\\). We assume that the variance of residuals is the same regardless of the factor level. Consider our conveyor belt example. All the observations go down the same conveyor belt. The conveyor belt does not split into multiple branches just before the last, random station. All the residuals come from the same distribution.\nIn the F-statistic calculation the denominator is a pooled variance; or in other words, an average of the within factor level variances. When factor level sample sizes are unequal, then the average variance is biased toward the factor level with the largest sample size. Thus, it becomes important to show that the variance estimate within each factor level is (relatively) equal when sample sizes are not equal. The greater disparity in sample sizes, the more important it is to have similar within factor levels variances. (Inflation of Type I error tends to be worse if the smallest group has the largest variance.) The F-distribution used to calculate p-values is based on the assumption of equal variances. When there is non-constant variance, the ratio of between group variance to within group variance no longer follows the F-distribution and the p-value calculations will be off.\nThe simplest, quickest, and most common way to check this assumption is a visual assessment of a residual plot. A residual plot shows the residuals on the y-axis and the factor levels or fitted values on the x-axis. The assumption is satisfied when the vertical spread of the data points within each factor level is roughly the same. This is called homogeneity of variance or homoscedasticity. When the spread is not the same it is called heterogeneity of variance, or heteroscedasticity.\nFigure 2 shows the residual plot in our toothbrush example where the effectiveness of 4 different types of toothbrush were studied.\n\n\nCode\nbf2 <- read_csv(\"data/toothpaste_BF2.csv\")\nbrush_aov <- aov(Plaque~Brush, data = bf2)\nwhich = plot(brush_aov, which = 1)\n\n\n\n\n\nFigure 2: Residual vs. Fitted plot to check constant variance assumption\n\n\n\n\n\n\n\n\n\n\nRed Line in the Residual Plot\n\n\n\nIgnore the red line in the residual plot. It can trick your eyes and draw your attention to the wrong thing. It is not meant to gauge constant variance.\n\n\nThe points in Figure 2 are in 4 vertical groupings corresponding to the factor levels of toothbrush. This is to be expected because the x-axis is fitted values. Each toothbrush has a different fitted, or predicted, plaque value. The group of points on the far left appears less vertically spread out than the group of points on the far right.\nOf course, the groupings will never all have exactly equal variance. How different does the spread in this plot need to be to conclude that the assumption is met or is violated? It is subjective and experience will help you spot trouble in the plot. You can also employ additional methods to help detect non-constant variance.\nAs a rule of thumb, you can check to see if the largest standard deviation is more than double the smallest standard deviation. Table 1 shows summary statistics for the toothbrush example. The smallest standard deviation of 1.7 belongs to the oscillating brush. The largest standard deviation of 3.9 belongs to the ultrasonic brush. Because \\(2*1.74 = 3.48 < 3.90\\), by this rule of thumb the constant variance assumption appears to be violated.\n\n\nCode\nfavstats(Plaque~Brush, data = bf2) |> kable(digits = 2)\n\n\n\n\nTable 1: Summary statistics for each toothbrush\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBrush\nmin\nQ1\nmedian\nQ3\nmax\nmean\nsd\nn\nmissing\n\n\n\n\nManual\n19.12\n22.04\n23.38\n24.01\n26.88\n23.09\n2.60\n6\n0\n\n\nOscillating\n17.62\n18.89\n19.94\n21.29\n22.09\n19.98\n1.74\n6\n0\n\n\nSonic\n18.99\n21.73\n23.20\n23.68\n25.58\n22.67\n2.27\n6\n0\n\n\nUltrasonic\n21.45\n23.62\n24.30\n25.35\n32.74\n25.31\n3.90\n6\n0\n\n\n\n\n\n\nThere are formal hypothesis tests that can help determine if variance is equal across factor levels. One such test is Levene’s test. Actually, Modified Levene’s test (also called Brown-Forsythe test) is usually recommended and is the default in R’s car package. The hypothesis for this test is\n\\[\nH_0: \\sigma_1 = \\sigma_2 = … = \\sigma_i \\\\\n\\] \\[\nH_a: \\text{At least one sigma is different from the rest}\n\\]\nThe details of Levene’s test will not be covered here, but essentially the test runs an ANOVA F-test on the factor level variances to determine if the variances are equal. If the p-value of the test is low and the null is rejected, then you would consider the assumption violated. As the researcher, you are hoping to fail to reject the null hypothesis so that you may continue on with your analysis.\n\n\n\n\n\n\nDon’t Forget to Think\n\n\n\nIt is tempting to turn off your brain and simply run the test or use a rule without looking at the data or thinking of the impact. Do NOT do this. In fact, you can often get by without running this test at all. It is better to consider the sample sizes, outliers, general shapes of the distributions, and effect sizes relative to variance within each factor level. Think about how different the groups of residuals really are rather than blindly trusting a rule.\n\n\n\n\nCode\nleveneTest(brush_aov) |> kable()\n\n\n\n\nTable 2: Levene’s test output for the toothbrush example\n\n\n\nDf\nF value\nPr(>F)\n\n\n\n\ngroup\n3\n0.2498376\n0.8604884\n\n\n\n20\nNA\nNA\n\n\n\n\n\n\nFor the toothbrush example, the p-value of Levene’s F-test in Table 2 is .8605, indicating the constant variance assumption is met. It is not uncommon for this hypothesis test to disagree with the rule of thumb. It appears that one outlier in the upper right portion of Figure 2 is the main cause of the unequal variance. If that point is ignored, the groups do look more alike and the rule of thumb agrees with the Levene’s test.\nThis is not to suggest the point be removed from the analysis; rather, to recognize the impact an outlier can have on the assumptions. This is especially true when the methods of checking the assumption don’t agree.\n\nMore than 1 structural factor\nIf you have more than 1 structural factor, multiple residual plots should be examined, or examine one plot that contains all factor level combinations. Consider the slightly more complicated example where researchers investigated toothpaste brand (name brand vs. off brand), toothbrush type, and their interaction.\nIn this case, the residual vs. fitted plot has 8 different vertical groupings - one for each factor level combination of brush and paste. You should not be concerned about looking at each group individually. Rather, look for overall trends or megaphone shapes in the data. For example, does the spread of the residuals increase as the fitted value increases? Or, does the spread of the residuals decrease as the fitted value decreases?\n\n\nCode\nbrush_aov2 <- aov(Plaque~Brush*Toothpaste, data = bf2)\nwhich = plot(brush_aov2, which = 1)\n\n\n\n\n\nFigure 3: Residual vs. Fitted plot to check constant variance assumption for the 2-factor example\n\n\n\n\nFigure 3 shows a slight megaphone shape. As we move from left to right along the x-axis the spread of the points increases (with the exception of the points at x=24.5). We can use a Levene’s test to help us determine if heterogeneity of variance is a problem. The result is shown in Table 3.\n\n\nCode\nleveneTest(brush_aov2) |> kable()\n\n\n\n\nTable 3: Levene’s test output for the 2-factor example\n\n\n\nDf\nF value\nPr(>F)\n\n\n\n\ngroup\n7\n0.8834329\n0.5409189\n\n\n\n16\nNA\nNA\n\n\n\n\n\n\nWith a p-value of .541 we fail to reject the null hypothesis. It appears the constant variance assumption is met."
  },
  {
    "objectID": "assumptions.html#shape-normal-residual-distribution",
    "href": "assumptions.html#shape-normal-residual-distribution",
    "title": "ANOVA Assumptions",
    "section": "Shape: normal residual distribution",
    "text": "Shape: normal residual distribution\nThe ANOVA model assumes that residuals will follow a (approximately) normal distribution. To check this assumption we use a Q-Q plot.\n\n\nThere are statistical tests for normality as well, but each come with their own set of drawbacks. Due to the robust nature of the F test, a visual assessment is usually sufficient.\nThe “Q” in Q-Q plot stands for quantile. For an explanation of quantiles and their relationship to percentiles go here. There are many variations of Q-Q plots and each software computes it slightly differently. The general concept is to plot two quantities on a scatter plot:\n\nResidual from the model2\nThe value from the standard normal distribution (i.e. Z distribution) associated with the sample quantile.\n\nClick to show/hide detailed explanation of Q-Q plot construction\n\n\nThe Q-Q plot is actually just a scatterplot created from ordered pairs. Each ordered pair consists of a residual from the model (that’s easy to find!) and the quantile from the normal distribution associated with that residual.\nBut how do you find a quantile from the normal distribution? To get this, each residual is converted into a sample quantile, then the theoretical Z score from the normal distribution associated with that quantile is calculated. For example, if I had 20 residuals I would calculate the 1/20 quantile (a.k.a. fifth percentile) from the z-distribution. From Figure 4 (a) I can see the 5th percentile of the Z distribution is -1.645. My first ordered pair on the scatterplot would be the smallest residual and the value -1.645.\n\n\nCode\nxqnorm(.05, return = \"plot\")\n\nxqnorm(.10, return = \"plot\")\n\n\n\n\n\n\n\n\n(a) 5th percentile\n\n\n\n\n\n\n\n(b) 10th percentile\n\n\n\n\nFigure 4: Z-score calculations from desired percentile\n\n\n\nThe next point on the Q-Q plot would be my second smallest residual on the y-axis and the \\(2/20 = .10\\) quantile from the Z distribution on the x-axis. The 0.10 quantile is -1.282 as seen in Figure 4 (b).\nThis process would be repeated for all 20 residuals.\n\n\nIf the sample data is normally distributed then the resulting plot of the two quantities will roughly be a straight line. The residuals will never be exactly normal, of course. Some amount of “wiggle” should be allowed.\nFigure 5 is a Q-Q plot for the toothbrush example.\n\n\nCode\nplot(brush_aov, which = 2)\n\n\n\n\n\nFigure 5: Q-Q plot of residuals for tootbrush 1-factor ANOVA example\n\n\n\n\nIt can be difficult to tell if the line is straight enough. qqPlot from the car package (see Figure 6) adds boundary lines to help you determine if the points are out of bounds3. If sections of the plot are out of bounds the assumption of normally distributed residuals can be considered violated.\n\n\nCode\n#The envelope argument controls whether the region between the lines is shaded or not\ncar::qqPlot(brush_aov, envelope = list(style = \"lines\"))\n\n\n[1] 1 9\n\n\n\n\n\nFigure 6: Boundaries added to Q-Q plot of residuals for tootbrush 1-factor ANOVA example\n\n\n\n\nA point on the far right is clearly out of the dashed boundary. It is not uncommon for 1 or 2 points at either end of the x-axis to stray far from the line. Overall, however, the points in this plot tend to follow the line and stay in bounds. I would conclude that the assumption of normally distributed residuals is met.\n\n\n\n\n\n\nNotation\n\n\n\nSo far we have shown the residuals come from a normal distribution, with mean zero and a standard deviation (sigma). This is expressed mathematically as \\(\\epsilon\\) ~ N( 0, \\(\\sigma\\) )."
  },
  {
    "objectID": "assumptions.html#independent-observations",
    "href": "assumptions.html#independent-observations",
    "title": "ANOVA Assumptions",
    "section": "Independent observations",
    "text": "Independent observations\nIn addition to making assumptions about the distribution of residuals, we also make an assumption regarding individual observations, or realizations, from the distribution of errors. Specifically, we assume each observation from the error distribution is independent of the rest. In other words, the residuals are not correlated with each other in any way.\nThis is violated when something is affecting the response that was not adequately randomized, controlled for, or included in the model. Not adequately accounting for treatment order in time or space is often a culprit. For example, suppose you run an experiment where respondents were given a task to complete under 3 distinct conditions. If you did not randomize the order of the conditions or neglected to account for the fact the same respondent provided 3 observations, you would have violated this assumption.\nSometimes looking at the data can provide a clue this requirement is violated, sometimes it cannot. Looking at the Residual vs. Fitted plot is a good place to start. For example, when a model over predicts all observations in condition 1 and under predicted all observations in condition 3 it may be an indicator that you neglected to address something important (i.e. subject identification, or order of conditions) in your experiment.\nAn order plot can also be useful in detecting a violation of this assumption. The order plot shows each residual on the y-axis and the chronological order in which the observation was made/collected along the x-axis. Figure 7 contains the order plot for our simple toothbrush example, assuming the row number indicates the order in which each observation was actually made.\n\n\nCode\nplot(brush_aov$residuals)\n\n\n\n\n\nFigure 7: Order plot for 1-factor toothbrush example\n\n\n\n\nIt is interesting to see in this plot that the very first observation is a bit of an outlier. Perhaps the technology wasn’t working right or the assistant had not yet learned the correct procedure for measuring percent area with plaque. As the researcher, this is something you would want to dig deeper into. An equally plausible explanation for the outlying value is that the person really did have more plaque. Throwing out the datapoint simply because it doesn’t meet your expectations or messes up your analysis is not good research.\n\n\n\n\n\n\nDanger\n\n\n\nYou should not throw out data points based alone on the fact that they appear anomalous.\n\n\nNo other trends are evident in Figure 7. If patterns/trends are evident, you may have violated the assumption of independent observations. Perhaps a tool lost calibration over time, or subjects/researchers experienced fatigue. Whatever the cause, you will want to investigate, fix the issue, and potentially redo the experiment. It really comes down to your ability/inability to defend the validity of your study in the minds of your audience. Bias in your design or execution will lead to violating this assumption.\nIn many cases, the data will not indicate there is bias unless you know exactly what to look for. These unknown sources of bias are particularly difficult to detect. Planning the study in great detail, thinking critically about your results, being familiar with the protocols of the experiment, and getting help from others to provide fresh perspectives is ultimately the best way to check this assumption and ensure bias does not affect your results."
  },
  {
    "objectID": "assumptions.html#assumptions-summary",
    "href": "assumptions.html#assumptions-summary",
    "title": "ANOVA Assumptions",
    "section": "Assumptions Summary",
    "text": "Assumptions Summary\n\n\n\n\n\n\n\nResidual Assumption\nMethod for Checking\n\n\n\n\nMean is zero\nDoesn’t need to be checked. This will be a direct result of how we create the model.\n\n\nConstant variance across factor levels\n\nRule of thumb comparing standard deviations\nResidual vs. fitted plot\nLevene’s Test\n\n\n\nNormally distributed residuals\nNormal Q-Q plot\n\n\nIndependent of each other\n\nCritical thinking\nOrder plot"
  },
  {
    "objectID": "assumptions.html#what-to-do-if-assumptions-are-violated",
    "href": "assumptions.html#what-to-do-if-assumptions-are-violated",
    "title": "ANOVA Assumptions",
    "section": "What To Do If Assumptions Are Violated?",
    "text": "What To Do If Assumptions Are Violated?\n\nPrinciples For How To Proceed\nYou now have some tools to help assess whether the ANOVA assumptions have been met. It is extremely common in practice to be faced with data that is in the “gray area”, and making this determination is not always easy. There are a couple of principles to keep in mind as you decide whether to proceed with the analysis or try to address potential assumption violations.\nFirst, your p-value and test statistic values will be wrong proportional to the degree your assumptions are violated. For example, a minor violation of the homogeneity of variance assumption slightly degrades the accuracy, or truthfulness, of your F statistic. If the F statistic is quite extreme, then being off a little bit will not change the conclusions of your study.\nIn fact, ANOVA is robust to minor/moderate violations of the assumptions. This is the second principle to keep in mind. This means that you can still obtain reasonably trustworthy results even when there are minor or moderate violations of the assumptions. If the sample size is large and balanced, ANOVA tends to be more robust (especially with regard to the normal distribution of errors assumption). The case where skew is present and data is unbalanced is another story, and becomes particularly problematic if you plan to do one-tailed t-tests of contrasts.\nANOVA’s robustness to the mathematical assumptions does not minimize the adverse impacts of bias in a study.\nThird, take into account the purpose and context of the study in the broader context. If violated assumptions can be easily fixed with a few extra lines of code, there is no reason you should not try to improve the situation. As the remedy becomes more difficult/requires more effort, the cost-benefit analysis of trying something else changes. Think about deadlines, project cost, degree of assumption violation, desired precision, and severity of consequences if a wrong conclusion is reached as you decide how to pursue solutions to violated assumptions.\n\n\nLack of time due to procrastination is not a good reason to violate assumptions.\nRather than simply stating if the assumption is met or not met, it is wise to consider the pros and cons of proceeding with the analysis and then document and explain your decision. Consider sample sizes, effect sizes, outliers, and the degree to which assumptions are met when interpreting your results. ANOVA is just one family of models, there are alternative ways to approach a problem. If the ANOVA model does not seem like a good fit, do not be afraid to ask for help or learn a new technique.\n\n\nRemedial Measures\nThe strategy to address violated assumptions depends on how and which assumptions were violated. But beware, none of the suggested measures below can correct bias in sampling or random assignment.\nIf an outlier or two are the source of trouble, investigate the outlier to ensure it is valid, belongs in the study, and does not represent an error in some way.\nTo address non-normality of residuals you will want to know what the distribution of residuals looks like. If a histogram of residuals reveals a multi-modal distribution, that is often an indicator that there are additional populations (i.e. subgroups) that your model did not take into account. Try to identify what variable is causing the multiple modes (e.g. gender) and include it in your model.\nTransforming the data is a technique that can help with the normal distribution assumption and with heteroscedasticity simultaneously. The transformation is applied to the response variable and then the ANOVA analysis is run as usual with the new, transformed variable as the response. Though the analysis is performed using the transformed variable, you can interpret the results in terms of the original units of the response variable. Groups that differ on the transformed response tend to differ on the untransformed response variable as well.\nKnowing what transformation to apply to the response variable can be a challenge. A square root, log transformation, or taking the reciprocal of the response variable are common transformations to use, especially if the response variable represents a count during a defined interval or a time until something occurs. If the response is a proportion (e.g. proportion of quiz questions answered correctly), this transformation may prove useful: \\(Y_\\text{transformed} = 2*arcsine(\\sqrt{Y})\\)\nThe Box-Cox is a more algorithmic way of choosing a transformation.\nIt is also important to recognize that ANOVA is just one of many analysis tools available4. Kruskal-Wallis is one example of an alternative test with less stringent assumptions. But if its requirements are met, ANOVA offers greater statistical power than Kruskal-Wallis. It can also be difficult to extend some of these alternative tests to more complex designs.\nOne other approach is to emphasize the tests of contrasts and comparisons rather than omnibus F-tests. These more specific tests can handle non-constant variances and non-normal residuals, but at the expense of increased complexity or reduced statistical power. In fact, many researchers skip the omnibus ANOVA F-test and will go directly to testing the specific comparisons that motivated the experiment in the first place."
  },
  {
    "objectID": "BasicFactorial.html",
    "href": "BasicFactorial.html",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "",
    "text": "The experimental designs in this section have 2 key characteristics in common:\nTo assign something completely at random means that each experimental unit has a known and equal chance of being selected for a particular treatment and that no other considerations are taken into account when making treatment assignments. Usually, for balance, the same number of units are assigned to each treatment. For example, if I have 4 treatment and 16 units, I may use a computer to randomly shuffle the units into treatment groups.\nFactorial experiments involve two or more factors that are crossed. Factorial crossing means that each combination of factor levels is considered as a treatment in the study. (A study with just one factor is not technically a factorial design, but we will lump it in with our discussion of factorial experiments her because of the completely random treatment assignment).\nContrast a factorial design with the one-at-a-time approach. In a one-at-a-time approach, if I had two factors I wanted to study I would run two separate experiments to evaluate the effect of each factor on the response one-at-time. Factorial designs have a couple of major advantages over one-factor-at-a-time studies.\nEXAMPLE of BF2???\nIn summary, “factorial” refers to how you determine which treatments will be included in the study, and “completely randomized” refers to how treatments are assigned to subjects."
  },
  {
    "objectID": "BasicFactorial.html#bf1",
    "href": "BasicFactorial.html#bf1",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "BF[1]",
    "text": "BF[1]\nA study with just one factor\n\nOverview\nIn a basic one-way factorial design (BF[1]), only one factor is purposefully varied. Each level of the factor is considered a treatment. Each experimental unit is randomly assigned to exactly one treatment.\n\nFactor structure\nThe factor structure for the model resulting from a completely randomized, one factor with design is:\n\nThe above diagram illustrates a factor with 4 levels, 6 replications at each level.\n\n\nHypotheses and model\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from treatment \\(i\\)\n\\(\\mu\\): the grand mean of the dataset. Also referred to as an overall mean or benchmark.\n\\(\\alpha_i\\): effect of treatment \\(i\\)\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its treatment mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\nAssumptions\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\nEach experimental unit is randomly assigned to only 1 treatment (or factor level)\nThe error term of the model (\\(\\epsilon_{ik}\\)) is normally distributed. This assumption is met when the residuals are normally distributed (as seen in a qq-plot).\nThe population variance of each group is equal. This is often called the homogeneity of variance, or constant variance assumption. This is considered met when each group of residuals in the residual vs. fitted-values plot shows a similar vertical spread.\n\n\n\n\n\nDesign\nIn a one factor design, one factor is purposefully varied and all other factors are controlled in order to isolate the effect of just the factor under study. Each level of the factor is considered a treatment.\nIn a completely randomized design, each experimental unit is randomly assigned to exactly 1 treatment. It is common to keep the number of units assigned to each treatment the same to ensure balance. This can be done by listing all the subjects, then listing the treatments, as seen below:\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n1\n\n\nSubject 2\nA\n2\n\n\nSubject 3\nB\n3\n\n\nSubject 4\nB\n4\n\n\nSubject 5\nC\n5\n\n\nSubject 6\nC\n6\n\n\n\nThen you randomly shuffle the treatment column. (You should also be paying attention to the order in which subjects and treatments are being experimented on as this could be a potential source of bias. In a BF[1], you randomize the order also.) The result might look something like this.\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n4\n\n\nSubject 2\nB\n3\n\n\nSubject 3\nC\n6\n\n\nSubject 4\nC\n5\n\n\nSubject 5\nA\n1\n\n\nSubject 6\nB\n2\n\n\n\nYou may notice in the above example that, even with randomization, treatment C occurs in the last 2 observations. If we were truly concerned about the order we could be more strategic and implement a blocked design to prevent “unlucky” ordering and pairing.\nConsider the following example. An experiment was done to asses different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included: Lecture/Materials (Control) (1), Monitor/Keyboard (2), Head Monitor Display/Joypad (3), and Head Monitor Display/Wearables (4). The response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test).\nTo obtain a balanced design, we will want each treatment to be assigned to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\ntreatment_list <- rep(1:4,4) #This repeats the sequence of 1 to 4, four times\ntreatment_list\n\n [1] 1 2 3 4 1 2 3 4 1 2 3 4 1 2 3 4\n\n\nHere it is reformatted in a easy to read table.\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\nThen we randomly shuffle treatments with subjects to get the following assignments. The R code could look like this\n\nset.seed(17) #only use this if you want the exact same random selection as this example\nsample(treatment_list, 16)\n\n [1] 2 4 1 4 3 1 3 2 2 2 4 3 4 1 3 1\n\n\nWe can see here that subject 1 should get treatment 2. Subject 2 gets treatment 4, Subject 3 gets treatment 1 and so on.\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n2\n\n\nSubject 2\n4\n\n\nSubject 3\n1\n\n\nSubject 4\n4\n\n\nSubject 5\n3\n\n\nSubject 6\n1\n\n\nSubject 7\n3\n\n\nSubject 8\n2\n\n\nSubject 9\n2\n\n\nSubject 10\n2\n\n\nSubject 11\n4\n\n\nSubject 12\n3\n\n\nSubject 13\n4\n\n\nSubject 14\n1\n\n\nSubject 15\n3\n\n\nSubject 16\n1\n\n\n\n\n\n\nDecomposition and Factor Structure\nThis section serves as a bridge between the design and the analysis of an experiment. It is equivalent to doing the analysis by hand. The primary goal is to see how the design decisions impact the analysis; including a deeper understanding of what the numbers in an ANOVA table mean and how they are calculated.\nA factor structure for an experimental design can help provide an effective way to organize and plan for the type of data needed for an experiment. For a basic one-way factorial design, three factors are involved for the experiment: the benchmark (or grand mean), the treatment, and the residual error. For example, an experiment was done to help train people in the procedure to launch a lifeboat. This was a Basic One-way Factorial Design, one where the treatments included: Lecture/Materials (Control) (1), Monitor/Keyboard (2), Head Monitor Display/Joypad (3), and Head Monitor Display/Wearables (4). The students were then given a pre-test before training and a post-test after training and the difference between the two scores was the measurement used from each student in the analysis. Therefore, we have four levels for the treatment with six replicates for each treatment (the actual study used 16 observations per treatment). The diagram below gives the factor structure of the design, and the accompanying mathematical model.\n\nA basic one-way factorial design has three factors: the benchmark, treatment, and residual. The effects of these factors can be summed together to find each observed value.\n\nThe observed values on the left show that there are 24 distinct observations of performance score, represented by the 24 cells - one for each of the observed values.\nThe benchmark represents the grand mean (or overall mean). The single large cell indicates that there is only one grand mean and it is part of every observation.\n\nThe treatment factor involves the four levels of the treatment represented by the four vertically long cells. Each treatment may have a distinct mean (or effect).\nThe residual error represents the difference between the observed value and the predicted value. The predicted value, also called the fitted value, is the sum of the grand mean and treatment effect. Each of the cells represent a distinct value for the residual error.\n\n\nInside vs. Outside Factors\nHaving a factor structure can help us determine the degrees of freedom and the effects of each factor. Before determining the degrees of freedom and the effects of each factor, understanding outside and inside factors is helpful.\nA factor is inside of another factor if all the levels of one factor (the inside factor) completely fits within a second factor (the outside factor).\nYou may find this analogy helpful. Pretend that an outside factor is a box, and the inside factor levels are blocks that fit perfectly within the box.\n\n  \n\nIn our basic one-way factorial design there are three factors: the benchmark, treatment, and residuals. In the picture below, benchmark is represented in red, treatment is drawn in blue, and the residual factor levels are depicted in black.\n\nIn order to understand the relationship between the benchmark and treatment factor, imagine picking up the levels of factor and placing them in the other factor one at a time. We will start with taking the levels of treatment and placing them inside of the benchmark.\n\nIn this picture you can see that one entire level of treatment can fit inside of a single level of benchmark. Even though they may share a boundary line, the level does not cross over and start sharing boundaries with any other level. You can repeat this for the other 3 levels of treatment with the same result. Therefore, we say that treatment is inside of benchmark, which is the same as saying that benchmark is outside of treatment.\nConsider now the relationship between treatment and residual. If we take a level of treatment and overlay it on the residual factor, we can see it does not fit neatly inside one of the levels of residual error. In fact, one level of treatment crosses the boundaries of many of the levels of residual error. Therefore, we cannot say that treatment is inside of residual error.\n\nSince treatment is not inside of residual error, does this necessarily mean that treatment is outside of residual error? We can determine this by taking one level of residual at a time and overlaying it on the treatment factor structure, as is pictured below. It can be seen that one level of residual error does NOT cross any of the treatment level boundaries. Therefore, we can safely say that treatment is indeed outside of residual error; or equivalently that treatment is outside of residual error.\n\nTo clarify a common misunderstanding, consider an experiment where we are looking at the inside vs. outside relationship of two factors: A, and B.\n\nWhen factor A is inside of factor B, we can also say factor B is outside of factor A.\nBut, when factor A is not inside of factor B, this does not necessarily mean that factor A is outside of factor B. Later you will come across designs where the two factors are neither outside nor inside of each other: they are crossed.\n\nIn summary, inside and outside factors for every basic one-way factorial design:\n\nThe benchmark factor is the outside factor for all the other factors (treatment and residual error)\nThe treatment factor is an inside factor to the benchmark factor but an outside factor to the residual error.\nThe residual error is an inside factor for all other factors (the benchmark and treatment factors).\n\n\n\nDegrees of Freedom\nWe can use our understanding of inside and outside factors to determine the degrees of freedom (df) for the benchmark, treatment, and residual errors factors.\nThe general formula for degrees of freedom for any factor in a design is:\n\n\ndf = Total levels of a factor minus the sum of the df of all outside factors\n\n\nAn alternative method of finding degrees of freedom is to count the number of unique pieces of information in a factor.\nGoing back to the lifeboat training example (see example above), we have 24 observations total and four levels of the treatment.\n\nFor benchmark, there is only one level of the factor (shown by the one cell) and there are no outside factors for benchmark. Therefore, the degrees of freedom for benchmark is one. Another way to think of this is that the degrees of freedom represents the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as I know the benchmark value (or better stated, as soon as I estimate the benchmark value) for just one of the observations, I know it for all the observations. Therefore, there is just one degree of freedom.\nFor treatment, there are four levels of the factor (shown by the four vertically long cells for treatment). Benchmark is the only factor outside of treatment. Take the number of levels for treatment (4) and subtract the degrees of freedom for benchmark (1), which yields 4-1 = 3 degrees of freedom for treatment.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the treatment effects really contains. Since all observations from the same treatment will have the same treatment effect applied, we really only need to know 4 pieces of information: the effect of each treatment. But the answer is actually less than that. Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom is 3. As soon as we know 3 of the treatment effects, we can fill in the treatment effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of the factor structure diagram). Both benchmark and treatment are outside factors for the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for benchmark and treatment (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the treatment effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 treatments is 20 observations, or in other words, 20 degrees of freedom.\n\n\nFactor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size for the benchmark, treatment, and residual errors factors. In other words, we can estimate the terms in the one-way ANOVA model.\nThe general formula for effect size for any factor of a design is:\n\n\nEffect size = factor level mean minus the sum of the effects of all outside factors\n\n\nTo demonstrate this, the lifeboat training study will be used; where each column of data comes from a different training method (a.k.a. treatment).\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the benchmark factor and the means for each treatment level.\nFor benchmark, get the mean of all 24 observations. The mean for all the observations is 6.5846. There is only one level for benchmark since, all observations come from the same benchmark. Therefore, this number is placed into each of the cells for the benchmark factor.\n\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. These numbers will be put in the columns associated with each level of the treatment (see below).\n\n\n\nCalculate effects\nFrom here we can calculate the effects for benchmark, treatment and residual errors. We will use the general formula for calculating effect size as stated above.\nFor the benchmark, there is only one level and there are no outside factors. Therefore, the effect due to benchmark is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nFor the treatment factor there are four means, one for each level. To calculate this, take the factor level mean and subtract it from the effect due to benchmark to get the effect for each treatment level. For Control, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the overall, or grand, mean. In a similar way you can find the effect for Monitor/Keyboard 7.8492 - 6.5846 = 1.2645. This means the student performance scores increased by 1.2645 on average in this condition compared to the overall mean. For Head Monitor Display/Joypad, the effect is -0.0058 (6.5789 - 6.5846). For Head Monitor Display/Wearables, the effect is 0.5770 (7.1616 - 6.5846) (see below).\n\nTo calculate the residual error effects we must remember that there are 24 levels of residuals. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for benchmark and the effect for the treatment that particular observation received. For instance, for the observation located in the top left of our dataset the observed value is 4.5614. Subtract the sum of the effects of outside factors (benchmark and treatment). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual errors effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was -0.1875 less than the average for all observations in the control group. In context of the this study, this individual’s performance was lower than his/her peers who received the same type of training.\nWe can repeat the calculation for the first residual in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to benchmark and its respective treatment (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in the table below on the right.\n\n\n\n\nCompleting the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA table enables us to conduct a hypothesis test of the significance of the treatment.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n     \n     \n     \n     \n  \n  \n    Treatment \n    3 \n     \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n     \n     \n     \n     \n  \n  \n    Total \n    24 \n     \n     \n     \n     \n  \n\n\n\n\n\nTo get the sum of squares (SS) for a factor, for each observation the effect for that factor needs to be squared. Then all the squared values are summed up to get the sum of squares.\nFor benchmark, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to benchmark.\n\\[\nSS_\\text{Benchmark} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor has four different effects, one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to treatment. For instance, for the control group, the effect is -1.8358. The value is then squared, and then multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Treatment} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the benchmark, treatment, and residual error factors.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n     \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n     \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWe can now calculate the mean squared error column, or mean square (MS). This mean is calculated by dividing sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation).\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. We can then see more clearly which factor is the a bigger source of variability.\nThe mean square calculations are:\n\\[\nMS_\\text{Benchmark} = \\frac{SS_\\text{Benchmark}}{df_\\text{Benchmark}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Treatment} = \\frac{SS_\\text{Treatment}}{df_\\text{Treatment}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWhen getting an F test statistic, testing for the treatment factor is the primary factor of interest so only the F test statistic for treatment is calculated for the analysis. To get the F test statistic for treatment, take the mean square (MS) due to treatment and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of this as calculating the variance in treatment effect sizes in the numerator and the variance of the distances for an observed value to its respective treatment mean in the denominator. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Treatment} = \\frac{MS_\\text{Treatment}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for treatment is calculated based on the F statistic for treatment and the degrees of freedom for both Treatment and Residual Error. In practice, you would not compute this by hand, but in order to complete the decomposition of variance in a manual way, we will calculate the p-value in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to treatment are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n    2.11 \n    0.131 \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\n\n\n\n\nR Instructions\nThe following stuff would belong in the R code pages instead of here\n\nNumerical Summaries\nIn the following explanations\n\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use as.factor(X) inside the aov(Y ~ as.factor(X),…) command.\nYourDataSet is the name of your data set.\n\nYou can take a tidyverse approach or a mosaic package approach to calculating numerical summaries.\nmosaic package:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\ntidyverse approach:\n\nlibrary(tidyverse)\nYourDataSet %>%\n  Group_by(X) %>%\n  Summarise(MeanY = mean(Y), sdY = sd(Y), sampleSize = n()) \n\n\n\nGraphical Summaries\nTo obtain a boxplot:\nboxplot(Y~X, data = YourDataSet)\nExample Code:\n\n\n\n\n\n\n\n\n\n\nResources\n\nExamples\nLifeboat launch training\nMosquito\n\n\nLinks to outside resources\nPopulate this section yourself with links to good examples, definitions, other sections within this textbook, or anything else you think will be interesting/helpful."
  },
  {
    "objectID": "BasicFactorial.html#bf2",
    "href": "BasicFactorial.html#bf2",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "BF[2]",
    "text": "BF[2]\nA study with exactly two factors used to predict a continuous response variable.\n\nOverview\nLorem Ipsum Overview\n\nHypotheses and model\nHere we would list the model in equation form along with the hypotheses we would want to test\n\n\nAssumptions\nA quick recount of the assumptions associated with the model. If this gets too repetitive maybe we could take it out and put it under broad topics\n\n\nFactor structure image\nThis image would actually probably go at the top somewhere, maybe even by or above the title, as a sort of visual anchor/synopsis as to what this design is all about in terms of its structural factors.\n\n\n\n\nDesign\nThis will explain how random assignment is conducted. It may generally be a short section, especially since I already explained about completely random assignment above. However, it could get more in-depth. For example, in blocking you can talk about the different methods for creating blocks, or for Latin Squares there’s a lot to describe. For partial fractional factorials it could get interesting, etc.\n\n\n\nDecomposition\nIt is what it sounds like: discussion of effect calculation, degree of freedom calculation, and factor structure diagrams. Where do things like notation get defined, and concepts like inside vs. outside factors? Should those go in the broad topics menu?\n\n\n\nR Instruction\nIt is what it sounds like: discussion of effect calculation, degree of freedom calculation, and factor structure diagrams. Where do things like notation get defined, and concepts like inside vs. outside factors? Should those go in the broad topics menu?\n\n\nResources\n\nExamples\nHere we could link to a full walk through example of the anlaysis (similar to the Math325 notebook)\n\n\nLinks to outside resources\nThis section the student would populate with links to good examples, definitions, other sections within this textbook, or anything else"
  },
  {
    "objectID": "BasicFactorial.html#bf3",
    "href": "BasicFactorial.html#bf3",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "BF[3]",
    "text": "BF[3]\nA study with exactly three factors used to predict a continuous response variable.\n\nOverview\nLorem Ipsum Overview\n\nHypotheses and model\nHere we would list the model in equation form along with the hypotheses we would want to test\n\n\nAssumptions\nA quick recount of the assumptions associated with the model. If this gets too repetitive maybe we could take it out and put it under broad topics\n\n\nFactor structure image\nThis image would actually probably go at the top somewhere, maybe even by or above the title, as a sort of visual anchor/synopsis as to what this design is all about in terms of its structural factors.\n\n\n\n\nDesign\nThis will explain how random assignment is conducted. It may generally be a short section, especially since I already explained about completely random assignment above. However, it could get more in-depth. For example, in blocking you can talk about the different methods for creating blocks, or for Latin Squares there’s a lot to describe. For partial fractional factorials it could get interesting, etc.\n\n\n\nDecomposition\nIt is what it sounds like: discussion of effect calculation, degree of freedom calculation, and factor structure diagrams. Where do things like notation get defined, and concepts like inside vs. outside factors? Should those go in the broad topics menu?\n\n\n\nR Instruction\nIt is what it sounds like: discussion of effect calculation, degree of freedom calculation, and factor structure diagrams. Where do things like notation get defined, and concepts like inside vs. outside factors? Should those go in the broad topics menu?\n\n\nResources\n\nExamples\nHere we could link to a full walk through example of the anlaysis (similar to the Math325 notebook)\n\n\nLinks to outside resources\nThis section the student would populate with links to good examples, definitions, other sections within this textbook, or anything else"
  },
  {
    "objectID": "BasicFactorial.html#fractional-factorial-designs",
    "href": "BasicFactorial.html#fractional-factorial-designs",
    "title": "Randomized, Basic Factorial Experiments",
    "section": "Fractional Factorial Designs",
    "text": "Fractional Factorial Designs\nThis would probably not follow a similar structure as other sections\n\nOverview??\nLorem Ipsum Overview\n\n\n\nHow many treatments, design rank\nHere we would list the model in equation form along with the hypotheses we would want to test\n\n\n\nConfounding and a Generating Function\nA quick recount of the assumptions associated with the model. If this gets too repetitive maybe we could take it out and put it under broad topics\n\n\n\nAnything else??\n\n\n\nAdditional resources and links\n\nExamples\nHere we could link to a full walk through example of the anlaysis (similar to the Math325 notebook)\n\n\nLinks to outside resources\nThis section the student would populate with links to good examples, definitions, other sections within this textbook, or anything else\n\nThe decompositions presented in this book are all for balanced designs. Unbalanced designs (where not all treatments have an equal number of observations) use more complicated formulas, but a similar approach/process of decomposition is used."
  },
  {
    "objectID": "BasicFactorial_intro.html",
    "href": "BasicFactorial_intro.html",
    "title": "Overview",
    "section": "",
    "text": "Independent variables are categorial and the response is quantitative\nTreatments are assigned to subjects (a.k.a. experimental units) completely at random\nFor studies with more than one factor, additional factors levels are created by crossing factors\nSimilar analysis using ANOVA\n\nTo assign something completely at random means that each experimental unit has a known and equal chance of being selected for a particular treatment and that no other considerations are taken into account when making treatment assignments.\nThe decomposition and formulas presented for each of the specific designs assumes the design is balanced, meaning each factor level combination has the same number of observations. In the case of unbalanced designs, formulas would need to be adjusted to account for the differences. Additional explanation of how to approach analysis for unbalanced data is found under broad topics>unbalanced."
  },
  {
    "objectID": "BasicFactorial_quarto.html#overview",
    "href": "BasicFactorial_quarto.html#overview",
    "title": "Basic Factorial",
    "section": "Overview",
    "text": "Overview\nIn a basic one-way factorial design (BF[1]), only one factor is purposefully varied. Each experimental unit is assigned to exactly one factor level. (In the case of an observational study, only one independent factor is under consideration.)\n\nFactor Structure\nThe factor structure for the model resulting from a completely randomized, one factor design is:\n\n\n\n\nFigure 1: Example of BF1 Factor Structure\n\n\n\nFigure 1 illustrates a factor with 4 levels, 6 replications at each level.\n\n\nHypothesis and Model\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from factor level \\(i\\)\n\\(\\mu\\): the grand mean of the data set.\n\\(\\alpha_i\\): effect of factor level \\(i\\)\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its factor level mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\nAssumptions\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nRule of thumb comparing standard deviations\n\\(max(s) < 2*min(s)\\)\n\n\n\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "BasicFactorial_quarto.html#design",
    "href": "BasicFactorial_quarto.html#design",
    "title": "Basic Factorial",
    "section": "Design",
    "text": "Design\nIn a one factor design, one factor is purposely varied and all other factors are controlled in order to isolate the effect of just the factor under study. Each level of the factor is considered a treatment.\nIn a completely randomized design, each experimental unit is randomly assigned to exactly 1 treatment. In this example we expect a balanced design (i.e. each factor level has the same number of observations). This can be done by listing all the subjects, then listing the treatments, as seen below:\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n1\n\n\nSubject 2\nA\n2\n\n\nSubject 3\nB\n3\n\n\nSubject 4\nB\n4\n\n\nSubject 5\nC\n5\n\n\nSubject 6\nC\n6\n\n\n\nThen you randomly shuffle the treatment column. (You should also be paying attention to the order in which subjects and treatments are being experimented on as this could be a potential source of bias. In a BF[1], you randomize the order also.) The result might look something like this.\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n4\n\n\nSubject 2\nB\n3\n\n\nSubject 3\nC\n6\n\n\nSubject 4\nC\n5\n\n\nSubject 5\nA\n1\n\n\nSubject 6\nB\n2\n\n\n\nYou may notice in the above example that, even with randomization, treatment C occurs in the last 2 observations. If we were truly concerned about the order we could be more strategic and implement a blocked design to prevent “unlucky” ordering and pairing.\nConsider the following example. An experiment was done to assess different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included:\n\nLecture/Materials (Control)\nMonitor/Keyboard\nHead Monitor Display/Joypad, and\nHead Monitor Display/Wearables.\n\nThe response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test).\nWe want to assign each treatment to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\n\nCode\n#Repeat the sequence of 1 to 4, four times\nTreatment <- rep(1:4,4) \n\n#Create a sequence from 1 to 16\n#Paste the word \"Subject \" in front of each id #\nSubject <- paste(\"Subject\", seq(1:16), sep = \" \")\n\n#Combine the vector of treatment numbers and Subject ID's into 1 tibble/data frame\nassignment_table <- tibble(Subject, Treatment)\n\n#print the table, pander() makes it look nice\npander(assignment_table) \n\n\n\n\n\n\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\n\n\nThen we randomly shuffle the Treatments column to get the following assignments. Check out the R-code to see how this is done.\n\n\nCode\n#set.seed() allows us to get the same random sample each time\nset.seed(42) \n\n#sample() will randomly select from the Treatment vector 16 times without replacement\n# %>% is called a pipe. It simply takes the output from the command on the left\n# and sends it to the command on the right\ntibble(Subject, sample(Treatment, 16)) %>% pander()\n\n\n\n\n\n\n\n\n\nSubject\nsample(Treatment, 16)\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n1\n\n\nSubject 3\n4\n\n\nSubject 4\n1\n\n\nSubject 5\n2\n\n\nSubject 6\n4\n\n\nSubject 7\n2\n\n\nSubject 8\n2\n\n\nSubject 9\n4\n\n\nSubject 10\n3\n\n\nSubject 11\n3\n\n\nSubject 12\n1\n\n\nSubject 13\n3\n\n\nSubject 14\n4\n\n\nSubject 15\n3\n\n\nSubject 16\n2\n\n\n\n\n\nWe can see here that subject 1 should get treatment 2. Subject 2 gets treatment 4, Subject 3 gets treatment 1, and so on."
  },
  {
    "objectID": "BasicFactorial_quarto.html#decomposition",
    "href": "BasicFactorial_quarto.html#decomposition",
    "title": "Basic Factorial",
    "section": "Decomposition",
    "text": "Decomposition\nThis section serves as a bridge between the design and the analysis of an experiment. It is equivalent to doing the analysis by hand. The primary goal is to see how the design decisions impact the analysis; including a deeper understanding of what the numbers in an ANOVA table mean and how they are calculated.\nThe factor structure diagram of an experimental design is an effective way to organize and plan for the type of data needed for an experiment. Recall that in our lifeboat example there were four levels of training method with six replicates for each (the actual study used 16 observations per treatment). The diagram below gives the factor structure of the design, and the accompanying mathematical model.\n\n\n\n\nExample of BF1 Factor Structure\n\n\n\nA basic one-way factorial design has three analysis factors: the grand mean, treatment, and residual. The effects of these factors can be summed together to find each observed value.\n\nThe observed values on the left show that there are 24 distinct observations of performance score, represented by the 24 cells - one for each of the observed values.\nThe grand mean factor represents the grand mean. The single large cell indicates that there is only one grand mean and it is part of every observation.\nThe treatment factor involves the four levels of the treatment represented by the four vertically long cells. Each treatment may have a distinct mean and effect.\nThe residual error represents the difference between the observed value and the predicted value. The predicted value, also called the fitted value, is the sum of the grand mean and treatment effect. Each of the cells represent a distinct value for the residual error.\n\n\nDegrees of Freedom\nWe can use our understanding of inside and outside factors to determine the degrees of freedom (df) for the grand mean, treatment, and residual errors factors. We start with 24 observations - or pieces of information. In other words, we have 24 degrees of freedom that need to be allocated to the 3 factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the lifeboat example, grand mean has one level (shown by the one cell in Figure 1) and there are no factors outside of grand mean. Therefore, its degrees of freedom equals one.\nRemember, the degrees of freedom represent the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as you estimate the grand mean for just one of the observations, you know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for the grand mean effect were also known. Therefore, there is just one unique piece of information in the grand mean factor. Grand mean has just 1 degree of freedom.\nFor treatment factor, there are four levels of the factor (shown by the four vertically long cells for treatment in Figure 1). Grand mean is the only factor outside of treatment. Take the number of levels for treatment factor (4 training methods) and subtract the degrees of freedom for grand mean (1), which yields 4-1 = 3 degrees of freedom for treatment.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the treatment effects really contain. Since all observations from the same treatment will have the same treatment effect applied, we only need to know 4 pieces of information: the effect of each treatment. But the answer is actually less than that. Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom are 3. As soon as we know 3 of the treatment effects, we can fill in the treatment effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of Figure 1). Both grand mean and treatment are outside of the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for grand mean and treatment (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the residual factor effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 treatments is 20 observations, or in other words, 20 degrees of freedom.\n\n\nFactor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size of the grand mean, treatment, and residual errors factors in the lifeboat training study. In other words, we can estimate the terms in the one-way ANOVA model.\n\n\n\n\n\n\nGeneral Rule for Effect Size\n\n\n\nEffect size = factor level mean - the sum of the effects of all outside factors\n\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the grand mean factor and the means for each level of training method.\nTo get the grand mean, average all 24 observations. The mean for all the observations is 6.5846. There is only one level for grand mean so this number is placed into each of the cells for the grand mean factor in ?@fig-benchmark.\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. In Figure 2 these means are placed in the respective training method column.\n\n\n\n\nFigure 2: Raw data and means for grand mean and training factors\n\n\n\n\n\nCalculate effects\nFrom here we can calculate the effects for grand mean, training method and residual errors. We will use the general formula for calculating effect size as stated above.\nFor the grand mean, there is only one level and there are no outside factors. Therefore, the effect due to grand mean is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nThe training method factor has four levels: one for each method. To calculate the effect of a training method, take the training method mean and subtract it from the effect due to the grand mean factor. For the “Control” method, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the grand mean. In a similar way you can find the effect for Monitor/Keyboard \\(7.8492 - 6.5846 = 1.2645\\). This means the student performance scores increased by 1.2645 on average in this training method compared to the grand mean. For Head Monitor Display/Joypad, the effect is \\(6.5789 - 6.5846 = -0.0058\\). For Head Monitor Display/Wearables the effect is \\(7.1616 - 6.5846 = 0.5770\\) (see below).\n\n\n\n\nFigure 3: Training Method Effects\n\n\n\nTo calculate the residual error effects remember that there are 24 levels of the residual error factor. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for grand mean and the effect for whichever training method that particular observation received. For instance, for the observation located in the top left of our data set the value is 4.5614. Subtract the sum of the effects of outside factors (grand mean and training). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual error effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was 0.1875 less than the mean of the control group. This individual’s performance was lower than the mean of his/her peers who received the same type of training.\nWe can repeat the residual calculation for the first observation in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to grand mean and its respective training (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in Figure 4.\n\n\n\n\nFigure 4: Residual Effects\n\n\n\n\n\n\nCompleting the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA table enables us to conduct a hypothesis test of the significance of the treatment.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n     \n     \n     \n     \n  \n  \n    Treatment \n    3 \n     \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n     \n     \n     \n     \n  \n  \n    Total \n    24 \n     \n     \n     \n     \n  \n\n\n\n\n\nTo get the sum of squares (SS) for a factor, for each observation the effect for that factor first needs to be squared. Then all the squared values are summed up to get the sum of squares.\nFor grand mean, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to benchmark.\n\\[\nSS_\\text{Benchmark} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor has four different effects, one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to treatment. For instance, for the control group, the effect is -1.8358. The value is then squared, and then multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Treatment} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the grand mean, treatment, and residual error factors.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    1040.57 \n     \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n     \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWe can now calculate the mean squared error column, or mean square (MS), by dividing the sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total (the sum of squares) into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation). The MS is calculated in this manner for each of the effects.\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. This works when looking at SS, since it is the total variance due to each factor. MS is then the average variability for each effect. We can then see clearly which factor is a bigger source of variability by comparing their mean squares.\nThe mean square calculations are:\n\\[\nMS_\\text{Grand Mean} = \\frac{SS_\\text{Grand Mean}}{df_\\text{Grand Mean}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Treatment} = \\frac{SS_\\text{Treatment}}{df_\\text{Treatment}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWhen getting an F test statistic, testing for the treatment factor is the primary factor of interest so only the F test statistic for treatment is calculated for the analysis. To get the F test statistic for the treatment factor take the mean square (MS) due to treatment factor and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of this as calculating the variance in treatment factor level means in the numerator and the variance of the distances for an observed value to its respective treatment factor level mean in the denominator. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Treatment} = \\frac{MS_\\text{Treatment}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for the treatment factor is calculated based on the F statistic and the degrees of freedom for both treatment factor and residual error. In practice, statistical software computes all the components of the ANOVA table, including the p-value. To complete the decomposition of variance in a manual way, the p-value is calculated in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to treatment are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Grand Mean \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n    2.11 \n    0.131 \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87"
  },
  {
    "objectID": "BasicFactorial_quarto.html#analysis-in-r",
    "href": "BasicFactorial_quarto.html#analysis-in-r",
    "title": "Basic Factorial",
    "section": "Analysis in R",
    "text": "Analysis in R\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots or scatterplots with the means displayed. Instructions for how to calculate numerical summaries and create these plots in R are found at R Instructions->Descriptive Summaries section of the book.\nYou then create the model using the aov() function. To see results of the F-test you can feed your model into a summary() function.\n\nmyaov <- aov(Y ~ X, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is the user defined name in which the results of the aov() model are stored\nY is the name of a numeric variable in your dataset which represents the quantitative response variable.\nX is the name of a qualitative variable in your dataset. It should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\nYourDataSet is the name of your data set.\n\nExample Code\n\n\n df A name you come up with for your dataset  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv( a command from the tidyverse to read in csv files  “data/toothpaste_BF2.csv” The path to the csv file containing the data  ) Functions always end with a closing parenthesis  plaque_aovA name you come up with for your model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  summary( Give important information about an object. When called on an aov object the default is to print the ANOVA table  plaque_aov  Whatever you named your ANOVA model in the previous line   )  Functions always end with a closing parenthesis  Click to view output Click to View Output. \n\n\n\n\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nWe then interpret the results. Toothbrush appears to be a significant factor. Since the p-value in this case is significant we may be able to look at the graphical summaries to understand which factor level effects are significant. We may also want to do some pairwise tests of the means or contrasts.\nNow that the model is created the assumptions need to be checked. Code and explanation for assumption checking can be found in the Model Diagnostics and Assumptions sections of the book respectively."
  },
  {
    "objectID": "BasicFactorial_quarto.html#resources",
    "href": "BasicFactorial_quarto.html#resources",
    "title": "Basic Factorial",
    "section": "Resources",
    "text": "Resources\n\nExamples\nLifeboat launch training\nMosquito\n\n\nLinks to outside resources\nPopulate this section yourself with links to good examples, definitions, other sections within this textbook, or anything else you think will be interesting/helpful."
  },
  {
    "objectID": "BF.html",
    "href": "BF.html",
    "title": "Basic Factorial",
    "section": "",
    "text": "The experimental designs in this section have 2 key characteristics in common:\nNOT SURE HOW CRITICAL THESE DEFINITIONS WILL BE HERE, DEPENDS ON WHAT BRETT COMES UP WITH. THERE IS ALREADY SOME OVERLAP/REPEATING WITH THE FACTOR STRUCTURE SECTION. BUT REPITITION MAY NOT BE A BAD THING.\nTo assign something completely at random means that each experimental unit has a known and equal chance of being selected for a particular treatment and that no other considerations are taken into account when making treatment assignments.\nFactorial experiments involve two or more factors that are crossed. Full factorial crossing occurs when each combination of factor levels is present in the study. (A study with just one factor is not technically a factorial design, but we will lump it in with our discussion of factorial experiments here because of the completely random treatment assignment).\nContrast a factorial design with the one-at-a-time approach. In a one-at-a-time approach, if I had two factors I wanted to study I would run two separate experiments to evaluate the effect of each factor on the response one-at-time. Factorial designs have a couple of major advantages over one-factor-at-a-time studies.\nIn summary, “factorial” refers to how you determine which fact level combinations will be included in the study, and “completely randomized” refers to how treatments are assigned to subjects."
  },
  {
    "objectID": "BF.html#overview",
    "href": "BF.html#overview",
    "title": "Basic Factorial",
    "section": "Overview",
    "text": "Overview\nIn a basic one-way factorial design (BF[1]), only one factor is purposefully varied. Each experimental unit belongs to exactly one factor level. (In the case of an observational study, only one independent factor is under consideration.)\n\nFactor Structure\nThe factor structure for the model resulting from a completely randomized, one factor design is:\n\n\n\n\nFigure 1: Example of BF1 Factor Structure\n\n\n\nFigure 1 illustrates a factor with 4 levels, 6 replications at each level.\n\n\nHypothesis and Model\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from factor \\(i\\)\n\\(\\mu\\): the grand mean of the data set. Also referred to as an overall mean or benchmark.\n\\(\\alpha_i\\): effect of treatment \\(i\\)\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its treatment mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\nAssumptions\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\nIndividual realizations of the error term (i.e. residuals) are independent of one another. We generally consider this requirement met if each experimental unit is randomly assigned to only 1 factor level. However, the researcher should always be on the look out for violations of this assumption and other bias.\nThe error term of the model (\\(\\epsilon_{ik}\\)) is normally distributed. This assumption is met when the residuals are normally distributed (as seen in a qq-plot).\nThe population variance of each group is equal. This is often called the homogeneity of variance, or constant variance assumption. This is considered met when each group of residuals in the residual vs. fitted-values plot shows a similar vertical spread."
  },
  {
    "objectID": "BF.html#design",
    "href": "BF.html#design",
    "title": "Basic Factorial",
    "section": "Design",
    "text": "Design\nIn a one factor design, one factor is purposefully varied and all other factors are controlled in order to isolate the effect of just the factor under study. Each level of the factor is considered a treatment.\nIn a completely randomized design, each experimental unit is randomly assigned to exactly 1 treatment. It is common to keep the number of units assigned to each treatment the same to ensure balance. This can be done by listing all the subjects, then listing the treatments, as seen below:\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n1\n\n\nSubject 2\nA\n2\n\n\nSubject 3\nB\n3\n\n\nSubject 4\nB\n4\n\n\nSubject 5\nC\n5\n\n\nSubject 6\nC\n6\n\n\n\nThen you randomly shuffle the treatment column. (You should also be paying attention to the order in which subjects and treatments are being experimented on as this could be a potential source of bias. In a BF[1], you randomize the order also.) The result might look something like this.\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n4\n\n\nSubject 2\nB\n3\n\n\nSubject 3\nC\n6\n\n\nSubject 4\nC\n5\n\n\nSubject 5\nA\n1\n\n\nSubject 6\nB\n2\n\n\n\nYou may notice in the above example that, even with randomization, treatment C occurs in the last 2 observations. If we were truly concerned about the order we could be more strategic and implement a blocked design to prevent “unlucky” ordering and pairing.\nConsider the following example. An experiment was done to assess different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included:\n\nLecture/Materials (Control)\nMonitor/Keyboard\nHead Monitor Display/Joypad, and\nHead Monitor Display/Wearables.\n\nThe response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test).\nWe want to assign each treatment to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\n\nCode\n#Repeat the sequence of 1 to 4, four times\nTreatment <- rep(1:4,4) \n\n#Create a sequence from 1 to 16\n#Paste the word \"Subject \" in front of each id #\nSubject <- paste(\"Subject\", seq(1:16), sep = \" \")\n\n#Combine the vector of treatment numbers and Subject ID's into 1 tibble/data frame\nassignment_table <- tibble(Subject, Treatment)\n\n#print the table, pander() makes it look nice\npander(assignment_table) \n\n\n\n\n\n\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\n\n\nThen we randomly shuffle the Treatments column to get the following assignments. Check out the R-code to see how this is done.\n\n\nCode\n#set.seed() allows us to get the same random sample each time\nset.seed(42) \n\n#sample() will randomly select from the Treatment vector 16 times without replacement\n# %>% is called a pipe. It simply takes the output from the command on the left\n# and sends it to the command on the right\ntibble(Subject, sample(Treatment, 16)) %>% pander()\n\n\n\n\n\n\n\n\n\nSubject\nsample(Treatment, 16)\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n1\n\n\nSubject 3\n4\n\n\nSubject 4\n1\n\n\nSubject 5\n2\n\n\nSubject 6\n4\n\n\nSubject 7\n2\n\n\nSubject 8\n2\n\n\nSubject 9\n4\n\n\nSubject 10\n3\n\n\nSubject 11\n3\n\n\nSubject 12\n1\n\n\nSubject 13\n3\n\n\nSubject 14\n4\n\n\nSubject 15\n3\n\n\nSubject 16\n2\n\n\n\n\n\nWe can see here that subject 1 should get treatment 2. Subject 2 gets treatment 4, Subject 3 gets treatment 1, and so on."
  },
  {
    "objectID": "BF.html#decomposition",
    "href": "BF.html#decomposition",
    "title": "Basic Factorial",
    "section": "Decomposition",
    "text": "Decomposition\nThis section serves as a bridge between the design and the analysis of an experiment. It is equivalent to doing the analysis by hand. The primary goal is to see how the design decisions impact the analysis; including a deeper understanding of what the numbers in an ANOVA table mean and how they are calculated.\nThe factor structure diagram of an experimental design is an effective way to organize and plan for the type of data needed for an experiment. Recall that in our lifeboat example there were four levels of training method with six replicates for each (the actual study used 16 observations per treatment). The diagram below gives the factor structure of the design, and the accompanying mathematical model.\n\n\n\n\nExample of BF1 Factor Structure\n\n\n\nA basic one-way factorial design has three analysis factors: the benchmark, treatment, and residual. The effects of these factors can be summed together to find each observed value.\n\nThe observed values on the left show that there are 24 distinct observations of performance score, represented by the 24 cells - one for each of the observed values.\nThe benchmark represents the grand mean (or overall mean). The single large cell indicates that there is only one grand mean and it is part of every observation.\nThe treatment factor involves the four levels of the treatment represented by the four vertically long cells. Each treatment may have a distinct mean (or effect).\nThe residual error represents the difference between the observed value and the predicted value. The predicted value, also called the fitted value, is the sum of the grand mean and treatment effect. Each of the cells represent a distinct value for the residual error.\n\n\nDegrees of Freedom\nWe can use our understanding of inside and outside factors to determine the degrees of freedom (df) for the benchmark, treatment, and residual errors factors. We start with 16 observations - or pieces of information. In other words, we have 16 degrees of freedom that need to be allocated to the 3 factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the lifeboat example, benchmark has one level (shown by the one cell in Figure 1) and there are no outside factors for benchmark. Therefore, the degrees of freedom for benchmark is one.\nRemember, the degrees of freedom represents the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as I estimate the benchmark effect for just one of the observations, I know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for benchmark were also known. Therefore, there is just one unique piece of information in the benchmark factor. Benchmark has just 1 degree of freedom.\nFor treatment factor, there are four levels of the factor (shown by the four vertically long cells for treatment in Figure 1). Benchmark is the only factor outside of treatment. Take the number of levels for treatment factor (4 training methods) and subtract the degrees of freedom for benchmark (1), which yields 4-1 = 3 degrees of freedom for treatment.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the treatment effects really contains. Since all observations from the same treatment will have the same treatment effect applied, we really only need to know 4 pieces of information: the effect of each treatment. But the answer is actually less than that. Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom is 3. As soon as we know 3 of the treatment effects, we can fill in the treatment effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of Figure 1). Both benchmark and treatment are outside factors for the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for benchmark and treatment (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the residual factor effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 treatments is 20 observations, or in other words, 20 degrees of freedom.\n\n\nFactor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size of the benchmark, treatment, and residual errors factors in the lifeboat training study. In other words, we can estimate the terms in the one-way ANOVA model.\n\n\n\n\n\n\nGeneral Rule for Effect Size\n\n\n\nEffect size = factor level mean - the sum of the effects of all outside factors\n\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the benchmark factor and the means for each level of training method.\nFor benchmark, get the mean of all 24 observations. The mean for all the observations is 6.5846. There is only one level for benchmark so this number is placed into each of the cells for the benchmark factor in Figure 2.\n\n\n\n\nFigure 2: Raw data and mean for benchmark factor\n\n\n\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. In Figure 3 these means are placed in the respective training method column.\n\n\n\n\nFigure 3: Raw data and means for benchmark and training factors\n\n\n\n\n\nCalculate effects\nFrom here we can calculate the effects for benchmark, training method and residual errors. We will use the general formula for calculating effect size as stated above.\nFor the benchmark, there is only one level and there are no outside factors. Therefore, the effect due to benchmark is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nThe training method factor has four levels: one for each method. To calculate the effect of a training method, take the training method mean and subtract it from the effect due to benchmark. For the “Control” method, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the grand mean. In a similar way you can find the effect for Monitor/Keyboard \\(7.8492 - 6.5846 = 1.2645\\). This means the student performance scores increased by 1.2645 on average in this training method compared to the grand mean. For Head Monitor Display/Joypad, the effect is \\(6.5789 - 6.5846 = -0.0058\\). For Head Monitor Display/Wearables the effect is \\(7.1616 - 6.5846 = 0.5770\\) (see below).\n\n\n\n\nFigure 4: Training Method Effects\n\n\n\nTo calculate the residual error effects we must remember that there are 24 levels of the residual error factor. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for benchmark and the effect for training method that particular observation received. For instance, for the observation located in the top left of our data set the observed value is 4.5614. Subtract the sum of the effects of outside factors (benchmark and training). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual error effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was 0.1875 less than the mean of the control group. In this case, this individual’s performance was lower than his/her peers who received the same type of training.\nWe can repeat the calculation for the first residual in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to benchmark and its respective training (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in Figure 5.\n\n\n\n\nFigure 5: Residual Effects\n\n\n\n\n\n\nCompleting the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA table enables us to conduct a hypothesis test of the significance of the treatment.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n     \n     \n     \n     \n  \n  \n    Treatment \n    3 \n     \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n     \n     \n     \n     \n  \n  \n    Total \n    24 \n     \n     \n     \n     \n  \n\n\n\n\n\nTo get the sum of squares (SS) for a factor, for each observation the effect for that factor needs to be squared. Then all the squared values are summed up to get the sum of squares.\nFor benchmark, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to benchmark.\n\\[\nSS_\\text{Benchmark} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor has four different effects, one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to treatment. For instance, for the control group, the effect is -1.8358. The value is then squared, and then multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Treatment} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the benchmark, treatment, and residual error factors.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n     \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n     \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWe can now calculate the mean squared error column, or mean square (MS). This mean is calculated by dividing sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation).\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. We can then see more clearly which factor is a bigger source of variability.\nThe mean square calculations are:\n\\[\nMS_\\text{Benchmark} = \\frac{SS_\\text{Benchmark}}{df_\\text{Benchmark}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Treatment} = \\frac{SS_\\text{Treatment}}{df_\\text{Treatment}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWhen getting an F test statistic, testing for the treatment factor is the primary factor of interest so only the F test statistic for treatment is calculated for the analysis. To get the F test statistic for treatment, take the mean square (MS) due to treatment and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of this as calculating the variance in treatment effect sizes in the numerator and the variance of the distances for an observed value to its respective treatment mean in the denominator. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Treatment} = \\frac{MS_\\text{Treatment}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for the treatment factor is calculated based on the F statistic and the degrees of freedom for both Treatment Factor and Residual Error. In practice, you would not compute this by hand, but in order to complete the decomposition of variance in a manual way, we will calculate the p-value in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to treatment are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n    2.11 \n    0.131 \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87"
  },
  {
    "objectID": "BF.html#analysis-in-r",
    "href": "BF.html#analysis-in-r",
    "title": "Basic Factorial",
    "section": "Analysis in R",
    "text": "Analysis in R\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots or scatterplots with the means displayed. Instructions for how to create these plots in R are found at R Instructions->Descriptive Summaries section of the book.\nYou then create the model using the aov() function. To see results of the F-test you can feed your model into a summary() function.\n\nmyaov <- aov(Y ~ X, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is some name you come up with to store the results of the aov() model.\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\nYourDataSet is the name of your data set.\n\nExample Code\n\n\ndfA name you come up with for your dataset <-The assignment operator. The result to the right of it gets stored in an object specified on the left read_csv(a command from the tidyverse to read in csv files “data/toothpaste_BF2.csv”The path to the csv file containing the data )Functions always end with a closing parenthesis plaque_aovA name you come up with for your model <-The assignment operator. The result to the right of it gets stored in an object specified on the left aov(A function to define the model PlaqueThe response, or y, variable in the model. It is numeric. ~The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s). Brush,The independent variable containing the names for the 4 types of toothbrushes. data = dfTell the model to look in the dataset named “df” for Plaque and Brush variables )Functions always end with a closing parenthesis summary(Give important information about an object. When called on an aov object the default is to print the ANOVA table plaque_aovWhatever you named your ANOVA model in the previous line )Functions always end with a closing parenthesisClick to view outputClick to View Output.\n\n\n\n\ndf <- read_csv(\"data/toothpaste_BF2.csv\")\nplaque_aov <- aov(Plaque ~ Brush, data = df)\nsummary(plaque_aov)\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nWe then interpret the results. Since the p-value is significant we may be able to the graphical summaries to understand which factor level effects are significant. We may also want to do some pairwise tests of the means or contrasts.\nNow that the model is created the assumption need to be checked. Code and explanation for assumption checking can be found at R Instructions->Model Assumptions section of the book."
  },
  {
    "objectID": "BF.html#resources",
    "href": "BF.html#resources",
    "title": "Basic Factorial",
    "section": "Resources",
    "text": "Resources\n\nExamples\nLifeboat launch training\nMosquito\n\n\nLinks to outside resources\nPopulate this section yourself with links to good examples, definitions, other sections within this textbook, or anything else you think will be interesting/helpful."
  },
  {
    "objectID": "BF1test.html",
    "href": "BF1test.html",
    "title": "Basic Factorial",
    "section": "",
    "text": "The experimental designs in this section have 2 key characteristics in common:\nNOT SURE HOW CRITICAL THESE DEFINITIONS WILL BE HERE, DEPENDS ON WHAT BRETT COMES UP WITH. THERE IS ALREADY SOME OVERLAP/REPEATING WITH THE FACTOR STRUCTURE SECTION. BUT REPITITION MAY NOT BE A BAD THING.\nTo assign something completely at random means that each experimental unit has a known and equal chance of being selected for a particular treatment and that no other considerations are taken into account when making treatment assignments.\nFactorial experiments involve two or more factors that are crossed. Full factorial crossing occurs when each combination of factor levels is present in the study. (A study with just one factor is not technically a factorial design, but we will lump it in with our discussion of factorial experiments here because of the completely random treatment assignment).\nContrast a factorial design with the one-at-a-time approach. In a one-at-a-time approach, if I had two factors I wanted to study I would run two separate experiments to evaluate the effect of each factor on the response one-at-time. Factorial designs have a couple of major advantages over one-factor-at-a-time studies.\nIn summary, “factorial” refers to how you determine which fact level combinations will be included in the study, and “completely randomized” refers to how treatments are assigned to subjects."
  },
  {
    "objectID": "BF1test.html#overview",
    "href": "BF1test.html#overview",
    "title": "Basic Factorial",
    "section": "Overview",
    "text": "Overview\nIn a basic one-way factorial design (BF[1]), only one factor is purposefully varied. Each experimental unit belongs to exactly one factor level. (In the case of an observational study, only one independent factor is under consideration.)\n\nFactor Structure\nThe factor structure for the model resulting from a completely randomized, one factor design is:\n\n\n\n\nFigure 1: Example of BF1 Factor Structure\n\n\n\nFigure 1 illustrates a factor with 4 levels, 6 replications at each level.\n\n\nHypothesis and Model\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from factor \\(i\\)\n\\(\\mu\\): the grand mean of the data set. Also referred to as an overall mean or benchmark.\n\\(\\alpha_i\\): effect of treatment \\(i\\)\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its treatment mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\] \\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\nAssumptions\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\nIndividual realizations of the error term (i.e. residuals) are independent of one another. We generally consider this requirement met if each experimental unit is randomly assigned to only 1 factor level. However, the researcher should always be on the look out for violations of this assumption and other bias.\nThe error term of the model (\\(\\epsilon_{ik}\\)) is normally distributed. This assumption is met when the residuals are normally distributed (as seen in a qq-plot).\nThe population variance of each group is equal. This is often called the homogeneity of variance, or constant variance assumption. This is considered met when each group of residuals in the residual vs. fitted-values plot shows a similar vertical spread."
  },
  {
    "objectID": "BF1test.html#design",
    "href": "BF1test.html#design",
    "title": "Basic Factorial",
    "section": "Design",
    "text": "Design\nIn a one factor design, one factor is purposefully varied and all other factors are controlled in order to isolate the effect of just the factor under study. Each level of the factor is considered a treatment.\nIn a completely randomized design, each experimental unit is randomly assigned to exactly 1 treatment. It is common to keep the number of units assigned to each treatment the same to ensure balance. This can be done by listing all the subjects, then listing the treatments, as seen below:\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n1\n\n\nSubject 2\nA\n2\n\n\nSubject 3\nB\n3\n\n\nSubject 4\nB\n4\n\n\nSubject 5\nC\n5\n\n\nSubject 6\nC\n6\n\n\n\nThen you randomly shuffle the treatment column. (You should also be paying attention to the order in which subjects and treatments are being experimented on as this could be a potential source of bias. In a BF[1], you randomize the order also.) The result might look something like this.\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n4\n\n\nSubject 2\nB\n3\n\n\nSubject 3\nC\n6\n\n\nSubject 4\nC\n5\n\n\nSubject 5\nA\n1\n\n\nSubject 6\nB\n2\n\n\n\nYou may notice in the above example that, even with randomization, treatment C occurs in the last 2 observations. If we were truly concerned about the order we could be more strategic and implement a blocked design to prevent “unlucky” ordering and pairing.\nConsider the following example. An experiment was done to assess different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included:\n\nLecture/Materials (Control)\nMonitor/Keyboard\nHead Monitor Display/Joypad, and\nHead Monitor Display/Wearables.\n\nThe response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test).\nWe want to assign each treatment to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\n\nCode\n#Repeat the sequence of 1 to 4, four times\nTreatment <- rep(1:4,4) \n\n#Create a sequence from 1 to 16\n#Paste the word \"Subject \" in front of each id #\nSubject <- paste(\"Subject\", seq(1:16), sep = \" \")\n\n#Combine the vector of treatment numbers and Subject ID's into 1 tibble/data frame\nassignment_table <- tibble(Subject, Treatment)\n\n#print the table, pander() makes it look nice\npander(assignment_table) \n\n\n\n\n\n\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\n\n\nThen we randomly shuffle the Treatments column to get the following assignments. Check out the R-code to see how this is done.\n\n\nCode\n#set.seed() allows us to get the same random sample each time\nset.seed(42) \n\n#sample() will randomly select from the Treatment vector 16 times without replacement\n# %>% is called a pipe. It simply takes the output from the command on the left\n# and sends it to the command on the right\ntibble(Subject, sample(Treatment, 16)) %>% pander()\n\n\n\n\n\n\n\n\n\nSubject\nsample(Treatment, 16)\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n1\n\n\nSubject 3\n4\n\n\nSubject 4\n1\n\n\nSubject 5\n2\n\n\nSubject 6\n4\n\n\nSubject 7\n2\n\n\nSubject 8\n2\n\n\nSubject 9\n4\n\n\nSubject 10\n3\n\n\nSubject 11\n3\n\n\nSubject 12\n1\n\n\nSubject 13\n3\n\n\nSubject 14\n4\n\n\nSubject 15\n3\n\n\nSubject 16\n2\n\n\n\n\n\nWe can see here that subject 1 should get treatment 2. Subject 2 gets treatment 4, Subject 3 gets treatment 1, and so on."
  },
  {
    "objectID": "BF1test.html#decomposition",
    "href": "BF1test.html#decomposition",
    "title": "Basic Factorial",
    "section": "Decomposition",
    "text": "Decomposition\nThis section serves as a bridge between the design and the analysis of an experiment. It is equivalent to doing the analysis by hand. The primary goal is to see how the design decisions impact the analysis; including a deeper understanding of what the numbers in an ANOVA table mean and how they are calculated.\nThe factor structure diagram of an experimental design is an effective way to organize and plan for the type of data needed for an experiment. Recall that in our lifeboat example there were four levels of training method with six replicates for each (the actual study used 16 observations per treatment). The diagram below gives the factor structure of the design, and the accompanying mathematical model.\n\n\n\n\nExample of BF1 Factor Structure\n\n\n\nA basic one-way factorial design has three analysis factors: the benchmark, treatment, and residual. The effects of these factors can be summed together to find each observed value.\n\nThe observed values on the left show that there are 24 distinct observations of performance score, represented by the 24 cells - one for each of the observed values.\nThe benchmark represents the grand mean (or overall mean). The single large cell indicates that there is only one grand mean and it is part of every observation.\nThe treatment factor involves the four levels of the treatment represented by the four vertically long cells. Each treatment may have a distinct mean (or effect).\nThe residual error represents the difference between the observed value and the predicted value. The predicted value, also called the fitted value, is the sum of the grand mean and treatment effect. Each of the cells represent a distinct value for the residual error.\n\n\nDegrees of Freedom\nWe can use our understanding of inside and outside factors to determine the degrees of freedom (df) for the benchmark, treatment, and residual errors factors. We start with 16 observations - or pieces of information. In other words, we have 16 degrees of freedom that need to be allocated to the 3 factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the lifeboat example, benchmark has one level (shown by the one cell in Figure 1) and there are no outside factors for benchmark. Therefore, the degrees of freedom for benchmark is one.\nRemember, the degrees of freedom represents the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as I estimate the benchmark effect for just one of the observations, I know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for benchmark were also known. Therefore, there is just one unique piece of information in the benchmark factor. Benchmark has just 1 degree of freedom.\nFor treatment factor, there are four levels of the factor (shown by the four vertically long cells for treatment in Figure 1). Benchmark is the only factor outside of treatment. Take the number of levels for treatment factor (4 training methods) and subtract the degrees of freedom for benchmark (1), which yields 4-1 = 3 degrees of freedom for treatment.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the treatment effects really contains. Since all observations from the same treatment will have the same treatment effect applied, we really only need to know 4 pieces of information: the effect of each treatment. But the answer is actually less than that. Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom is 3. As soon as we know 3 of the treatment effects, we can fill in the treatment effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of Figure 1). Both benchmark and treatment are outside factors for the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for benchmark and treatment (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the residual factor effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 treatments is 20 observations, or in other words, 20 degrees of freedom.\n\n\nFactor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size of the benchmark, treatment, and residual errors factors in the lifeboat training study. In other words, we can estimate the terms in the one-way ANOVA model.\n\n\n\n\n\n\nGeneral Rule for Effect Size\n\n\n\nEffect size = factor level mean - the sum of the effects of all outside factors\n\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the benchmark factor and the means for each level of training method.\nFor benchmark, get the mean of all 24 observations. The mean for all the observations is 6.5846. There is only one level for benchmark so this number is placed into each of the cells for the benchmark factor in Figure 2.\n\n\n\n\nFigure 2: Raw data and mean for benchmark factor\n\n\n\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. In Figure 3 these means are placed in the respective training method column.\n\n\n\n\nFigure 3: Raw data and means for benchmark and training factors\n\n\n\n\n\nCalculate effects\nFrom here we can calculate the effects for benchmark, training method and residual errors. We will use the general formula for calculating effect size as stated above.\nFor the benchmark, there is only one level and there are no outside factors. Therefore, the effect due to benchmark is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nThe training method factor has four levels: one for each method. To calculate the effect of a training method, take the training method mean and subtract it from the effect due to benchmark. For the “Control” method, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the grand mean. In a similar way you can find the effect for Monitor/Keyboard \\(7.8492 - 6.5846 = 1.2645\\). This means the student performance scores increased by 1.2645 on average in this training method compared to the grand mean. For Head Monitor Display/Joypad, the effect is \\(6.5789 - 6.5846 = -0.0058\\). For Head Monitor Display/Wearables the effect is \\(7.1616 - 6.5846 = 0.5770\\) (see below).\n\n\n\n\nFigure 4: Training Method Effects\n\n\n\nTo calculate the residual error effects we must remember that there are 24 levels of the residual error factor. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for benchmark and the effect for training method that particular observation received. For instance, for the observation located in the top left of our data set the observed value is 4.5614. Subtract the sum of the effects of outside factors (benchmark and training). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual error effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was 0.1875 less than the mean of the control group. In this case, this individual’s performance was lower than his/her peers who received the same type of training.\nWe can repeat the calculation for the first residual in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to benchmark and its respective training (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in Figure 5.\n\n\n\n\nFigure 5: Residual Effects\n\n\n\n\n\n\nCompleting the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA table enables us to conduct a hypothesis test of the significance of the treatment.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n     \n     \n     \n     \n  \n  \n    Treatment \n    3 \n     \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n     \n     \n     \n     \n  \n  \n    Total \n    24 \n     \n     \n     \n     \n  \n\n\n\n\n\nTo get the sum of squares (SS) for a factor, for each observation the effect for that factor needs to be squared. Then all the squared values are summed up to get the sum of squares.\nFor benchmark, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to benchmark.\n\\[\nSS_\\text{Benchmark} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor has four different effects, one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to treatment. For instance, for the control group, the effect is -1.8358. The value is then squared, and then multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Treatment} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the benchmark, treatment, and residual error factors.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n     \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n     \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n     \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWe can now calculate the mean squared error column, or mean square (MS). This mean is calculated by dividing sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation).\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. We can then see more clearly which factor is a bigger source of variability.\nThe mean square calculations are:\n\\[\nMS_\\text{Benchmark} = \\frac{SS_\\text{Benchmark}}{df_\\text{Benchmark}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Treatment} = \\frac{SS_\\text{Treatment}}{df_\\text{Treatment}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n     \n     \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87 \n     \n     \n     \n  \n\n\n\n\n\nWhen getting an F test statistic, testing for the treatment factor is the primary factor of interest so only the F test statistic for treatment is calculated for the analysis. To get the F test statistic for treatment, take the mean square (MS) due to treatment and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of this as calculating the variance in treatment effect sizes in the numerator and the variance of the distances for an observed value to its respective treatment mean in the denominator. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Treatment} = \\frac{MS_\\text{Treatment}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for the treatment factor is calculated based on the F statistic and the degrees of freedom for both Treatment Factor and Residual Error. In practice, you would not compute this by hand, but in order to complete the decomposition of variance in a manual way, we will calculate the p-value in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to treatment are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n \n  \n    Source \n    df \n    SS \n    MS \n    Fvalue \n    pvalue \n  \n \n\n  \n    Benchmark \n    1 \n    1040.57 \n    1040.57 \n     \n     \n  \n  \n    Treatment \n    3 \n    31.81 \n    10.60 \n    2.11 \n    0.131 \n  \n  \n    Residual Error \n    20 \n    100.49 \n    5.02 \n     \n     \n  \n  \n    Total \n    24 \n    1172.87"
  },
  {
    "objectID": "BF1test.html#analysis-in-r",
    "href": "BF1test.html#analysis-in-r",
    "title": "Basic Factorial",
    "section": "Analysis in R",
    "text": "Analysis in R\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots or scatterplots with the means displayed. Instructions for how to create these plots in R are found at R Instructions->Descriptive Summaries section of the book.\nYou then create the model using the aov() function. To see results of the F-test you can feed your model into a summary() function.\n\nmyaov <- aov(Y ~ X, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is some name you come up with to store the results of the aov() model.\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\nYourDataSet is the name of your data set.\n\nExample Code\n\n\n df A name you come up with for your dataset  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv( a command from the tidyverse to read in csv files  “data/toothpaste_BF2.csv” The path to the csv file containing the data  ) Functions always end with a closing parenthesis  plaque_aovA name you come up with for your model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  summary( Give important information about an object. When called on an aov object the default is to print the ANOVA table  plaque_aov  Whatever you named your ANOVA model in the previous line   )  Functions always end with a closing parenthesis  Click to view output Click to View Output. \n\n\n\n\n\n            Df Sum Sq Mean Sq F value Pr(>F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nWe then interpret the results. Toothbrush appears to be a significant factor. Since the p-value in this case is significant we may be able to look at the graphical summaries to understand which factor level effects are significant. We may also want to do some pairwise tests of the means or contrasts.\nNow that the model is created the assumption need to be checked. Code and explanation for assumption checking can be found in the R Instructions->Model Assumptions section of the book."
  },
  {
    "objectID": "BF1test.html#resources",
    "href": "BF1test.html#resources",
    "title": "Basic Factorial",
    "section": "Resources",
    "text": "Resources\n\nExamples\nLifeboat launch training\nMosquito\n\n\nLinks to outside resources\nPopulate this section yourself with links to good examples, definitions, other sections within this textbook, or anything else you think will be interesting/helpful."
  },
  {
    "objectID": "bf2.html#overview",
    "href": "bf2.html#overview",
    "title": "BF[2]",
    "section": "Overview",
    "text": "Overview\nFactorial experiments involve two or more factors that are crossed. Full factorial crossing occurs when each combination of factor levels is present in the study. (A study with just one factor is not technically a factorial design, but we will lump it in with our discussion of factorial experiments here because of the completely random treatment assignment).\nContrast a factorial design with the one-at-a-time approach. In a one-at-a-time approach, if I had two factors I wanted to study I would run two separate experiments to evaluate the effect of each factor on the response one-at-time. Factorial designs have a couple of major advantages over one-factor-at-a-time studies.\n\nThey are a more efficient use of our time and material: I can get information about both of my factors from just one observation\nPerhaps most importantly, factorial designs allow the researcher to estimate interaction effects. Or in other words, we can observe how one factor’s effect on the response variable changes for different levels of the other factor."
  },
  {
    "objectID": "contrast.html",
    "href": "contrast.html",
    "title": "Contrasts",
    "section": "",
    "text": "The ANOVA F test is considered an omnibus test, meaning it tests all the factor levels of a factor at once. If the test suggests the null hypothesis should be rejected it seems to give rise to more questions than answers. Specifically, you will want to know which factor levels are significantly different from which other factor levels.\nUsually during the design of an experiment, the researcher has specific comparisons in mind that are of particular interest. For example, they may be interested in comparing treatment effects for two dosing levels. These pre-planned comparisons usually drive the experimental design. When it comes time for analysis, an omnibus F-test test may be skipped entirely in favor of jumping directly to the planned comparisons. Or, if the F-test finds statistical significance, the researcher may follow-up with focused post-hoc tests of specific factor levels.\nWhen one factor level mean is compared to another, it is called a pairwise comparison. For example, in our toothbrush experiment we may be interested in comparing the oscillating brush to the control group (manual brush). Or we may be especially interested in comparing sonic to ultra sonic.\nLess commonly, the comparison of interest may involve averages of two or more factor level means. This is most likely to occur when the factor levels lend themselves to natural groupings that may be of particular interest to compare. For example, we may want to compare the mean of the sonic and ultrasonic groups to the mean of the oscillating group. Another example might include a comparison of the average of all the “treatment” toothbrushes vs. the control group (manual). When an average across groups is involved, this is called a complex comparison, or linear contrast.\nWe can represent the null hypotheses of these 4 example contrasts as:\n\n\nThough contrast and comparison are technically synonomous, “comparison” most often refers to simple, pairwise comparisons; and “contrast” refers to complex comparisons.\n\n\n\n\nVenn Diagram\n\n\n\n\\(\\begin{aligned} H_0: \\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\nThe above hypotheses can all be expressed as a sum, where each factor level mean is multiplied by a coefficient. When a factor level is not a part of the hypotheses, it has a coefficient of zero.\n\n\nTable 1: Expanded Hypotheses\n\n\n\n\n\n\nFour Null Hypotheses\nHypotheses expressed as a sum of mean and coefficients\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(-1*\\mu_\\text{man} + 1*\\mu_\\text{osc} + 0*\\mu_\\text{sonic} + 0*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 0*\\mu_\\text{osc} + 1*\\mu_\\text{sonic} + -1*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 1*\\mu_\\text{osc} + -\\frac{1}{2}*\\mu_\\text{sonic} + -\\frac{1}{2}*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\n\\(1*\\mu_\\text{man} + -\\frac{1}{3}*\\mu_\\text{osc} + -\\frac{1}{3}*\\mu_\\text{sonic} + -\\frac{1}{3}*\\mu_\\text{ultra}\\)\n\n\n\n\nThe contents on the left of the equals sign in the right column of Table 1 are referred to as contrasts. We will use the symbol \\(\\psi\\) to represent the contrast. A contrast is formed by multiplying each factor level mean by a coefficient. Simply put, it is a weighted sum. The above hypotheses are all examples of valid contrasts. To be considered a valid contrast, the only restriction is that the sum of the coefficients must be zero. We will often write coefficients used in a contrast as a set, in curly braces as shown in Table 2. Thinking of a contrast in terms of its set of coefficients is helpful for identifying orthogonality of contrasts. Also, when calculating/testing a contrast with software, you are required to input the set (or vector) of coefficients to define the contrast.\n\n\nTable 2: Contrast Coefficients\n\n\n\n\n\n\n\n\\(H_0\\)\nContrast (\\(\\psi\\)) Tested in \\(H_0\\)\nSet of Contrast Coefficients\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(-1*\\mu_\\text{man} + 1*\\mu_\\text{osc} + 0*\\mu_\\text{sonic} + 0*\\mu_\\text{ultra}\\)\n\\(\\{ -1, 1, 0, 0 \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 0*\\mu_\\text{osc} + 1*\\mu_\\text{sonic} + -1*\\mu_\\text{ultra}\\)\n\\(\\{ 0, 0, 1, -1 \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 1*\\mu_\\text{osc} + -\\frac{1}{2}*\\mu_\\text{sonic} + -\\frac{1}{2}*\\mu_\\text{ultra}\\)\n\\(\\{ 0, 1, -\\frac{1}{2}, -\\frac{1}{2} \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\n\\(1*\\mu_\\text{man} + -\\frac{1}{3}*\\mu_\\text{osc} + -\\frac{1}{3}*\\mu_\\text{sonic} + -\\frac{1}{3}*\\mu_\\text{ultra}\\)\n\\(\\{ 1, -\\frac{1}{3}, -\\frac{1}{3}, -\\frac{1}{3} \\}\\)\n\n\n\n\nThere are an infinite number of contrasts that could be tested. Realistically though, the contrasts that make sense to test are generally obvious and depend on your understanding/context of the experiment. Testing pairwise comparisons (i.e. simple contrasts where the coefficients are either -1, 0, or 1) is quite common; averaging across factor level means as part of the comparison is less common, but is still something you should be prepared to do. Contrasts can get quite complicated, especially for experiments with complicated designs. In this class though we will stick to relatively simple contrasts."
  },
  {
    "objectID": "contrast.html#testing-a-contrast",
    "href": "contrast.html#testing-a-contrast",
    "title": "Contrasts",
    "section": "Testing a Contrast",
    "text": "Testing a Contrast\n\nt-test for Pairwise Comparisons\nPairwise comparisons (i.e. simple contrasts) of means using a t-test is something you are probably familiar with from previous statistics classes. The procedure was most likely called something like, “independent samples t-test of two means”. We can build on that understanding to come up with a more general approach that will allow us to test any contrast.\nRecall, that a t-test for one sample has the general form:\n\\[\nt = \\frac{\\bar{y} - \\mu_0}{s_\\bar{y}}\n\\]\nWhere \\(\\bar{y}\\) is the sample mean, \\(\\mu_0\\) is the value from the null hypothesis, and \\(s_\\bar{y}\\) is the standard error of the mean. We can expand this to test whether a difference of two means is zero, in other words an independent samples t-test of two means. Recall, that in ANOVA we assume constant variance across factor levels. (This is a slightly different assumption, resulting in a slightly different calculation than the independent samples t-tests presented in Math221 and Math3251).\n\n\nStandard error of the mean is equal to standard deviation of the individual observations divided by square root of the sample size, \\(s_\\bar{y} = \\frac{s_y}{\\sqrt{n}}\\). See Math221 text for review.\nIn our toothbrush experiment, if we want to test whether the mean of manual brushes is equal to the mean of oscillating brushes we have for our null hypothesis:\n\\[\nH_0: \\mu_\\text{man} - \\mu_\\text{osc} = 0\n\\]\nWe use a t statistic:\n\\[\nt = \\frac{(\\bar{y}_\\text{man} - \\bar{y}_\\text{osc})}{\\sqrt{s^2_p*(\\frac{1}{n_1} + \\frac{1}{n_2})}}\n\\qquad(1)\\]\nThe difference in the numerator is calculated directly from the contrast (multiplying the set of coefficients by their respective factor level mean). In the denominator, the pooled variance (\\(s^2_p\\)) is identical to the mean squared error from the ANOVA summary table. The degrees of freedom for this test statistic are equivalent to the residual degrees of freedom.\n\n\n\n\n\n\nNote, by using the MSE from the ANOVA summary table we are also able to take advantage of the information about the size of the residual errors contained in the observations of sonic and ultrasonic brushes as well as the observations from manual and oscillating.\n\n\n\nFor our study on toothbrushes we have the model:\n\\[\ny_\\text{ij} = \\mu + \\alpha_i + \\epsilon_\\text{ij}\n\\qquad(2)\\]\nWhere\n\n\\(y_\\text{ij}\\) is an observation\n\\(\\mu\\) is the grand mean\n\\(\\alpha_i\\) represents the effect of factor level \\(i\\)\n\\(\\epsilon_\\text{ij}\\) is the residual error for the \\(j^\\text{th}\\) observation in factor level \\(i\\)\n\nBelow is the table of factor level means and the ANOVA summary table.\n\n\nCode\n```{r}\n#| label: tbl-brush_analysis\n#| message: false\n#| tbl-cap: \"Toothbrush Experiment Results\"\n#| tbl-subcap:\n#| - \"Factor Level Means\"\n#| - \"ANOVA Summary Table\"\n#| layout-ncol: 2\n#| code-fold: true\n\nbf2 <- read_csv(\"data/toothpaste_BF2.csv\") \n\nmeans_tbl <- bf2 |> group_by(Brush) |> summarise(mean = mean(Plaque),\n                                    `sample size` = n())\nmeans_tbl |> pander::pander()\n\n\nbrush_aov <- aov(Plaque~Brush, data = bf2)\nsummary(brush_aov) |> pander::pander()\n\n#These lines store values in variables so that I can write them in\n#the latex equation below programmatically rather than hardcoding them\nmean_man <- means_tbl[[1,2]]\nmean_osc <- means_tbl[[2,2]]\nnsize <- means_tbl[[1,3]]\nmse <- summary(brush_aov)[[1]][2,3] #This gets the number from the summary table\ntstat <- (mean_man - mean_osc)/sqrt(mse*(1/nsize + 1/nsize))\npprob <- pt(q=tstat, df=brush_aov$df.resid, lower.tail=FALSE) * 2\n```\n\n\n\nTable 3: Toothbrush Experiment Results\n\n\n\n\n(a) Factor Level Means\n\n\n\n\n\n\n\nBrush\nmean\nsample size\n\n\n\n\nManual\n23.09\n6\n\n\nOscillating\n19.98\n6\n\n\nSonic\n22.67\n6\n\n\nUltrasonic\n25.31\n6\n\n\n\n\n\n\n(b) ANOVA Summary Table\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(>F)\n\n\n\n\nBrush\n3\n86.31\n28.77\n3.822\n0.02583\n\n\nResiduals\n20\n150.6\n7.528\nNA\nNA\n\n\n\n\n\n\n\nPlugging the values from Table 3 into Equation 1 we can calculate the t statistic:\n\\[\nt = \\frac{ 3.11 }{\\sqrt{ 7.53 * (\\frac{1}{ 6 } + \\frac{1}{ 6 })}} = 1.97\n\\qquad(3)\\]\nA t statistic of 1.97 leads to a p-value of 0.063. Since the p-value is greater than our traditional alpha of 0.05, we fail to reject the null hypothesis of equality. In other words, there is insufficient evidence to claim that the manual brush and the oscillating brush have different mean values for percent area of teeth with plaque.\n\n\nt-test for Any Contrast\nThis same t-test approach can be extended so that we can test any contrast, not just pairwise comparisons. To extend the approach, recognize that the \\(1's\\) in Equation 3 appearing directly above each sample size actually represent the squared coefficient of the contrast (see Table 1). Thus, Equation 1 used to compare two factor level means, is actually just a special case of a more general formula, Equation 4, which allows us to perform a hypothesis test of any contrast. This equation continues with the general structure of a t statistic: the numerator contains a sample estimate of the difference, the denominator is the standard error of that difference.\n\\[\nt = \\frac{\\hat{\\psi}}{s_\\hat{\\psi}} = \\frac{\\hat{\\psi}}{\\sqrt{MSE * \\sum(c^2_j / n_j)}}\n\\qquad(4)\\]\nWhere,\n\n\\(\\hat{\\psi}\\) is an estimate of the contrast, obtained by multiplying each factor level mean by its respective contrast coefficient. For a simple pairwise comparison, it is just the difference in means.\n\\(MSE\\) is the mean squares of residuals obtained from the ANOVA summary table\n\\(c_j\\) is the coefficient for the \\(j^\\text{th}\\) factor level and\n\\(n_j\\) is the sample size of the \\(j^\\text{th}\\) factor level.\n\nThe degrees of freedom for \\(t\\) will be equal to the degrees of freedom for residual error in the ANOVA summary table.\nLet’s use this more general approach in Equation 4 to test the fourth hypothesis contained in Table Table 1. Our alternative hypothesis will be the contrast is not equal to zero. Though you can use directional (i.e. 1-tailed) tests of a contrast, the default is to use a two-tailed alternative hypothesis of “not equal to zero”.\nPlugging the values from Table 3 into Equation 4 we can calculate the t statistic:\nNumerator: \\[\n\\hat{\\psi} = 1 * 23.09 + -\\frac{1}{3} * 19.98 + -\\frac{1}{3} * 22.67 + -\\frac{1}{3} * 25.31 = 0.438\n\\]\nDenominator: \\[\ns_\\hat{\\psi} = \\sqrt{MSE * \\sum(c^2_j / n_j)} = \\sqrt{ 7.53 * \\left( \\frac{1^2}{6} + \\frac{-\\frac{1}{3}^2}{6} + \\frac{-\\frac{1}{3}^2}{6} + \\frac{-\\frac{1}{3}^2}{6} \\right) } = 1.294\n\\]\nt statistic: \\[\nt = \\frac{\\hat{\\psi}}{s_\\hat{\\psi}} = \\frac{0.438}{1.294} = .34\n\\qquad(5)\\]\nA test statistic \\(t_\\text{20} = .34\\) is not large enough to be significant.\n\n\n\n\n\n\nDanger\n\n\n\nActually, it does not make a lot of sense to compare the control group (manual brush) to the average of the other three brushes. For a contrast of the control mean vs. average of the treatments to make sense, the treatments would need to have more commonality. For example, if there were two treatments and both used oscillating toothbrushes: one oscillated in a clockwise fashion and the other oscillated in a counter-clockwise. In that case it would make sense to combine the treatment factor levels since they could be interpreted generally as “oscillating brush”. Then you could compare the average of the oscillating groups against the average of the control group (manual brush).\n\n\n\n\nF-test vs. t-test\nWe could have reached exactly the same conclusions by conducting an appropriate F test for the contrast instead of a t-test2. It can be shown that \\(F = t^2\\). When t is based on the degrees of freedom for residuals, and F has \\(df_\\text{numerator}\\) = 1 and \\(df_\\text{denominator} = df_\\text{residuals}\\) , the two tests given identical p-values and thus lead to the same conclusion.\n\n\nR Instructions\nThis section illustrates just one way to test custom contrasts in R. There are many packages, each with their unique syntax, for computing and testing contrasts. As you work more in the field, you may find another package better suits your needs.\nThere are sets of comparisons (a.k.a. contrasts) that are commonly done in practice. The calculation of these sets can be obtained with simpler code than what is shown here. In addition, when testing multiple contrasts simultaneously there are potentially other adjustments that should be made. Please read “Multiple Comparisons” to understand what other adjustments to consider as well as the R code for conducting these common sets of comparisons.\n\nCaution, the contrasts() function from the stats package in base R will produce the correct p-value for the test of a contrast, but without extra work will not produce the correct estimate of the contrast itself. For this reason, we illustrate estimating and testing the contrast with the emmeans package, which stands for “estimated marginal means”.\nThe first step is to create the model. Then use the emmeans() command to create a grid of factor level summary statistics, including: means, standard deviations, standard error, degrees of freedom associated with the standard error estimate, and confidence intervals around the mean. Unlike a summarize() or favstats() command, emmeans() has the output structured so that it can easily be used in the next step. Store the grid of means into a new object.\n\nmyaov <- aov(Y ~ X, data = df)\nmymeans <- emmeans(myaov, \"X\")\n\n\nmyaov is some name you come up with to store the results of the aov() model.\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\ndf is the name of your data set.\nmymeans is some name you come up with to store the results of the emmeans() command.\n\nDefine the contrasts your are interested in testing inside the contrast() function, which returns the hypothesis test results. You can also feed the result into a confint() function if you prefer confidence intervals over p-values.\n\ncontrast(brush_means,list(name_of_contrast1 = coefficient vector,\n                       name_of_contrast2 = another coefficient vector))) \n\nname_of_contrast are descriptive names you should give to the contrast to help you remember what it represents. The coefficient vector is how you define the contrast.\nWe will repeat the contrasts we did by hand in the sections above, but this time using R.\nExample Code Using Toothbrush Experiment:\n\n\n df The name you want for your dataset  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv(“../data/toothpaste_BF2.csv”) A tidyverse command to read the data in from the specified path  plaque_aov Name you want for your ANOVA model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  brush_means The name you want for the output of the emmeans command  <- The assignment operator. The result to the right of it gets stored in an object specified on the left   emmeans(  Function to calculate stats about marginal means  plaque_aov, aov model created in previous step  “Brush” Factor for whose levels you want to calculate means  ) Functions always end with a closing parenthesis  contrast_results Name you want to store contrast results in  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  contrast( Function to define and test contrasts  brush_means, Grid of stats about marginal means you named in the previous step list( create a list object, which allows you to pass multiple contrast coefficient vectors  man_v_osc = A descriptive name to help you remember what the contrast represents  c(1,-1,0,0) Vector of coefficients used to define the contrast  , Seperator to allow additional inputs to the list     man_v_others = A descriptive name to help you remember what the contrast represents  c(1,-(1/3),-(1/3),-(1/3)) Vector of coefficients used to define the contrast  ), A list is closed with a parenthesis  adjust = Specify what type of adjustment (if any) to make for multiple testing. Default is “none” if this argument is not included.  “none” Read help at ?summary.emmGrid for other acceptable values  ) Functions always end with a closing parenthesis  contrast_results View the test results stored in this object in the previous step  confint( Function to create confidence intervals around contrasts  contrast_results Name of object where you stored contrasts  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n contrast     estimate   SE df t.ratio p.value\n man_v_osc       3.117 1.58 20   1.967  0.0632\n man_v_others    0.438 1.29 20   0.339  0.7382\n\n\n\n\n contrast     estimate   SE df lower.CL upper.CL\n man_v_osc       3.117 1.58 20   -0.188     6.42\n man_v_others    0.438 1.29 20   -2.260     3.14\n\nConfidence level used: 0.95"
  },
  {
    "objectID": "contrast.html#othogonal-contrast",
    "href": "contrast.html#othogonal-contrast",
    "title": "Contrasts",
    "section": "Othogonal Contrast",
    "text": "Othogonal Contrast\nStay tuned…Under Construction"
  },
  {
    "objectID": "DescribeData.html",
    "href": "DescribeData.html",
    "title": "Describing Data",
    "section": "",
    "text": "In the following explanations\n\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable. It would represent a treatment factor.\nYourDataSet is the name of your data set.\n\nYou can take a tidyverse approach or a mosaic package approach to calculating numerical summaries for each treatment.\n\nmosaic package:tidyverse approach\n\n\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  Month min   Q1 median    Q3 max     mean       sd  n missing\n1     5  56 60.0     66 69.00  81 65.54839 6.854870 31       0\n2     6  65 76.0     78 82.75  93 79.10000 6.598589 30       0\n3     7  73 81.5     84 86.00  92 83.90323 4.315513 31       0\n4     8  72 79.0     82 88.50  97 83.96774 6.585256 31       0\n5     9  63 71.0     76 81.00  93 76.90000 8.355671 30       0\n\n\n\nWhen calculating treatment means for combinations of 2 or more factors you can use + or | to separate the factors. | (read as ‘vertical bar’ or ‘pipe’) has the advantage that in addition to calculating means for every factor level combination, favstats will also output the marginal means for each level of the last factor listed.\nNOTE: unlike it’s use in the aov() command, using the * within favstats does not yield expected results and should NOT be used.\n\nlibrary(mosaic)\nfavstats(Y ~ X + Z, data = YourDataSet) \n#OR\nfavstats(Y ~ X | Z, data = YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  + This allows us to create additional subgroups within ‘am’ for each level of ‘cyl’.  cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  am.cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1    0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2    1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3    0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4    1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5    0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6    1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n\n\n\nNotice that the first column in the output contains the factor level combinations of am and cyl. So, ‘0.4’ is interpreted as level 0 for am and level 4 for cyl. Or in other words, the summary statistics on that row are for automatic tranmission, 4 cylinder engine vehicles. The column label of ‘am.cyl’ indicates which factor is represented on which side of the period. The next example uses the same way of labeling the factor level combinations, but the column label is not as intuitive or helpful.\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  | Referred to as a vertical bar or pipe, this symbol further defines subgroups of the variable on its left, using the values of the variable on its right side   cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to View Output  Click to View Output. \n\n\n\n\n\n  cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1 0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2 1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3 0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4 1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5 0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6 1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n7   4 21.4 22.800  26.00 30.400 33.9 26.66364 4.5098277 11       0\n8   6 17.8 18.650  19.70 21.000 21.4 19.74286 1.4535670  7       0\n9   8 10.4 14.400  15.20 16.250 19.2 15.10000 2.5600481 14       0\n\n\n\n\n\n\nCalculating treatment means for one factor:\n\nlibrary(tidyverse)\nYourDataSet %>%\n  Group_by(X) %>%\n  Summarise(MeanY = mean(Y), sdY = sd(Y), sampleSize = n()) \n\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  airquality airquality is a dataset in R.   %>%  The pipe operator that will send the airquality dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the airquality dataset into “little” datasets, one dataset for each value in the “Month” column.  Month “Month” is a column from the airquality dataset that can be treated as qualitative.  ) Functions must always end with a closing parenthesis.   %>%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  aveTemp =  “AveTemp” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  Temp Temp is a quantitative variable (numeric vector) from the airquality dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\nMonth\naveTemp\n\n\n\n\n5\n65.55\n\n\n6\n79.1\n\n\n7\n83.9\n\n\n8\n83.97\n\n\n9\n76.9\n\n\n\n\n\nNote that R calculated the mean Temp for each month in Month from the airquality dataset.\nMay (5), June (6), July (7), August (8), and September (9), respectively.\nFurther, note that to get the “nicely formatted” table, you would have to use\nlibrary(pander)\nairquality %>% \n  group_by(Month) %>%\n  summarise(aveTemp = mean(Temp)) %>%\n  pander()\n\nTo calculate treatment means for each combination of factor levels of 2 or more factors, simply add the additional variable to the group_by() statement.\nExample code:\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  mpg mtcars is a dataset in preloaded in R.   %>%  The pipe operator that will send the mtcars dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the mtcars dataset into “little” datasets, one dataset for each combination of values in the ‘am’ and ‘cyl’ variables  am, cyl ‘am’ and ‘cyl’ are both columns in mtcars. By listing them both here we are going to get output for each combination of ‘am’ and ‘cyl’ that exists in the dataset  ) Functions must always end with a closing parenthesis.   %>%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  mean_mpg =  “mean_mpg” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  mpg mpg is a quantitative variable (numeric vector) from the mtcars dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n`summarise()` has grouped output by 'am'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\n\n\n\n\nam\ncyl\nmean_mpg\n\n\n\n\n0\n4\n22.9\n\n\n0\n6\n19.12\n\n\n0\n8\n15.05\n\n\n1\n4\n28.07\n\n\n1\n6\n20.57\n\n\n1\n8\n15.4"
  },
  {
    "objectID": "DescribeData.html#graphical-summaries",
    "href": "DescribeData.html#graphical-summaries",
    "title": "Describing Data",
    "section": "Graphical Summaries",
    "text": "Graphical Summaries\n\nBoxplots\n\n\n\n\n\n\n\n\nOverviewR InstructionsExplanation\n\n\n\nGraphical depiction of the five-number summary. Great for comparing the distributions of data across several groups or categories. Provides a quick visual understanding of the location of the median as well as the range of the data. Can be useful in showing outliers. Sample size should be larger than at least five, or computing the five-number summary is not very meaningful.\n\n\n\n\n\n\nBase R ggplot2 plotly\n\n\n\nTo make a boxplot in R use the function:\nboxplot(object)\nTo make side-by-side boxplots:\nboxplot(object ~ group, data=NameOfYourData, ...)\n\nobject must be quantitative data. R refers to this as a “numeric vector.”\ngroup must be qualitative data. R refers to this as either a “character vector” or a “factor.” However, a “numeric vector” can also act as a qualitative variable.\nNameOfYourData is the name of the dataset containing object and group.\n... implies there are many other options that can be given to the boxplot() function. Type ?boxplot in your R Console for more details.\n\nExample Code\nBasic Single Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  $ The $ allows us to access any variable from the airquality dataset.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.  )\nClosing parenthesis for the function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nMore Useful… Basic Side-by-Side Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Names under each Box\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  names=c(“May”,“June”,“July”,“Aug”,“Sep”) names= is used to tell R what labels to place on the x-axis below each boxplot.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Color and Labels\n\n\n boxplot(Temp ~ Month, data=airquality This code was explained in the previous example code.  ,  The comma is used to separate each additional command to a function.  xlab=“Month of the Year” xlab= stands for “x label.” Use it to specify the text to print on the plot under the x-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  ylab=“Temperature” ylab= stands for “y label.” Use it to specify the text to print on the plot next to the y-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  main=“La Guardia Airport Daily Temperatures” main= stands for the “main label” of the plot, which is placed at the top center of the plot. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  col=“wheat” col= stands for the “color” of the plot. The color name “wheat” is an available color in R. Type colors() in the R Console to see more options. The color name must always be placed in quotes.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a boxplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_boxplot()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_boxplot() causes the ggplot to become a boxplot.\n\n\nExample Code\nBasic Single Boxplot\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the y-axis should become.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot() The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n Side-by-side Boxplot and Color Change\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box in the boxplot.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Labels \n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_histogram()” function causes the ggplot to become a histogram. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.   +  The addition symbol + is used to add further elements to the ggplot.     labs( The “labs” function is used to add labels to the plot, like a main title, x-label and y-label.  title=“La Guardia Airport Daily Mean Temperature”,  The “title=” command allows you to control the main title at the top of the graphic.  x=“Month of the Year”,  The “x=” command allows you to control the x-label of the graphic.  y=“Daily Mean Temperature” The “y=” command allows you to control the y-label of the graphic.  )\nClosing parenthesis for the labs function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nGallery\nSee what past students have done…\nClick to view.\n\nHover to see code.\n \n ggplot(data = mtcars, aes(x = as.factor(cyl), y = mpg, fill=as.factor(cyl))) +  geom_boxplot()  +  stat_summary(fun.y = mean, geom = \"errorbar\", aes(ymax = ..y.., ymin = ..y..),     width = .75, linetype = \"dashed\", color=\"firebrick\") +  theme_light() +  theme(panel.grid.major=element_blank()) +  scale_fill_brewer(palette=\"Dark2\") +  geom_jitter(width=0.1, height=0) +  labs(title = \"Miles Per Gallon Based on Cylinders\",     x=\"Number of Cylinders\",     fill=\"Cylinders\",     y=\"Miles Per Gallon\")   \n \n ggplot(data = ToothGrowth, aes(x = as.factor(dose), y = len, fill=as.factor(dose))) +  geom_boxplot( )  +  facet_wrap(~supp) +  theme_bw() +  scale_fill_manual(values=c(\"#999999\", \"#E69F00\", \"#56B4E9\")) +  geom_jitter(width=0.1, height=0) +  labs(title = \"Tooth Length Based on Doses     According to Supplement Type\",     fill=\"Doses\",     x=\"Dosage Amount(mg)\",     y=\"Tooth Length\" )   \n\n\n\n\n\nTo make a histogram in plotly first load\nlibrary(plotly)\nThen, use the function:\nplot_ly(dataName, y=~columnNameY, x=~columnNameX, type=\"box\")\n\ndataName is the name of a data set\ncolumnNameY must be the name of a column of quantitative data. R refers to this as a “numeric vector.” This will become the y-axis of the plot.\ncolumnNameX must be the name of a column of qualitative data. This will provide the “groups” forming each individual box in the boxplot.\ntype=\"box\" tells the plot_ly(…) function to create a boxplot.\n\nVisit plotly.com/r/box-plots for more details.\n\nExample Code\nHover your mouse over the example codes to learn more. Click on them to see what they create.\nBasic Boxplot\n\n\n plot_ly An R function “plot_ly” from library(plotly) used to create any plotly plot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality,  “airquality” is a dataset. Type “View(airquality)” in R to see it.  y= The y= allows us to declare which column of the data set will become the y-axis of the boxplot. In other words, the quantitative data we are interested in studying for each group.  ~Temp,   “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset. The ~ is required before column names inside all plot_ly(…) commands.  x= The x= allows us to declare which column of the data set will become the x-axis of the boxplot. In other words, the “groups” forming each separate box in the boxplot.  ~as.factor(Month),   since “Month” is a quantitative variable (numeric vector) from the “airquality” dataset we have to change it to a “factor” which forces R to treat it as a qualitative (groups) variable. The ~ is required before column names inside all plot_ly(…) commands.  type=“box” This option tells the plot_ly(…) function what “type” of graph to make. In this case, a boxplot.  )\nClosing parenthesis for the plot_ly function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nChange Color\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”,  This code was explained in the first example code.  fillcolor=“skyblue”,  this changes the fill color of the boxes in the boxplot to the color specified, in this case “skyblue.”  line=list(color=“darkgray”, width=3),  this “list(…)” of options that will be specified will effect the edges of the boxes in the boxplot. We are changing their color to “darkgray” and their width to 3 pixels wide.  marker=list( this “list(…)” of options that will be specified will effect the outlying dots shown in the boxplots beyond the “fences” of each box.  color = “orange”,  this will change the color of the dots to orange.  line = list(,  this opens a list of options to specify for the “lines” around the “markers.”  color = “red”,  this will change the color of the lines around the outlier dots to red.  width = 1 this will change the width of the lines around the outlier dots to 1 pixel.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nAdd Titles\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”, fillcolor=“skyblue”, line=list(color=“darkgray”, width=3), marker = list(color=“orange”, line = list(color=“red”, width=1)))  This code was explained in the above example code.  %>% the pipe operator sends the completed plot_ly(…) code into the layout function.  layout( The layout(…) function is used for specifying details about the axes and their labels.  title=“La Guardia Airport Daily Mean Temperatures” This declares a main title for the top of the graph.  xaxis=list( This declares a list of options to be specified for the xaxis. The same can be done for the yaxis(…).  title=“Month of the Year” This declares a title underneath the x-axis.  ),  Functions always end with a closing parenthesis.  yaxis=list( This declares a list of options to be specified for the y-axis.  title=“Temperature in Degrees F” This declares a title beside the y-axis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding how a boxplot is created is the best way to understand what the boxplot shows.\n\nHow Boxplots are Made\n\nThe five-number summary is computed.\nA box is drawn with one edge located at the first quartile and the opposite edge located at the third quartile.\nThis box is then divided into two boxes by placing another line inside the box at the location of the median.\nThe maximum value and minimum value are marked on the plot.\nWhiskers are drawn from the first quartile out towards the minimum and from the third quartile out towards the maximum.\nIf the minimum or maximum is too far away, then the whisker is ended early.\nAny points beyond the line ending the whisker are marked on the plot as dots. This helps identify possible outliers in the data.\n\n\n\n\n\n\n\n\n\nScatterplot, with Means\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nScatterplots of a catgorical variable on the x axis and quantitative variable on the y axis are sometimes called strip charts, or side-by-side strip charts. When sample sizes are not too big and there are not too many repeated value this type of chart is an excellent way to see the variability in the data without the abstraction of a boxplot. By plotting individual observations you also can see the size of the sample for each factor level. Including factor level means on the plot adds additional insight. The mean of each factor level is often connected with a line for visual impact.\n\n\n\n\nmosaic ggplot2 plotly\n\n\n\nTo make a scatterplot use the function:\nxyplot(y~x, data = mydata)\n\ny is the quantitative response variable, i.e., “numeric vector.”\nx is the independent, explanatory variable\nmy is the name of the dataset containing y and x.\n\nThis will return a scatterplot regardless of how your x variable is stored in R (numeric, character, factor). This function is flexible and with minimal effort can include averages or make an interaction plot. xyplot() is a part of the lattice package, which is loaded when the mosaic package is loaded.\nNote: plot() from base R will also give a scatterplot, but only if the x variable is quantitative. If x is a character or factor variable the default is to return a boxplot plot.\nExample Code\nBy reading the documentation for the dataset (visible when ?ToothGrowth is run in the console) we can see that our “x” variable, “dose”, is a numeric variable in R. Because of this the x-axis maintains the relative distance of doses on the x-axis.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nIf you start with a numeric x variable, you may or may not want to convert it to a factor variable. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed. Compare the output of the previous example code with this example code. This example code converts our x variable of “dose” to a factor variable.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nTo include the means on the plot and connect them with a line use this code\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  , \nThe “,” is required to start specifying additional commands for the function.  type =\nThe type argument allows you to add different types of lines to the plot. Run ?panel.xyplot() to read more about values for this argument  c( Combines the following values into one vector. This allows me to pass multiple values as one input to “type =”. Useful for if I want to plot something in addition to the default of plotting points.  ‘p’\nThis requests the points to be plotted. It is the default value. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  , \nThe “,” is required to start specifying additional commands for the function.  ‘a’ This requests the average for each factor level to be connected with a line. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a scatterplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_point()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_point() causes the ggplot to become a scatterplot; or in other words to draw points to represent data.\n\n\nExample Code\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n If you start with a numeric x variable, you may or may not want to convert it to a factor variable. You do this by using ‘factor(x)’ instead of just ‘x’ as shown below. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed.\nggplot(ToothGrowth, aes(x = factor(dose), y = len)) +   geom_point(color = \"blue\")\nAdding averages to the plot and connecting them with a line requires a little more effort and is demonstrated in the code below. I also add some more descriptive labels to the chart.\nNote the use of stat_summary to indicate I want to add a layer that plots a numerical summary, not the original data. Some geoms have stat summaries built in to them (like geom_bar or geom_boxplot), but in our case we have to define the summary.\nIn the stat_summary I provide additional arguments to the aesthetics helper function. Defining the aesthetics in ggplot() is like a global definition, all additional layers inherit those aesthetic mappings. Defining them in a geom_* or a stats_* allows you to add to or override what was defined in ggplot() for that layer only. The group aesthetic is required in order to use a line geometry. In this case, group could just as easily have been defined in ggplot(aes()).\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_point( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.   +  The addition symbol + is used to add further elements to the ggplot.    stat_summary( This function will calculate a statistical summary to be plotted on the chart  fun = mean, fun is short for function. The summary function I want to apply to my y variable is “mean”.  geom = “line”, The “geom=” argument is used to tell what kind of geometry should be drawn to represent the means. Here we are asking for the means to be connected with a line.  aes( The aes or “aesthetics” function allows you to tell ggplot what variables should be mapped to what visual aspects of the chart; including what the x-axis or y-axis should become. Including it her means the aesthetic will only be applied to this layer.  group = 1 indicates which variable should be grouped by when drawing multiple lines (one line for each factor level). We write the number 1 to indicate there is just 1 group; we are not further splitting the data.  )\nClosing parenthesis for the geom_boxplot function.  )\nClosing parenthesis for the geom_boxplot function.   +  The addition symbol + is used to add further elements to the ggplot.    labs( Function to edit labels of the plot  x = “Vitamin C mg/day”, Edit the x-axis label  y = “Length”, Edit the y-axis label  title = “Tooth Growth in Guinea Pigs” Edit the chart title  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nUnder construction.\n\n\n\n\n\n\n\n\nInteraction Plot\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nUnder construction\n\n\n\n\nmosaic ggplot2 plotly\n\nUnder construction"
  },
  {
    "objectID": "diagnostics.html",
    "href": "diagnostics.html",
    "title": "Model Diagnostics",
    "section": "",
    "text": "A key assumption for ANOVA tests is that the error, or residual term, has a constant variance across all factor levels. This is sometimes call homogeneity of variance, or homoscedasticity.\nWe explain three ways to check the assumption: rule of thumb when comparing standard deviations for each factor level, a visual assessment of the residual vs. fitted plot, and Levene’s test. These methods may not always agree. You should be aware of the underlying data. Understanding why this assumption is important and how it will affect results when violated will help you decide how to proceed after checking these diagnostics. It is also worth noting that the ANOVA F-test is robust in the face of mild to moderate violation of this assumption.\nWe will use the pre-loaded dataset ToothGrowth. To learn more about the dataset, run ?ToothGrowth in the console. len will be our response variable, supp is an independent factor, and dose is the other independent factor. We will analyze this a two-way, basic factorial design. Because dose is stored as a numeric variable, we will convert it to a categorical variable and rename it dose_f before including it in the model. Don’t forget to load the tidyverse in order to use mutate().\n\n\n tg The name you want for your modified dataset  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  ToothGrowth A preloaded dataset in R  |> The result on the left is piped into the first argument of the function on the right  mutate( A tidyverse function to compute a new column for a dataset  dose_f = The name you want to give to the new column  factor( A function to convert a variable from numeric to quantitative  dose A numeric variable in ToothGrowth  )) Functions always end with a closing parenthesis  aov2th A name you come up with for your model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  len The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  dose_f Column in the tg dataset where doese is stored as a factor  * Crosses two factors. Both simple factors and the interaction factor are included in the model   supp variable with 2 levels of delivery method: orange juice or asorbic acid (vc)  , Seperates multiple input arguments to a function.  data = tg Tell the model that the variable names come from the tg dataset  ) Functions always end with a closing parenthesis \n\n\n\n\n\n\n\n\n\n\nA quick rule of thumb to check this assumption is to compare standard deviations across factor levels. If the largest standard deviation is no more than double the smallest standard deviation, then the standard deviations (and the variances) are close enough to be considered equal. Check the R Instructions>Describing Data>Numerical Summaries section of the textbook on how to calculate standard deviations for each factor level.\nIn cases with more than 1 factor, you can compare the standard deviation of each factor level combination (i.e. the interaction factor). Sometimes though, looking at the interaction results in a very small sample size at each level or you may be concerned about a particular factor level of an experimental factor. In that case you may want to apply this rule of thumb to each factor individually. When faced with a situation where the rule of thumb is met for some factors but not for others use your best judgement. An understanding of how a violation may affect your results is critical. You can see that this approach can be tricky to implement, especially as you go beyond studies with just two factors.\n\n\n\nAnother informal approach to checking the constant variance assumption is looking at a residual vs. fitted plot. Similar to the rule of thumb, in situations with more than 1 factor, you can either create a plot that shows all factor level combinations OR look at multiple plots, one for each experimental factor. In order to view this plot, you must first create the ANOVA model. Once the model is created, there are a couple of ways to get a residual vs. fitted plot.\nConstruct the plot manually from vectors within the aov object\nThe plot can be constructed using the vector of residuals and vector of fitted values contained in the aov object.\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\nplot(myaov$fittedvalues, myaov$residuals)\n\nNote: If you want to know all the named items in an R object, you can run names(object). In this case we have an aov object called myaov. To see what it contains we can run names(myaov) in the console.\nExample code:\n\n\n\n plot( Base R function to create a scatterplot  aov2th$  Look in the aov2th object for the item named on the right of the $  fitted.values  This vector, stored in the aov object, contains the fitted, or predicted, values.  , Seperates multiple input arguments to a function  aov2th$ Look in the aov2th object for the item names on the righ tof the $  residuals Vector in the aov object that contains model residuals  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\nNote the resulting plot show 6 vertical groupings, one for each factor level combination. (3 does levels x 2 levels of supp = 6 factor level combinations) ::: {.cell} ::: {.cell-output-display}  ::: :::\n\n\nConstruct the plot with a shortcut\nWhen the function plot() is called on an aov object, 4 diagnostic plots are produced. Instead of viewing all four, chose which ones to see with the which= argument. The first of the four plots is the residual vs. fitted plot.\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\nplot(myaov, which = 1)\n\nExample code:\n\n\n\n plot( Base R function, when fed an aov object it produces 4 diagnostic plots  aov2th,  The aov object for our model  which = Which of the four diagnostic plots do we want  1 The first of the 4 plots is the residual vs. fitted plot  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\nIgnore the red line on the plot. It does not measure variance and so can be distracting. ::: {.cell} ::: {.cell-output-display}  ::: :::\n\n\n\n\n\nLevene’s test is a formal hypothesis test to determine if the variances are equal. In essence, this is an ANOVA F-test comparing sample variances across factor levels (as opposed to comparing sample means). A large p-value for the test indicates there is insufficient evidence to conclude one of the variances is different; and therefore the assumption of constant variance is met.\nThis test comes in handy when there are multiple factors in a study and it is burdensome to informally evaluate all their factor level combinations.\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\ncar::leveneTest(myaov)\n\nExample code:\n\n\n\n car Levene’s test comes from the car package.   :: Allows you to reference functions from the package named on the left without having to load the entire package.  leveneTest( function to run Levene’s test  aov2th name of the aov object to run the test on  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  5  1.7086 0.1484\n      54"
  },
  {
    "objectID": "diagnostics.html#normal-distribution",
    "href": "diagnostics.html#normal-distribution",
    "title": "Model Diagnostics",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nAnother key assumption for ANOVA tests is that the error, or residual, term follows a normal distribution. We use the Q-Q plot to check this assumption. There are two ways to create the Q-Q plot.\nWe will continue to use the aov2th model that was created at the beginning of the Constant Variance section.\nConstruct the Q-Q plot with a shortcut\nWhen the function plot() is called on an aov object, 4 diagnostic plots are produced. Instead of viewing all four, chose which ones to see with the which= argument. The second of the four plots is a normal Q-Q plot.\nExample code:\n\n\n\n plot( Base R function, when fed an aov object it produces 4 diagnostic plots  aov2th,  The aov object for our model  which = Which of the four diagnostic plots do we want  2 The second of the 4 plots is the normal Q-Q plot  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\n\n\n\n\n\nThe advantage of this method is that you can easily get the residual vs. fitted plot and the normal Q-Q plot with one command by providing the which = argument a vector containing the values 1 and 2. (The : is shorthand to create a vector that starts at the value of the left of the : and increments by 1 until reaching the value on the right side of the :.)\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\nplot(myaov, which = 1:2)\n\nThe disadvantage of this method is that it can be difficult to determine if the points follow the line closely enough. To help with this decision, you may prefer to use the Q-Q plot from the car package.\nConstruct the Q-Q plot from the car package\nThe Q-Q plot from the car package provides boundary lines. When points are out of the boundaries that is evidence that the normal residual assumption is violated.\nYou can customize the way the acceptable region for points is designated. The default is shading a region. Below is code to draw dashed-line boundary.\nExample code:\n\n\n\n car qqPlot comes from the car package.   :: Allows you to reference functions from the package named on the left without having to load the entire package.  qqPlot( function to a Q-Q plot from the car package  aov2th, name of the aov object  envelope = Argument to control the formatting for the acceptable region for points  list( There are potentially many arguments to affect the envelope, so they are provided as a list.  style = “filled” shading, boundary “lines”, or none  “lines” designate the acceptable region with lines  )) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\n\n\n\n[1] 32 49"
  },
  {
    "objectID": "diagnostics.html#independent-errors",
    "href": "diagnostics.html#independent-errors",
    "title": "Model Diagnostics",
    "section": "Independent Errors",
    "text": "Independent Errors\nAn order plot can serve as a partial check of the assumption that the residuals are independent. If there are patterns/trends in the plot that may be grounds to say the assumption is violated.\nThe plot assumes that the dataset is sorted in the same order the data was recorded. If the data has been re-sorted or is from an observational study (i.e. the chronology of collection is unknown or irrelevant) the order plot does not make sense as a check of independence.\nExample code:\n\n\n\n plot( A function to plot the data  aov2th Name you gave your model  $ Access a named object within an object  residuals residuals of the model  ) Functions always end with a closing parenthesis  Toggle output Toggle Output."
  },
  {
    "objectID": "effects_model.html",
    "href": "effects_model.html",
    "title": "Effects Model",
    "section": "",
    "text": "Consider an experiment conducted to test 4 different types of toothbrushes: manual, oscillating, sonic and ultrasonic. The response variable is percent of area on teeth that has plaque. Twenty-four individuals participate in the experiment, yielding 6 observations per treatment. Up to this point we have primarily been interested in calculating means in order to compare toothbrushes. If I reported that the mean percent of teeth surface area with plaque was 23.09 for a manual brush, you would not know how that value compares to the other types of brushes.\nA graph or table reporting the other means would be necessary to provide context. Figure 1 depicts the data points and mean for each factor level.\nIn an earlier, introductory statistics class you most likely learned how to test whether these means are equal using analysis of variance (ANOVA). This approach of testing means is valid and works when you only have 1 factor. However, it is limited in its ability to include more factors or more complicated designs.\nThere is another metric we use to compare factor levels: the effect size. Reporting the effect of a factor level has the benefit of providing some context on how that factor level is influencing the response variable relative to other levels of the same factor. Using effect sizes (as opposed to factor level means) allows us to model and test much more complicated scenarios than a simple one factor experiment.1"
  },
  {
    "objectID": "effects_model.html#assembly-line-metaphor",
    "href": "effects_model.html#assembly-line-metaphor",
    "title": "Effects Model",
    "section": "Assembly Line Metaphor",
    "text": "Assembly Line Metaphor\nYou can imagine that each data point in your data set is created by going down an assembly line, much like you would find in a factory that makes cars or appliances. All points start with the grand mean value. As it progresses through the assembly line the data point is altered to reflect the effect of the factor levels it belongs to.\n\n\n\n\n\n\nIn the toothbrush and toothpaste experiment all the points start the assembly line at the same value: the grand mean of the data set. The first station on the line receives the data point and adds or subtracts to it based on the type of brush it is. For example, the value would be added upon if the brush type was “manual”. The next station alters the value depending on what the instructions for that data point say: off-brand or name brand. After going through each station (one station for each factor) in the assembly line the data point arrives at the last station.\nThe last station is worked by a person who makes random adjustments! Some adjustments will be big, and some will be small; some will be positive, and some will be negative. (In a typical factory this person would be fired. But we would rather have randomness than unknown, systematic adjustments , i.e. bias). Though the adjustments at this last station for residual error are random, they do follow a pattern. Namely, the mean of the adjustments is zero and they follow a normal distribution."
  },
  {
    "objectID": "examples/mosquito.html",
    "href": "examples/mosquito.html",
    "title": "Mosquitos",
    "section": "",
    "text": "Code\nlibrary(mosaic)\nlibrary(DT)\nlibrary(pander)\nlibrary(car)\nlibrary(tidyverse)\n\n## Data from original article:\nmosquito <- read_csv(\"../data/mosquito_patch.csv\")"
  },
  {
    "objectID": "examples/mosquito.html#background",
    "href": "examples/mosquito.html#background",
    "title": "Mosquitos",
    "section": "Background",
    "text": "Background\nFive pre-treated patches were compared to to see which material did the best in reducing mosquito human contact for the Armed Forces in India. The five treatments included Odomos(1), Deltamethrin (2), Cyfluthrin(3), D+O(4), C+O(5) Each of the treatments included 30 replicates per treatment\nSource: A. Bhatnagar and V.K. Mehta (2007). “Efficacy of Deltamethrin and Cyfluthrin Impregnated Cloth Over Uniform Against Mosquito Bites,” Medical Journal Armed Forces India, Vol. 63, pp. 120-122"
  },
  {
    "objectID": "examples/mosquito.html#analysis",
    "href": "examples/mosquito.html#analysis",
    "title": "Mosquitos",
    "section": "Analysis",
    "text": "Analysis\nApplying a one-way ANOVA to this study, we have the following model:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\nWhere \\(y_{ij}\\) is the \\(j^{th}\\) observation from treatment \\(i\\)\n\\(\\mu\\) is the grand mean of the dataset.\n\\(\\alpha_i\\) is the effect of the treatment as described in the background.\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. Since there are 30 subjects for each treatment, \\(j\\) ranges from 1 to 30.\nApplying a one-way ANOVA to this study, we have the null hypothesis that the effect of human mosquito contact, represented by α, is equal for each of the factors. This is formally written as follows. \\[ H_0:\\alpha_\\text{Odomos} = \\alpha_\\text{Deltamethrin} = \\alpha_\\text{Cyfluthrin} = \\alpha_\\text{D+O} = \\alpha_\\text{C+O} = 0 \\] The alternative hypothesis states that at least one of the effects due to material is different than zero \\[ H_a: \\text{at least one } \\alpha \\text{ is different than 0} \\] Using these hypotheses will allow for us to address the question whether any of the materials are better at minimizing mosquito-human contact.\n\nHypothesis test\nWe will use a level of significance of α = 0.05 for the analysis.\nFor the analysis, we perform the following one-way ANOVA\n\n\nCode\nmosquito <- mosquito %>% \n   mutate(\n         Treatment = case_when(\n           trt.mosq %in% 1  ~ \"Odomos\",\n           trt.mosq %in% 2  ~ \"Deltamethrin\",\n           trt.mosq %in% 3  ~ \"Cyfluthrin\",\n           trt.mosq %in% 4  ~ \"D+O\",\n           trt.mosq %in% 5  ~ \"C+O\"\n          )\n        )\n\nmosquito.aov <- aov(y.mosq ~ Treatment, data=mosquito)\nsummary(mosquito.aov) %>% pander()\n\n\n\nAnalysis of Variance Model\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(>F)\n\n\n\n\nTreatment\n4\n184.6\n46.16\n4.48\n0.001924\n\n\nResiduals\n145\n1494\n10.3\nNA\nNA\n\n\n\n\n\nThe p-value for this test is significant (p = 0.001924). Based on this result, the null hypothesis is rejected and we have sufficient evidence that at least one of the effects due to material is different for human mosquito contact.\nThe requirements of equal variances for ANOVA is met. This is shown by the residual versus fitted plot, which shows roughly a constant variance within each vertical group of dots. The QQ-plot of residuals on the right shows some non-normality as evidenced by some of the points outside of the dashed line boundaries. However, it is not severe and we will move forward with the analysis.\n\n\nCode\npar(mfrow=c(1,2))\nplot(mosquito.aov, which=1, pch=16)\nqqPlot(mosquito.aov, id=FALSE)\n\n\n\n\n\nThe following plot shows which types of material minimize the human mosquito contact.\n\n\nCode\nboxplot(y.mosq ~ as.factor(Treatment), data=mosquito, main=\"Human Mosquito Contact Based on Type of Material\", xlab =\"Treatment\", ylab = \"Amount of Mosquito Human Contact\")\n\n\n\n\n\nThe averages are illustrated with the blue line in the plot above and the table below shows the means, standard deviations, and sample sizes for each of the five different materials.\n\n\nCode\nfavstats(y.mosq ~ Treatment, data=mosquito) %>% \n  select(Treatment,mean,sd,n) %>% \n  arrange(mean) %>% \n  pander()\n\n\n\n\n\n\n\n\n\n\n\nTreatment\nmean\nsd\nn\n\n\n\n\nC+O\n5.367\n3.068\n30\n\n\nD+O\n6.333\n3.121\n30\n\n\nOdomos\n7.901\n3.366\n30\n\n\nCyfluthrin\n8.033\n3.01\n30\n\n\nDeltamethrin\n8.133\n3.46\n30\n\n\n\n\n\n\n\nPairwise comparisons\nWe now that smallest mean (C+O) must be different than the largest mean (Deltamethrin) because the F-test was significant above. In order to better understand which treatments perform better than which other treatments we will look at all pairwise comparisons and apply Tukey’s correction to the family error rate.\n\n\nCode\n#This code would work, but...\n# TukeyHSD(mosquito.aov, \"Treatment\")\n\n#I want to do this fancy stuff below to sort the output\nTukeyHSD(mosquito.aov, \"Treatment\")$Treatment %>% \n  as_tibble(rownames = \"id\") %>% \n  arrange(`p adj`) %>% #Have to put the column name in back ticks since it has a space\n  pander() \n\n\n\n\n\n\n\n\n\n\n\n\nid\ndiff\nlwr\nupr\np adj\n\n\n\n\nDeltamethrin-C+O\n2.766\n0.4764\n5.056\n0.009359\n\n\nCyfluthrin-C+O\n2.666\n0.3761\n4.955\n0.01367\n\n\nOdomos-C+O\n2.534\n0.2441\n4.823\n0.02204\n\n\nDeltamethrin-D+O\n1.8\n-0.4899\n4.089\n0.1965\n\n\nD+O-Cyfluthrin\n-1.699\n-3.989\n0.5902\n0.2477\n\n\nOdomos-D+O\n1.567\n-0.7222\n3.857\n0.3268\n\n\nD+O-C+O\n0.9663\n-1.323\n3.256\n0.7707\n\n\nOdomos-Deltamethrin\n-0.2323\n-2.522\n2.057\n0.9986\n\n\nOdomos-Cyfluthrin\n-0.132\n-2.422\n2.158\n0.9999\n\n\nDeltamethrin-Cyfluthrin\n0.1003\n-2.189\n2.39\n1\n\n\n\n\n\nC+O is significantly lower than 3 of the treatments at the 0.05 level; and no other treatment has a sample mean lower than C+O’s."
  },
  {
    "objectID": "examples/mosquito.html#interpretation",
    "href": "examples/mosquito.html#interpretation",
    "title": "Mosquitos",
    "section": "Interpretation",
    "text": "Interpretation\nIt appears the the best type of material is the C+O material to minimize the amount of mosquito human contact. The lowest mean came from the C+O material where the average amount of mosquito/human contact was 5.367. With a mean of 6.333, D+O was not significantly different than C+O and could also be an option. Conducting a new experiment that focuses on the difference between C+O and D+O and gives them a larger sample size in order to better detect significant would be reasonable.\nA future study could look into other types of material as well as doing this analysis at different locations throughout the world."
  },
  {
    "objectID": "examples/VirtualTrain.html",
    "href": "examples/VirtualTrain.html",
    "title": "Lifeboat Launch Training Methods",
    "section": "",
    "text": "Code\nlibrary(mosaic)\nlibrary(DT)\nlibrary(pander)\nlibrary(car)\nlibrary(tidyverse)\n\n## Data from original article:\nvirtual <- read.csv(\"../data/virtual_training.csv\", header=TRUE)"
  },
  {
    "objectID": "examples/VirtualTrain.html#background",
    "href": "examples/VirtualTrain.html#background",
    "title": "Lifeboat Launch Training Methods",
    "section": "Background",
    "text": "Background\nAn experiment was done to help train people in the procedure to launch a lifeboat. This was a Completely Randomized Design with 16 subjects per treatment, for a total of 64 subjects. The response variable is the performance on a procedural knowledge test. The treatments included: Lecture/Materials (Control) (1), Monitor/Keyboard (2), Head Monitor Display/Joypad (3), and Head Monitor Display/Wearables (4)\nSource: J.Jung and Y.J. Ahn (2018). “Effects of Interface on Procedural Skill Transfer in Virtual Training: Lifeboat Launching Operation Study,” Computer Animation & Virtual Worlds, Vol. 29, pp. e1812. https://doi.org/10.1002/cav.1812"
  },
  {
    "objectID": "examples/VirtualTrain.html#analysis",
    "href": "examples/VirtualTrain.html#analysis",
    "title": "Lifeboat Launch Training Methods",
    "section": "Analysis",
    "text": "Analysis\nApplying a one-way ANOVA to this study, we have the following model:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\nWhere \\(y_{ij}\\) is the \\(j^{th}\\) observation from treatment \\(i\\)\n\\(\\mu\\) is the grand mean of the dataset. Also referred to as an overall mean or benchmark.\n\\(\\alpha_i\\) is the effect of the training method. 1 = control/lecture, 2 = Monitor/keyboard, 3 = head monitor/joypad, 4 = head monitor/wearables.\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. Since there are 16 subjects for each treatment, \\(j\\) ranges from 1 to 16.\n\nHypothesis Test\nThe null hypothesis is that the effect of all training methods, represented by α, is equal to zero. This is formally written as follows.\n\\[ H_0:\\alpha_\\text{Control} = \\alpha_\\text{Monitor/Keyboard} = \\alpha_\\text{Joypad} = \\alpha_\\text{Wearables} = 0 \\]\nThe alternative hypothesis states that at least one of the effects due to material is different than zero \\[ H_a: \\text{at least one } \\alpha \\text{ is different than 0} \\]\nUsing these hypotheses will allow for us to address the question whether any of the type of training is different to improve test score.\nWe will use a level of significance of α = 0.05 for the analysis.\nFor the analysis, we perform the following one-way ANOVA\n\n\nCode\nvirtual <- virtual %>% \n   mutate(\n         Treatment = case_when(\n           grp.trt %in% 1  ~ \"Control\",\n           grp.trt %in% 2  ~ \"Monitor/Keyboard\",\n           grp.trt %in% 3  ~ \"Joypad\",\n           grp.trt %in% 4  ~ \"Wearables\"\n          )\n        )\n\nvirtual.aov <- aov(procKnow ~ Treatment, data=virtual)\nsummary(virtual.aov) %>% pander()\n\n\n\nAnalysis of Variance Model\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(>F)\n\n\n\n\nTreatment\n3\n65.66\n21.89\n4.941\n0.003931\n\n\nResiduals\n60\n265.8\n4.43\nNA\nNA\n\n\n\n\n\nThe p-value for this test is significant (p = 0.003931). Based on this result, the null hypothesis is rejected and we have sufficient evidence that at least one of the effects due to training is different for post test score.\n\n\nCheck Requirements\nIn order to trust this result, we must verify the requirements for the ANOVA model are met. The requirement of equal variances appears to be met since the residuals versus fitted plot shows roughly a constant variance within each vertical group of dots.\nThe QQ-plot of residuals on the right is used to check whether residuals are normally distributed. There are a few points outside the boundaries that might be a concern for this ANOVA requirement, but generally there are no strong departures from normality and so we consider this requirement to be met also.\n\n\nCode\npar(mfrow=c(1,2))\nplot(virtual.aov, which=1, pch=16)\nqqPlot(virtual.aov, id=FALSE)\n\n\n\n\n\n\n\nTraining method’s effect on test score\nThe following plot shows which types of training increases the post test score.\n\n\nCode\nxyplot(procKnow ~ as.factor(Treatment), data=virtual, type=c(\"p\",\"a\"), main=\"Score based on Type of Training\", xlab =\"Treatment\", ylab = \"Test Score\")\n\n\n\n\n\nThe averages are illustrated with the blue line in the plot above and the table below shows the means, standard deviations, and sample sizes for each of the five different materials.\n\n\nCode\npander(favstats(procKnow ~ Treatment, data=virtual)[,c(\"Treatment\",\"mean\",\"sd\",\"n\")])\n\n\n\n\n\n\n\n\n\n\n\nTreatment\nmean\nsd\nn\n\n\n\n\nControl\n4.931\n1.94\n16\n\n\nJoypad\n6.736\n2.82\n16\n\n\nMonitor/Keyboard\n7.708\n1.43\n16\n\n\nWearables\n6.875\n1.99\n16"
  },
  {
    "objectID": "examples/VirtualTrain.html#interpretation",
    "href": "examples/VirtualTrain.html#interpretation",
    "title": "Lifeboat Launch Training Methods",
    "section": "Interpretation",
    "text": "Interpretation\nIt appears the the best type of training may be the Monitor/Keyboard type training. The highest mean came from the Monitor/Keyboard where the average procedural knowledge post test score was 7.708. The head monitor training methods may perform better on different types of assessments that were not part of this study. A future study could look into other training methods to improve readiness in lifeboat launching."
  },
  {
    "objectID": "experimental_units.html",
    "href": "experimental_units.html",
    "title": "Experimental Units",
    "section": "",
    "text": "The first example will study to see if a specific SAT prep class improves individual’s SAT math scores. Twenty randomly selected students are randomly divided into two groups. One group will take the prep class and the other group will not take the class. In this case the experimental unit is the student because factor level assignments were made for each student. The observational unit is also the student because the math scores are measured for each student.\nThe next example will be slightly, but distinctly different. In this case, we will be applying a new teaching method to a math classroom to see if it improves math scores. Six randomly selected classrooms are randomly divided into 2 groups. One group will be randomly assigned the new teaching method and the other group will be randomly assigned the standard method. Within each classroom there are 25 students and math scores will be taken from each student. In this case, the classrooms are the experimental unit because the factor levels are assigned to each classroom. The students are the observational unit because the scores are measured for each student. The new teaching method will have 75 observations (3 classrooms with 25 students in each). However, the research objectives are concerning the classroom, and assignments of the teaching method are made at the classroom level, so the number of experimental units for each teaching method is just 3 for this analyses. Even though there were many observations, the limited number of experimental units limits the ability to make convincing inference to the broader population. We would like more classrooms involved be be more sure the succes/failure of the new teaching method was not due to a few particularly good/bad teachers. The researcher needs to be aware when this type of sampling is occurring so that a more complex analysis technique can be used to tease out the effect of teachers vs. method - and enhance our ability to make inference. This technique is discussed in further detail with the Nested Factor Designs.\nNow let’s apply this to the toothbrush study. Each person will be assigned to use one type of toothbrush, so person is the experimental unit. The measurements will be taken from teeth, so the observational unit will be tooth. If measurements are taken from multiple teeth, then a more complex design, like the Nested Factor designs should be considered."
  },
  {
    "objectID": "factor_structure.html",
    "href": "factor_structure.html",
    "title": "Factor Structure",
    "section": "",
    "text": "In this section you will learn about factors in context of analyzing results of an experiment:"
  },
  {
    "objectID": "factor_structure.html#inside-and-outside",
    "href": "factor_structure.html#inside-and-outside",
    "title": "Factor Structure",
    "section": "Inside and Outside",
    "text": "Inside and Outside\nThink about our toothbrush example, but ignore toothpaste for a moment. If toothbrush is the only treatment under scrutiny we have three factors in the analysis: the grand mean, toothbrush type, and the residual error.\nRecall that in the simplest version of the toothbrush experiment there were 4 levels of the treatment (toothbrush type), with six replicates for each toothbrush. In the following factor structure diagrams grand mean is represented in red, toothbrush type is drawn in blue, and the residual factor levels are depicted in black.\n\n\n\nA factor is inside of another factor if all the levels of one factor (the inside factor) completely fit within a second factor (the outside factor).\nYou may find this analogy helpful. Pretend that an outside factor is a box, and the inside factor levels are blocks that fit perfectly within the box.\n\n\n\n\n\nTo determine if a factor is inside another factor, imagine picking up the levels of the factor one by one and placing them inside the other factor. If they all fit without crossing the partition lines of a factor,then it is considered inside.\nThis is illustrated with the toothbrush example. We will start by taking the levels of toothbrush and placing them inside of grand mean\n\n\n\n\n\nIn the figure above you can see that one entire level of toothbrush can fit inside of a single level of benchmark. Even though they may share a boundary line, the toothbrush level does not cross over any lines or start sharing boundaries with any other level of benchmark (this is of course impossible since benchmark only has one level). You can repeat this for the other 3 levels of toothbrush with the same result. Therefore, we say that toothbrush is inside of benchmark, which is the same as saying that benchmark is outside of toothbrush.\nConsider now the relationship between toothbrush and residual as shown below. If we take a level of toothbrush and overlay it on the residual factor, we can see it does not fit neatly inside one of the levels of residual error. In fact, one level of toothbrush crosses the boundaries of many of the levels of residual error. Therefore, we cannot say that toothbrush is inside of residual error.\n\n\n\n\n\nSince toothbrush is not inside of residual error, does this necessarily mean that toothbrush is outside of residual error? No! This is something that has to be checked. To determine whether toothbrush is outside of residual we must take the levels of residual error one at a time and overlay them on the toothbrush factor structure, as shown below. You can see that one level of residual error does NOT cross any of the toothbrush level boundaries. Therefore, toothbrush is indeed outside of residual error; or equivalently, residual error is inside of toothbrush.\n\n\n\n\n\nLet’s pause here to clarify a common misunderstanding. Consider an experiment where we are looking at the inside vs. outside relationship of two factors: A and B.\n\nWhen factor A is inside of factor B, we can also say factor B is outside of factor A.\nBut, when factor A is not inside of factor B, this does not necessarily mean that factor A is outside of factor B. There are situations where two factors are neither inside nor outside of each other; they are crossed."
  },
  {
    "objectID": "factor_structure.html#crossed-factors",
    "href": "factor_structure.html#crossed-factors",
    "title": "Factor Structure",
    "section": "Crossed Factors",
    "text": "Crossed Factors\nTwo factors are crossed when their partition lines cross in a way that creates new groups of observations that represent every possible combination of the factor levels. More succinctly stated, factors are crossed when all factor level combinations are present in the study. We saw this in the toothbrush study when brand of toothpaste was included in the experiment. Toothbrush and toothpaste are neither inside nor outside of each other; rather, they are crossed.\n\n\n\n\n\n\n\n\n\n\n\nThe crossing of toothpaste brand and toothbrush created an interaction factor"
  },
  {
    "objectID": "hoveRmd/BF1_R_Instructions.html",
    "href": "hoveRmd/BF1_R_Instructions.html",
    "title": "BF1 R Instructions",
    "section": "",
    "text": "Df Sum Sq Mean Sq F value Pr(>F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "hoveRmd/contrast_R_instructions.html",
    "href": "hoveRmd/contrast_R_instructions.html",
    "title": "Math326 Notebook",
    "section": "",
    "text": "The first step is to create the model. Then use the emmeans() command to create a grid of factor level summary statistics, including: means, standard deviations, standard error, degrees of freedom associated with the standard error estimate, and confidence intervals around the mean. Unlike a summarize() or favstats() command, emmeans() has the output structured so that it can easily be used in the next step. Store the grid of means into a new object.\n\nmyaov <- aov(Y ~ X, data = df)\nmymeans <- emmeans(myaov, \"X\")\n\n\nmyaov is some name you come up with to store the results of the aov() model.\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\ndf is the name of your data set.\nmymeans is some name you come up with to store the results of the emmeans() command.\n\nDefine the contrasts your are interested in testing inside the contrast() function, which returns the hypothesis test results. You can also feed the result into a confint() function if you prefer confidence intervals over p-values.\n\ncontrast(brush_means,list(name_of_contrast1 = coefficient vector,\n                       name_of_contrast2 = another coefficient vector))) \n\nname_of_contrast are descriptive names you should give to the contrast to help you remember what it represents. The coefficient vector is how you define the contrast.\nWe will repeat the contrasts we did by hand in the sections above, but this time using R.\nExample Code Using Toothbrush Experiment:\n\n\n df The name you want for your dataset  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv(“../data/toothpaste_BF2.csv”) A tidyverse command to read the data in from the specified path  plaque_aov Name you want for your ANOVA model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  brush_means The name you want for the output of the emmeans command  <- The assignment operator. The result to the right of it gets stored in an object specified on the left   emmeans(  Function to calculate stats about marginal means  plaque_aov, aov model created in previous step  “Brush” Factor for whose levels you want to calculate means  ) Functions always end with a closing parenthesis  contrast_results Name you want to store contrast results in  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  contrast( Function to define and test contrasts  brush_means, Grid of stats about marginal means you named in the previous step list( create a list object, which allows you to pass multiple contrast coefficient vectors  man_v_osc = A descriptive name to help you remember what the contrast represents  c(1,-1,0,0) Vector of coefficients used to define the contrast  , Seperator to allow additional inputs to the list     man_v_others = A descriptive name to help you remember what the contrast represents  c(1,-(1/3),-(1/3),-(1/3)) Vector of coefficients used to define the contrast  ), A list is closed with a parenthesis  adjust = Specify what type of adjustment (if any) to make for multiple testing. Default is “none” if this argument is not included.  “none” Read help at ?summary.emmGrid for other acceptable values  ) Functions always end with a closing parenthesis  contrast_results View the test results stored in this object in the previous step  confint( Function to create confidence intervals around contrasts  contrast_results Name of object where you stored contrasts  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n contrast     estimate   SE df t.ratio p.value\n man_v_osc       3.117 1.58 20   1.967  0.0632\n man_v_others    0.438 1.29 20   0.339  0.7382\n\n\n\n\n contrast     estimate   SE df lower.CL upper.CL\n man_v_osc       3.117 1.58 20   -0.188     6.42\n man_v_others    0.438 1.29 20   -2.260     3.14\n\nConfidence level used: 0.95"
  },
  {
    "objectID": "hoveRmd/DescribeData_backup.html",
    "href": "hoveRmd/DescribeData_backup.html",
    "title": "Describing Data",
    "section": "",
    "text": "In the following explanations\n\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable. It would represent a treatment factor.\nYourDataSet is the name of your data set.\n\nYou can take a tidyverse approach or a mosaic package approach to calculating numerical summaries for each treatment.\n\nmosaic package:tidyverse approach\n\n\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  Month min   Q1 median    Q3 max     mean       sd  n missing\n1     5  56 60.0     66 69.00  81 65.54839 6.854870 31       0\n2     6  65 76.0     78 82.75  93 79.10000 6.598589 30       0\n3     7  73 81.5     84 86.00  92 83.90323 4.315513 31       0\n4     8  72 79.0     82 88.50  97 83.96774 6.585256 31       0\n5     9  63 71.0     76 81.00  93 76.90000 8.355671 30       0\n\n\n\nWhen calculating treatment means for combinations of 2 or more factors you can use + or | to separate the factors. | (read as ‘vertical bar’ or ‘pipe’) has the advantage that in addition to calculating means for every factor level combination, favstats will also output the marginal means for each level of the last factor listed.\nNOTE: unlike it’s use in the aov() command, using the * within favstats does not yield expected results and should NOT be used.\n\nlibrary(mosaic)\nfavstats(Y ~ X + Z, data = YourDataSet) \n#OR\nfavstats(Y ~ X | Z, data = YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  + This allows us to create additional subgroups within ‘am’ for each level of ‘cyl’.  cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  am.cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1    0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2    1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3    0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4    1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5    0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6    1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n\n\n\nNotice that the first column in the output contains the factor level combinations of am and cyl. So, ‘0.4’ is interpreted as level 0 for am and level 4 for cyl. Or in other words, the summary statistics on that row are for automatic tranmission, 4 cylinder engine vehicles. The column label of ‘am.cyl’ indicates which factor is represented on which side of the period. The next example uses the same way of labeling the factor level combinations, but the column label is not as intuitive or helpful.\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  | Referred to as a vertical bar or pipe, this symbol further defines subgroups of the variable on its left, using the values of the variable on its right side   cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to View Output  Click to View Output. \n\n\n\n\n\n  cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1 0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2 1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3 0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4 1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5 0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6 1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n7   4 21.4 22.800  26.00 30.400 33.9 26.66364 4.5098277 11       0\n8   6 17.8 18.650  19.70 21.000 21.4 19.74286 1.4535670  7       0\n9   8 10.4 14.400  15.20 16.250 19.2 15.10000 2.5600481 14       0\n\n\n\n\n\n\nCalculating treatment means for one factor:\n\nlibrary(tidyverse)\nYourDataSet %>%\n  Group_by(X) %>%\n  Summarise(MeanY = mean(Y), sdY = sd(Y), sampleSize = n()) \n\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  airquality airquality is a dataset in R.   %>%  The pipe operator that will send the airquality dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the airquality dataset into “little” datasets, one dataset for each value in the “Month” column.  Month “Month” is a column from the airquality dataset that can be treated as qualitative.  ) Functions must always end with a closing parenthesis.   %>%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  aveTemp =  “AveTemp” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  Temp Temp is a quantitative variable (numeric vector) from the airquality dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\nMonth\naveTemp\n\n\n\n\n5\n65.55\n\n\n6\n79.1\n\n\n7\n83.9\n\n\n8\n83.97\n\n\n9\n76.9\n\n\n\n\n\nNote that R calculated the mean Temp for each month in Month from the airquality dataset.\nMay (5), June (6), July (7), August (8), and September (9), respectively.\nFurther, note that to get the “nicely formatted” table, you would have to use\nlibrary(pander)\nairquality %>% \n  group_by(Month) %>%\n  summarise(aveTemp = mean(Temp)) %>%\n  pander()\n\nTo calculate treatment means for each combination of factor levels of 2 or more factors, simply add the additional variable to the group_by() statement.\nExample code:\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  mpg mtcars is a dataset in preloaded in R.   %>%  The pipe operator that will send the mtcars dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the mtcars dataset into “little” datasets, one dataset for each combination of values in the ‘am’ and ‘cyl’ variables  am, cyl ‘am’ and ‘cyl’ are both columns in mtcars. By listing them both here we are going to get output for each combination of ‘am’ and ‘cyl’ that exists in the dataset  ) Functions must always end with a closing parenthesis.   %>%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  mean_mpg =  “mean_mpg” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  mpg mpg is a quantitative variable (numeric vector) from the mtcars dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n`summarise()` has grouped output by 'am'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\n\n\n\n\nam\ncyl\nmean_mpg\n\n\n\n\n0\n4\n22.9\n\n\n0\n6\n19.12\n\n\n0\n8\n15.05\n\n\n1\n4\n28.07\n\n\n1\n6\n20.57\n\n\n1\n8\n15.4"
  },
  {
    "objectID": "hoveRmd/DescribeData_backup.html#graphical-summaries",
    "href": "hoveRmd/DescribeData_backup.html#graphical-summaries",
    "title": "Describing Data",
    "section": "Graphical Summaries",
    "text": "Graphical Summaries\n\nBoxplots\n\n\n\n\n\n\n\n\nOverviewR InstructionsExplanation\n\n\n\nGraphical depiction of the five-number summary. Great for comparing the distributions of data across several groups or categories. Provides a quick visual understanding of the location of the median as well as the range of the data. Can be useful in showing outliers. Sample size should be larger than at least five, or computing the five-number summary is not very meaningful.\n\n\n\n\n\n\nBase R ggplot2 plotly\n\n\n\nTo make a boxplot in R use the function:\nboxplot(object)\nTo make side-by-side boxplots:\nboxplot(object ~ group, data=NameOfYourData, ...)\n\nobject must be quantitative data. R refers to this as a “numeric vector.”\ngroup must be qualitative data. R refers to this as either a “character vector” or a “factor.” However, a “numeric vector” can also act as a qualitative variable.\nNameOfYourData is the name of the dataset containing object and group.\n... implies there are many other options that can be given to the boxplot() function. Type ?boxplot in your R Console for more details.\n\nExample Code\nBasic Single Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  $ The $ allows us to access any variable from the airquality dataset.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.  )\nClosing parenthesis for the function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nMore Useful… Basic Side-by-Side Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Names under each Box\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  names=c(“May”,“June”,“July”,“Aug”,“Sep”) names= is used to tell R what labels to place on the x-axis below each boxplot.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Color and Labels\n\n\n boxplot(Temp ~ Month, data=airquality This code was explained in the previous example code.  ,  The comma is used to separate each additional command to a function.  xlab=“Month of the Year” xlab= stands for “x label.” Use it to specify the text to print on the plot under the x-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  ylab=“Temperature” ylab= stands for “y label.” Use it to specify the text to print on the plot next to the y-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  main=“La Guardia Airport Daily Temperatures” main= stands for the “main label” of the plot, which is placed at the top center of the plot. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  col=“wheat” col= stands for the “color” of the plot. The color name “wheat” is an available color in R. Type colors() in the R Console to see more options. The color name must always be placed in quotes.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a boxplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_boxplot()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_boxplot() causes the ggplot to become a boxplot.\n\n\nExample Code\nBasic Single Boxplot\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the y-axis should become.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot() The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n Side-by-side Boxplot and Color Change\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box in the boxplot.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Labels \n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_histogram()” function causes the ggplot to become a histogram. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.   +  The addition symbol + is used to add further elements to the ggplot.     labs( The “labs” function is used to add labels to the plot, like a main title, x-label and y-label.  title=“La Guardia Airport Daily Mean Temperature”,  The “title=” command allows you to control the main title at the top of the graphic.  x=“Month of the Year”,  The “x=” command allows you to control the x-label of the graphic.  y=“Daily Mean Temperature” The “y=” command allows you to control the y-label of the graphic.  )\nClosing parenthesis for the labs function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nGallery\nSee what past students have done…\nClick to view.\n\nHover to see code.\n \n ggplot(data = mtcars, aes(x = as.factor(cyl), y = mpg, fill=as.factor(cyl))) +  geom_boxplot()  +  stat_summary(fun.y = mean, geom = \"errorbar\", aes(ymax = ..y.., ymin = ..y..),     width = .75, linetype = \"dashed\", color=\"firebrick\") +  theme_light() +  theme(panel.grid.major=element_blank()) +  scale_fill_brewer(palette=\"Dark2\") +  geom_jitter(width=0.1, height=0) +  labs(title = \"Miles Per Gallon Based on Cylinders\",     x=\"Number of Cylinders\",     fill=\"Cylinders\",     y=\"Miles Per Gallon\")   \n \n ggplot(data = ToothGrowth, aes(x = as.factor(dose), y = len, fill=as.factor(dose))) +  geom_boxplot( )  +  facet_wrap(~supp) +  theme_bw() +  scale_fill_manual(values=c(\"#999999\", \"#E69F00\", \"#56B4E9\")) +  geom_jitter(width=0.1, height=0) +  labs(title = \"Tooth Length Based on Doses     According to Supplement Type\",     fill=\"Doses\",     x=\"Dosage Amount(mg)\",     y=\"Tooth Length\" )   \n\n\n\n\n\nTo make a histogram in plotly first load\nlibrary(plotly)\nThen, use the function:\nplot_ly(dataName, y=~columnNameY, x=~columnNameX, type=\"box\")\n\ndataName is the name of a data set\ncolumnNameY must be the name of a column of quantitative data. R refers to this as a “numeric vector.” This will become the y-axis of the plot.\ncolumnNameX must be the name of a column of qualitative data. This will provide the “groups” forming each individual box in the boxplot.\ntype=\"box\" tells the plot_ly(…) function to create a boxplot.\n\nVisit plotly.com/r/box-plots for more details.\n\nExample Code\nHover your mouse over the example codes to learn more. Click on them to see what they create.\nBasic Boxplot\n\n\n plot_ly An R function “plot_ly” from library(plotly) used to create any plotly plot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality,  “airquality” is a dataset. Type “View(airquality)” in R to see it.  y= The y= allows us to declare which column of the data set will become the y-axis of the boxplot. In other words, the quantitative data we are interested in studying for each group.  ~Temp,   “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset. The ~ is required before column names inside all plot_ly(…) commands.  x= The x= allows us to declare which column of the data set will become the x-axis of the boxplot. In other words, the “groups” forming each separate box in the boxplot.  ~as.factor(Month),   since “Month” is a quantitative variable (numeric vector) from the “airquality” dataset we have to change it to a “factor” which forces R to treat it as a qualitative (groups) variable. The ~ is required before column names inside all plot_ly(…) commands.  type=“box” This option tells the plot_ly(…) function what “type” of graph to make. In this case, a boxplot.  )\nClosing parenthesis for the plot_ly function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nChange Color\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”,  This code was explained in the first example code.  fillcolor=“skyblue”,  this changes the fill color of the boxes in the boxplot to the color specified, in this case “skyblue.”  line=list(color=“darkgray”, width=3),  this “list(…)” of options that will be specified will effect the edges of the boxes in the boxplot. We are changing their color to “darkgray” and their width to 3 pixels wide.  marker=list( this “list(…)” of options that will be specified will effect the outlying dots shown in the boxplots beyond the “fences” of each box.  color = “orange”,  this will change the color of the dots to orange.  line = list(,  this opens a list of options to specify for the “lines” around the “markers.”  color = “red”,  this will change the color of the lines around the outlier dots to red.  width = 1 this will change the width of the lines around the outlier dots to 1 pixel.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nAdd Titles\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”, fillcolor=“skyblue”, line=list(color=“darkgray”, width=3), marker = list(color=“orange”, line = list(color=“red”, width=1)))  This code was explained in the above example code.  %>% the pipe operator sends the completed plot_ly(…) code into the layout function.  layout( The layout(…) function is used for specifying details about the axes and their labels.  title=“La Guardia Airport Daily Mean Temperatures” This declares a main title for the top of the graph.  xaxis=list( This declares a list of options to be specified for the xaxis. The same can be done for the yaxis(…).  title=“Month of the Year” This declares a title underneath the x-axis.  ),  Functions always end with a closing parenthesis.  yaxis=list( This declares a list of options to be specified for the y-axis.  title=“Temperature in Degrees F” This declares a title beside the y-axis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding how a boxplot is created is the best way to understand what the boxplot shows.\n\nHow Boxplots are Made\n\nThe five-number summary is computed.\nA box is drawn with one edge located at the first quartile and the opposite edge located at the third quartile.\nThis box is then divided into two boxes by placing another line inside the box at the location of the median.\nThe maximum value and minimum value are marked on the plot.\nWhiskers are drawn from the first quartile out towards the minimum and from the third quartile out towards the maximum.\nIf the minimum or maximum is too far away, then the whisker is ended early.\nAny points beyond the line ending the whisker are marked on the plot as dots. This helps identify possible outliers in the data.\n\n\n\n\n\n\n\n\n\nScatterplot, with Means\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nScatterplots of a catgorical variable on the x axis and quantitative variable on the y axis are sometimes called strip charts, or side-by-side strip charts. When sample sizes are not too big and there are not too many repeated value this type of chart is an excellent way to see the variability in the data without the abstraction of a boxplot. By plotting individual observations you also can see the size of the sample for each factor level. Including factor level means on the plot adds additional insight. The mean of each factor level is often connected with a line for visual impact.\n\n\n\n\nmosaic ggplot2 plotly\n\n\n\nTo make a scatterplot use the function:\nxyplot(y~x, data = mydata)\n\ny is the quantitative response variable, i.e., “numeric vector.”\nx is the independent, explanatory variable\nmy is the name of the dataset containing y and x.\n\nThis will return a scatterplot regardless of how your x variable is stored in R (numeric, character, factor). This function is flexible and with minimal effort can include averages or make an interaction plot. xyplot() is a part of the lattice package, which is loaded when the mosaic package is loaded.\nNote: plot() from base R will also give a scatterplot, but only if the x variable is quantitative. If x is a character or factor variable the default is to return a boxplot plot.\nExample Code\nBy reading the documentation for the dataset (visible when ?ToothGrowth is run in the console) we can see that our “x” variable, “dose”, is a numeric variable in R. Because of this the x-axis maintains the relative distance of doses on the x-axis.\nBy reading the documentation for the dataset (visible when ?ToothGrowth is run in the console) we can see that our “x” variable, “dose”, is a numeric variable in R. Because of this the x-axis maintains the relative distance of doses on the x-axis.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nIf you start with a numeric x variable, you may or may not want to convert it to a factor variable. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed. Compare the output of the previous example code with this example code. This example code converts our x variable of “dose” to a factor variable.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nTo include the means on the plot and connect them with a line use this code\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  , \nThe “,” is required to start specifying additional commands for the function.  type =\nThe type argument allows you to add different types of lines to the plot. Run ?panel.xyplot() to read more about values for this argument  c( Combines the following values into one vector. This allows me to pass multiple values as one input to “type =”. Useful for if I want to plot something in addition to the default of plotting points.  ‘p’\nThis requests the points to be plotted. It is the default value. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  , \nThe “,” is required to start specifying additional commands for the function.  ‘a’ This requests the average for each factor level to be connected with a line. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a scatterplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_point()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_point() causes the ggplot to become a scatterplot; or in other words to draw points to represent data.\n\n\nExample Code\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n If you start with a numeric x variable, you may or may not want to convert it to a factor variable. You do this by using ‘factor(x)’ instead of just ‘x’ as shown below. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed.\nggplot(ToothGrowth, aes(x = factor(dose), y = len)) +   geom_point(color = \"blue\")\nAdding averages to the plot and connecting them with a line requires a little more effort and is demonstrated in the code below. I also add some more descriptive labels to the chart.\nNote the use of stat_summary to indicate I want to add a layer that plots a numerical summary, not the original data. Some geoms have stat summaries built in to them (like geom_bar or geom_boxplot), but in our case we have to define the summary.\nIn the stat_summary I provide additional arguments to the aesthetics helper function. Defining the aesthetics in ggplot() is like a global definition, all additional layers inherit those aesthetic mappings. Defining them in a geom_* or a stats_* allows you to add to or override what was defined in ggplot() for that layer only. The group aesthetic is required in order to use a line geometry. In this case, group could just as easily have been defined in ggplot(aes()).\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_point( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.   +  The addition symbol + is used to add further elements to the ggplot.    stat_summary( This function will calculate a statistical summary to be plotted on the chart  fun = mean, fun is short for function. The summary function I want to apply to my y variable is “mean”.  geom = “line”, The “geom=” argument is used to tell what kind of geometry should be drawn to represent the means. Here we are asking for the means to be connected with a line.  aes( The aes or “aesthetics” function allows you to tell ggplot what variables should be mapped to what visual aspects of the chart; including what the x-axis or y-axis should become. Including it her means the aesthetic will only be applied to this layer.  group = 1 indicates which variable should be grouped by when drawing multiple lines (one line for each factor level). We write the number 1 to indicate there is just 1 group; we are not further splitting the data.  )\nClosing parenthesis for the geom_boxplot function.  )\nClosing parenthesis for the geom_boxplot function.   +  The addition symbol + is used to add further elements to the ggplot.    labs( Function to edit labels of the plot  x = “Vitamin C mg/day”, Edit the x-axis label  y = “Length”, Edit the y-axis label  title = “Tooth Growth in Guinea Pigs” Edit the chart title  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nUnder construction.\n\n\n\n\n\n\n\n\nInteraction Plot\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nUnder construction\n\n\n\n\nmosaic ggplot2 plotly\n\nUnder construction"
  },
  {
    "objectID": "hoveRmd/model_diagnostics.html",
    "href": "hoveRmd/model_diagnostics.html",
    "title": "Model Diagnostics",
    "section": "",
    "text": "A key assumption for ANOVA tests is that the error, or residual term, has a constant variance across all factor levels. This is sometimes call homogeneity of variance, or homoscedasticity.\nWe explain three ways to check the assumption: rule of thumb when comparing standard deviations for each factor level, a visual assessment of the residual vs. fitted plot, and Levene’s test. These methods may not always agree. You should be aware of the underlying data. Understanding why this assumption is important and how it will affect results when violated will help you decide how to proceed after checking these diagnostics. It is also worth noting that the ANOVA F-test is robust in the face of mild to moderate violation of this assumption.\nWe will use the pre-loaded dataset ToothGrowth. To learn more about the dataset, run ?ToothGrowth in the console. len will be our response variable, supp is an independent factor, and dose is the other independent factor. We will analyze this a two-way, basic factorial design. Because dose is stored as a numeric variable, we will convert it to a categorical variable and rename it dose_f before including it in the model. Don’t forget to load the tidyverse in order to use mutate().\n\n\n tg The name you want for your modified dataset  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  ToothGrowth A preloaded dataset in R  |> The result on the left is piped into the first argument of the function on the right  mutate( A tidyverse function to compute a new column for a dataset  dose_f = The name you want to give to the new column  factor( A function to convert a variable from numeric to quantitative  dose A numeric variable in ToothGrowth  )) Functions always end with a closing parenthesis  aov2th A name you come up with for your model  <- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  len The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  dose_f Column in the tg dataset where doese is stored as a factor  * Crosses two factors. Both simple factors and the interaction factor are included in the model   supp variable with 2 levels of delivery method: orange juice or asorbic acid (vc)  , Seperates multiple input arguments to a function.  data = tg Tell the model that the variable names come from the tg dataset  ) Functions always end with a closing parenthesis \n\n\n\n\n\n\n\n\n\n\nA quick rule of thumb to check this assumption is to compare standard deviations across factor levels. If the largest standard deviation is no more than double the smallest standard deviation, then the standard deviations (and the variances) are close enough to be considered equal. Check the R Instructions>Describing Data>Numerical Summaries section of the textbook on how to calculate standard deviations for each factor level.\nIn cases with more than 1 factor, you can compare the standard deviation of each factor level combination (i.e. the interaction factor). Sometimes though, looking at the interaction results in a very small sample size at each level or you may be concerned about a particular factor level of an experimental factor. In that case you may want to apply this rule of thumb to each factor individually. When faced with a situation where the rule of thumb is met for some factors but not for others use your best judgement. An understanding of how a violation may affect your results is critical. You can see that this approach can be tricky to implement, especially as you go beyond studies with just two factors.\n\n\n\nAnother informal approach to checking the constant variance assumption is looking at a residual vs. fitted plot. Similar to the rule of thumb, in situations with more than 1 factor, you can either create a plot that shows all factor level combinations OR look at multiple plots, one for each experimental factor. In order to view this plot, you must first create the ANOVA model. Once the model is created, there are a couple of ways to get a residual vs. fitted plot.\nConstruct the plot manually from vectors within the aov object\nThe plot can be constructed using the vector of residuals and vector of fitted values contained in the aov object.\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\nplot(myaov$fittedvalues, myaov$residuals)\n\nNote: If you want to know all the named items in an R object, you can run names(object). In this case we have an aov object called myaov. To see what it contains we can run names(myaov) in the console.\nExample code:\n\n\n\n plot( Base R function to create a scatterplot  aov2th$  Look in the aov2th object for the item named on the right of the $  fitted.values  This vector, stored in the aov object, contains the fitted, or predicted, values.  , Seperates multiple input arguments to a function  aov2th$ Look in the aov2th object for the item names on the righ tof the $  residuals Vector in the aov object that contains model residuals  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\nNote the resulting plot show 6 vertical groupings, one for each factor level combination. (3 does levels x 2 levels of supp = 6 factor level combinations) ::: {.cell} ::: {.cell-output-display}  ::: :::\n\n\nConstruct the plot with a shortcut\nWhen the function plot() is called on an aov object, 4 diagnostic plots are produced. Instead of viewing all four, chose which ones to see with the which= argument. The first of the four plots is the residual vs. fitted plot.\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\nplot(myaov, which = 1)\n\nExample code:\n\n\n\n plot( Base R function, when fed an aov object it produces 4 diagnostic plots  aov2th,  The aov object for our model  which = Which of the four diagnostic plots do we want  1 The first of the 4 plots is the residual vs. fitted plot  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\nIgnore the red line on the plot. It does not measure variance and so can be distracting. ::: {.cell} ::: {.cell-output-display}  ::: :::\n\n\n\n\n\nLevene’s test is a formal hypothesis test to determine if the variances are equal. In essence, this is an ANOVA F-test comparing sample variances across factor levels (as opposed to comparing sample means). A large p-value for the test indicates there is insufficient evidence to conclude one of the variances is different; and therefore the assumption of constant variance is met.\nThis test comes in handy when there are multiple factors in a study and it is burdensome to informally evaluate all their factor level combinations.\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\ncar::leveneTest(myaov)\n\nExample code:\n\n\n\n car Levene’s test comes from the car package.   :: Allows you to reference functions from the package named on the left without having to load the entire package.  leveneTest( function to run Levene’s test  aov2th name of the aov object to run the test on  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(>F)\ngroup  5  1.7086 0.1484\n      54"
  },
  {
    "objectID": "hoveRmd/model_diagnostics.html#normal-distribution",
    "href": "hoveRmd/model_diagnostics.html#normal-distribution",
    "title": "Model Diagnostics",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nAnother key assumption for ANOVA tests is that the error, or residual, term follows a normal distribution. We use the Q-Q plot to check this assumption. There are two ways to create the Q-Q plot.\nWe will continue to use the aov2th model that was created at the beginning of the Constant Variance section.\nConstruct the Q-Q plot with a shortcut\nWhen the function plot() is called on an aov object, 4 diagnostic plots are produced. Instead of viewing all four, chose which ones to see with the which= argument. The second of the four plots is a normal Q-Q plot.\nExample code:\n\n\n\n plot( Base R function, when fed an aov object it produces 4 diagnostic plots  aov2th,  The aov object for our model  which = Which of the four diagnostic plots do we want  2 The second of the 4 plots is the normal Q-Q plot  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\n\n\n\n\n\nThe advantage of this method is that you can easily get the residual vs. fitted plot and the normal Q-Q plot with one command by providing the which = argument a vector containing the values 1 and 2. (The : is shorthand to create a vector that starts at the value of the left of the : and increments by 1 until reaching the value on the right side of the :.)\n\nmyaov <- aov(Y~X*Z, data = YourDataSet)\nplot(myaov, which = 1:2)\n\nThe disadvantage of this method is that it can be difficult to determine if the points follow the line closely enough. To help with this decision, you may prefer to use the Q-Q plot from the car package.\nConstruct the Q-Q plot from the car package\nThe Q-Q plot from the car package provides boundary lines. When points are out of the boundaries that is evidence that the normal residual assumption is violated.\nYou can customize the way the acceptable region for points is designated. The default is shading a region. Below is code to draw dashed-line boundary.\nExample code:\n\n\n\n car qqPlot comes from the car package.   :: Allows you to reference functions from the package named on the left without having to load the entire package.  qqPlot( function to a Q-Q plot from the car package  aov2th, name of the aov object  envelope = Argument to control the formatting for the acceptable region for points  list( There are potentially many arguments to affect the envelope, so they are provided as a list.  style = “filled” shading, boundary “lines”, or none  “lines” designate the acceptable region with lines  )) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\n\n\n\n[1] 32 49"
  },
  {
    "objectID": "hoveRmd/model_diagnostics.html#independent-errors",
    "href": "hoveRmd/model_diagnostics.html#independent-errors",
    "title": "Model Diagnostics",
    "section": "Independent Errors",
    "text": "Independent Errors\nAn order plot can serve as a partial check of the assumption that the residuals are independent. If there are patterns/trends in the plot that may be grounds to say the assumption is violated.\nThe plot assumes that the dataset is sorted in the same order the data was recorded. If the data has been re-sorted or is from an observational study (i.e. the chronology of collection is unknown or irrelevant) the order plot does not make sense as a check of independence.\nExample code:\n\n\n\n plot( A function to plot the data  aov2th Name you gave your model  $ Access a named object within an object  residuals residuals of the model  ) Functions always end with a closing parenthesis  Toggle output Toggle Output."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BYU-Idaho Math326: Design and Analysis of Experiments",
    "section": "",
    "text": "This book is meant to be a starting point for you to learn design and analysis of experiments. You should feel free to edit the Rmarkdown files so that the book becomes your own.\n\n\nUnder Principles of Experiments the most foundational issues that face each experimenter are described.\nThe Specific Designs section addresses specific designs we will learn about in this course. Each design will have an image next to it representing the diagram of the structural factors. Within each of these designs there are subsections:\n\nOverview contains the model, factor structure and hypotheses\nDesign discusses how the randomization is implemented and why\nDecomposition is a bridge between the design and analysis. It walks through creating an ANOVA table by hand for the given design to allow you to see how the factor structure affects the analysis.\nR instructions provides interactive code illustrating how to run the model\nResources contains worked examples and a space for you to store other links and info\n\nThe section labeled Broad Topics seeks to address topics that are relevant to many experiment designs.\nFinally, a section dedicated to R code that can be used in multiple designs. This includes numerical and graphical data summaries as well as code for model diagnostics/assumption checking.\nYou should add additional topics and designs as you learn more, even after the course is over. The book is meant to be fully customizable and growing to reflect your growing understanding.\n\n\nThis book was specifically designed for the Math326 Design and Analysis of Experiments class at BYU-Idaho, as it stands in 2022. BYU-I follows a 14 week semester. After introducing some foundational principles of experimental design, the recommended sequence follows the general pattern of\n\nIntroduce a specific design: suitability/benefits of the design, explanation of the design, factor structure and decomposition, steps for analysis (including R code)\nDiscuss new topics/complexities/considerations associated with that design located in the Broad Topics list."
  },
  {
    "objectID": "index.html#book-scope",
    "href": "index.html#book-scope",
    "title": "BYU-Idaho Math326: Design and Analysis of Experiments",
    "section": "Book Scope",
    "text": "Book Scope\nThis is an introductory book intended to familiarize students with foundational concepts and vocabulary in the design and analysis of experiments. The designs covered in this book are the most basic and all assume a continuous response variable. Hopefully with this foundation students will be prepared to excel in experimental design and analysis courses in grad school, or be able to extend these principles to more complex designs as practitioners."
  },
  {
    "objectID": "key_principles.html",
    "href": "key_principles.html",
    "title": "Key Principles of Experimentation",
    "section": "",
    "text": "This textbook will explore the necessary steps to consider as you plan and perform an experiment. These steps include: 1. Understand the objectives of your research. What questions should be answered?\n2. Determine the measurements that will be needed to help answer the questions of interest. 3. Determine which variables, which we will call factors, are the sources of variation in the measurements. Determine which of these factors you will be testing and decide which levels of those factors will be included in the study. Determine which of these factors you will hold constant. 4. Determine how sampling and treatment assignments will be done and then collect the data. 5. Identify the analysis technique that will be applied, including how to test hypotheses 6. Describe the data using numerical and graphical summaries. 7. Perform the analysis and make sure that the analysis is appropriate. 8. Make conclusions.\nThis textbook will further discuss each of these steps in detail and offer examples. Steps 1-4 will be discussed in the “Basics of Design” section. Steps 5, 7, and 8 will be discussed in the “Specific Designs” and “Broad Topics” sections. Step 6 will be discussed in the “R Instructions” section.\nBefore detailing each of these steps, it is important to understand the differences between observational studies and designed experiments. In observational studies the researchers do not control the conditions of the study. The data are collected by observation. In this case, the researchers cannot assign the subjects to the conditions and factors in the study. An example of this would be studying to see if there is a difference in the amount of wind at the three Brigham Young University (BYU) campuses. In this study the factor is campus. The campus factor has 3 levels: BYU, BYU-Idaho, and BYU-Hawaii. The measurement taken would be the average wind speed for a particular day. The researchers cannot assign the particular days to a specific campus. Instead, they may select random days and then collect the data for those days. This data would be collected through observation, not through experimentation.\nDesigned experiments are studies in which the researchers control the conditions in which the study is performed. In designed experiments the researchers assign subjects to levels of a factor. The method used in making those assignments will be discussed further in the “Sampling and Data Collection” section. An example of this would be determining which of four different toothbrush types are better at reducing plaque. The researchers would randomly assign each subject to one of the toothbrush types and then carry out the experiment.\nExperiments have the advantage over observational studies in isolating a factor’s effect on a response, and thereby proving causality. Sometimes however it is not ethical to assign someone to a condition that is of interest, for example you should not assign anyone to experience the effects of smoking - even if you wanted to study the impact of smoking. In some cases, it may be impossible to assign someone to a condition, for example gender. Furthermore, an observational study may be preferred because it may be a more realistic view of how something will truly play out “in the real world”, rather than in a contrived lab experiment.\nAlthough both types of studies can be used to better understand and answer research questions, this textbook will mostly focus on the steps needed to best design an experiment. The toothbrush study just introduced above will be used to help illustrate how to work thru the process of designing an experiment."
  },
  {
    "objectID": "randomization.html",
    "href": "randomization.html",
    "title": "Randomization: Sampling and Assignment",
    "section": "",
    "text": "Selection bias – the sampling plan excludes part of the population during selection. Samples taken out of convenience or only from volunteers are examples of possible selection bias.\nMeasurement bias – the measurement method results in measurements that are different from the true values of the response variable. Measurement bias can be caused by uncalibrated equipment, poorly trained personnel, or any step along the experimental process that is not carefully designed or clearly defined.\nNon-response bias – this occurs when data are not available for all the individuals in the sample. If those individuals missing data would respond in a different way than those that did respond, then a bias is introduced.\n\nCare should be taken to minimize bias.\n\n\n\n\n\n\nWarning\n\n\n\nLarger sample sizes are not a remedy for biased samples.\n\n\nThe best way to minimize bias is to choose the sample randomly from the population. When results are based on a random sample, the conclusions can be generalized to the population. Random samples are accomplished by allowing each member of the population the same probability of being selected in the sample. Randomization should occur in at least two parts of an experiment: 1) the selection of experimental units from the population and 2) the random assignment of those units to the factor levels. Another randomization to consider is the order in which the experimental runs will occur. Performing all the runs for one level and then moving to the next level can introduce a time or order related bias that could be confounded with the factor. Randomizing the order will remove this bias and possible confounding. There may be other parts of the experiment where randomization should be applied. Good advice to follow is “control what you can, and randomize the rest”1.\nMultiple observations are needed within each factor level so that the variability can be estimated for each level. This variability makes up the unexplained variation, as mentioned earlier. Replication is when an experimental run is conducted under the same conditions (same factor levels), but with different experimental units. The number of replicates is the number of experimental units that are assigned to a specific factor level, or combination of levels from multiple factors. Replication is different than repeated measures. Repeated measures are when multiple measurements are taken within the same experimental run / experimental unit. The material in which repeated measures are taken are the observational units, as was discussed in a previous section. In our study method example, in the Experimental Units section, each student is considered a repeated measure.\nStatistical power will increase as more replicates are taken. The question of how many replicates are needed for a study is an important question that will not be covered in this class. There are statistical algorithms that estimate the statistical power for a specific design given the number of replicates. The R package pwr is a good resource for power calculations for various statistical tests, including analysis of variance.\nNow let’s apply each of these concepts to the example toothbrush study. A random selection of 40 possible participants should be taken from the population. Our population may be limited to those people who live near the testing location. It might also be limited to adults. Next, they are randomly assigned a toothbrush. There are 4 toothbrush types, 10 people assigned to each type. At the end of the study, the order in which their data will be collected will also be randomized. Because there are 10 participants in each group, there are 10 replicates in this study. Repeated measures will be used by collecting percent of surface area with plaque for the first molar in each of the four quadrants of the mouth for each participant.\n\n\n\n\nFootnotes\n\n\nCobb, G.W. Introduction to Design and Analysis of Experiments. Wiley, 2014.↩︎"
  },
  {
    "objectID": "referencing_other_file.html",
    "href": "referencing_other_file.html",
    "title": "referencing another file",
    "section": "",
    "text": "library(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nDP Example code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output."
  },
  {
    "objectID": "research_objectives.html",
    "href": "research_objectives.html",
    "title": "Research Objectives",
    "section": "",
    "text": "Specific: Define your desired outcomes. These outcomes need to be concisely written. They should be written in a way to reduce confusion. Refine these outcomes as you consider the next steps along the SMART process.\nMeasurable: Objectives will be better understood and accomplished when they are measurable. Designed experiments require the collection of data to determine how objectives are met. The population of the study should be considered, so that the collected data are representative of that population. The collected data need to be appropriate and able to answer the questions posed by the objectives. Some concepts, like happines, depression or engagement, are not directly measurable. Ensure that whatever is measured in the study can adequately address research objectives.\nAchievable: Realistic expectations need to be considered when determining objectives. Studies are more effective when the number of objectives is limited and well-focused. Time, resources, and budget need to be strongly considered when creating achievable objectives.\nRelevant: Be careful to make sure that your objectives are relevant to your research and overall goals. Review the literature available concerning your research to help drive your objectives towards relevant outcomes that will be appreciated by others in that research area.\nTime-based: Create a schedule for the main elements of the experiment to keep your research on track. This can be done by defining inch-stones (small tasks and deadlines) and milestones (major tasks and deadlines).\nNow, we’ll apply the SMART process to the toothbrush study example.\n\nSpecific: The research objectives for this study will be 1) determining how well each toothbrush type reduces plaque and 2) determining if there are any significant differences in plaque reduction between these toothbrush types.\nMeasure: Plaque coverage over teeth, measured as a percent of surface area, is measurable with the use of plaque staining dye, an oral camera, and software.\nAchievable: There are only two objectives mentioned in the research objectives, both of which can be answered with the defined measure, keeping this study simple and focused.\nRelevant: Considering that the purpose of our research may be to determine which toothbrush to use, this study should be relevant to those that brush their teeth.\nTime-based: Three inch-stones along the schedule will help us keep on track: 1) find the subjects to be used in the study; 2) collect the data, which would include a 2-month brushing window before collecting the data; and 3) analyze the data. The milestone would be the final report."
  },
  {
    "objectID": "response_variable.html",
    "href": "response_variable.html",
    "title": "The Response Variable",
    "section": "",
    "text": "The measurements that are recorded during an experiment and used to help evaluate the objectives are called the response variable (or dependent variable). Although it is possible to analyze data with multiple response variables, we will focus only on methods that require one response variable. The response variable is the measurement that measures the outcome of the research objectives and is used to help us determine how different factors influence that outcome.\nWhen defining a response variable, it is important to understand measurement scales. The four possible measurement scales are: nominal, ordinal, interval, and ratio. These four scales will now be discussed further and are listed in order of least information provided (nominal) to most information provided (ratio).\n\nData that are represented by labelled categories would be considered nominal. Nominal categories have no quantitative value and have no particular order. Gender and color are examples of nominal measurements. A dichotomous (having two categories) variable is a common nominal measurement scale. Analysis of variance, the common analytical technique used throughout this textbook, is not appropriate when the response variable is nominal.\nAn ordinal variable is similar to the nominal variable, except that the categories fall in a significant and meaningful order. A likert scale is a commonly used ordinal measurement. A simple example of likert, ordinal scale would be “bad”, “good”, and “great”. There is an obvious order, however, the distances between the categories are not quantitative. This means that the distance between “bad” and “good” can’t be quantitatively determined and it is not known if that difference is similar to or different than the distance between “good” and “great”. Analysis of variance is generally not appropriate when the response variable is ordinal, especially when the researcher is not comfortable in calculating a mean across the ordinal values.\nInterval measurements are quantitative with a meaningful notion of distance between values, however zero does not have a true zero value. An example of an interval variable is temperature, measured in Fahrenheit. Time is also an interval variable when there is no zero-point defined. Analysis of variance is generally appropriate when the response variable is interval.\nRatio measurements are also quantitative with a meaningful notion of distance between values and zero does have a true zero value. Most quantitative measurements are on a ratio scale. Examples of ratio variables include distance, length, weight, and height. Analysis of variance is generally appropriate when the response variable is ratio. All response variables used in this textbook will be quantitative, either interval or ratio.\n\nThe example toothbrush study, explained previously, wanted to determine if there were differences in plaque build-up when considering 4 different toothbrush types. Plaque build-up is a ratio scale measurement and would be the response variable for this study.\nAn example of a nominal scale to measure plaque build-up would be recording a “yes” if plaque was present, or “no” if plaque wasn’t present. This is a simple response variable, but not very informative. An improvement on this would be to classify each amount of plaque build-up into one of five groups: “no plaque”, “very little plaque”, “moderate plaque”, “heavy plaque”, and “complete plaque”. This would be an ordinal scale, and while it has more information than the nominal scale, it still is vaguely informative and not appropriate for analysis of variance.\nThe best measurement would be quantitative, either interval or ratio. By using red dye indicating the presence of plaque, an oral camera, and software, the percentage of the tooth area covered in plaque could be determined. This response variable would be a ratio scale and would provide much better information than the nominal or ordinal scales. When possible, it is best to have a response variable that is quantitative (interval or ratio).\n??Would this be a good place to talk about validity of a measure in terms of how directly it can address the research objective? For example, why a percent of the tooth area was used as a measure instead of area measured in squared mm (or something)? Or maybe this discussion fits above when discussing “relevance” (i.e. a % is relevant to all, but a specific number may not be relevant to those with smaller or larger mouths). Benefits and pitfalls of %’s I think would also be helpful to discuss. Latent variable and using proxies might also be a good discussion since we have so many psych students.?? -DP"
  },
  {
    "objectID": "sources_of_variances.html",
    "href": "sources_of_variances.html",
    "title": "Sources of Variation - Factors and Conditions",
    "section": "",
    "text": "Types of Variance\nAnalysis of variance, which is the statistical technique used in this course to analyze the data from an experiment, is just that, an analysis of the variances. There are three types of variance identified in an analysis of variance:\n\nthe total variation (the sum of the next two types: explained variations and unexplained variation),\nthe explained variation, of which each factor in the experimental design has a component,\nthe unexplained variation, usually one component consisting of variation due to random and unknown elements of the experimental design\n\nThe total variation is the variation that exists in the data measurements. This variance does not consider any knowledge about factors from the experimental design. It only measures the variance in the data values. The total variation is made up of two general variance components, the explained variation and the unexplained variation.\nThe degree to which the response variable changes in connection with a change in a controlled factor’s levels is called explained variance. If the value of the response varies substantially from one factor level to the next, then that factor is said to have a large explained variance. Or in other words, variability in the response can largely be explained by variation in the factor. If the explained variation is small for a factor, then the factor has little correlation with the response.\nThe unexplained variation considers all the variability in the response that is not explained by the controlled factors in the analysis. This variation is due to factors that are not known, not measured, and not controlled, and random chance error. When the unexplained variation is small, it makes the effect of the controlled factors easier to see. When the unexplained variation is large, it makes the effect of the controlled factors difficult to see. Therefore, it is important to identify the factors that can influence the data measurements and to either account for them as a controlled factor, or to hold them constant, so they are not contributing more variability to the unexplained variation.\n\n\nSummary Table\n\n\n\n\n\n\n\nTypes of Factors\nRelationship to Variance\n\n\n\n\nControlled\nEnables calculation of explained variance\n\n\nHeld constant\nReduces total variance\n\n\nNot controlled, but measured\nCan reduce unexplained variance\n\n\nNot controlled, not measured\nSource of unexplained variance"
  },
  {
    "objectID": "testqmd.html",
    "href": "testqmd.html",
    "title": "Describing Data",
    "section": "",
    "text": "A section to reference another file\n\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nDP Example code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\nNew section\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output."
  },
  {
    "objectID": "testrmd.html",
    "href": "testrmd.html",
    "title": "Describing Data",
    "section": "",
    "text": "library(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nDP Example code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output."
  }
]