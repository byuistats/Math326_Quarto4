[
  {
    "objectID": "unbalanced.html",
    "href": "unbalanced.html",
    "title": "Analysis of Unbalanced Data",
    "section": "",
    "text": "A balanced dataset is one in which there are an equal number of replicates for each and every factor level combination. Unbalanced datasets are those that have an unequal number of replicates in at least one factor level combination. In reality, it is more common to have unbalanced data than balanced data. This is particularly true for observational studies. Therefore, it is critical to learn how to analyze unbalanced data.\nThe formulas for unbalanced data are more complicated than when the data is balanced. This is not an issue since we will let computers do the calculations. The bigger issue deals with the fact that unbalanced datasets often result in correlated factor effects. Due to the equal number of replicates, factors in a balanced dataset are orthogonal. Factors in an unbalanced dataset are not guaranteed this desirable property.1\n\n\nFigure 1 is a graphical depiction of an unbalanced dataset for two factors A and B, each with 2 levels, coded as -1 and 1. You can see that each factor level combination appears an equal number of times2.\n\n\n\n\n\nFigure 1: Balanced, orthogonal data\n\n\n\n\nThe correlation of these two columns of 1’s and -1’s is zero.\n\n\nWe are measuring the correlation of the coded factors with each other. We have not even bothered to define the response variable in these examples, since it is irrelevant to the discussion.\nNow consider Figure 2, where there are fewer observations for the A=1, B=-1 combination, and more observations for A=1, B=1.\n\n\n\n\n\nFigure 2: Unbalanced, non-orthogonal data\n\n\n\n\nThe correlation between the two factors is NOT zero.\nThe issue with correlated factors is that their effects on the response are also confounded. When the response varies it cannot be determined how much of the variation in the response is due to factor A and how much was due to factor B."
  },
  {
    "objectID": "unbalanced.html#type-i-1",
    "href": "unbalanced.html#type-i-1",
    "title": "Analysis of Unbalanced Data",
    "section": "Type I",
    "text": "Type I\nFor an example of when Type I may be useful we do not need to look any further than the plant study we have been using all along on this page. Say our research question aims to test the effectiveness of thinning after accounting for the plant’s initial size our hypothesis matches a Type I approach. The research question specifies the order in which we want to consider the factors. Since Type I ANOVA is dependent on the order in which factors are specified in the model, we are able to incorporate the desired order from our research question into the analysis."
  },
  {
    "objectID": "unbalanced.html#type-ii-1",
    "href": "unbalanced.html#type-ii-1",
    "title": "Analysis of Unbalanced Data",
    "section": "Type II",
    "text": "Type II\nYou may want to use a Type II ANOVA if the disparity in sample sizes reflects a similar disparity in population size. Perhaps your end goal is to apply the treatment to all members of the population and you want any difference observed in the study to be present in the population. In that case, Type II may be the best choice. This will be more common in observational studies.\nFor example, a web developer randomly assigns website visitors to one of two website designs. The population that visits this website is predominantly male. Therefore, Design A and Design B receive many more males than females. In this case, the lopsided nature of the gender distribution may accurately reflect the population of website visitors being predominantly male.\nThe test of the main effects for gender and website design will be influenced by sample sizes. Say we conclude that people tend to buy more products when presented with website B. This conclusion will be influenced more heavily by males since males represented a larger proportion of the sample. But in this case that’s okay because males also represent a larger part of our target audience (website visitors)."
  },
  {
    "objectID": "unbalanced.html#type-iii-1",
    "href": "unbalanced.html#type-iii-1",
    "title": "Analysis of Unbalanced Data",
    "section": "Type III",
    "text": "Type III\nLet’s continue with the website design and gender study mentioned above. Now, instead of taking the role of a business owner, we assume the role of a cognitive psychologist. We are not interested in trying to maximize profits for a target market. Rather, we are interested in knowing how individuals respond to the two different site designs. The fact that we partnered with a website with predominantly male clientele is incidental. We want to arrive at conclusions that will be useful in explaining/predicting behavior of an individual.\nIf we use Type II ANOVA the result of the significance test will be confounded with the fact that males account for a larger portion of the sample. A Type III ANOVA will not weight by sample size and will treat the estimated means of males and females equally. Thus our results can be used to predict an individual’s behavior based on their gender and website design. Our findings can now be used by other websites with a different clientele (e.g. predominantly female) to correctly predict/explain individual’s actions."
  },
  {
    "objectID": "unbalanced.html#summary",
    "href": "unbalanced.html#summary",
    "title": "Analysis of Unbalanced Data",
    "section": "summary()",
    "text": "summary()\nMany students are in the habit of using summary() to evaluate model hypothesis tests. When called on an aov object (i.e. an object created using the aov() command), summary()’ prints a Type I ANOVA table.\nHowever, when called on an lm() object, summary() does not print an ANOVA table at all. The default output is to print variable coefficients, standard deviations, and t-test results (t statistic and p-value). If the object has an independent, categorical factor variable a t-test will be conducted for the factor levels. (Actually, all but 1 factor level will be tested. The missing factor level is considered the reference level and is included in the intercept). If there are only two factor levels, the p-value from the t-test of that factor will be equal to the p-values from a Type III ANOVA applied to the same model.\n\n\nlm() is usually preferred over aov() if there are more than 1 numeric independent variables in the model.\nTo get an ANOVA table and the F-tests for a factor’s overall significance you can call car::Anova() or anova() on an lm() object."
  },
  {
    "objectID": "unbalanced.html#footnotes",
    "href": "unbalanced.html#footnotes",
    "title": "Analysis of Unbalanced Data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor a brief, accessible description of how orthogonality relates to balanced designs, read here: https://www.statisticshowto.com/orthogonality/. The last sentence states “Orthogonality is present in a model if any factor’s effects sum to zero across the effects of any other factors in the table.” We know a factor’s effects sum to zero, and when factors are crossed, the above quoted statement is also true IF there are an equal number of replicates at each factor level. When the number of replicates is not equal, the sum across factor levels is not guaranteed to be exactly zero; so, orthogonality is no longer guaranteed.↩︎\nhttps://stats.stackexchange.com/questions/552702/multifactor-anova-what-is-the-connection-between-sample-size-and-orthogonality↩︎\n Journal of Animal Ecology, Volume: 79, Issue: 2, Pages: 308-316, First published: 05 February 2010, DOI: (10.1111/j.1365-2656.2009.01634.x)↩︎\nShaw, R.G. & Mitchell-Olds, T. (1993) ANOVA for unbalanced data: an overview. Ecology, 74, 1638–1645.↩︎\n Journal of Animal Ecology, Volume: 79, Issue: 2, Pages: 308-316, First published: 05 February 2010, DOI: (10.1111/j.1365-2656.2009.01634.x)↩︎\nThere is also the possibility the total sum of squares is more than the sum of squares total due to “double counting” the variation. This is much more difficult to illustrate with Venn diagrams.↩︎"
  },
  {
    "objectID": "testqmd.html",
    "href": "testqmd.html",
    "title": "Describing Data",
    "section": "",
    "text": "A section to reference another file\n\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nDP Example code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\nNew section\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output."
  },
  {
    "objectID": "sources_of_variances.html",
    "href": "sources_of_variances.html",
    "title": "Sources of Variation - Factors and Conditions",
    "section": "",
    "text": "Once the response variable is determined, it is important to identify all possible factors and conditions that could influence the data measurements. Factors are often referred to as explanatory variables because they explain the variation in the response variable. They are also called independent variables since the response variable is thought to depend on the value of the factor. For each factor you identify, determine how you want it to influence your experiment. List those factors that you will be controlling during the experiment. List those factors and conditions that you will purposely hold constant. List those factors and conditions that you cannot control and determine if the values of those factors can be measured or not. Each of these lists will now be discussed in further detail.\n\n\nThese factors are of high importance because the experiment is specifically designed to determine if each controlled factor is influencing the data values. When you decide to control a factor, you must then decide which groups (or values) will be tested for that factor. These groups are called levels. It is important to remember that samples need to be taken at each level, so a reasonable, but not overwhelming, number of levels should be included, somewhere from 2 to 8 levels.\nOne level of the factor to consider is a control group. A control group is often used to establish a baseline for comparisons and can establish a cause-and-effect relationship by helping the researcher understand its effect on the response variable. A control group is often given a placebo. For example, in a study testing a medication’s efficacy, subjects in the control group receive no actual medication, but are asked to take a sugar pill. The goal of the placebo is to make the experience of the control group and the group that received medication as similar as possible. The very act of taking a pill, or thinking you are receiving medicine, can affect the way you perceive a situation and can even effect the way your body physiologically responds.\nPlacebo does not just refer to medicinal studies. In a study of whether a supervisor’s positive encouragement or negative critiques were more effective at increasing productivity of employees, a placebo group may receive neutral comments. This way, employees’ experience of having an interaction with the supervisor is the same for all 3 groups, but the placebo condition is designed specifically with the goal of not being efficacious.\nAnother issue to consider, which is closely related to placebos, is determining whether the factor level assignment made to a participant should be known to the participants and/or the researchers. When assignments are not known to an individual, the experiment is known as blind. Blinding will reduce potential for bias in the results. Blinding is often used when bias could be introduced if participants know which factor level they are assigned to. If researchers study the impact of pricing on sales of a new product, the participants reaction could be different if they realized other participants were offered a much lower price. If both the participants and researchers do not know the factor level assignments, then it is called double blind.\nIn our toothbrush study, we only discussed looking at the factor of type of toothbrush. This is the factor that we will control in our experiment. The levels would be the 4 different toothbrush types: handheld manual brush, sonic brush, oscillating brush, and ultra-sonic brush. The manual handheld brush could be considered the control group, since it is typically the most common brush, and it makes sense to compare the others to it. The participants would be assigned to a randomly determined brush. It is not possible to blind the participants as to which brush they are using. When the data are collected from the participants it is possible to blind the researchers who are applying the plaque identifying dye and taking the oral pictures. This will remove any biases that could occur from the researchers knowing which brush each participant is using. An example of bias would be if the researcher knew that the participant used a manual handheld brush, so the researcher did not carefully apply the dye or take good pictures because they were not as interested in manual brush results.\n\n\n\nAfter the factors that will be controlled are identified, it is important to list other factors that could influence the data measurements. From that list of factors, identify which factors should be held constant during the experiment, and determine at what value they should be held. Many of the factors you identify may be characteristics of your experimental units. The more uniform that the experimental units and experimental procedures are, the less random uncertainty will be introduced into the experiment. Reducing this unwanted variability will increase the ability of the designed experiment to find significant differences in the controlled factors. This will be discussed in further detail at the end of this section.\nThere are many other factors in our toothbrush study that can affect the amount of plaque on a tooth. We want to hold as many of these constant as we can. Examples of the factors to be held constant and what level to use include: having all participants use the same toothpaste, instructing all participants on how to properly brush their teeth, asking participants to refrain from plaque inducing foods and drinks (give them a specific list of foods/drinks to avoid), having participants brush for the same number of weeks before the data are collected, and asking participants not to floss during the study.\n\n\n\nWhen a factor is not controlled or held constant in an experiment, it would be ideal to be able to measure it, so the researchers can determine if it is influencing the data measurements. This may lead to the necessity of a more complex analysis technique. Later in the course we will discuss using these types of measurements, which are called covariates, and analyzing this data using the analysis of covariance method.\nUnfortunately, uncontrolled factors that change throughout an experiment have the potential to introduce confounding to the study. Confounding occurrs when the effects of one factor cannot be teased apart from the effect of another factor. Consider investigating whether ice cream sales is related to the number of crimes committed in a day. It’s quite possible that higher ice cream sales will occur when higher numbers of crimes are committed. This might lead to the erroneous conclusion that higher ice cream sales result in more crime. In reality, there may be a confounding factor that is influencing both ice cream sales and crime. In this case, that factor could be temperature. As temperature increases, ice cream sales and crime increase. If temperature was not included in the study of crime and ice cream sales, then temperature’s effect cannot be distinguished from the effect of ice cream sales on crime rates. In other words, temperature is confounded with ice cream sales.\nAs shown from this example, confounding can lead to your analysis showing that a controlled factor has significant influence on the response variable when, in fact, there was another factor that may be the real cause of the influence. Measuring an uncontrolled factor will at least allow you to determine if confounding was an issue, it will not, however, fix an issue of confounding. The best way to avoid confounding is to hold uncontrolled factors constant or include the possibly confounding factor as a controlled factor in a well-designed experiment. Even factors that are both included in an experiment can be confounded, especially if the experiment is not designed well.\nWith the toothbrush study, it is quite possible that each participant starts with some amount of plaque which could confound the effect of the brush. One solution would be to clean all the teeth, as well as possible, so that the participant’s initial plaque amount is at (or very close) to zero. Thus, the experimental units would be more uniform. Even after cleaning, the teeth may not be fully clean. So, in addition, you could redefine the response variable to be the difference in initial plaque and ending plaque amount. You could also include the initial plaque amount as a covariate factor in the analysis.\n\n\n\nFrom the list of factors that you will not be controlling or holding constant, there may be factors that cannot be measured. These factors have the potential to cause issues with your experiment. Randomization in your assignment of factor levels to participants and randomization within the experimental process are the best way to minimize the bias that may be introduced due to these factors. Randomization will be discussed in more detail in the next section.\nThe variability caused by factors that are neither controlled nor measured is called random error. These factors may be known or completely unknown. If there is a systematic pattern with the random error, then the random errors will be biased. If the measurements are quite spread out, then the random error is large and the measurements have low reliability. Reliability is a measure of how consistently repeatable the measurements are when values of the measured/controlled factors are identical.\nFigure 1 shows how bias and reliability work. Consider each target, where the bullseye (center of the target) is the truth. Plot 1 is ideal: the measurements (the blue points) have low bias, meaning the measurements are centered around the bullseye, and are close together, meaning the reliability is high. Plot 2 shows substantial bias (points are centered far from the bullseye), although the measurements are highly reliable. Plot 3 shows a low bias in the measurements as they centered near, but not exactly around the bullseye; but the random error is large, meaning low reliability. Plot 4 shows a high bias (measurements centered far from the bullseye) and a low reliability (large variability in the measurements).\nThe systematic variability that causes the high bias as shown in Plots 2 and 4 distorts the results from the truth, which can cause erroneous conclusions to be made. While highly reliable measurements are desirable, measurements that result in low reliability may still result in meaningful conclusions. Though an experiment should strive for low bias and high reliability, reducing bias is usually the top priority. Randomization, as discussed in the next section, is a way to reduce possible bias.\n\n\n\nFigure 1: Four targets illustrating bias and reliability\n\n\nExperiments designed to achieve high reliability increase a study’s statistical power. Statistical power is the probability of finding significant differences between levels of a factor, when, in fact, those differences are real. We will now discuss conceptually how different sources of variation make up the analyses."
  },
  {
    "objectID": "sources_of_variances.html#factors-controlled-during-the-experiment",
    "href": "sources_of_variances.html#factors-controlled-during-the-experiment",
    "title": "Sources of Variation - Factors and Conditions",
    "section": "",
    "text": "These factors are of high importance because the experiment is specifically designed to determine if each controlled factor is influencing the data values. When you decide to control a factor, you must then decide which groups (or values) will be tested for that factor. These groups are called levels. It is important to remember that samples need to be taken at each level, so a reasonable, but not overwhelming, number of levels should be included, somewhere from 2 to 8 levels.\nOne level of the factor to consider is a control group. A control group is often used to establish a baseline for comparisons and can establish a cause-and-effect relationship by helping the researcher understand its effect on the response variable. A control group is often given a placebo. For example, in a study testing a medication’s efficacy, subjects in the control group receive no actual medication, but are asked to take a sugar pill. The goal of the placebo is to make the experience of the control group and the group that received medication as similar as possible. The very act of taking a pill, or thinking you are receiving medicine, can affect the way you perceive a situation and can even effect the way your body physiologically responds.\nPlacebo does not just refer to medicinal studies. In a study of whether a supervisor’s positive encouragement or negative critiques were more effective at increasing productivity of employees, a placebo group may receive neutral comments. This way, employees’ experience of having an interaction with the supervisor is the same for all 3 groups, but the placebo condition is designed specifically with the goal of not being efficacious.\nAnother issue to consider, which is closely related to placebos, is determining whether the factor level assignment made to a participant should be known to the participants and/or the researchers. When assignments are not known to an individual, the experiment is known as blind. Blinding will reduce potential for bias in the results. Blinding is often used when bias could be introduced if participants know which factor level they are assigned to. If researchers study the impact of pricing on sales of a new product, the participants reaction could be different if they realized other participants were offered a much lower price. If both the participants and researchers do not know the factor level assignments, then it is called double blind.\nIn our toothbrush study, we only discussed looking at the factor of type of toothbrush. This is the factor that we will control in our experiment. The levels would be the 4 different toothbrush types: handheld manual brush, sonic brush, oscillating brush, and ultra-sonic brush. The manual handheld brush could be considered the control group, since it is typically the most common brush, and it makes sense to compare the others to it. The participants would be assigned to a randomly determined brush. It is not possible to blind the participants as to which brush they are using. When the data are collected from the participants it is possible to blind the researchers who are applying the plaque identifying dye and taking the oral pictures. This will remove any biases that could occur from the researchers knowing which brush each participant is using. An example of bias would be if the researcher knew that the participant used a manual handheld brush, so the researcher did not carefully apply the dye or take good pictures because they were not as interested in manual brush results."
  },
  {
    "objectID": "sources_of_variances.html#factors-held-constant-during-the-experiment",
    "href": "sources_of_variances.html#factors-held-constant-during-the-experiment",
    "title": "Sources of Variation - Factors and Conditions",
    "section": "",
    "text": "After the factors that will be controlled are identified, it is important to list other factors that could influence the data measurements. From that list of factors, identify which factors should be held constant during the experiment, and determine at what value they should be held. Many of the factors you identify may be characteristics of your experimental units. The more uniform that the experimental units and experimental procedures are, the less random uncertainty will be introduced into the experiment. Reducing this unwanted variability will increase the ability of the designed experiment to find significant differences in the controlled factors. This will be discussed in further detail at the end of this section.\nThere are many other factors in our toothbrush study that can affect the amount of plaque on a tooth. We want to hold as many of these constant as we can. Examples of the factors to be held constant and what level to use include: having all participants use the same toothpaste, instructing all participants on how to properly brush their teeth, asking participants to refrain from plaque inducing foods and drinks (give them a specific list of foods/drinks to avoid), having participants brush for the same number of weeks before the data are collected, and asking participants not to floss during the study."
  },
  {
    "objectID": "sources_of_variances.html#factors-not-controlled-but-measured-during-the-experiment",
    "href": "sources_of_variances.html#factors-not-controlled-but-measured-during-the-experiment",
    "title": "Sources of Variation - Factors and Conditions",
    "section": "",
    "text": "When a factor is not controlled or held constant in an experiment, it would be ideal to be able to measure it, so the researchers can determine if it is influencing the data measurements. This may lead to the necessity of a more complex analysis technique. Later in the course we will discuss using these types of measurements, which are called covariates, and analyzing this data using the analysis of covariance method.\nUnfortunately, uncontrolled factors that change throughout an experiment have the potential to introduce confounding to the study. Confounding occurrs when the effects of one factor cannot be teased apart from the effect of another factor. Consider investigating whether ice cream sales is related to the number of crimes committed in a day. It’s quite possible that higher ice cream sales will occur when higher numbers of crimes are committed. This might lead to the erroneous conclusion that higher ice cream sales result in more crime. In reality, there may be a confounding factor that is influencing both ice cream sales and crime. In this case, that factor could be temperature. As temperature increases, ice cream sales and crime increase. If temperature was not included in the study of crime and ice cream sales, then temperature’s effect cannot be distinguished from the effect of ice cream sales on crime rates. In other words, temperature is confounded with ice cream sales.\nAs shown from this example, confounding can lead to your analysis showing that a controlled factor has significant influence on the response variable when, in fact, there was another factor that may be the real cause of the influence. Measuring an uncontrolled factor will at least allow you to determine if confounding was an issue, it will not, however, fix an issue of confounding. The best way to avoid confounding is to hold uncontrolled factors constant or include the possibly confounding factor as a controlled factor in a well-designed experiment. Even factors that are both included in an experiment can be confounded, especially if the experiment is not designed well.\nWith the toothbrush study, it is quite possible that each participant starts with some amount of plaque which could confound the effect of the brush. One solution would be to clean all the teeth, as well as possible, so that the participant’s initial plaque amount is at (or very close) to zero. Thus, the experimental units would be more uniform. Even after cleaning, the teeth may not be fully clean. So, in addition, you could redefine the response variable to be the difference in initial plaque and ending plaque amount. You could also include the initial plaque amount as a covariate factor in the analysis."
  },
  {
    "objectID": "sources_of_variances.html#factors-not-controlled-and-not-measured",
    "href": "sources_of_variances.html#factors-not-controlled-and-not-measured",
    "title": "Sources of Variation - Factors and Conditions",
    "section": "",
    "text": "From the list of factors that you will not be controlling or holding constant, there may be factors that cannot be measured. These factors have the potential to cause issues with your experiment. Randomization in your assignment of factor levels to participants and randomization within the experimental process are the best way to minimize the bias that may be introduced due to these factors. Randomization will be discussed in more detail in the next section.\nThe variability caused by factors that are neither controlled nor measured is called random error. These factors may be known or completely unknown. If there is a systematic pattern with the random error, then the random errors will be biased. If the measurements are quite spread out, then the random error is large and the measurements have low reliability. Reliability is a measure of how consistently repeatable the measurements are when values of the measured/controlled factors are identical.\nFigure 1 shows how bias and reliability work. Consider each target, where the bullseye (center of the target) is the truth. Plot 1 is ideal: the measurements (the blue points) have low bias, meaning the measurements are centered around the bullseye, and are close together, meaning the reliability is high. Plot 2 shows substantial bias (points are centered far from the bullseye), although the measurements are highly reliable. Plot 3 shows a low bias in the measurements as they centered near, but not exactly around the bullseye; but the random error is large, meaning low reliability. Plot 4 shows a high bias (measurements centered far from the bullseye) and a low reliability (large variability in the measurements).\nThe systematic variability that causes the high bias as shown in Plots 2 and 4 distorts the results from the truth, which can cause erroneous conclusions to be made. While highly reliable measurements are desirable, measurements that result in low reliability may still result in meaningful conclusions. Though an experiment should strive for low bias and high reliability, reducing bias is usually the top priority. Randomization, as discussed in the next section, is a way to reduce possible bias.\n\n\n\nFigure 1: Four targets illustrating bias and reliability\n\n\nExperiments designed to achieve high reliability increase a study’s statistical power. Statistical power is the probability of finding significant differences between levels of a factor, when, in fact, those differences are real. We will now discuss conceptually how different sources of variation make up the analyses."
  },
  {
    "objectID": "research_objectives.html",
    "href": "research_objectives.html",
    "title": "Research Objectives",
    "section": "",
    "text": "Research objectives focus on the outcomes that the researchers hope to accomplish during their study. This may be done by forming questions of interest and determining how those questions can be answered. An effective way to define research objectives is to follow the SMART process: specific, measurable, achievable, relevant, and time-based.\nSpecific: Define your desired outcomes. These outcomes need to be concisely written. They should be written in a way to reduce confusion. Refine these outcomes as you consider the next steps along the SMART process.\nMeasurable: Objectives will be better understood and accomplished when they are measurable. Designed experiments require the collection of data to determine how objectives are met. The population of the study should be considered, so that the collected data are representative of that population. The collected data need to be appropriate and able to answer the questions posed by the objectives. Some concepts, like happiness, depression, or engagement are not directly measurable. Ensure that whatever is measured in the study can adequately address research objectives. In other words, your study needs to have validity. Validity is the degree a study or a measure actually represents what it claims to represent. The validity of a study may be affected by the quality of the sample and/or the choice of response variable. It is discussed more in the Response Variable page.\nAchievable: Realistic expectations need to be considered when determining objectives. Studies are more effective when the number of objectives is limited and well-focused. Time, resources, and budget need to be strongly considered when creating achievable objectives.\nRelevant: Be careful to make sure that your objectives are relevant to your research and overall goals. Review the literature available concerning your research to help drive your objectives towards relevant outcomes that will be appreciated by others in that research area.\nTime-based: Create a schedule for the main elements of the experiment to keep your research on track. This can be done by defining inch-stones (small tasks and deadlines) and milestones (major tasks and deadlines).\nNow, we’ll apply the SMART process to the toothbrush study example.\n\nSpecific: The research objectives for this study will be 1) determining how well each toothbrush type reduces plaque and 2) determining if there are any significant differences in plaque reduction between these toothbrush types.\nMeasure: Plaque coverage over teeth, measured as a percent of surface area, is measurable with the use of plaque staining dye, an oral camera, and software.\nAchievable: There are only two objectives mentioned in the research objectives, both of which can be answered with the defined measure, keeping this study simple and focused.\nRelevant: Considering that the purpose of our research may be to determine which toothbrush to use, this study should be relevant to those that brush their teeth.\nTime-based: Three inch-stones along the schedule will help us keep on track: 1) find the subjects to be used in the study; 2) collect the data, which would include a 2-month brushing window before collecting the data; and 3) analyze the data. The milestone would be the final report."
  },
  {
    "objectID": "randomization.html",
    "href": "randomization.html",
    "title": "Randomization: Sampling and Assignment",
    "section": "",
    "text": "Samples should be representative of the population as defined in the research objectives. When the sample is different from the population in a systematic way, then bias occurs. Biased samples may still contain useful information, but the population which the sample proports to represent may be different than the actual population represented. Common sources of bias include:\n\nSelection bias – the sampling plan excludes part of the population during selection. Samples taken out of convenience or only from volunteers are examples of possible selection bias.\nMeasurement bias – the measurement method results in measurements that are different from the true values of the response variable. Measurement bias can be caused by uncalibrated equipment, poorly trained personnel, or any step along the experimental process that is not carefully designed or clearly defined.\nNon-response bias – this occurs when data are not available for all the individuals in the sample. If those individuals missing data would respond in a different way than those that did respond, then a bias is introduced.\n\nCare should be taken to minimize bias.\n\n\n\n\n\n\nWarning\n\n\n\nLarger sample sizes are not a remedy for biased samples."
  },
  {
    "objectID": "randomization.html#footnotes",
    "href": "randomization.html#footnotes",
    "title": "Randomization: Sampling and Assignment",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nCobb, G.W. Introduction to Design and Analysis of Experiments. Wiley, 2014.↩︎"
  },
  {
    "objectID": "NestedFactor.html",
    "href": "NestedFactor.html",
    "title": "The Split Plot Design",
    "section": "",
    "text": "This section will describe how to set up and analyze factorial designs with 2 levels of experimental units. This situation occurs when one level of the experiment cannot be easily randomized because of physical constraints. These types of studies are common in agriculture, psychology and laboratory experiments.\nWe introduce the concept of nested experimental designs with a Split-Plot design common in agriculture. We conclude this chapter with a discussion about other versions of nested designs and why different terminologies arise in different contexts.\nA split-plot design consists of a whole-plot factor and a Sub-plot factor.\nBecause of the physical limitation of randomization, whole-plot factors often have limited replications compared to the subplot factor. To analyze these designs appropriately, it is necessary to account for the fact that each level of experimental unit has different levels of replication. It requires 2 separate error terms to test each level of experimental unit.\nConsider 2 examples:\n\nA researcher wants to test the impact of humidity, fungicide and their interaction on tomato yield in greenhouses. Because it is impossible to randomly assign humidity levels within a section of greenhouse, greenhouse would be one level of experimental unit (whole-plot) and fertilizer treatment randomly assigned within a greenhouse would be another level of experimental unit (sub-plot).\nA lab manager would like to test the impact of freezer temperature on the life cycle of certain reagents. It is impossible to randomly assign temperature within a given freezer. To get replications of the whole-plot, we would need to have 2 or more freezers set at the same temperature level to get true replications of the whole-plot factor. We could replicate reagent (sub-plot factor) within freezers.\n\n\n\nReview the discussion on nested subsample. It will be critical to recognizing the challenge of appropriately analyzing a nested design.\nIn this chapter you will learn how to identify levels of experimental units within a nested factorial design and its appropriate analysis. To identify and analyze a nested design, you will need to have a solid understanding of:\n\nExperimental units\nTrue replication\nDegrees of Freedom for Error\n\n\n\n\nConsider an example from agriculture. Farmer John would like to compare yield for a specific variety of maize treated with 2 different fungicides: generic vs premium. Farmer John learned about the importance of independent applications of the experimental levels and gets his neighbor, Farmer Maggot, to participate. Their design is a basic single factor design with 2 replicates:\n\n\n\n\n\nFarmer John could still be interested in the within-field variation and takes sub-samples within a each experimental unit and measures yield at each sample point:\n\n\n\n\n\n\nBecause the treatments are replicated, we can analyze this model as we did in Nested Subsamples:\nWe would need to include the sub-sample term in the model to preserve the appropriate degrees of freedom for error for our whole-plot. In this example, we have N = 4 experimental units and k = 2 levels of the experiment, leaving us with N-k = 2 degrees of freedom for testing Fungicide efficacy.\n\n\nSuppose Farmer John suspects that the impact of fungicide type is different for varieties of maize. We could add 3 maize varieties to the experiment, but because of mechanical constraints we cannot completely randomize Fungicide by Variety treatment combinations. We’re still stuck spraying half the field with Fungicide A and the other with Fungicide B.\n\n\n\n\n\nHopefully you can spot the challenge. Nothing has changed for the fungicide treatment level. If the variety plots are harvested separately, variety is just a sub-sample within Fungicide treatment. We actually have 2 levels of experimental units!\n\n\n\n\n\nWith 2 levels of experimental units, we need 2 separate error terms each with the appropriate degrees of freedom for error (related to the number of true replications for each experimental unit).\nIgnoring Variety for a moment, you can see that the Residual error for Fungicide should be estimated by how the larger experimental units vary. It’s the Field-to-Field variation.\nIf we treat Fungicide treatments as blocks, then the residual error for Variety will be the variety-plot-to-variety-plot variation within the blocks."
  },
  {
    "objectID": "NestedFactor.html#nested-factor-designs",
    "href": "NestedFactor.html#nested-factor-designs",
    "title": "The Split Plot Design",
    "section": "",
    "text": "Review the discussion on nested subsample. It will be critical to recognizing the challenge of appropriately analyzing a nested design.\nIn this chapter you will learn how to identify levels of experimental units within a nested factorial design and its appropriate analysis. To identify and analyze a nested design, you will need to have a solid understanding of:\n\nExperimental units\nTrue replication\nDegrees of Freedom for Error"
  },
  {
    "objectID": "NestedFactor.html#motivating-example",
    "href": "NestedFactor.html#motivating-example",
    "title": "The Split Plot Design",
    "section": "",
    "text": "Consider an example from agriculture. Farmer John would like to compare yield for a specific variety of maize treated with 2 different fungicides: generic vs premium. Farmer John learned about the importance of independent applications of the experimental levels and gets his neighbor, Farmer Maggot, to participate. Their design is a basic single factor design with 2 replicates:\n\n\n\n\n\nFarmer John could still be interested in the within-field variation and takes sub-samples within a each experimental unit and measures yield at each sample point:\n\n\n\n\n\n\nBecause the treatments are replicated, we can analyze this model as we did in Nested Subsamples:\nWe would need to include the sub-sample term in the model to preserve the appropriate degrees of freedom for error for our whole-plot. In this example, we have N = 4 experimental units and k = 2 levels of the experiment, leaving us with N-k = 2 degrees of freedom for testing Fungicide efficacy.\n\n\nSuppose Farmer John suspects that the impact of fungicide type is different for varieties of maize. We could add 3 maize varieties to the experiment, but because of mechanical constraints we cannot completely randomize Fungicide by Variety treatment combinations. We’re still stuck spraying half the field with Fungicide A and the other with Fungicide B.\n\n\n\n\n\nHopefully you can spot the challenge. Nothing has changed for the fungicide treatment level. If the variety plots are harvested separately, variety is just a sub-sample within Fungicide treatment. We actually have 2 levels of experimental units!\n\n\n\n\n\nWith 2 levels of experimental units, we need 2 separate error terms each with the appropriate degrees of freedom for error (related to the number of true replications for each experimental unit).\nIgnoring Variety for a moment, you can see that the Residual error for Fungicide should be estimated by how the larger experimental units vary. It’s the Field-to-Field variation.\nIf we treat Fungicide treatments as blocks, then the residual error for Variety will be the variety-plot-to-variety-plot variation within the blocks."
  },
  {
    "objectID": "NestedFactor.html#degrees-of-freedom",
    "href": "NestedFactor.html#degrees-of-freedom",
    "title": "The Split Plot Design",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nIn this example, there are a total of 36 degrees of freedom to be allocated for each level of the experiment. Special care must be taken to account for the field-level degrees of freedom because they will define the denominator degrees of freedom for the F-test for fungicide.\nFor this example, it is easiest to count up the unique pieces of information in each of the components in figure xx above.\nAs in the case with other models, there is 1 degree of the grand mean.\nBecause all the the other factor effects are constrained to sum to zero, we can reduce the count of unique pieces of information by one to get the degrees of freedom.\nFor the spray effect above, if I know one value the effect for a fungicide, I also know what the others need to be to sum to zero. So I have 1 degree of freedom for Fungicide.\nFor the Field effect, there are 2 values and their negative values which gives us 2 unique pieces of information.\nIf I know 2 of the variety effects, the third one is also known, so I have 2 degrees of freedom.\nThe interaction effect only has 2 degrees of freedom because each of the fungicide treatment combinations must sum to zero across varieties."
  },
  {
    "objectID": "NestedFactor.html#repeated-measures",
    "href": "NestedFactor.html#repeated-measures",
    "title": "The Split Plot Design",
    "section": "Repeated Measures",
    "text": "Repeated Measures\nMany experiments are interested in the effect of a treatment over time. These designs often measure subjects within treatment groups at several time points after treatment. Time is a nested factor measured within-subjects. Individuals become the blocks for measuring the time effect. This type of design is called Repeated Measures.\nIn a Repeated Measures design, we do not refer to subjects as whole-plots and repeated measurements across time as sub-plots, though they behave functionally the same in the analysis. For clarity, we refer to the larger experimental unit (subjects) as the between-subjects factor and the factor associated with time point measurements as the within-subjects factor.\nThe factorization of the Repeated Measures design can be represented (Cobb, 2015) as:\n where CR corresponds to the between-subjects factor and CB refers to the within-blocks factor."
  },
  {
    "objectID": "NestedFactor.html#generic-terminology",
    "href": "NestedFactor.html#generic-terminology",
    "title": "The Split Plot Design",
    "section": "Generic Terminology",
    "text": "Generic Terminology\nIn some instances, larger experimental units are simply referred to as blocks. Treatments assigned to the larger and smaller experimental units are called between-blocks factor and within-blocks factor respectively. This terminology is complicated by the fact that blocks are not always used for experimental treatments."
  },
  {
    "objectID": "latin_square.html",
    "href": "latin_square.html",
    "title": "Latin Square",
    "section": "",
    "text": "The CB[1] design works well when there is only one variable to block on. What can be done when there are two nuisance factors to block on? If those two blocking factors and the treatment all have the same number of levels, then a latin square design should be used.\n\n\n\n\n\n\nWhen to use Latin Square\n\n\n\nLatin Square designs are appropriate when\n\nTwo blocking factors and one treatment factor\nAll three factors have the same number of levels\nTreatments can be assigned to experimental units\n\n\n\nPreviously, in the CB[1] design we used the toothbrush study and blocked on participant. If we only had 4 participants and we considered “order” a nuisance factor, we could use a Latin Square. By adding “order” as a blocking variable, we can ensure that the order of the treatments does not all become the same by random chance alone.\nBlocking on subjects and order of treatments is one of the most common applications of a Latin Square design in psychology. (Treatments, of course, must be something that can be assigned to experimental units). Be aware that in these types of experiments carry-over effects (such as learning and fatigue) can be problematic. Experimental protocols need to proactively address potential carry-over effects1.\nLatin Square designs are also common in agriculture, where they were originally developed. The field is divided into a square grid and treatments are randomly applied to each cell of the grid. The blocking variables are the row position and column position in the grid respectively.\nFigure 1 shows two images of Latin Square designs in agriculture, pulled from Bailey, Cameron, and Connelly’s 2008 article in American Mathematical Monthly 2. Figure 1 (a) is a picture of a 5×5 forestry experiment on a hill in Beddgelert in Wales. The experiment was “designed by Fisher, laid out in 1929, and photographed in about 1945”. Figure 1 (b) shows “a 6×6 experiment to compare methods of controlling aphids; conducted by Lesley Smart at Rothamsted Research, photographed in 2004.”\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n(b)\n\n\n\n\nFigure 1: Agricultural examples of latin squares\n\n\nRegardless of whether the application is psychology, agriculture or something else, the key design feature of a Latin Square design is that each treatment appears exactly once in each row and in each column of the square.\nThere are various extensions to this basic Latin Square idea. Graeco Latin Squares can be used if you have more than 2 variables to block on (provided all factors have the same number of levels, and the number is not 6). Replicated Latin Squares is useful if the number of experimental units is a multiple of (instead of exactly equal to) the number of treatment factor levels. Replicated Latin Squares (including “Latin Rectangles”) is discussed briefly here and here.\n\n\nIn the factor diagram, one nuisance factor’s levels are associated with the row partitions of the dataset. The other nuisance factor’s levels are marked by partitioning the dataset by columns. The treatment is assigned a letter inside the factor diagram. Figure 2 is a factor structure diagram for a Latin Square design where the controlled factors all have 4 levels. This is an unrandomized layout of the treatments: each row (and column) follows the same sequence of treatments. In the Design section we will learn to randomize the design.\n\n\n\nFigure 2: Factor Structure for Latin Square Design with 4 Treatment Levels\n\n\n\n\n\nEach factor (i.e. meaningful partition of the data) in Figure 2 corresponds to a term on the right hand side of Equation 1:\n\\[\ny_{ijk} = \\mu + \\alpha_i + \\beta_j + \\gamma_k + \\epsilon_{ijk}\n\\tag{1}\\]\nWhere\n\n\\(y_{ij}\\) is the observation that belongs to level i of \\(\\alpha\\), level j of \\(\\beta\\), and level k of \\(\\gamma\\).\n\\(\\mu\\) is the grand mean of the entire dataset.\n\\(\\alpha\\) is the effect of the block factor partitioned by rows\n\\(\\beta\\) is the effect of the block factor partitioned by columns\n\\(\\gamma\\) is the effect of the treatment factor, designated by a letter value. Each treatment appears exactly once in each row and each column.\n\\(\\epsilon\\) is the residual error term\n\nThe Latin Square is an incomplete block design. In other words, each treatment does not show up in each block. In other words, not all subscript combinations of i, j, and k will be observed. Therefore there are insufficient observations to estimate and test interaction effects.\nThe hypothesis for the treatment is\n\\[H_0: \\gamma_k = 0 \\text{ for all }k\\]\n\\[H_a: \\gamma_k \\ne 0 \\text{ for some }k\\]\n\n\nThe focus of the study is on the treatment factor. However, you can test the block factors in the same way you test the treatment factor.\n\n\n\nAn ANOVA model may be used to analyze data from a LS[1] design if the following requirements are satisfied.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "latin_square.html#factor-structure",
    "href": "latin_square.html#factor-structure",
    "title": "Latin Square",
    "section": "",
    "text": "In the factor diagram, one nuisance factor’s levels are associated with the row partitions of the dataset. The other nuisance factor’s levels are marked by partitioning the dataset by columns. The treatment is assigned a letter inside the factor diagram. Figure 2 is a factor structure diagram for a Latin Square design where the controlled factors all have 4 levels. This is an unrandomized layout of the treatments: each row (and column) follows the same sequence of treatments. In the Design section we will learn to randomize the design.\n\n\n\nFigure 2: Factor Structure for Latin Square Design with 4 Treatment Levels"
  },
  {
    "objectID": "latin_square.html#model-and-hypotheses",
    "href": "latin_square.html#model-and-hypotheses",
    "title": "Latin Square",
    "section": "",
    "text": "Each factor (i.e. meaningful partition of the data) in Figure 2 corresponds to a term on the right hand side of Equation 1:\n\\[\ny_{ijk} = \\mu + \\alpha_i + \\beta_j + \\gamma_k + \\epsilon_{ijk}\n\\tag{1}\\]\nWhere\n\n\\(y_{ij}\\) is the observation that belongs to level i of \\(\\alpha\\), level j of \\(\\beta\\), and level k of \\(\\gamma\\).\n\\(\\mu\\) is the grand mean of the entire dataset.\n\\(\\alpha\\) is the effect of the block factor partitioned by rows\n\\(\\beta\\) is the effect of the block factor partitioned by columns\n\\(\\gamma\\) is the effect of the treatment factor, designated by a letter value. Each treatment appears exactly once in each row and each column.\n\\(\\epsilon\\) is the residual error term\n\nThe Latin Square is an incomplete block design. In other words, each treatment does not show up in each block. In other words, not all subscript combinations of i, j, and k will be observed. Therefore there are insufficient observations to estimate and test interaction effects.\nThe hypothesis for the treatment is\n\\[H_0: \\gamma_k = 0 \\text{ for all }k\\]\n\\[H_a: \\gamma_k \\ne 0 \\text{ for some }k\\]\n\n\nThe focus of the study is on the treatment factor. However, you can test the block factors in the same way you test the treatment factor."
  },
  {
    "objectID": "latin_square.html#assumptions",
    "href": "latin_square.html#assumptions",
    "title": "Latin Square",
    "section": "",
    "text": "An ANOVA model may be used to analyze data from a LS[1] design if the following requirements are satisfied.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "latin_square.html#r-randomization",
    "href": "latin_square.html#r-randomization",
    "title": "Latin Square",
    "section": "R randomization",
    "text": "R randomization\n\nWide format\nIf the design is laid out similar to the factor structure diagram it is considered to be in wider format. This code creates a table in wider format of the unrandomized design.\n\n#First create the unrandomized layout design, labeling the rows and columns as 1, 2, 3, 4\nls_design &lt;- tibble(`1` = c(`1`  = \"A\", `2` =\"B\", `3`=  \"C\", `4` = \"D\"), \n                             `2` = c(\"B\", \"C\", \"D\", \"A\"), \n                             `3` = c(\"C\", \"D\", \"A\", \"B\"), \n                             `4` = c(\"D\", \"A\", \"B\", \"C\"))\nls_design\n\n# A tibble: 4 × 4\n  `1`   `2`   `3`   `4`  \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 A     B     C     D    \n2 B     C     D     A    \n3 C     D     A     B    \n4 D     A     B     C    \n\n\nOne simple way is to carry out the randomization is to use the sample() command in conjunction with the [] notation. The sample() command randomly shuffles the values it is given. The square brackets allow you to reference rows and columns of a matrix. The first argument in the square brackets refers to rows, the second argument refers to columns.\n\n#Then randomize rows\nset.seed(42)\nrow_randomized &lt;- ls_design[sample(nrow(ls_design)), ]\n\nset.seed(42)\n#Then randomize columns\nall_randomized &lt;- row_randomized[ , sample(ncol(row_randomized))]\n\nset.seed(17)\n#The above randomization steps can be combined into one command\nls_design[ sample(nrow(ls_design)), sample(ncol(ls_design))]\n\n# A tibble: 4 × 4\n  `3`   `4`   `1`   `2`  \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 D     A     B     C    \n2 C     D     A     B    \n3 B     C     D     A    \n4 A     B     C     D    \n\n\n\n\nLonger format\nThe R language often wants data in longer format. To create the unrandomized design in longer format, use this code:\n\ntibble(row_blocks = rep(1:4, each = 4), \n       column_blocks = rep(1:4, times = 4),\n       treatment = c(\"A\", \"B\", \"C\", \"D\", \n                     \"B\", \"C\", \"D\", \"A\", \n                     \"C\", \"D\", \"A\", \"B\",\n                     \"D\", \"A\", \"B\", \"C\"))\n\n# A tibble: 16 × 3\n   row_blocks column_blocks treatment\n        &lt;int&gt;         &lt;int&gt; &lt;chr&gt;    \n 1          1             1 A        \n 2          1             2 B        \n 3          1             3 C        \n 4          1             4 D        \n 5          2             1 B        \n 6          2             2 C        \n 7          2             3 D        \n 8          2             4 A        \n 9          3             1 C        \n10          3             2 D        \n11          3             3 A        \n12          3             4 B        \n13          4             1 D        \n14          4             2 A        \n15          4             3 B        \n16          4             4 C        \n\n\nTo randomize the rows and columns, put the vector 1:4 within the sample() command when defining the row blocks and the column blocks, as shown below:\n\n#randomize rows\nset.seed(42)\nrandomized_design &lt;- tibble(row_blocks = rep(sample(1:4), each = 4),\n                            column_blocks = rep(sample(1:4), times = 4),\n                            treatment = c(\"A\", \"B\", \"C\", \"D\", \n                                          \"B\", \"C\", \"D\", \"A\", \n                                          \"C\", \"D\", \"A\", \"B\",\n                                          \"D\", \"A\", \"B\", \"C\"))\nrandomized_design\n\nAfter carrying out the experiment and gathering data, a vector containing the observed values can be added to the dataset using mutate(), cbind(), or dplyr::bind_col() from the tidyverse. Only the cbind() option is shown in the code below.\n\n#Store observed data in a vector. \n# These observed values are copmletely made up\nobserved_values &lt;- c(-1, 2, 6, 11, -5, 2, 7, 5, 4,-2, -3, 8, 8, 2, 1, 0)\ncbind(randomized_design, observed_values)"
  },
  {
    "objectID": "latin_square.html#degrees-of-freedom",
    "href": "latin_square.html#degrees-of-freedom",
    "title": "Latin Square",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nAs is the case with other designs learned so far, the grand mean factor is outside of all other factors. There is only one grand mean associated with the dataset, so there is just one degree of freedom associated with grand mean.\nThe general rule for calculating degrees of freedom states that the degrees of freedom for a factor are equal to the number of levels of that factor minus the sum of degrees of freedom of all outside factors.\nGrand mean is the only factor outside of intersection (rows), time of day (column), and treatment (algorithm)5. Therefore, for each of these factors we can take their number of levels and subtract one; the degrees of freedom for the 3 structural factors are 4-1 = 3.\nThere is one residual for each observation, therefore the number of factor levels for residual is equal to the sample size, 16. The residual factor is inside of all other factors, so degrees of freedom for residual is 16 – (1 + 3 + 3 + 3) = 66."
  },
  {
    "objectID": "latin_square.html#factor-effects",
    "href": "latin_square.html#factor-effects",
    "title": "Latin Square",
    "section": "Factor Effects",
    "text": "Factor Effects\nTo calculate factor effects, we start by calculating means for each level of every factor.\n\nFactor Means\nBelow is a table that contains observed throughput for the combinations of intersection, time of day, and algorithm (represented as A, B, C or D).\n\nObserved Throughput for Traffic Light Timing Algorithm Experiment\n\n\n\n8am\n11am\n2pm\n5pm\n\n\n\n\nIntersection 1\nA (32)\nB (33)\nC (47)\nD (53)\n\n\nIntersection 2\nB (36)\nD (53)\nA (42)\nC (54)\n\n\nIntersection 3\nC (51)\nA (44)\nD (62)\nB (49)\n\n\nIntersection 4\nD (81)\nC (78)\nB (72)\nA (73)\n\n\n\nThe grand mean and the mean of each factor level will be calculated for the 3 structural factors.\nThe grand mean is simply the mean of all the observations and is equal to 53.8.\nThe calculation to find the mean of an intersection (row) are as follows:\n\\[\n\\bar{y}_\\text{intersection 1} = \\bar{y}_{1\\cdot\\cdot} = \\frac{32 + 33 + 47 +  53}{4} = 41.3\n\\]\n\nSimilar calculations can be applied to obtain the row mean for the other rows.\nNow find the mean for each time of day (column). The calculation for the first column is shown below. Similar calculations can be applied to obtain the mean for each of the other columns as well.\n\\[\n\\bar{y}_\\text{8am} = \\bar{y}_{\\cdot 1 \\cdot} = \\frac{32 + 36 + 51 + 81}{4} = 50\n\\]\nTo find the mean for each algorithm, we add together the 4 observations that belong to each algorithm and divide by four.\n\\[\\begin{align}\n\\bar{y}_A = \\bar{y}_{\\cdot \\cdot 1} &= \\frac{32 + 44 + 42 + 73}{4} = 47.8 \\\\\n\n\\bar{y}_B = \\bar{y}_{\\cdot \\cdot 2} &= \\frac{36 + 33 + 72 + 79}{4} = 47.5 \\\\\n\n\\bar{y}_C = \\bar{y}_{\\cdot \\cdot 3} &= \\frac{51 + 78 + 47 + 54}{4} = 57.5 \\\\\n\n\\bar{y}_D = \\bar{y}_{\\cdot \\cdot 4} &= \\frac{81 + 53 + 62 + 53}{4} = 62.3\n\\end{align}\\]\nWe do not need to calculate means for residual error factor for two reasons. First, there is only one observation per level of residual error, so the mean is the observation itself. Second, nothing is inside of residual error. It is the last step in the process and its mean is not needed to calculate factor effects.\nThe means for each factor level are shown in Figure 4.\n\n\n\nFigure 4: Factor Level Means\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe means in the image are rounded to 1 decimal place to save on space, but calculations should take advantage of full decimal precision."
  },
  {
    "objectID": "latin_square.html#factor-effects-1",
    "href": "latin_square.html#factor-effects-1",
    "title": "Latin Square",
    "section": "Factor Effects",
    "text": "Factor Effects\nNow that means for each level of each factor are calculated, we can move on to calculate effects of the factor levels. We will use the general formula for calculating effect size,\n\\[\n\\text{factor level effect} = \\text{factor level mean} - \\text{sum of all outside factor effects}\n\\]\nFor the grand mean, there is only one level and there are no outside factors. Therefore, the effect due to grand mean is 53.8 (equivalent to its mean) and this affect is applied to all 16 observations.\nThe intersection factor has four levels: one for each intersection. To calculate the effect of an intersection, take the intersection mean and subtract it from the effect due to the grand mean factor. For the intersection 1 this looks like:\n\\[\n41.25 - 53.75 = -12.5\n\\]\nThis result indicates that the mean throughput at intersection 1 is 12.5 fewer cars than the grand mean. Effects for the other 3 intersections are found with a similar calcultion.\nTo find the effect of a specific time of day, subtract the grand mean from the level’s mean. For “8am”, the calculation is\n\\[\n50 - 53.75 = -3.75\n\\]\nEffects of the other times of day are similarly calculated.\nTo find the effect of timing algorithm A, subtract the grand mean from the mean of algorithm A:\n\\[\n47.75 - 53.75 = -6\n\\]\nSimilarly, the effect of algorithm B is \\(47.5 - 53.75 = 3.25\\), algorithm C’s effect is \\(57.5 - 53.75 = 3.75\\) and D’s effect is \\(62.26 - 53.75 = 8.5\\).\nLastly, the residuals (or residual effects) need to be calculated. The mean for each level of residual is simply the observation itself. Effects associated with an observation’s factor levels are subtracted from the observed value. Whatever is left over is considered the residual. In other words, we have applied the general rule for calculating effect size. For the residual factor, the effect can concisely be stated as “observed value - predicted value”.\nAs an example, the residual in the top left corner of the residual factor was obtained with this calculation:\n\\[\n32 - (53.75 + -12.5 + -3.25 + -6) = 0.5\n\\]\nFigure 5 uses the factor structure diagram to show the build-up of each observations as the summation of each of its factor level effects.\n\n\n\n\nFigure 5: Factor Effects"
  },
  {
    "objectID": "latin_square.html#completing-the-anova-table",
    "href": "latin_square.html#completing-the-anova-table",
    "title": "Latin Square",
    "section": "Completing the ANOVA Table",
    "text": "Completing the ANOVA Table\nNow that we have calculated degrees of freedom and effects for each factor, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. A completed ANOVA summary table contains the information we need for a hypothesis test of the treatment effect.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. The total degrees of freedom are the total number of observations.\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n\n\n\n\n\n\nIntersection (row)\n3\n\n\n\n\n\n\nTime of day (column)\n3\n\n\n\n\n\n\nAlgorithm (treatment)\n3\n\n\n\n\n\n\nResidual Error\n6\n\n\n\n\n\n\nTotal\n16\n\n\n\n\n\n\n\n\n\n\n\nTo get the sum of squares (SS) of a factor, the effects of the factor must be squared, and then summed. The factor effects were displayed in Figure 5 above. Figure 6 (below) shows squared effects for the factors, excluding the grand mean and the observations.\n\n\n\n\nFigure 6: Squared Factor Effects\n\n\n\nThe total sum of squares (\\(SS_{total}\\)) represents all the squared variability that we will need to allocate to the various factors. It is calculated by squaring each observation and then summing them together:\n\\[\nSS_{total} = 32^2 + 33^2 + … + 73^2 = 49856\n\\]\nTo get the Sum of Squares for the grand mean factor we first square the effect of grand mean, \\(53.75^2 = 2889.0625\\). That value occurs 16 times in the dataset (once for each observation), so \\(SS_\\text{grand mean} = 2889.0625 * 16 = 46225\\).\nTo get the sum of squares for each factor, we simply add all the squared effects. Since for intersections, time of day, and timing algorithm, each effect is repeated exactly 4 times, we will use some multiplication to simplify the calculation:\n\\[\\begin{align}\n\nSS_\\text{intersections} &= 4*(156.3 + 56.3 + 5.1 + 495.1) = 2850.5 \\\\\n\nSS_\\text{time of day} &= 4 *(14.1 + 3.1 + 4 + 12.3) = 133.5 \\\\\n\nSS_\\text{algorithm} &= 4 * (36 + 39.1 + 14.1 + 72.3) = 645.5 \\\\\n\nSS_\\text{residual} &= 4 * (0.25 + 0.06 + 0 + 0.06) = 1.5\n\\end{align}\\]\nPutting this information into the ANOVA table gives us Table 1.\n\n\n\n\nTable 1: Sums of squares\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n46225.0\n\n\n\n\n\nIntersection (row)\n3\n2850.5\n\n\n\n\n\nTime of day (column)\n3\n133.5\n\n\n\n\n\nAlgorithm (treatment)\n3\n645.5\n\n\n\n\n\nResidual Error\n6\n1.5\n\n\n\n\n\nTotal\n16\n49856.0\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can verify that we have successfully partitioned out the SS_total, try adding the sum of squares for all the factors together. The result should be equal to the sum of squares you got by squaring the observed values and summing them.\nThe next step is to covert the total variability (sum of squares) to an average variability per factor (mean squares). To create an average from a total, you must divide by the number of informative pieces of information that were summed to create the total, in this case the degrees of freedom. The mean squares can be thought of as the sample variance between factor level means.\nObtain the mean squares for each factor by dividing its sum of squares by its degrees of freedom.\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n46225.0\n46225.00\n\n\n\n\nIntersection (row)\n3\n2850.5\n950.17\n\n\n\n\nTime of day (column)\n3\n133.5\n44.50\n\n\n\n\nAlgorithm (treatment)\n3\n645.5\n215.17\n\n\n\n\nResidual Error\n6\n1.5\n0.25\n\n\n\n\nTotal\n16\n49856.0\n3116.00\n\n\n\n\n\n\n\n\n\nThe objective of the study was to evaluate differences in timing algorithms of traffic lights. The intersection and time of day factors were simply nuisance factors we blocked on to better isolate the effect of timing algorithm. For that reason, we will only show the hypothesis test of the treatment factor (algorithm) here, though a similar test could be done for the blocking factors (intersection and time of day).\nIn Equation 1, \\(\\gamma\\) represents the effect of algorithm. Our hypotheses therefore are\n\\[\nH_o: \\gamma_k = 0 \\text{, for all } k\n\\]\n\\[\nH_a: \\gamma_k \\ne 0 \\text{, for some } k\n\\]\nTo test the hypothesis, we need to compare the mean square (MS) for algorithm to the mean square for residual error (abbreviated as MSE). This ratio of variances is called an F statistic.\n\\[\n\\text{F statistic} = \\frac{MS_{algorithm}}{MS_{error}} = \\frac{215.1\\overline{6}}{0.25} = 860.\\overline{6}\n\\]\nThis F statistic has 3 and 6 degrees of freedom, written as \\(F_{3,6} = 860.\\overline{6}\\). This is a huge F statistic.\nThe associated p-value is approximately zero as calculated in Excel with the function = f.dist.rt(860.6667, 3, 6).\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n46225.0\n46225.00\n\n\n\n\nIntersection (row)\n3\n2850.5\n950.17\n\n\n\n\nTime of day (column)\n3\n133.5\n44.50\n\n\n\n\nAlgorithm (treatment)\n3\n645.5\n215.17\n860.667\n0\n\n\nResidual Error\n6\n1.5\n0.25\n\n\n\n\nTotal\n16\n49856.0\n3116.00\n\n\n\n\n\n\n\n\n\nWe can conclude from these results that at least one of the timing algorithms has a statistically significant effect on the number of cars flowing through an intersection. As calculated earlier, Algorithm D had the largest positive effect on throughput at an intersection and it seems reasonable to recommend this algorithm to those in charge of traffic lights."
  },
  {
    "objectID": "latin_square.html#check-assumptions",
    "href": "latin_square.html#check-assumptions",
    "title": "Latin Square",
    "section": "Check Assumptions",
    "text": "Check Assumptions\nFor a more detailed explanation of the code, output, and theory behind these assumptions visit the Assumptions page.\n\nConstant Variance of Residuals\nThe residuals need to demonstrate constant variance, regardless of the fitted or predicted value. We use a residual plot to check this assumption.\n\n\nCode\nplot(my_ls_aov, which = 1)\n\n\n\n\n\nFigure 8: Checking constant variance\n\n\n\n\n\n\nIgnore the red line in this plot\nThe x-axis of Figure 8 shows the fitted values, also called predicted values. An observation’s fitted value is the sum of the effects contributing to a datapoint: it includes all effects except for the residual effect. The residual is plotted on the y-axis.\nThe points in the plot do not show any increase (or decreasing) in vertical spread as we move along the x-axis. Therefore, we conclude this requirement is met.\n\n\nNormally Distributed Residuals\nWe check the assumption that residuals are normally distributed in Figure 9. All the points are in the shaded region.\n\n\nCode\ncar::qqPlot(my_ls_aov$residuals, id = FALSE)\n\n\n\n\n\nFigure 9: Checking normality of residuals\n\n\n\n\n\n\nIndependent Residuals\nThe dataset we are analyzing does not include information about the order in which the data was collected. In fact, it is possible some conditions of the experiment were run simultaneously and there is no specific order. From what we know, there is no reason to think there is a potential order bias."
  },
  {
    "objectID": "latin_square.html#summary",
    "href": "latin_square.html#summary",
    "title": "Latin Square",
    "section": "Summary",
    "text": "Summary\nThe ANOVA model assumptions all appear to be met. We can trust the p-values in the ANOVA summary table. Thus we conclude algorithm has a significant effect on throughput. To gain further insight, pairwise comparisons for the algorithm levels could be run."
  },
  {
    "objectID": "latin_square.html#footnotes",
    "href": "latin_square.html#footnotes",
    "title": "Latin Square",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA carry-over effect occurs when the effect of a treatment applied to block spreads beyond the borders of the block. For example, a fertilizer applied to a particular area is carried by wind or water to some adjacent area that is supposed to be receiving a different treatment.\nIn the case of temporal (rather than spatial) blocks, a carry-over effect occurs when the effect of the previous treatment influences the outcome for a particular subject even after the subject has begun a new phase of the experiment under a different treatment condition.\nCarry over effects also include when effects of repetition (such as learning or fatigue) are mixed with effects of the treatment, and the two become confounded.↩︎\nBailey, R. & Cameron, Peter & Connelly, R.. (2008). Sudoku, Gerechte Designs, Resolutions, Affine Space, Spreads, Reguli, and Hamming Codes. American Mathematical Monthly. 115. 10.1080/00029890.2008.11920542.↩︎\nSince this sequence is randomly generated, running the same code on your machine will give a different sequence each time you run it. You can create the sequence by first running set.seed(6), and then sample(1:4). If sample(1:4) command is run again without resetting the random seed or doing any other random sampling, the result will be the sequence which was obtained for the columns in step 2.↩︎\nSince this sequence is randomly generated, running the same code on your machine will give a different sequence each time you run it. You can create the sequence by first running set.seed(6), and then sample(1:4). If sample(1:4) command is run again without resetting the random seed or doing any other random sampling, the result will be the sequence which was obtained for the columns in step 2.↩︎\nDeciding whether the treatment factor is inside or outside of another factor is a little unusual since the partitions for treatment are not contiguous. However, the definition of outside or inside is still the same. Let’s look at the relationship between treatment at grand mean.\n\nTreatment A fits nicely inside of the Grand Mean partition. The partitions for the other treatment levels also fit in Grand Mean; so Treatment is “inside” of Grand Mean.\nTreatment and the Column Factor can also be investigated. In this case, level A of Treatment does not fit nicely inside of the column factor. In fact, one level of Treatment spans all 4 levels of the column factor. Treatment is certainly not inside of the Column Factor.\n\nWe can also see that the Column Factor partitions do not fit inside of Treatment.\n\nThe factors are crossed since each level of Treatment appears in combination with each level of the Column Factor. A similar process can be carried out to determine that Treatment and the Row Factor are also crossed.↩︎\nThe counting free numbers approach of determining degrees of freedom for residuals may be less clear to apply than it was in other designs due to the non-continuous partitions of the treatment factor. There are 3 structural factors: rows, columns, and treatments. (In the traffic example, that corresponds to intersections, times of day, and timing algorithm respectively). The residuals in each of these partitions must sum to zero.\nFor the treatment, all the residuals for observations from Treatment A must sum to zero. Similarly, the observations from Treatment B will have residuals that sum to zero. And so on for each treatment. It is not obvious in the factor diagram which observation should be chosen as “locked” and which ones we can count as free to vary. But consider for a moment that in any row, each of the treatments appears only once. We will select a row (let’s use the top row for convenience), and say that each of those residuals is “locked”. This essentially reduces the residual factor from a 4x4 table of free values, to a 3x4 table.\n\nNow apply the fact that in order to sum to zero across rows, the last value in each row is “locked”. Similarly, the residuals for each level of the column factor of the remaining 3x4 table of free values must also sum to zero. Therefore, the last (bottom) residual of each column is also “locked”.\n\nThis leads to a general result for finding residual degrees of freedom for a Latin Square: (# rows – 2) x (# columns – 1).↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BYU-Idaho Math326: Design and Analysis of Experiments",
    "section": "",
    "text": "This book is meant to be a starting point for you to learn design and analysis of experiments. You should feel free to edit the Rmarkdown files so that the book becomes your own.\n\n\nUnder Basics of Design the most foundational issues that face each experimenter are described.\nThe Specific Designs section addresses specific designs we will learn about in this course. Each design will have an image next to it representing the diagram of the structural factors. Within each of these designs there are subsections:\n\nOverview contains the model, factor structure and hypotheses\nDesign discusses how the randomization is implemented and why\nDecomposition is a bridge between the design and analysis. It walks through creating an ANOVA table by hand for the given design to allow you to see how the factor structure affects the analysis.\nR instructions provides code illustrating how to run the model\nResources contains worked examples and a space for you to store other links and info\n\nThe section labeled Broad Topics seeks to address topics that are relevant to many experiment designs.\nFinally, a section dedicated to R code that can be used in multiple designs. This includes numerical and graphical data summaries as well as code for model diagnostics/assumption checking.\nYou should add additional topics and designs as you learn more, even after the course is over. The book is meant to be fully customizable and growing to reflect your growing understanding.\n\n\nThis book was specifically designed for the Math326 Design and Analysis of Experiments class at BYU-Idaho, as it stands in 2022. BYU-I follows a 14 week semester. After introducing some foundational principles of experimental design, the recommended sequence follows the general pattern of\n\nIntroduce a specific design: suitability/benefits of the design, explanation of the design, factor structure and decomposition, steps for analysis (including R code)\nDiscuss new topics/complexities/considerations associated with that design located in the Broad Topics list.\n\nHere is a specific, suggested reading schedule:\n\n\nRead the pages under the Basics of Design menu in order\nRead the following pages in order under “Broad Topics” menu: Factor Structure through Assumptions\nRead Basic Factorial Introduction and BF[1] under Specific Designs menu\nPages under the R Instructions menu can act as a resource. They may fit well as a review here\nUnder Broad Topics menu Read Contrasts and Multiple Comparisons\nRead BF[2] under Specific Design menu\nRead Unbalanced Datasets under Broad Topics menu"
  },
  {
    "objectID": "index.html#a-customizable-textbook",
    "href": "index.html#a-customizable-textbook",
    "title": "BYU-Idaho Math326: Design and Analysis of Experiments",
    "section": "",
    "text": "This book is meant to be a starting point for you to learn design and analysis of experiments. You should feel free to edit the Rmarkdown files so that the book becomes your own.\n\n\nUnder Basics of Design the most foundational issues that face each experimenter are described.\nThe Specific Designs section addresses specific designs we will learn about in this course. Each design will have an image next to it representing the diagram of the structural factors. Within each of these designs there are subsections:\n\nOverview contains the model, factor structure and hypotheses\nDesign discusses how the randomization is implemented and why\nDecomposition is a bridge between the design and analysis. It walks through creating an ANOVA table by hand for the given design to allow you to see how the factor structure affects the analysis.\nR instructions provides code illustrating how to run the model\nResources contains worked examples and a space for you to store other links and info\n\nThe section labeled Broad Topics seeks to address topics that are relevant to many experiment designs.\nFinally, a section dedicated to R code that can be used in multiple designs. This includes numerical and graphical data summaries as well as code for model diagnostics/assumption checking.\nYou should add additional topics and designs as you learn more, even after the course is over. The book is meant to be fully customizable and growing to reflect your growing understanding.\n\n\nThis book was specifically designed for the Math326 Design and Analysis of Experiments class at BYU-Idaho, as it stands in 2022. BYU-I follows a 14 week semester. After introducing some foundational principles of experimental design, the recommended sequence follows the general pattern of\n\nIntroduce a specific design: suitability/benefits of the design, explanation of the design, factor structure and decomposition, steps for analysis (including R code)\nDiscuss new topics/complexities/considerations associated with that design located in the Broad Topics list.\n\nHere is a specific, suggested reading schedule:\n\n\nRead the pages under the Basics of Design menu in order\nRead the following pages in order under “Broad Topics” menu: Factor Structure through Assumptions\nRead Basic Factorial Introduction and BF[1] under Specific Designs menu\nPages under the R Instructions menu can act as a resource. They may fit well as a review here\nUnder Broad Topics menu Read Contrasts and Multiple Comparisons\nRead BF[2] under Specific Design menu\nRead Unbalanced Datasets under Broad Topics menu"
  },
  {
    "objectID": "index.html#book-scope",
    "href": "index.html#book-scope",
    "title": "BYU-Idaho Math326: Design and Analysis of Experiments",
    "section": "Book Scope",
    "text": "Book Scope\nThis is an introductory book intended to familiarize students with foundational concepts and vocabulary in the design and analysis of experiments. The designs covered in this book are the most basic and all assume a continuous response variable. Hopefully with this foundation students will be prepared to excel in experimental design and analysis courses in grad school, or be able to extend these principles to more complex designs as practitioners."
  },
  {
    "objectID": "hoveRmd/DescribeData_backup.html",
    "href": "hoveRmd/DescribeData_backup.html",
    "title": "Describing Data",
    "section": "",
    "text": "In the following explanations\n\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable. It would represent a treatment factor.\nYourDataSet is the name of your data set.\n\nYou can take a tidyverse approach or a mosaic package approach to calculating numerical summaries for each treatment.\n\nmosaic package:tidyverse approach\n\n\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  Month min   Q1 median    Q3 max     mean       sd  n missing\n1     5  56 60.0     66 69.00  81 65.54839 6.854870 31       0\n2     6  65 76.0     78 82.75  93 79.10000 6.598589 30       0\n3     7  73 81.5     84 86.00  92 83.90323 4.315513 31       0\n4     8  72 79.0     82 88.50  97 83.96774 6.585256 31       0\n5     9  63 71.0     76 81.00  93 76.90000 8.355671 30       0\n\n\n\nWhen calculating treatment means for combinations of 2 or more factors you can use + or | to separate the factors. | (read as ‘vertical bar’ or ‘pipe’) has the advantage that in addition to calculating means for every factor level combination, favstats will also output the marginal means for each level of the last factor listed.\nNOTE: unlike it’s use in the aov() command, using the * within favstats does not yield expected results and should NOT be used.\n\nlibrary(mosaic)\nfavstats(Y ~ X + Z, data = YourDataSet) \n#OR\nfavstats(Y ~ X | Z, data = YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  + This allows us to create additional subgroups within ‘am’ for each level of ‘cyl’.  cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  am.cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1    0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2    1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3    0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4    1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5    0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6    1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n\n\n\nNotice that the first column in the output contains the factor level combinations of am and cyl. So, ‘0.4’ is interpreted as level 0 for am and level 4 for cyl. Or in other words, the summary statistics on that row are for automatic tranmission, 4 cylinder engine vehicles. The column label of ‘am.cyl’ indicates which factor is represented on which side of the period. The next example uses the same way of labeling the factor level combinations, but the column label is not as intuitive or helpful.\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  | Referred to as a vertical bar or pipe, this symbol further defines subgroups of the variable on its left, using the values of the variable on its right side   cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to View Output  Click to View Output. \n\n\n\n\n\n  cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1 0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2 1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3 0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4 1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5 0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6 1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n7   4 21.4 22.800  26.00 30.400 33.9 26.66364 4.5098277 11       0\n8   6 17.8 18.650  19.70 21.000 21.4 19.74286 1.4535670  7       0\n9   8 10.4 14.400  15.20 16.250 19.2 15.10000 2.5600481 14       0\n\n\n\n\n\n\nCalculating treatment means for one factor:\n\nlibrary(tidyverse)\nYourDataSet %&gt;%\n  Group_by(X) %&gt;%\n  Summarise(MeanY = mean(Y), sdY = sd(Y), sampleSize = n()) \n\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  airquality airquality is a dataset in R.   %&gt;%  The pipe operator that will send the airquality dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the airquality dataset into “little” datasets, one dataset for each value in the “Month” column.  Month “Month” is a column from the airquality dataset that can be treated as qualitative.  ) Functions must always end with a closing parenthesis.   %&gt;%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  aveTemp =  “AveTemp” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  Temp Temp is a quantitative variable (numeric vector) from the airquality dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\nMonth\naveTemp\n\n\n\n\n5\n65.55\n\n\n6\n79.1\n\n\n7\n83.9\n\n\n8\n83.97\n\n\n9\n76.9\n\n\n\n\n\nNote that R calculated the mean Temp for each month in Month from the airquality dataset.\nMay (5), June (6), July (7), August (8), and September (9), respectively.\nFurther, note that to get the “nicely formatted” table, you would have to use\nlibrary(pander)\nairquality %&gt;% \n  group_by(Month) %&gt;%\n  summarise(aveTemp = mean(Temp)) %&gt;%\n  pander()\n\nTo calculate treatment means for each combination of factor levels of 2 or more factors, simply add the additional variable to the group_by() statement.\nExample code:\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  mpg mtcars is a dataset in preloaded in R.   %&gt;%  The pipe operator that will send the mtcars dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the mtcars dataset into “little” datasets, one dataset for each combination of values in the ‘am’ and ‘cyl’ variables  am, cyl ‘am’ and ‘cyl’ are both columns in mtcars. By listing them both here we are going to get output for each combination of ‘am’ and ‘cyl’ that exists in the dataset  ) Functions must always end with a closing parenthesis.   %&gt;%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  mean_mpg =  “mean_mpg” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  mpg mpg is a quantitative variable (numeric vector) from the mtcars dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n`summarise()` has grouped output by 'am'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\n\n\n\n\nam\ncyl\nmean_mpg\n\n\n\n\n0\n4\n22.9\n\n\n0\n6\n19.12\n\n\n0\n8\n15.05\n\n\n1\n4\n28.07\n\n\n1\n6\n20.57\n\n\n1\n8\n15.4"
  },
  {
    "objectID": "hoveRmd/DescribeData_backup.html#numerical-summaries",
    "href": "hoveRmd/DescribeData_backup.html#numerical-summaries",
    "title": "Describing Data",
    "section": "",
    "text": "In the following explanations\n\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable. It would represent a treatment factor.\nYourDataSet is the name of your data set.\n\nYou can take a tidyverse approach or a mosaic package approach to calculating numerical summaries for each treatment.\n\nmosaic package:tidyverse approach\n\n\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  Month min   Q1 median    Q3 max     mean       sd  n missing\n1     5  56 60.0     66 69.00  81 65.54839 6.854870 31       0\n2     6  65 76.0     78 82.75  93 79.10000 6.598589 30       0\n3     7  73 81.5     84 86.00  92 83.90323 4.315513 31       0\n4     8  72 79.0     82 88.50  97 83.96774 6.585256 31       0\n5     9  63 71.0     76 81.00  93 76.90000 8.355671 30       0\n\n\n\nWhen calculating treatment means for combinations of 2 or more factors you can use + or | to separate the factors. | (read as ‘vertical bar’ or ‘pipe’) has the advantage that in addition to calculating means for every factor level combination, favstats will also output the marginal means for each level of the last factor listed.\nNOTE: unlike it’s use in the aov() command, using the * within favstats does not yield expected results and should NOT be used.\n\nlibrary(mosaic)\nfavstats(Y ~ X + Z, data = YourDataSet) \n#OR\nfavstats(Y ~ X | Z, data = YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  + This allows us to create additional subgroups within ‘am’ for each level of ‘cyl’.  cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  am.cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1    0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2    1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3    0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4    1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5    0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6    1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n\n\n\nNotice that the first column in the output contains the factor level combinations of am and cyl. So, ‘0.4’ is interpreted as level 0 for am and level 4 for cyl. Or in other words, the summary statistics on that row are for automatic tranmission, 4 cylinder engine vehicles. The column label of ‘am.cyl’ indicates which factor is represented on which side of the period. The next example uses the same way of labeling the factor level combinations, but the column label is not as intuitive or helpful.\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  | Referred to as a vertical bar or pipe, this symbol further defines subgroups of the variable on its left, using the values of the variable on its right side   cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to View Output  Click to View Output. \n\n\n\n\n\n  cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1 0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2 1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3 0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4 1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5 0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6 1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n7   4 21.4 22.800  26.00 30.400 33.9 26.66364 4.5098277 11       0\n8   6 17.8 18.650  19.70 21.000 21.4 19.74286 1.4535670  7       0\n9   8 10.4 14.400  15.20 16.250 19.2 15.10000 2.5600481 14       0\n\n\n\n\n\n\nCalculating treatment means for one factor:\n\nlibrary(tidyverse)\nYourDataSet %&gt;%\n  Group_by(X) %&gt;%\n  Summarise(MeanY = mean(Y), sdY = sd(Y), sampleSize = n()) \n\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  airquality airquality is a dataset in R.   %&gt;%  The pipe operator that will send the airquality dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the airquality dataset into “little” datasets, one dataset for each value in the “Month” column.  Month “Month” is a column from the airquality dataset that can be treated as qualitative.  ) Functions must always end with a closing parenthesis.   %&gt;%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  aveTemp =  “AveTemp” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  Temp Temp is a quantitative variable (numeric vector) from the airquality dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\nMonth\naveTemp\n\n\n\n\n5\n65.55\n\n\n6\n79.1\n\n\n7\n83.9\n\n\n8\n83.97\n\n\n9\n76.9\n\n\n\n\n\nNote that R calculated the mean Temp for each month in Month from the airquality dataset.\nMay (5), June (6), July (7), August (8), and September (9), respectively.\nFurther, note that to get the “nicely formatted” table, you would have to use\nlibrary(pander)\nairquality %&gt;% \n  group_by(Month) %&gt;%\n  summarise(aveTemp = mean(Temp)) %&gt;%\n  pander()\n\nTo calculate treatment means for each combination of factor levels of 2 or more factors, simply add the additional variable to the group_by() statement.\nExample code:\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  mpg mtcars is a dataset in preloaded in R.   %&gt;%  The pipe operator that will send the mtcars dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the mtcars dataset into “little” datasets, one dataset for each combination of values in the ‘am’ and ‘cyl’ variables  am, cyl ‘am’ and ‘cyl’ are both columns in mtcars. By listing them both here we are going to get output for each combination of ‘am’ and ‘cyl’ that exists in the dataset  ) Functions must always end with a closing parenthesis.   %&gt;%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  mean_mpg =  “mean_mpg” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  mpg mpg is a quantitative variable (numeric vector) from the mtcars dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n`summarise()` has grouped output by 'am'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\n\n\n\n\nam\ncyl\nmean_mpg\n\n\n\n\n0\n4\n22.9\n\n\n0\n6\n19.12\n\n\n0\n8\n15.05\n\n\n1\n4\n28.07\n\n\n1\n6\n20.57\n\n\n1\n8\n15.4"
  },
  {
    "objectID": "hoveRmd/DescribeData_backup.html#graphical-summaries",
    "href": "hoveRmd/DescribeData_backup.html#graphical-summaries",
    "title": "Describing Data",
    "section": "Graphical Summaries",
    "text": "Graphical Summaries\n\nBoxplots\n\n\n\n\n\n\n\n\nOverviewR InstructionsExplanation\n\n\n\nGraphical depiction of the five-number summary. Great for comparing the distributions of data across several groups or categories. Provides a quick visual understanding of the location of the median as well as the range of the data. Can be useful in showing outliers. Sample size should be larger than at least five, or computing the five-number summary is not very meaningful.\n\n\n\n\n\nBase R ggplot2 plotly\n\n\n\nTo make a boxplot in R use the function:\nboxplot(object)\nTo make side-by-side boxplots:\nboxplot(object ~ group, data=NameOfYourData, ...)\n\nobject must be quantitative data. R refers to this as a “numeric vector.”\ngroup must be qualitative data. R refers to this as either a “character vector” or a “factor.” However, a “numeric vector” can also act as a qualitative variable.\nNameOfYourData is the name of the dataset containing object and group.\n... implies there are many other options that can be given to the boxplot() function. Type ?boxplot in your R Console for more details.\n\nExample Code\nBasic Single Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  $ The $ allows us to access any variable from the airquality dataset.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.  )\nClosing parenthesis for the function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nMore Useful… Basic Side-by-Side Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Names under each Box\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  names=c(“May”,“June”,“July”,“Aug”,“Sep”) names= is used to tell R what labels to place on the x-axis below each boxplot.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Color and Labels\n\n\n boxplot(Temp ~ Month, data=airquality This code was explained in the previous example code.  ,  The comma is used to separate each additional command to a function.  xlab=“Month of the Year” xlab= stands for “x label.” Use it to specify the text to print on the plot under the x-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  ylab=“Temperature” ylab= stands for “y label.” Use it to specify the text to print on the plot next to the y-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  main=“La Guardia Airport Daily Temperatures” main= stands for the “main label” of the plot, which is placed at the top center of the plot. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  col=“wheat” col= stands for the “color” of the plot. The color name “wheat” is an available color in R. Type colors() in the R Console to see more options. The color name must always be placed in quotes.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a boxplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_boxplot()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_boxplot() causes the ggplot to become a boxplot.\n\n\nExample Code\nBasic Single Boxplot\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the y-axis should become.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot() The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n Side-by-side Boxplot and Color Change\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box in the boxplot.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Labels \n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_histogram()” function causes the ggplot to become a histogram. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.   +  The addition symbol + is used to add further elements to the ggplot.     labs( The “labs” function is used to add labels to the plot, like a main title, x-label and y-label.  title=“La Guardia Airport Daily Mean Temperature”,  The “title=” command allows you to control the main title at the top of the graphic.  x=“Month of the Year”,  The “x=” command allows you to control the x-label of the graphic.  y=“Daily Mean Temperature” The “y=” command allows you to control the y-label of the graphic.  )\nClosing parenthesis for the labs function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nGallery\nSee what past students have done…\nClick to view.\n\nHover to see code.\n \n ggplot(data = mtcars, aes(x = as.factor(cyl), y = mpg, fill=as.factor(cyl))) +  geom_boxplot()  +  stat_summary(fun.y = mean, geom = \"errorbar\", aes(ymax = ..y.., ymin = ..y..),     width = .75, linetype = \"dashed\", color=\"firebrick\") +  theme_light() +  theme(panel.grid.major=element_blank()) +  scale_fill_brewer(palette=\"Dark2\") +  geom_jitter(width=0.1, height=0) +  labs(title = \"Miles Per Gallon Based on Cylinders\",     x=\"Number of Cylinders\",     fill=\"Cylinders\",     y=\"Miles Per Gallon\")   \n \n ggplot(data = ToothGrowth, aes(x = as.factor(dose), y = len, fill=as.factor(dose))) +  geom_boxplot( )  +  facet_wrap(~supp) +  theme_bw() +  scale_fill_manual(values=c(\"#999999\", \"#E69F00\", \"#56B4E9\")) +  geom_jitter(width=0.1, height=0) +  labs(title = \"Tooth Length Based on Doses     According to Supplement Type\",     fill=\"Doses\",     x=\"Dosage Amount(mg)\",     y=\"Tooth Length\" )   \n\n\n\n\n\nTo make a histogram in plotly first load\nlibrary(plotly)\nThen, use the function:\nplot_ly(dataName, y=~columnNameY, x=~columnNameX, type=\"box\")\n\ndataName is the name of a data set\ncolumnNameY must be the name of a column of quantitative data. R refers to this as a “numeric vector.” This will become the y-axis of the plot.\ncolumnNameX must be the name of a column of qualitative data. This will provide the “groups” forming each individual box in the boxplot.\ntype=\"box\" tells the plot_ly(…) function to create a boxplot.\n\nVisit plotly.com/r/box-plots for more details.\n\nExample Code\nHover your mouse over the example codes to learn more. Click on them to see what they create.\nBasic Boxplot\n\n\n plot_ly An R function “plot_ly” from library(plotly) used to create any plotly plot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality,  “airquality” is a dataset. Type “View(airquality)” in R to see it.  y= The y= allows us to declare which column of the data set will become the y-axis of the boxplot. In other words, the quantitative data we are interested in studying for each group.  ~Temp,   “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset. The ~ is required before column names inside all plot_ly(…) commands.  x= The x= allows us to declare which column of the data set will become the x-axis of the boxplot. In other words, the “groups” forming each separate box in the boxplot.  ~as.factor(Month),   since “Month” is a quantitative variable (numeric vector) from the “airquality” dataset we have to change it to a “factor” which forces R to treat it as a qualitative (groups) variable. The ~ is required before column names inside all plot_ly(…) commands.  type=“box” This option tells the plot_ly(…) function what “type” of graph to make. In this case, a boxplot.  )\nClosing parenthesis for the plot_ly function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nChange Color\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”,  This code was explained in the first example code.  fillcolor=“skyblue”,  this changes the fill color of the boxes in the boxplot to the color specified, in this case “skyblue.”  line=list(color=“darkgray”, width=3),  this “list(…)” of options that will be specified will effect the edges of the boxes in the boxplot. We are changing their color to “darkgray” and their width to 3 pixels wide.  marker=list( this “list(…)” of options that will be specified will effect the outlying dots shown in the boxplots beyond the “fences” of each box.  color = “orange”,  this will change the color of the dots to orange.  line = list(,  this opens a list of options to specify for the “lines” around the “markers.”  color = “red”,  this will change the color of the lines around the outlier dots to red.  width = 1 this will change the width of the lines around the outlier dots to 1 pixel.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nAdd Titles\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”, fillcolor=“skyblue”, line=list(color=“darkgray”, width=3), marker = list(color=“orange”, line = list(color=“red”, width=1)))  This code was explained in the above example code.  %&gt;% the pipe operator sends the completed plot_ly(…) code into the layout function.  layout( The layout(…) function is used for specifying details about the axes and their labels.  title=“La Guardia Airport Daily Mean Temperatures” This declares a main title for the top of the graph.  xaxis=list( This declares a list of options to be specified for the xaxis. The same can be done for the yaxis(…).  title=“Month of the Year” This declares a title underneath the x-axis.  ),  Functions always end with a closing parenthesis.  yaxis=list( This declares a list of options to be specified for the y-axis.  title=“Temperature in Degrees F” This declares a title beside the y-axis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding how a boxplot is created is the best way to understand what the boxplot shows.\n\nHow Boxplots are Made\n\nThe five-number summary is computed.\nA box is drawn with one edge located at the first quartile and the opposite edge located at the third quartile.\nThis box is then divided into two boxes by placing another line inside the box at the location of the median.\nThe maximum value and minimum value are marked on the plot.\nWhiskers are drawn from the first quartile out towards the minimum and from the third quartile out towards the maximum.\nIf the minimum or maximum is too far away, then the whisker is ended early.\nAny points beyond the line ending the whisker are marked on the plot as dots. This helps identify possible outliers in the data.\n\n\n\n\n\n\n\n\n\nScatterplot, with Means\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nScatterplots of a catgorical variable on the x axis and quantitative variable on the y axis are sometimes called strip charts, or side-by-side strip charts. When sample sizes are not too big and there are not too many repeated value this type of chart is an excellent way to see the variability in the data without the abstraction of a boxplot. By plotting individual observations you also can see the size of the sample for each factor level. Including factor level means on the plot adds additional insight. The mean of each factor level is often connected with a line for visual impact.\n\n\n\n\nmosaic ggplot2 plotly\n\n\n\nTo make a scatterplot use the function:\nxyplot(y~x, data = mydata)\n\ny is the quantitative response variable, i.e., “numeric vector.”\nx is the independent, explanatory variable\nmydata is the name of the dataset containing y and x.\n\nThis will return a scatterplot regardless of how your x variable is stored in R (numeric, character, factor). This function is flexible and with minimal effort can include averages or make an interaction plot. xyplot() is a part of the lattice package, which is loaded when the mosaic package is loaded.\nNote: plot() from base R will also give a scatterplot, but only if the x variable is quantitative. If x is a character or factor variable the default is to return a boxplot plot.\nExample Code\nBy reading the documentation for the dataset (visible when ?ToothGrowth is run in the console) we can see that our “x” variable, “dose”, is a numeric variable in R. Because of this the x-axis maintains the relative distance of doses on the x-axis.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nIf you start with a numeric x variable, you may or may not want to convert it to a factor variable. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed. Compare the output of the previous example code with this example code. This example code converts our x variable of “dose” to a factor variable.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nTo include the means on the plot and connect them with a line use this code\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  , \nThe “,” is required to start specifying additional commands for the function.  type =\nThe type argument allows you to add different types of lines to the plot. Run ?panel.xyplot() to read more about values for this argument  c( Combines the following values into one vector. This allows me to pass multiple values as one input to “type =”. Useful for if I want to plot something in addition to the default of plotting points.  ‘p’\nThis requests the points to be plotted. It is the default value. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  , \nThe “,” is required to start specifying additional commands for the function.  ‘a’ This requests the average for each factor level to be connected with a line. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a scatterplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_point()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_point() causes the ggplot to become a scatterplot; or in other words to draw points to represent data.\n\n\nExample Code\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n If you start with a numeric x variable, you may or may not want to convert it to a factor variable. You do this by using ‘factor(x)’ instead of just ‘x’ as shown below. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed.\nggplot(ToothGrowth, aes(x = factor(dose), y = len)) +   geom_point(color = \"blue\")\nAdding averages to the plot and connecting them with a line requires a little more effort and is demonstrated in the code below. I also add some more descriptive labels to the chart.\nNote the use of stat_summary to indicate I want to add a layer that plots a numerical summary, not the original data. Some geoms have stat summaries built in to them (like geom_bar or geom_boxplot), but in our case we have to define the summary.\nIn the stat_summary I provide additional arguments to the aesthetics helper function. Defining the aesthetics in ggplot() is like a global definition, all additional layers inherit those aesthetic mappings. Defining them in a geom_* or a stats_* allows you to add to or override what was defined in ggplot() for that layer only. The group aesthetic is required in order to use a line geometry. In this case, group could just as easily have been defined in ggplot(aes()).\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_point( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.   + The addition symbol + is used to add further elements to the ggplot.    stat_summary( This function will calculate a statistical summary to be plotted on the chart  fun = mean, fun is short for function. The summary function I want to apply to my y variable is “mean”.  geom = “line”, The “geom=” argument is used to tell what kind of geometry should be drawn to represent the means. Here we are asking for the means to be connected with a line.  aes( The aes or “aesthetics” function allows you to tell ggplot what variables should be mapped to what visual aspects of the chart; including what the x-axis or y-axis should become. Including it her means the aesthetic will only be applied to this layer.  group = 1 indicates which variable should be grouped by when drawing multiple lines (one line for each factor level). We write the number 1 to indicate there is just 1 group; we are not further splitting the data.  )\nClosing parenthesis for the geom_boxplot function.  )\nClosing parenthesis for the geom_boxplot function.   + The addition symbol + is used to add further elements to the ggplot.    labs( Function to edit labels of the plot  x = “Vitamin C mg/day”, Edit the x-axis label  y = “Length”, Edit the y-axis label  title = “Tooth Growth in Guinea Pigs” Edit the chart title  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nUnder construction.\n\n\n\n\n\n\n\n\n\nInteraction Plot\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nThese plots are used to visualize two categorical factors (mapped to the x-axis and the line color/type) and a quantitative response variable (displayed on the y-axis). A point for each factor level combination mean is plotted, and then points are connected with lines to aid the visual interpretation of the plot. Because they show two factors, they are ideal for two-way ANOVA.\nInteraction plots are a great way to see factor effects. In particular, they can be helpful in understanding the nature of an interaction factor, or detecting the lack thereof. If the line segments in the plot are all (nearly) parallel, this is indicative that no interaction effect exists between the two factors. The more non-parallel the line segments, the more likely a significant interaction effect is present.\nA formal hypothesis test should be conducted to determine the significance of an interaction term, since sometimes the hypothesis test result can run counter to what a quick visual inspection might suggest. When a significant interaction is present, an interaction plot can be a critical part of understanding the nature of the interaction.\nIf there are three factors in a study, multiple interaction plots can be used (one at each value of the third factor) to explore the nature of two-way and three-way interactions. This approach can be extended for analyses involving more than 3 factors. However, interactions involving more than 3 variables are rare in practice. Therefore, if more than 3 factors are present in an analysis, interaction plots are not usually used as an exploratory tool. Instead, statistical tests are used to find significant interactions, and then interaction plots are used to describe the nature of those interactions.\n\n\n\n\nBase R ggplot2 plotly\n\n\n\nTo make a scatterplot use the function:\ninteraction.plot(mydata$factor_x, mydata$factor_line, mydata$response)\n\nmydata is the name of the dataset containing the factors and response.\nfactor_x is factor (or string) variable that will be plotted on the x-axis\nfactor_line is factor (or string) variable that will have different colored/types of lines on the plot\ny is the quantitative response variable, i.e., “numeric vector.”\n\nNote, unlike the other plotting we have done so far, there is no data = argument. Each variable must be specified using the $ notation if it exists inside a dataset. There are many additional arguments to specify colors, line types, legend formatting, etc.\nExample Code\nBy reading the documentation for the dataset (visible when ?ToothGrowth is run in the console) we can see that our “x” variable, “dose”, is a numeric variable in R. Because of this we convert it to a factor variable in the plot command with the factor() command. This changes the nature of dose only within that particular plot, not within the dataset generally.\n\n\n\n interaction.plot( An R function used to create an interaction plot  factor( A function to make a variable categorical.  ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  ) parenthesis to close the factor function  , separate arguments to a function with commas  ToothGrowth Name of the dataset that contains the variables.  $ The $ allows you to refer to a variable in a dataset by name  supp a different line will be drawn for each value of supp  , separate arguments to a function with commas   ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  len name of the response variable in ToothGrowth  , separate arguments to a function with commas ylab= argument to specify y-axis label  “Tooth length” Label for the y-axis must be put in quotes  ,  separate arguments to a function with commas  xlab= argument to specify x-axis label  “Dose (vitamin C mg/day)” Label for the x-axis must be put in quotes  , separate arguments to a function with commas  trace.label= argument to specify the trace label which will appear in the legend  “Delivery Method” Label for the trace factor must be put in quotes  , separate arguments to a function with commas  main= argument to specify the chart title  “Tooth Growth in Guinea Pigs” Chart title must be put in quotes  ) parenthesis to close the interaction.plot function      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\nBecause not all the line segments are parallel, you may begin to suspect an interaction is present. To determine if the interaction is significant you can do a hypothesis test for.\nNote, an easy/slick method for changing the legend position does not (currently) exist for interaction.plot(), though some hacked solutions can be used.\nYou can adjust things like line color, plotting points, etc. as shown in this next example.\n\n\n\n interaction.plot( An R function used to create an interaction plot  factor( A function to make a variable categorical.  ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  ) parenthesis to close the factor function  , separate arguments to a function with commas  ToothGrowth Name of the dataset that contains the variables.  $ The $ allows you to refer to a variable in a dataset by name  supp a different line will be drawn for each value of supp  , separate arguments to a function with commas   ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  len name of the response variable in ToothGrowth  , separate arguments to a function with commas ylab= argument to specify y-axis label  “Tooth length” Label for the y-axis must be put in quotes  ,  separate arguments to a function with commas  xlab= argument to specify x-axis label  “Dose (vitamin C mg/day)” Label for the x-axis must be put in quotes  , separate arguments to a function with commas  trace.label= argument to specify the trace label which will appear in the legend  “Delivery Method” Label for the trace factor must be put in quotes  , separate arguments to a function with commas  main= argument to specify the chart title  “Tooth Growth in Guinea Pigs” Chart title must be put in quotes  , separate arguments to a function with commas  type=\nargument to specify whether lines, points, or both should be plotted  ‘b’ b, in quotes, indicates lines and points should be drawn on the plot  , separate arguments to a function with commas   pch=\nargument to specify shape of the points  16 an integer value from 0 to 25 is expected.   , separate arguments to a function with commas  lty=\nargument to specify line type.   1 1 for a solid line. Line type can be specified with an integer from 0 - 6, or text “solid”.  , separate arguments to a function with commas  col=\nargument to specify colors to be used for different values of the trace factor, supp  c( concatenate function used to create a vector  “darkblue” color to be used for first value of supp. Can be given in name form, integer, or rgb specs  ,\nseparate values in a vector with a comma   “deeppink3” color to be used for first value of supp. Can be given in name form, integer, or rgb specs  ) end the vector with a parenthesis  ) parenthesis to close the interaction.plot function      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make an interaction plot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=factor1, color=factor2, group=factor2, y=response) +\n  stat_summary(fun = mean, geom = \"line\")\n\ndata is the name of your dataset.\nfactor1 is a column of data from your dataset that is a qualitative factor whose values you want to plot along the x-axis.\nfactor2 is a column of data from your dataset that is a qualitative factor. You want to draw a different colored line for each value of this factor.\nresponse is the name of the quantitative response variable in your dataset.\nThe aesthetic helper function aes() is how you tell R which variables you want mapped to which aesthetics (i.e. visual attributes) of your chart. This is actually the input to the mapping= argument, but for conciseness mapping= is usually not typed out.\n\nThe group aesthetic indicates that any summary statistics that are calculated should be calculated separately for each value of factor2. It’s similar to a group_by() statement.\nBecause factor2 is also the value for color, each value of factor2 will be represented with a different color.\n\nstat_summary() does two things:\n\ncalculates a summary statistic. In this case we tell it to calculate the mean for each factor level combination with the fun = mean code. fun stands for “function”.\nindicates we want to connect the means with a line. geom stands for our desired geometry, in this case lines.\n\n\nNote if one of your factor variables is not coded as a factor (e.g. it is numeric), use factor() to convert it to the correct data type.\n\nHere is a basic interaction plot using ggplot2 package. In a later example we will add additional formatting, labels, etc.\n\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function is actually an input to the mapping= argument. It allows you to which variable is mapped to aspects of the chart. This includes things like what the x-axis or y-axis should become.  x= “x=” declares which variable will become the x-axis of the graphic.  factor(dose), factor converts dose, a numeric variable, into a categorical variable  color=supp,  declares that each value of supp will be represented with a different color  group=supp,  declares that each value of supp must be drawn separately. We specify the geometry to be drawn later with geom.  y=len declares which variable will become the y-axis of the graphic.  )) close the aes and ggplot functions with a parenthesis   + The addition symbol is used to add/tweak chart elements.    stat_summary( this adds a layer to the chart that will show summary statistics  fun = mean,  “mean” is the function used to get a summary statistic  geom=“line” The geometry used on the chart will be lines  ) parenthesis to close the stat_summary function      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\nAdd different line types, points for each factor level mean, and improved labelling\nLook at the code below and notice that with the exception of the group aesthetic, a label is applied to each aesthetic mapping. linetype and color have the same label and R is smart enough to therefore combine the legend for these two aesthetic mappings into one legend. If the labels are not identical, each aesthetic will have a unique legend.\n\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function is actually an input to the mapping= argument. It allows you to which variable is mapped to aspects of the chart. This includes things like what the x-axis or y-axis should become.  x= “x=” declares which variable will become the x-axis of the graphic.  factor(dose), factor converts dose, a numeric variable, into a categorical variable  color=supp,  declares that each value of supp will be represented with a different color  group=supp,  declares that each value of supp must be drawn separately. We specify the geometry to be drawn later with geom.  linetype=supp,  declares that each value of supp will be represented with a different line type  y=len declares which variable will become the y-axis of the graphic.  )) close the aes and ggplot functions with a parenthesis   + The addition symbol is used to add/tweak chart elements.    stat_summary( this adds a layer to the chart that will show summary statistics  fun=mean,  “mean” is the function used to get a summary statistic  geom=“line”,  The geometry used on the chart will be lines  size=1 Change the line thickness  ) parenthesis to close the stat_summary function   + The addition symbol is used to add/tweak chart elements.    stat_summary( this adds a layer to the chart that will show summary statistics  fun=mean,  “mean” is the function used to get a summary statistic  geom=“point”,  The geometry used on the chart will be points  size=3 Change the size of the points  ) parenthesis to close the stat_summary function   + The addition symbol is used to add/tweak chart elements.    labs( use this layer to change chart labels  x=“Vitamin C dose (mg/day)”, Put the x-axis label in quotes     y=“Tooth Length”, Put the x-axis label in quotes     title=“Guinea Pig Study”, Put the chart title in quotes     color=“Delivery Method”, Put the color label in quotes     linetype=“Delivery Method” Put the linetype label in quotes  ) Close labs with a parenthesis      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nUnder construction."
  },
  {
    "objectID": "hoveRmd/BF1_R_Instructions_boat.html",
    "href": "hoveRmd/BF1_R_Instructions_boat.html",
    "title": "BF1 R Instructions",
    "section": "",
    "text": "method_aovA name you come up with for your model  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  procKnow The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Treatment, The independent variable containing the names for the 4 training methods  data = virtual Tell the model to look in the dataset named “virtual” for procKnow and Treatment variables  ) Functions always end with a closing parenthesis  summary( Give important information about an object. When called on an aov object the default is to print the ANOVA summary table  method_aov  Whatever you named your ANOVA model in the previous line   )  Functions always end with a closing parenthesis  Click to toggle output Click to toggle output. \n\n\n\n\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)\nTreatment    3  31.81  10.604   2.111  0.131\nResiduals   20 100.49   5.024"
  },
  {
    "objectID": "factor_structure.html",
    "href": "factor_structure.html",
    "title": "Factor Structure",
    "section": "",
    "text": "In this section you will learn about factors in context of analyzing results of an experiment:"
  },
  {
    "objectID": "factor_structure.html#inside-and-outside",
    "href": "factor_structure.html#inside-and-outside",
    "title": "Factor Structure",
    "section": "Inside and Outside",
    "text": "Inside and Outside\nThink about our toothbrush example, but ignore toothpaste for a moment. If toothbrush is the only treatment under scrutiny we have three factors in the analysis: the grand mean, toothbrush type, and the residual error.\nRecall that in the simplest version of the toothbrush experiment there were 4 levels of the treatment (toothbrush type), with six replicates for each toothbrush. In the following factor structure diagrams grand mean is represented in red, toothbrush type is drawn in blue, and the residual factor levels are depicted in black.\n\n\n\nA factor is inside of another factor if all the levels of one factor (the inside factor) completely fit within a second factor (the outside factor).\nYou may find this analogy helpful. Pretend that an outside factor is a box, and the inside factor levels are blocks that fit neatly within the box.\n\n\n\n\n\nTo determine if a factor is inside another factor, imagine picking up the levels of the factor one by one and placing them inside the other factor. If they all fit without crossing the partition lines of a factor,then it is considered inside.\nThis is illustrated with the toothbrush example. We will start by taking the levels of toothbrush and placing them inside of grand mean\n\n\n\n\n\nIn the figure above you can see that one entire level of toothbrush can fit inside of a single level of benchmark. Even though they may share a boundary line, the toothbrush level does not cross over any lines or start sharing boundaries with any other level of benchmark (this is of course impossible since benchmark only has one level). You can repeat this for the other 3 levels of toothbrush with the same result. Therefore, we say that toothbrush is inside of benchmark, which is the same as saying that benchmark is outside of toothbrush.\nConsider now the relationship between toothbrush and residual as shown below. If we take a level of toothbrush and overlay it on the residual factor, we can see it does not fit neatly inside one of the levels of residual error. In fact, one level of toothbrush crosses the boundaries of many of the levels of residual error. Therefore, we cannot say that toothbrush is inside of residual error.\n\n\n\n\n\nSince toothbrush is not inside of residual error, does this necessarily mean that toothbrush is outside of residual error? No! This is something that has to be checked. To determine whether toothbrush is outside of residual we must take the levels of residual error one at a time and overlay them on the toothbrush factor structure, as shown below. You can see that one level of residual error does NOT cross any of the toothbrush level boundaries. Therefore, toothbrush is indeed outside of residual error; or equivalently, residual error is inside of toothbrush.\n\n\n\n\n\nLet’s pause here to clarify a common misunderstanding. Consider an experiment where we are looking at the inside vs. outside relationship of two factors: A and B.\n\nWhen factor A is inside of factor B, we can also say factor B is outside of factor A.\nBut, when factor A is not inside of factor B, this does not necessarily mean that factor A is outside of factor B. There are situations where two factors are neither inside nor outside of each other; they are crossed."
  },
  {
    "objectID": "factor_structure.html#crossed-factors",
    "href": "factor_structure.html#crossed-factors",
    "title": "Factor Structure",
    "section": "Crossed Factors",
    "text": "Crossed Factors\nTwo factors are crossed when their partition lines cross in a way that creates new groups of observations that represent every possible combination of the factor levels. More succinctly stated, factors are crossed when all factor level combinations are present in the study. We see this type of relationship in the toothbrush study with two controlled factors: toothbrush type (4 levels) and toothpaste brand (2 levels). Toothbrush and toothpaste are neither inside nor outside of each other; rather, they are crossed.\n\n\n\n\n\n\n\n\n\n\n\nThe crossing of toothpaste brand and toothbrush created an interaction factor.\n\n\n\nWhen two factors are crossed, the resulting (interaction) factor’s levels will always be inside of each of the factors that was crossed to create it. This fact is illustrated below for the toothbrush factor and could similarly be shown for toothpaste brand factor."
  },
  {
    "objectID": "examples/VirtualTrain.html",
    "href": "examples/VirtualTrain.html",
    "title": "Lifeboat Launch Training Methods",
    "section": "",
    "text": "Code\nlibrary(mosaic)\nlibrary(DT)\nlibrary(pander)\nlibrary(car)\nlibrary(tidyverse)\n\n## Data from original article:\nvirtual &lt;- read.csv(\"../data/virtual_training.csv\", header=TRUE)"
  },
  {
    "objectID": "examples/VirtualTrain.html#background",
    "href": "examples/VirtualTrain.html#background",
    "title": "Lifeboat Launch Training Methods",
    "section": "Background",
    "text": "Background\nAn experiment was done to help train people in the procedure to launch a lifeboat. This was a Completely Randomized Design with 16 subjects per treatment, for a total of 64 subjects. The response variable is the performance on a procedural knowledge test. The treatments included: Lecture/Materials (Control) (1), Monitor/Keyboard (2), Head Monitor Display/Joypad (3), and Head Monitor Display/Wearables (4)\nSource: J.Jung and Y.J. Ahn (2018). “Effects of Interface on Procedural Skill Transfer in Virtual Training: Lifeboat Launching Operation Study,” Computer Animation & Virtual Worlds, Vol. 29, pp. e1812. https://doi.org/10.1002/cav.1812"
  },
  {
    "objectID": "examples/VirtualTrain.html#analysis",
    "href": "examples/VirtualTrain.html#analysis",
    "title": "Lifeboat Launch Training Methods",
    "section": "Analysis",
    "text": "Analysis\nApplying a one-way ANOVA to this study, we have the following model:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\nWhere \\(y_{ij}\\) is the \\(j^{th}\\) observation from treatment \\(i\\)\n\\(\\mu\\) is the grand mean of the dataset. Also referred to as an overall mean or benchmark.\n\\(\\alpha_i\\) is the effect of the training method. 1 = control/lecture, 2 = Monitor/keyboard, 3 = head monitor/joypad, 4 = head monitor/wearables.\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. Since there are 16 subjects for each treatment, \\(j\\) ranges from 1 to 16.\n\nHypothesis Test\nThe null hypothesis is that the effect of all training methods, represented by α, is equal to zero. This is formally written as follows.\n\\[ H_0:\\alpha_\\text{Control} = \\alpha_\\text{Monitor/Keyboard} = \\alpha_\\text{Joypad} = \\alpha_\\text{Wearables} = 0 \\]\nThe alternative hypothesis states that at least one of the effects due to material is different than zero \\[ H_a: \\text{at least one } \\alpha \\text{ is different than 0} \\]\nUsing these hypotheses will allow for us to address the question whether any of the type of training is different to improve test score.\nWe will use a level of significance of α = 0.05 for the analysis.\nFor the analysis, we perform the following one-way ANOVA\n\n\nCode\nvirtual &lt;- virtual %&gt;% \n   mutate(\n         Treatment = case_when(\n           grp.trt %in% 1  ~ \"Control\",\n           grp.trt %in% 2  ~ \"Monitor/Keyboard\",\n           grp.trt %in% 3  ~ \"Joypad\",\n           grp.trt %in% 4  ~ \"Wearables\"\n          )\n        )\n\nvirtual.aov &lt;- aov(procKnow ~ Treatment, data=virtual)\nsummary(virtual.aov) %&gt;% pander()\n\n\n\nAnalysis of Variance Model\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nTreatment\n3\n65.66\n21.89\n4.941\n0.003931\n\n\nResiduals\n60\n265.8\n4.43\nNA\nNA\n\n\n\n\n\nThe p-value for this test is significant (p = 0.003931). Based on this result, the null hypothesis is rejected and we have sufficient evidence that at least one of the effects due to training is different for post test score.\n\n\nCheck Requirements\nIn order to trust this result, we must verify the requirements for the ANOVA model are met. The requirement of equal variances appears to be met since the residuals versus fitted plot shows roughly a constant variance within each vertical group of dots.\nThe QQ-plot of residuals on the right is used to check whether residuals are normally distributed. There are a few points outside the boundaries that might be a concern for this ANOVA requirement, but generally there are no strong departures from normality and so we consider this requirement to be met also.\n\n\nCode\npar(mfrow=c(1,2))\nplot(virtual.aov, which=1, pch=16)\nqqPlot(virtual.aov, id=FALSE)\n\n\n\n\n\n\n\nTraining method’s effect on test score\nThe following plot shows which types of training increases the post test score.\n\n\nCode\nxyplot(procKnow ~ as.factor(Treatment), data=virtual, type=c(\"p\",\"a\"), main=\"Score based on Type of Training\", xlab =\"Treatment\", ylab = \"Test Score\")\n\n\n\n\n\nThe averages are illustrated with the blue line in the plot above and the table below shows the means, standard deviations, and sample sizes for each of the five different materials.\n\n\nCode\npander(favstats(procKnow ~ Treatment, data=virtual)[,c(\"Treatment\",\"mean\",\"sd\",\"n\")])\n\n\n\n\n\n\n\n\n\n\n\nTreatment\nmean\nsd\nn\n\n\n\n\nControl\n4.931\n1.94\n16\n\n\nJoypad\n6.736\n2.82\n16\n\n\nMonitor/Keyboard\n7.708\n1.43\n16\n\n\nWearables\n6.875\n1.99\n16"
  },
  {
    "objectID": "examples/VirtualTrain.html#interpretation",
    "href": "examples/VirtualTrain.html#interpretation",
    "title": "Lifeboat Launch Training Methods",
    "section": "Interpretation",
    "text": "Interpretation\nIt appears the the best type of training may be the Monitor/Keyboard type training. The highest mean came from the Monitor/Keyboard where the average procedural knowledge post test score was 7.708. The head monitor training methods may perform better on different types of assessments that were not part of this study. A future study could look into other training methods to improve readiness in lifeboat launching."
  },
  {
    "objectID": "effects_model.html",
    "href": "effects_model.html",
    "title": "Effects Model",
    "section": "",
    "text": "In science, statistics, mathematics, etc. we are interested in discovering and describing truth about the world we live in. We can use models to represent a phenomenon or system. The model’s purpose may be to describe and explain something about the way things work and/or to make prediction. An ANOVA model is a model that uses mathematical terms and constructs, in the form of an equation. The ANOVA model quantifies the relationship between factor(s) and a response.\nIf we were able to observe all items in a population we would be able to quantify with exactness how a factor variable is related to a response variable with an ANOVA model. This “true”, or exact quantification of how the two variables relate is called a parameter. However, with rare exceptions, we cannot observe every item in a population. Instead, we must rely on a sample to calculate estimates of the parameter.\nBy the end of this section you should know how to interpret the terms in an ANOVA model (i.e. know what they mean), and also perform the calculations necessary to estimate ANOVA model parameters.\n\n\n\nConsider an experiment conducted to test 4 different types of toothbrushes: manual, oscillating, sonic and ultrasonic. The response variable is percent of area on teeth that has plaque. Twenty-four individuals participate in the experiment, yielding 6 observations per treatment. We will discuss the creation of an ANOVA model using the context of this specific example. In this section and “Calculating Effect Sizes” section we will be referring to estimates of model parameters using this sample data.\nUp to this point we have primarily been interested in calculating means in order to compare toothbrushes. If the mean percent of teeth surface area with plaque was 23.09 for a manual brush, you would want to know how that value compares to the other types of brushes. A graph or table reporting the other sample means would be necessary to provide context. Figure 1 depicts the data points and the mean for each factor level.\n\n\n\n\n\nFigure 1: Brush means and grand mean\n\n\n\n\nIn an earlier, introductory statistics class you most likely learned how to use sample means in order to test whether populations means for different groups are equal using analysis of variance (ANOVA). This hypothesis test of multiple population means is valid and works when you only have 1 factor. This is often called the cell means model.1 However, it is limited in its ability to include more factors or more complicated designs.\nThere is another metric we use to compare factor levels: the effect size. Reporting the effect of a factor level has the benefit of providing some context on how that factor level is influencing the response variable relative to other levels of the same factor. Using effect sizes (as opposed to factor level means) allows us to model and test much more complicated scenarios than a simple one factor experiment."
  },
  {
    "objectID": "effects_model.html#models",
    "href": "effects_model.html#models",
    "title": "Effects Model",
    "section": "",
    "text": "In science, statistics, mathematics, etc. we are interested in discovering and describing truth about the world we live in. We can use models to represent a phenomenon or system. The model’s purpose may be to describe and explain something about the way things work and/or to make prediction. An ANOVA model is a model that uses mathematical terms and constructs, in the form of an equation. The ANOVA model quantifies the relationship between factor(s) and a response.\nIf we were able to observe all items in a population we would be able to quantify with exactness how a factor variable is related to a response variable with an ANOVA model. This “true”, or exact quantification of how the two variables relate is called a parameter. However, with rare exceptions, we cannot observe every item in a population. Instead, we must rely on a sample to calculate estimates of the parameter.\nBy the end of this section you should know how to interpret the terms in an ANOVA model (i.e. know what they mean), and also perform the calculations necessary to estimate ANOVA model parameters."
  },
  {
    "objectID": "effects_model.html#toothbrush-example",
    "href": "effects_model.html#toothbrush-example",
    "title": "Effects Model",
    "section": "",
    "text": "Consider an experiment conducted to test 4 different types of toothbrushes: manual, oscillating, sonic and ultrasonic. The response variable is percent of area on teeth that has plaque. Twenty-four individuals participate in the experiment, yielding 6 observations per treatment. We will discuss the creation of an ANOVA model using the context of this specific example. In this section and “Calculating Effect Sizes” section we will be referring to estimates of model parameters using this sample data.\nUp to this point we have primarily been interested in calculating means in order to compare toothbrushes. If the mean percent of teeth surface area with plaque was 23.09 for a manual brush, you would want to know how that value compares to the other types of brushes. A graph or table reporting the other sample means would be necessary to provide context. Figure 1 depicts the data points and the mean for each factor level.\n\n\n\n\n\nFigure 1: Brush means and grand mean\n\n\n\n\nIn an earlier, introductory statistics class you most likely learned how to use sample means in order to test whether populations means for different groups are equal using analysis of variance (ANOVA). This hypothesis test of multiple population means is valid and works when you only have 1 factor. This is often called the cell means model.1 However, it is limited in its ability to include more factors or more complicated designs.\nThere is another metric we use to compare factor levels: the effect size. Reporting the effect of a factor level has the benefit of providing some context on how that factor level is influencing the response variable relative to other levels of the same factor. Using effect sizes (as opposed to factor level means) allows us to model and test much more complicated scenarios than a simple one factor experiment."
  },
  {
    "objectID": "effects_model.html#assembly-line-metaphor",
    "href": "effects_model.html#assembly-line-metaphor",
    "title": "Effects Model",
    "section": "Assembly Line Metaphor",
    "text": "Assembly Line Metaphor\nYou can imagine that each data point in your data set is created by going down an assembly line, much like you would find in a factory that makes cars or appliances. All points start with the grand mean value. As it progresses through the assembly line the data point is altered to reflect the effect of the factor levels it belongs to.\n\n\n\n\n\n\nIn the toothbrush and toothpaste experiment all the points start the assembly line at the same value: the grand mean of the data set. The first station on the line receives the data point and adds or subtracts to it based on the type of brush it is. For example, the value would be added upon if the brush type was “manual” because the mean plaque percentage for the manual type was higher than the grand mean. The next station alters the value depending on which toothpaste was used: off-brand or name brand. After going through each station (one station for each factor) in the assembly line the data point arrives at the last station.\nThe last station is worked by a person who makes random adjustments! Some adjustments will be big, and some will be small; some will be positive, and some will be negative. (In a typical factory this person would be fired. But we would rather have randomness than unknown, systematic adjustments , i.e. bias). These random adjustments are driven by any/all factors that we did not explicitly measure.\nFor example, variability in the experimental unit’s diet, hardness of the water used when brushing, the impact of flossing, outside temperature, and the price of rice in China are all factors that were not taken into account. Effects from these and an infinite number of other factors are all lumped into the residual error factor effects. The effects of factors unrelated to the response should be negligible. Effects from other factors that were sufficiently randomized should usually cancel each other out. The point is that all these factor’s effects show up in one (hopefully small) adjustment at the last station and are referred to as “unexplained variance” (review Sources of Variance).\nThough the adjustments at this last station for residual error are (assumed) random, they do follow a pattern. Namely, the mean of the adjustments is zero and they follow a normal distribution."
  },
  {
    "objectID": "effects_model.html#footnotes",
    "href": "effects_model.html#footnotes",
    "title": "Effects Model",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe algebraic form of the cell means model is\n\\[\ny_\\text{ij} = \\mu_i + \\epsilon_\\text{ij}\n\\]\nWhere \\(y_\\text{ij}\\) is an observation, \\(\\mu_i\\) is the mean of factor level \\(i\\), and \\(\\epsilon_\\text{ij}\\) is the residual for each observation. The ANOVA F-test hypothesis for this model is \\(H_0: \\text{All means are equal to each other}\\).↩︎\nPartial fit is a term that refers to an estimated model, or estimated prediction, using only some of the factors. Often, in ANOVA, partial fit refers to a model or prediction estimated using just outside factors. Thus, for this model Equation 5 could be restated as Factor level effect size = Factor level mean - partial fit.↩︎\nYou can think of an effect as a deviation from a mean. Other synonyms for deviation are error and variance. When you calculate an effect, you are also calculating a deviation or error. Thus, residual error effect is a bit redundant. Residual error and residual effect may be used interchangeably.↩︎\nCobb, George. Introduction to Design and Analysis of Experiments. Wiley, 2014. ↩︎\nThe model for the experiment that includes toothpaste brand and toothbrush type is\n\\[\ny_\\text{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_\\text{ij} + \\epsilon_\\text{ijk}\n\\]\nHere\n\n\\(\\alpha\\) is the effect of toothbrush, and \\(i\\) goes from 1 to 4 since there are 4 toothbrush types\n\\(\\beta\\) is the effect of toothpaste, and \\(j\\) is either 1 or 2 since there are 2 levels (Name brand and Generic brand).\n\\(\\alpha\\beta)_\\text{ij}\\) is the interaction term. An interaction is discussed on the BF[2] page.\n\\(\\epsilon\\) is the residual error term, and \\(k\\) is the replicate count within a factor level combination.\n\n↩︎"
  },
  {
    "objectID": "DescribeData.html",
    "href": "DescribeData.html",
    "title": "Describing Data",
    "section": "",
    "text": "In the following explanations\n\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable. It would represent a treatment factor.\nYourDataSet is the name of your data set.\n\nYou can take a tidyverse approach or a mosaic package approach to calculating numerical summaries for each treatment.\n\nmosaic package:tidyverse approach\n\n\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  Month min   Q1 median    Q3 max     mean       sd  n missing\n1     5  56 60.0     66 69.00  81 65.54839 6.854870 31       0\n2     6  65 76.0     78 82.75  93 79.10000 6.598589 30       0\n3     7  73 81.5     84 86.00  92 83.90323 4.315513 31       0\n4     8  72 79.0     82 88.50  97 83.96774 6.585256 31       0\n5     9  63 71.0     76 81.00  93 76.90000 8.355671 30       0\n\n\n\nWhen calculating treatment means for combinations of 2 or more factors you can use + or | to separate the factors. | (read as ‘vertical bar’ or ‘pipe’) has the advantage that in addition to calculating means for every factor level combination, favstats will also output the marginal means for each level of the last factor listed.\nNOTE: unlike it’s use in the aov() command, using the * within favstats does not yield expected results and should NOT be used.\n\nlibrary(mosaic)\nfavstats(Y ~ X + Z, data = YourDataSet) \n#OR\nfavstats(Y ~ X | Z, data = YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  + This allows us to create additional subgroups within ‘am’ for each level of ‘cyl’.  cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  am.cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1    0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2    1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3    0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4    1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5    0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6    1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n\n\n\nNotice that the first column in the output contains the factor level combinations of am and cyl. So, ‘0.4’ is interpreted as level 0 for am and level 4 for cyl. Or in other words, the summary statistics on that row are for automatic tranmission, 4 cylinder engine vehicles. The column label of ‘am.cyl’ indicates which factor is represented on which side of the period. The next example uses the same way of labeling the factor level combinations, but the column label is not as intuitive or helpful.\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  | Referred to as a vertical bar or pipe, this symbol further defines subgroups of the variable on its left, using the values of the variable on its right side   cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to View Output  Click to View Output. \n\n\n\n\n\n  cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1 0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2 1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3 0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4 1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5 0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6 1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n7   4 21.4 22.800  26.00 30.400 33.9 26.66364 4.5098277 11       0\n8   6 17.8 18.650  19.70 21.000 21.4 19.74286 1.4535670  7       0\n9   8 10.4 14.400  15.20 16.250 19.2 15.10000 2.5600481 14       0\n\n\n\n\n\n\nCalculating treatment means for one factor:\n\nlibrary(tidyverse)\nYourDataSet %&gt;%\n  Group_by(X) %&gt;%\n  Summarise(MeanY = mean(Y), sdY = sd(Y), sampleSize = n()) \n\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  airquality airquality is a dataset in R.   %&gt;%  The pipe operator that will send the airquality dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the airquality dataset into “little” datasets, one dataset for each value in the “Month” column.  Month “Month” is a column from the airquality dataset that can be treated as qualitative.  ) Functions must always end with a closing parenthesis.   %&gt;%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  aveTemp =  “AveTemp” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  Temp Temp is a quantitative variable (numeric vector) from the airquality dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\nMonth\naveTemp\n\n\n\n\n5\n65.55\n\n\n6\n79.1\n\n\n7\n83.9\n\n\n8\n83.97\n\n\n9\n76.9\n\n\n\n\n\nNote that R calculated the mean Temp for each month in Month from the airquality dataset.\nMay (5), June (6), July (7), August (8), and September (9), respectively.\nFurther, note that to get the “nicely formatted” table, you would have to use\nlibrary(pander)\nairquality %&gt;% \n  group_by(Month) %&gt;%\n  summarise(aveTemp = mean(Temp)) %&gt;%\n  pander()\n\nTo calculate treatment means for each combination of factor levels of 2 or more factors, simply add the additional variable to the group_by() statement.\nExample code:\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  mpg mtcars is a dataset in preloaded in R.   %&gt;%  The pipe operator that will send the mtcars dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the mtcars dataset into “little” datasets, one dataset for each combination of values in the ‘am’ and ‘cyl’ variables  am, cyl ‘am’ and ‘cyl’ are both columns in mtcars. By listing them both here we are going to get output for each combination of ‘am’ and ‘cyl’ that exists in the dataset  ) Functions must always end with a closing parenthesis.   %&gt;%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  mean_mpg =  “mean_mpg” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  mpg mpg is a quantitative variable (numeric vector) from the mtcars dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n`summarise()` has grouped output by 'am'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\n\n\n\n\nam\ncyl\nmean_mpg\n\n\n\n\n0\n4\n22.9\n\n\n0\n6\n19.12\n\n\n0\n8\n15.05\n\n\n1\n4\n28.07\n\n\n1\n6\n20.57\n\n\n1\n8\n15.4"
  },
  {
    "objectID": "DescribeData.html#numerical-summaries",
    "href": "DescribeData.html#numerical-summaries",
    "title": "Describing Data",
    "section": "",
    "text": "In the following explanations\n\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable. It would represent a treatment factor.\nYourDataSet is the name of your data set.\n\nYou can take a tidyverse approach or a mosaic package approach to calculating numerical summaries for each treatment.\n\nmosaic package:tidyverse approach\n\n\nCalculating treatment means for one factor:\n\nlibrary(mosaic)\nlibrary(pander)\nfavstats(Y~X, data=YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  library(pander) pander is an R Package that makes R output look pretty  favstats( a function from the mosaic package that returns a set of favorite summary statistics  Temp This is our response variable. From ?airquality you can see in the help file that Temp is the maximum daily temp in degrees F at La Gaurdia Aiport during 1973  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x is on the right.   Month, “Month” is a column from the airquality dataset that can be treated as qualitative.  data = airquality You have to tell R what dataset the variables Temp and Month come from. ‘airquality’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  Month min   Q1 median    Q3 max     mean       sd  n missing\n1     5  56 60.0     66 69.00  81 65.54839 6.854870 31       0\n2     6  65 76.0     78 82.75  93 79.10000 6.598589 30       0\n3     7  73 81.5     84 86.00  92 83.90323 4.315513 31       0\n4     8  72 79.0     82 88.50  97 83.96774 6.585256 31       0\n5     9  63 71.0     76 81.00  93 76.90000 8.355671 30       0\n\n\n\nWhen calculating treatment means for combinations of 2 or more factors you can use + or | to separate the factors. | (read as ‘vertical bar’ or ‘pipe’) has the advantage that in addition to calculating means for every factor level combination, favstats will also output the marginal means for each level of the last factor listed.\nNOTE: unlike it’s use in the aov() command, using the * within favstats does not yield expected results and should NOT be used.\n\nlibrary(mosaic)\nfavstats(Y ~ X + Z, data = YourDataSet) \n#OR\nfavstats(Y ~ X | Z, data = YourDataSet)\n\nExample code:\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  + This allows us to create additional subgroups within ‘am’ for each level of ‘cyl’.  cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to view output  Click to View Output. \n\n\n\n\n\n  am.cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1    0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2    1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3    0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4    1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5    0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6    1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n\n\n\nNotice that the first column in the output contains the factor level combinations of am and cyl. So, ‘0.4’ is interpreted as level 0 for am and level 4 for cyl. Or in other words, the summary statistics on that row are for automatic tranmission, 4 cylinder engine vehicles. The column label of ‘am.cyl’ indicates which factor is represented on which side of the period. The next example uses the same way of labeling the factor level combinations, but the column label is not as intuitive or helpful.\n\n\n library(mosaic) mosaic is an R Package that is useful in the teaching of statistics to beginning programmers.  favstats( a function from the mosaic package that returns a set of favorite summary statistics  mpg This is a quantitative variable (numerical vector) from the mtcars dataset  ~ “~” is the tilde symbol. It can be interpreted as “y broken down by x”; “y modeled by x”; “y explained by x”, etc. Where y is on the left of the tilde and x variables are on the right.   am A qualitative variable from the mtcars dataset. It is coded as 0 and 1 and so therefore is treated as numeric. That is a key distinction when creating the model, but it does not matter when calling favstats().  | Referred to as a vertical bar or pipe, this symbol further defines subgroups of the variable on its left, using the values of the variable on its right side   cyl, A variable from the mtcars dataset with 3 distinct values: 4, 6, and 8. Though it is a numeric column we want to treat it as a factor. This is a key distinction when creating the model, but it does not matter when calling favstats().  data = mtcars You have to tell R what dataset the variables ‘mpg’, ‘am’, and ‘cyl’ come from. ‘mtcars’ is a preloaded dataset in R.   ) Functions must always end with a closing parenthesis.   Click to View Output  Click to View Output. \n\n\n\n\n\n  cyl  min     Q1 median     Q3  max     mean        sd  n missing\n1 0.4 21.5 22.150  22.80 23.600 24.4 22.90000 1.4525839  3       0\n2 1.4 21.4 25.200  28.85 30.900 33.9 28.07500 4.4838599  8       0\n3 0.6 17.8 18.025  18.65 19.750 21.4 19.12500 1.6317169  4       0\n4 1.6 19.7 20.350  21.00 21.000 21.0 20.56667 0.7505553  3       0\n5 0.8 10.4 14.050  15.20 16.625 19.2 15.05000 2.7743959 12       0\n6 1.8 15.0 15.200  15.40 15.600 15.8 15.40000 0.5656854  2       0\n7   4 21.4 22.800  26.00 30.400 33.9 26.66364 4.5098277 11       0\n8   6 17.8 18.650  19.70 21.000 21.4 19.74286 1.4535670  7       0\n9   8 10.4 14.400  15.20 16.250 19.2 15.10000 2.5600481 14       0\n\n\n\n\n\n\nCalculating treatment means for one factor:\n\nlibrary(tidyverse)\nYourDataSet %&gt;%\n  Group_by(X) %&gt;%\n  Summarise(MeanY = mean(Y), sdY = sd(Y), sampleSize = n()) \n\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  airquality airquality is a dataset in R.   %&gt;%  The pipe operator that will send the airquality dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the airquality dataset into “little” datasets, one dataset for each value in the “Month” column.  Month “Month” is a column from the airquality dataset that can be treated as qualitative.  ) Functions must always end with a closing parenthesis.   %&gt;%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  aveTemp =  “AveTemp” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  Temp Temp is a quantitative variable (numeric vector) from the airquality dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\nMonth\naveTemp\n\n\n\n\n5\n65.55\n\n\n6\n79.1\n\n\n7\n83.9\n\n\n8\n83.97\n\n\n9\n76.9\n\n\n\n\n\nNote that R calculated the mean Temp for each month in Month from the airquality dataset.\nMay (5), June (6), July (7), August (8), and September (9), respectively.\nFurther, note that to get the “nicely formatted” table, you would have to use\nlibrary(pander)\nairquality %&gt;% \n  group_by(Month) %&gt;%\n  summarise(aveTemp = mean(Temp)) %&gt;%\n  pander()\n\nTo calculate treatment means for each combination of factor levels of 2 or more factors, simply add the additional variable to the group_by() statement.\nExample code:\n\n\n library(tidyverse) tidyverse is an R Package that is very useful for working with data.  mpg mtcars is a dataset in preloaded in R.   %&gt;%  The pipe operator that will send the mtcars dataset down inside of the code on the following line.     group_by( “group_by” is a function from library(tidyverse) that allows us to split the mtcars dataset into “little” datasets, one dataset for each combination of values in the ‘am’ and ‘cyl’ variables  am, cyl ‘am’ and ‘cyl’ are both columns in mtcars. By listing them both here we are going to get output for each combination of ‘am’ and ‘cyl’ that exists in the dataset  ) Functions must always end with a closing parenthesis.   %&gt;%  The pipe operator that will send the grouped version of the airquality dataset down inside of the code on the following line.     summarise( “summarise” is a function from library(tidyverse) that allows us to compute numerical summaries on data.  mean_mpg =  “mean_mpg” is just a name we made up. It will contain the results of the mean(…) function.  mean( “mean” is an R function used to calculate the mean.  mpg mpg is a quantitative variable (numeric vector) from the mtcars dataset.  ) Functions must always end with a closing parenthesis.  ) Functions must always end with a closing parenthesis.      \nPress Enter to run the code.   Click to View Output  Click to View Output. \n\n\n\n\n\n`summarise()` has grouped output by 'am'. You can override using the `.groups`\nargument.\n\n\n\n\n\n\n\n\n\n\nam\ncyl\nmean_mpg\n\n\n\n\n0\n4\n22.9\n\n\n0\n6\n19.12\n\n\n0\n8\n15.05\n\n\n1\n4\n28.07\n\n\n1\n6\n20.57\n\n\n1\n8\n15.4"
  },
  {
    "objectID": "DescribeData.html#graphical-summaries",
    "href": "DescribeData.html#graphical-summaries",
    "title": "Describing Data",
    "section": "Graphical Summaries",
    "text": "Graphical Summaries\n\nBoxplots\n\n\n\n\n\n\n\n\nOverviewR InstructionsExplanation\n\n\n\nGraphical depiction of the five-number summary. Great for comparing the distributions of data across several groups or categories. Provides a quick visual understanding of the location of the median as well as the range of the data. Can be useful in showing outliers. Sample size should be larger than at least five, or computing the five-number summary is not very meaningful.\n\n\n\n\n\nBase R ggplot2 plotly\n\n\n\nTo make a boxplot in R use the function:\nboxplot(object)\nTo make side-by-side boxplots:\nboxplot(object ~ group, data=NameOfYourData, ...)\n\nobject must be quantitative data. R refers to this as a “numeric vector.”\ngroup must be qualitative data. R refers to this as either a “character vector” or a “factor.” However, a “numeric vector” can also act as a qualitative variable.\nNameOfYourData is the name of the dataset containing object and group.\n... implies there are many other options that can be given to the boxplot() function. Type ?boxplot in your R Console for more details.\n\nExample Code\nBasic Single Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  $ The $ allows us to access any variable from the airquality dataset.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.  )\nClosing parenthesis for the function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nMore Useful… Basic Side-by-Side Boxplot\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Names under each Box\n\n\n boxplot An R function “boxplot” used to create boxplots.  ( Parenthesis to begin the function. Must touch the last letter of the function.  Temp “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset.   ~  The ~ is used to tell R that you want one boxplot of the quantitative variable (“Temp”) for each group found in the qualitative variable (“Month”).  Month “Month” is a qualitative variable (in this case a “numeric vector” defining months by 5, 6, 7, 8, and 9) from the “airquality” dataset.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  data=airquality data= is used to tell R that the “Temp” and “Month” variables are located in the airquality dataset. Without this, R will not know where to find “Temp” and “Month” and the command will give an error.  , \nThe “,” is required to start specifying additional commands for the “boxplot()” function.  names=c(“May”,“June”,“July”,“Aug”,“Sep”) names= is used to tell R what labels to place on the x-axis below each boxplot.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Color and Labels\n\n\n boxplot(Temp ~ Month, data=airquality This code was explained in the previous example code.  ,  The comma is used to separate each additional command to a function.  xlab=“Month of the Year” xlab= stands for “x label.” Use it to specify the text to print on the plot under the x-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  ylab=“Temperature” ylab= stands for “y label.” Use it to specify the text to print on the plot next to the y-axis. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  main=“La Guardia Airport Daily Temperatures” main= stands for the “main label” of the plot, which is placed at the top center of the plot. The desired text must always be contained in quotes.  ,  The comma is used to separate each additional command to a function.  col=“wheat” col= stands for the “color” of the plot. The color name “wheat” is an available color in R. Type colors() in the R Console to see more options. The color name must always be placed in quotes.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a boxplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_boxplot()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_boxplot() causes the ggplot to become a boxplot.\n\n\nExample Code\nBasic Single Boxplot\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the y-axis should become.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot() The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n Side-by-side Boxplot and Color Change\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_boxplot()” function causes the ggplot to become a boxplot. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box in the boxplot.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nAdd Labels \n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality “airquality” is a dataset. Type “View(airquality)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=factor(Month),  “x=” declares which variable will become the x-axis of the graphic. Since Month is “numeric” we must use “factor(Month)” instead of just “Month”.  y=Temp “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_histogram()” function causes the ggplot to become a histogram. There are many other “geom_” functions that could be used.  fill=“skyblue”,  The “fill” command controls the color of the insides of each box.  color=“black” The “color” command controls the color of the edges of each box.  )\nClosing parenthesis for the geom_boxplot function.   +  The addition symbol + is used to add further elements to the ggplot.     labs( The “labs” function is used to add labels to the plot, like a main title, x-label and y-label.  title=“La Guardia Airport Daily Mean Temperature”,  The “title=” command allows you to control the main title at the top of the graphic.  x=“Month of the Year”,  The “x=” command allows you to control the x-label of the graphic.  y=“Daily Mean Temperature” The “y=” command allows you to control the y-label of the graphic.  )\nClosing parenthesis for the labs function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\nGallery\nSee what past students have done…\nClick to view.\n\nHover to see code.\n \n ggplot(data = mtcars, aes(x = as.factor(cyl), y = mpg, fill=as.factor(cyl))) +  geom_boxplot()  +  stat_summary(fun.y = mean, geom = \"errorbar\", aes(ymax = ..y.., ymin = ..y..),     width = .75, linetype = \"dashed\", color=\"firebrick\") +  theme_light() +  theme(panel.grid.major=element_blank()) +  scale_fill_brewer(palette=\"Dark2\") +  geom_jitter(width=0.1, height=0) +  labs(title = \"Miles Per Gallon Based on Cylinders\",     x=\"Number of Cylinders\",     fill=\"Cylinders\",     y=\"Miles Per Gallon\")   \n \n ggplot(data = ToothGrowth, aes(x = as.factor(dose), y = len, fill=as.factor(dose))) +  geom_boxplot( )  +  facet_wrap(~supp) +  theme_bw() +  scale_fill_manual(values=c(\"#999999\", \"#E69F00\", \"#56B4E9\")) +  geom_jitter(width=0.1, height=0) +  labs(title = \"Tooth Length Based on Doses     According to Supplement Type\",     fill=\"Doses\",     x=\"Dosage Amount(mg)\",     y=\"Tooth Length\" )   \n\n\n\n\n\nTo make a histogram in plotly first load\nlibrary(plotly)\nThen, use the function:\nplot_ly(dataName, y=~columnNameY, x=~columnNameX, type=\"box\")\n\ndataName is the name of a data set\ncolumnNameY must be the name of a column of quantitative data. R refers to this as a “numeric vector.” This will become the y-axis of the plot.\ncolumnNameX must be the name of a column of qualitative data. This will provide the “groups” forming each individual box in the boxplot.\ntype=\"box\" tells the plot_ly(…) function to create a boxplot.\n\nVisit plotly.com/r/box-plots for more details.\n\nExample Code\nHover your mouse over the example codes to learn more. Click on them to see what they create.\nBasic Boxplot\n\n\n plot_ly An R function “plot_ly” from library(plotly) used to create any plotly plot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  airquality,  “airquality” is a dataset. Type “View(airquality)” in R to see it.  y= The y= allows us to declare which column of the data set will become the y-axis of the boxplot. In other words, the quantitative data we are interested in studying for each group.  ~Temp,   “Temp” is a quantitative variable (numeric vector) from the “airquality” dataset. The ~ is required before column names inside all plot_ly(…) commands.  x= The x= allows us to declare which column of the data set will become the x-axis of the boxplot. In other words, the “groups” forming each separate box in the boxplot.  ~as.factor(Month),   since “Month” is a quantitative variable (numeric vector) from the “airquality” dataset we have to change it to a “factor” which forces R to treat it as a qualitative (groups) variable. The ~ is required before column names inside all plot_ly(…) commands.  type=“box” This option tells the plot_ly(…) function what “type” of graph to make. In this case, a boxplot.  )\nClosing parenthesis for the plot_ly function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nChange Color\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”,  This code was explained in the first example code.  fillcolor=“skyblue”,  this changes the fill color of the boxes in the boxplot to the color specified, in this case “skyblue.”  line=list(color=“darkgray”, width=3),  this “list(…)” of options that will be specified will effect the edges of the boxes in the boxplot. We are changing their color to “darkgray” and their width to 3 pixels wide.  marker=list( this “list(…)” of options that will be specified will effect the outlying dots shown in the boxplots beyond the “fences” of each box.  color = “orange”,  this will change the color of the dots to orange.  line = list(,  this opens a list of options to specify for the “lines” around the “markers.”  color = “red”,  this will change the color of the lines around the outlier dots to red.  width = 1 this will change the width of the lines around the outlier dots to 1 pixel.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\nAdd Titles\n\n\n plot_ly(airquality, y=~Temp, x=~as.factor(Month), type=“box”, fillcolor=“skyblue”, line=list(color=“darkgray”, width=3), marker = list(color=“orange”, line = list(color=“red”, width=1)))  This code was explained in the above example code.  %&gt;% the pipe operator sends the completed plot_ly(…) code into the layout function.  layout( The layout(…) function is used for specifying details about the axes and their labels.  title=“La Guardia Airport Daily Mean Temperatures” This declares a main title for the top of the graph.  xaxis=list( This declares a list of options to be specified for the xaxis. The same can be done for the yaxis(…).  title=“Month of the Year” This declares a title underneath the x-axis.  ),  Functions always end with a closing parenthesis.  yaxis=list( This declares a list of options to be specified for the y-axis.  title=“Temperature in Degrees F” This declares a title beside the y-axis.  ) Functions always end with a closing parenthesis.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding how a boxplot is created is the best way to understand what the boxplot shows.\n\nHow Boxplots are Made\n\nThe five-number summary is computed.\nA box is drawn with one edge located at the first quartile and the opposite edge located at the third quartile.\nThis box is then divided into two boxes by placing another line inside the box at the location of the median.\nThe maximum value and minimum value are marked on the plot.\nWhiskers are drawn from the first quartile out towards the minimum and from the third quartile out towards the maximum.\nIf the minimum or maximum is too far away, then the whisker is ended early.\nAny points beyond the line ending the whisker are marked on the plot as dots. This helps identify possible outliers in the data.\n\n\n\n\n\n\n\n\n\nScatterplot, with Means\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nScatterplots of a catgorical variable on the x axis and quantitative variable on the y axis are sometimes called strip charts, or side-by-side strip charts. When sample sizes are not too big and there are not too many repeated value this type of chart is an excellent way to see the variability in the data without the abstraction of a boxplot. By plotting individual observations you also can see the size of the sample for each factor level. Including factor level means on the plot adds additional insight. The mean of each factor level is often connected with a line for visual impact.\n\n\n\n\nmosaic ggplot2 plotly\n\n\n\nTo make a scatterplot use the function:\nxyplot(y~x, data = mydata)\n\ny is the quantitative response variable, i.e., “numeric vector.”\nx is the independent, explanatory variable\nmydata is the name of the dataset containing y and x.\n\nThis will return a scatterplot regardless of how your x variable is stored in R (numeric, character, factor). This function is flexible and with minimal effort can include averages or make an interaction plot. xyplot() is a part of the lattice package, which is loaded when the mosaic package is loaded.\nNote: plot() from base R will also give a scatterplot, but only if the x variable is quantitative. If x is a character or factor variable the default is to return a boxplot plot.\nExample Code\nBy reading the documentation for the dataset (visible when ?ToothGrowth is run in the console) we can see that our “x” variable, “dose”, is a numeric variable in R. Because of this the x-axis maintains the relative distance of doses on the x-axis.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nIf you start with a numeric x variable, you may or may not want to convert it to a factor variable. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed. Compare the output of the previous example code with this example code. This example code converts our x variable of “dose” to a factor variable.\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\nTo include the means on the plot and connect them with a line use this code\n\n\n\n xyplot An R function used to create a scatterplot.  ( Parenthesis to begin the function. Must touch the last letter of the function.  len “len” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the response variable (y-axis) for this plot.   ~  The ~ is used to tell R that you want a scatterplot with the quantitative variable “len” on the y-axis and the variable “dose” on the x-axis.  factor An R function to convert how data is stored in a variable. The variable input into this function will now be treated as a factor variable in this command  ( Parenthesis to begin the function. Must touch the last letter of the function.  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot. Because it is an input to the factor function it will be treated as a factor variable  ) Functions always end with a closing parenthesis.  , \nThe “,” is required to start specifying additional commands for the function.  data=ToothGrowth data= is used to tell R that the “len” and “dose” variables are located in the ToothGrowth dataset. Without this, R will not know where to find “len” and “dose”. Learn more about the dataset by entering ?ToothGrowth into the console.  , \nThe “,” is required to start specifying additional commands for the function.  xlab = “Vitamin C dose in mg/day” xlab= allows you to specify an x-axis label. The units mg/day is explained in the dataset documentation, visible when ?ToothGrowth is run in the console.   , \nThe “,” is required to start specifying additional commands for the function.  ylab = “Length” ylab= allows you to specify an y-axis label.  , \nThe “,” is required to start specifying additional commands for the function.  type =\nThe type argument allows you to add different types of lines to the plot. Run ?panel.xyplot() to read more about values for this argument  c( Combines the following values into one vector. This allows me to pass multiple values as one input to “type =”. Useful for if I want to plot something in addition to the default of plotting points.  ‘p’\nThis requests the points to be plotted. It is the default value. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  , \nThe “,” is required to start specifying additional commands for the function.  ‘a’ This requests the average for each factor level to be connected with a line. Other acceptable values for the type argument can be seen by running ?panel.xyplot() in the console.  ) Functions always end with a closing parenthesis.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make a scatterplot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=groupsColumn, y=dataColumn) +\n  geom_point()\n\ndata is the name of your dataset.\ngroupsColumn is a column of data from your dataset that is qualitative and represents the groups that should each have a boxplot.\ndataColumn is a column of data from your dataset that is quantitative.\nThe aesthetic helper function aes(x= , y=) is how you tell the gpplot to make the x-axis have the values in your groupsColumn of data, the y-axis become your dataColumn. Note if groupsColumn is not a factor, use factor(groupsColumn) instead.\nThe geometry helper function geom_point() causes the ggplot to become a scatterplot; or in other words to draw points to represent data.\n\n\nExample Code\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_boxplot( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n If you start with a numeric x variable, you may or may not want to convert it to a factor variable. You do this by using ‘factor(x)’ instead of just ‘x’ as shown below. Doing so will make each factor level, or category, equally spaced along the x-axis. It also “cleans up” the axis by removing additional tic-marks and axis values that aren’t needed.\nggplot(ToothGrowth, aes(x = factor(dose), y = len)) +   geom_point(color = \"blue\")\nAdding averages to the plot and connecting them with a line requires a little more effort and is demonstrated in the code below. I also add some more descriptive labels to the chart.\nNote the use of stat_summary to indicate I want to add a layer that plots a numerical summary, not the original data. Some geoms have stat summaries built in to them (like geom_bar or geom_boxplot), but in our case we have to define the summary.\nIn the stat_summary I provide additional arguments to the aesthetics helper function. Defining the aesthetics in ggplot() is like a global definition, all additional layers inherit those aesthetic mappings. Defining them in a geom_* or a stats_* allows you to add to or override what was defined in ggplot() for that layer only. The group aesthetic is required in order to use a line geometry. In this case, group could just as easily have been defined in ggplot(aes()).\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function allows you to tell the ggplot how it should appear. This includes things like what the x-axis or y-axis should become.  x=dose,  “x=” declares which variable will become the x-axis of the graphic.  y=len “y=” declares which variable will become the y-axis of the graphic.  )\nClosing parenthesis for the aes function.  )\nClosing parenthesis for the ggplot function.   +  The addition symbol + is used to add further elements to the ggplot.     geom_point( The “geom_point()” function causes the ggplot to draw data as points, thus it become a scatterplot. There are many other “geom_” functions that could be used.  color=“blue” The “color” command controls the color of the points. It can be confusing to know when to use “color” vs. “fill”.  )\nClosing parenthesis for the geom_boxplot function.   + The addition symbol + is used to add further elements to the ggplot.    stat_summary( This function will calculate a statistical summary to be plotted on the chart  fun = mean, fun is short for function. The summary function I want to apply to my y variable is “mean”.  geom = “line”, The “geom=” argument is used to tell what kind of geometry should be drawn to represent the means. Here we are asking for the means to be connected with a line.  aes( The aes or “aesthetics” function allows you to tell ggplot what variables should be mapped to what visual aspects of the chart; including what the x-axis or y-axis should become. Including it her means the aesthetic will only be applied to this layer.  group = 1 indicates which variable should be grouped by when drawing multiple lines (one line for each factor level). We write the number 1 to indicate there is just 1 group; we are not further splitting the data.  )\nClosing parenthesis for the geom_boxplot function.  )\nClosing parenthesis for the geom_boxplot function.   + The addition symbol + is used to add further elements to the ggplot.    labs( Function to edit labels of the plot  x = “Vitamin C mg/day”, Edit the x-axis label  y = “Length”, Edit the y-axis label  title = “Tooth Growth in Guinea Pigs” Edit the chart title  )\nClosing parenthesis for the geom_boxplot function.      \nPress Enter to run the code.   …  Click to View Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nUnder construction.\n\n\n\n\n\n\n\n\n\nInteraction Plot\n\n\n\n\n\n\n\n\nOverviewR Instructions\n\n\nThese plots are used to visualize two categorical factors (mapped to the x-axis and the line color/type) and a quantitative response variable (displayed on the y-axis). A point for each factor level combination mean is plotted, and then points are connected with lines to aid the visual interpretation of the plot. Because they show two factors, they are ideal for two-way ANOVA.\nInteraction plots are a great way to see factor effects. In particular, they can be helpful in understanding the nature of an interaction factor, or detecting the lack thereof. If the line segments in the plot are all (nearly) parallel, this is indicative that no interaction effect exists between the two factors. The more non-parallel the line segments, the more likely a significant interaction effect is present.\nA formal hypothesis test should be conducted to determine the significance of an interaction term, since sometimes the hypothesis test result can run counter to what a quick visual inspection might suggest. When a significant interaction is present, an interaction plot can be a critical part of understanding the nature of the interaction.\nIf there are three factors in a study, multiple interaction plots can be used (one at each value of the third factor) to explore the nature of two-way and three-way interactions. This approach can be extended for analyses involving more than 3 factors. However, interactions involving more than 3 variables are rare in practice. Therefore, if more than 3 factors are present in an analysis, interaction plots are not usually used as an exploratory tool. Instead, statistical tests are used to find significant interactions, and then interaction plots are used to describe the nature of those interactions.\n\n\n\n\nBase R ggplot2 plotly\n\n\n\nTo make a scatterplot use the function:\ninteraction.plot(mydata$factor_x, mydata$factor_line, mydata$response)\n\nmydata is the name of the dataset containing the factors and response.\nfactor_x is factor (or string) variable that will be plotted on the x-axis\nfactor_line is factor (or string) variable that will have different colored/types of lines on the plot\ny is the quantitative response variable, i.e., “numeric vector.”\n\nNote, unlike the other plotting we have done so far, there is no data = argument. Each variable must be specified using the $ notation if it exists inside a dataset. There are many additional arguments to specify colors, line types, legend formatting, etc.\nExample Code\nBy reading the documentation for the dataset (visible when ?ToothGrowth is run in the console) we can see that our “x” variable, “dose”, is a numeric variable in R. Because of this we convert it to a factor variable in the plot command with the factor() command. This changes the nature of dose only within that particular plot, not within the dataset generally.\n\n\n\n interaction.plot( An R function used to create an interaction plot  factor( A function to make a variable categorical.  ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  ) parenthesis to close the factor function  , separate arguments to a function with commas  ToothGrowth Name of the dataset that contains the variables.  $ The $ allows you to refer to a variable in a dataset by name  supp a different line will be drawn for each value of supp  , separate arguments to a function with commas   ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  len name of the response variable in ToothGrowth  , separate arguments to a function with commas ylab= argument to specify y-axis label  “Tooth length” Label for the y-axis must be put in quotes  ,  separate arguments to a function with commas  xlab= argument to specify x-axis label  “Dose (vitamin C mg/day)” Label for the x-axis must be put in quotes  , separate arguments to a function with commas  trace.label= argument to specify the trace label which will appear in the legend  “Delivery Method” Label for the trace factor must be put in quotes  , separate arguments to a function with commas  main= argument to specify the chart title  “Tooth Growth in Guinea Pigs” Chart title must be put in quotes  ) parenthesis to close the interaction.plot function      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\nBecause not all the line segments are parallel, you may begin to suspect an interaction is present. To determine if the interaction is significant you can do a hypothesis test for.\nNote, an easy/slick method for changing the legend position does not (currently) exist for interaction.plot(), though some hacked solutions can be used.\nYou can adjust things like line color, plotting points, etc. as shown in this next example.\n\n\n\n interaction.plot( An R function used to create an interaction plot  factor( A function to make a variable categorical.  ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  dose “dose” is a quantitative variable (numeric vector) from the “ToothGrowth” dataset that is being used as the explanatory variable (x-axis) for this plot.  ) parenthesis to close the factor function  , separate arguments to a function with commas  ToothGrowth Name of the dataset that contains the variables.  $ The $ allows you to refer to a variable in a dataset by name  supp a different line will be drawn for each value of supp  , separate arguments to a function with commas   ToothGrowth Name of the dataset that contains the dose variable.  $ The $ allows you to refer to a variable in a dataset by name  len name of the response variable in ToothGrowth  , separate arguments to a function with commas ylab= argument to specify y-axis label  “Tooth length” Label for the y-axis must be put in quotes  ,  separate arguments to a function with commas  xlab= argument to specify x-axis label  “Dose (vitamin C mg/day)” Label for the x-axis must be put in quotes  , separate arguments to a function with commas  trace.label= argument to specify the trace label which will appear in the legend  “Delivery Method” Label for the trace factor must be put in quotes  , separate arguments to a function with commas  main= argument to specify the chart title  “Tooth Growth in Guinea Pigs” Chart title must be put in quotes  , separate arguments to a function with commas  type=\nargument to specify whether lines, points, or both should be plotted  ‘b’ b, in quotes, indicates lines and points should be drawn on the plot  , separate arguments to a function with commas   pch=\nargument to specify shape of the points  16 an integer value from 0 to 25 is expected.   , separate arguments to a function with commas  lty=\nargument to specify line type.   1 1 for a solid line. Line type can be specified with an integer from 0 - 6, or text “solid”.  , separate arguments to a function with commas  col=\nargument to specify colors to be used for different values of the trace factor, supp  c( concatenate function used to create a vector  “darkblue” color to be used for first value of supp. Can be given in name form, integer, or rgb specs  ,\nseparate values in a vector with a comma   “deeppink3” color to be used for first value of supp. Can be given in name form, integer, or rgb specs  ) end the vector with a parenthesis  ) parenthesis to close the interaction.plot function      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo make an interaction plot in R using the ggplot approach, first ensure\nlibrary(ggplot2)\nis loaded. Then,\nggplot(data, aes(x=factor1, color=factor2, group=factor2, y=response) +\n  stat_summary(fun = mean, geom = \"line\")\n\ndata is the name of your dataset.\nfactor1 is a column of data from your dataset that is a qualitative factor whose values you want to plot along the x-axis.\nfactor2 is a column of data from your dataset that is a qualitative factor. You want to draw a different colored line for each value of this factor.\nresponse is the name of the quantitative response variable in your dataset.\nThe aesthetic helper function aes() is how you tell R which variables you want mapped to which aesthetics (i.e. visual attributes) of your chart. This is actually the input to the mapping= argument, but for conciseness mapping= is usually not typed out.\n\nThe group aesthetic indicates that any summary statistics that are calculated should be calculated separately for each value of factor2. It’s similar to a group_by() statement.\nBecause factor2 is also the value for color, each value of factor2 will be represented with a different color.\n\nstat_summary() does two things:\n\ncalculates a summary statistic. In this case we tell it to calculate the mean for each factor level combination with the fun = mean code. fun stands for “function”.\nindicates we want to connect the means with a line. geom stands for our desired geometry, in this case lines.\n\n\nNote if one of your factor variables is not coded as a factor (e.g. it is numeric), use factor() to convert it to the correct data type.\n\nHere is a basic interaction plot using ggplot2 package. In a later example we will add additional formatting, labels, etc.\n\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function is actually an input to the mapping= argument. It allows you to which variable is mapped to aspects of the chart. This includes things like what the x-axis or y-axis should become.  x= “x=” declares which variable will become the x-axis of the graphic.  factor(dose), factor converts dose, a numeric variable, into a categorical variable  color=supp,  declares that each value of supp will be represented with a different color  group=supp,  declares that each value of supp must be drawn separately. We specify the geometry to be drawn later with geom.  y=len declares which variable will become the y-axis of the graphic.  )) close the aes and ggplot functions with a parenthesis   + The addition symbol is used to add/tweak chart elements.    stat_summary( this adds a layer to the chart that will show summary statistics  fun = mean,  “mean” is the function used to get a summary statistic  geom=“line” The geometry used on the chart will be lines  ) parenthesis to close the stat_summary function      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\nAdd different line types, points for each factor level mean, and improved labelling\nLook at the code below and notice that with the exception of the group aesthetic, a label is applied to each aesthetic mapping. linetype and color have the same label and R is smart enough to therefore combine the legend for these two aesthetic mappings into one legend. If the labels are not identical, each aesthetic will have a unique legend.\n\n\n\n ggplot An R function “ggplot” used to create a framework for a graphic that will have elements added to it with the + sign.  ( Parenthesis to begin the function. Must touch the last letter of the function.  ToothGrowth “ToothGrowth” is a dataset. Type “View(ToothGrowth)” in R to see it.  ,  The comma allows us to specify optional commands to the function. The space after the comma is not required. It just looks nice.  aes( The aes or “aesthetics” function is actually an input to the mapping= argument. It allows you to which variable is mapped to aspects of the chart. This includes things like what the x-axis or y-axis should become.  x= “x=” declares which variable will become the x-axis of the graphic.  factor(dose), factor converts dose, a numeric variable, into a categorical variable  color=supp,  declares that each value of supp will be represented with a different color  group=supp,  declares that each value of supp must be drawn separately. We specify the geometry to be drawn later with geom.  linetype=supp,  declares that each value of supp will be represented with a different line type  y=len declares which variable will become the y-axis of the graphic.  )) close the aes and ggplot functions with a parenthesis   + The addition symbol is used to add/tweak chart elements.    stat_summary( this adds a layer to the chart that will show summary statistics  fun=mean,  “mean” is the function used to get a summary statistic  geom=“line”,  The geometry used on the chart will be lines  size=1 Change the line thickness  ) parenthesis to close the stat_summary function   + The addition symbol is used to add/tweak chart elements.    stat_summary( this adds a layer to the chart that will show summary statistics  fun=mean,  “mean” is the function used to get a summary statistic  geom=“point”,  The geometry used on the chart will be points  size=3 Change the size of the points  ) parenthesis to close the stat_summary function   + The addition symbol is used to add/tweak chart elements.    labs( use this layer to change chart labels  x=“Vitamin C dose (mg/day)”, Put the x-axis label in quotes     y=“Tooth Length”, Put the x-axis label in quotes     title=“Guinea Pig Study”, Put the chart title in quotes     color=“Delivery Method”, Put the color label in quotes     linetype=“Delivery Method” Put the linetype label in quotes  ) Close labs with a parenthesis      \nPress Enter to run the code.   …  Toggle Output. \n\n\n\n\n\n\n\n\n\n\n\n\n\nUnder construction."
  },
  {
    "objectID": "cb1.html",
    "href": "cb1.html",
    "title": "CB[1]",
    "section": "",
    "text": "In a complete block design (CB[1]), there are two controlled factors: a treatment factor and a blocking factor. The study’s objective is usually to measure and/or test the treatment factor effects. The blocking factor is included to avoid confounding the treatment factor with the blocking factor and to reduce the variance of the error term.\n\n\n\n\n\n\nTip\n\n\n\nIn a CB[1] design, there is only one observation per treatment per block, and thus an interaction effect cannot be estimated. In a CB[1], the treatment by block interaction is therefore assumed to be zero.\n\n\nThe toothbrush example can be used to illustrate this design. Imagine the toothbrush researchers are still in the planning stages of the experiment. Researchers want to pre-emptively address the argument that one toothbrush performs better (or worse) simply because the people who use that brush in the study are in some way better at brushing. There are a couple of things the researchers can do. They should of course provide training/education to each participant about the proper way to brush. This would help, but old brushing habits die hard, and skeptics can argue that behavior won’t change.\nIn addition to adjusting experimental protocols, the design of the experiment can be adjusted to address the concern. Specifically, the researchers can block on participant. The experiment would look like this:\n\nA person uses a particular brush for a set period.\nAt the end of the period, their plaque amount would be measured and their teeth cleaned\nThen they would use a different brush for the same set amount of time.\nThe process would repeat until the person had used all 4 brushes.\n\nThe order of the brush will be randomized for each person to remove any bias due to learning, fatigue, or gradual plaque build up.\n\n\nThe factor structure for a CB[1] design still has the two universal factors of the grand mean and residual error. There are also two structural factors: blocks and treatments.\n\n\n\n\nFigure 1: Factor Structure for CB[1]\n\n\n\nIn this case, the blocks factor accounts for variation in participants, and the treatment is toothbrush type. There are 6 participants in the study (6 block factor levels). Each toothbrush type appears once in each block. There are 24 observations total, 1 observation for each combination of block and toothbrush.\n\n\n\nEach factor (i.e. meaningful partition of the data) in Figure 1 corresponds to a term on the right hand side of Equation 1:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\beta_j + \\epsilon_{ij}\n\\tag{1}\\]\nWhere\n\n\\(y_{ij}\\) is the observation that belongs to level i of \\(\\alpha\\) and level j of \\(\\beta\\).\n\\(\\mu\\) is the grand mean of the entire dataset.\n\\(\\alpha\\) is the effect of participant, and j goes from 1 to 6 since there are 6 participants / blocks.\n\\(\\beta\\) is the effect of toothbrush, and i goes from 1 to 4 since there are 4 toothbrush types.\n\\(\\epsilon\\) is the residual error term\n\nNote that since there is only one observation per factor level combination, there is not enough degrees of freedom to estimate an interaction effect.\nThe hypothesis of interest for a CB[1] study is about the treatment factor:\n\n\nBlock is a nuisance factor and not of particular interest. If you desired to test the Block factor as well, the null hypohtesis would be \\[ Ho: \\alpha_i = 0 \\text{ for all } i\\]\n\\[H_a: \\alpha_i \\ne 0 \\text{ for some }i\\]\n\\[H_0: \\beta_j = 0 \\text{ for all }j\\]\n\\[H_a: \\beta_i \\ne 0 \\text{ for some }j\\]\n\n\n\nAn ANOVA model may be used to analyze data from a CB[1] design if the following requirements are satisfied.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels1\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "cb1.html#factor-structure",
    "href": "cb1.html#factor-structure",
    "title": "CB[1]",
    "section": "",
    "text": "The factor structure for a CB[1] design still has the two universal factors of the grand mean and residual error. There are also two structural factors: blocks and treatments.\n\n\n\n\nFigure 1: Factor Structure for CB[1]\n\n\n\nIn this case, the blocks factor accounts for variation in participants, and the treatment is toothbrush type. There are 6 participants in the study (6 block factor levels). Each toothbrush type appears once in each block. There are 24 observations total, 1 observation for each combination of block and toothbrush."
  },
  {
    "objectID": "cb1.html#hypothesis-and-model",
    "href": "cb1.html#hypothesis-and-model",
    "title": "CB[1]",
    "section": "",
    "text": "Each factor (i.e. meaningful partition of the data) in Figure 1 corresponds to a term on the right hand side of Equation 1:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\beta_j + \\epsilon_{ij}\n\\tag{1}\\]\nWhere\n\n\\(y_{ij}\\) is the observation that belongs to level i of \\(\\alpha\\) and level j of \\(\\beta\\).\n\\(\\mu\\) is the grand mean of the entire dataset.\n\\(\\alpha\\) is the effect of participant, and j goes from 1 to 6 since there are 6 participants / blocks.\n\\(\\beta\\) is the effect of toothbrush, and i goes from 1 to 4 since there are 4 toothbrush types.\n\\(\\epsilon\\) is the residual error term\n\nNote that since there is only one observation per factor level combination, there is not enough degrees of freedom to estimate an interaction effect.\nThe hypothesis of interest for a CB[1] study is about the treatment factor:\n\n\nBlock is a nuisance factor and not of particular interest. If you desired to test the Block factor as well, the null hypohtesis would be \\[ Ho: \\alpha_i = 0 \\text{ for all } i\\]\n\\[H_a: \\alpha_i \\ne 0 \\text{ for some }i\\]\n\\[H_0: \\beta_j = 0 \\text{ for all }j\\]\n\\[H_a: \\beta_i \\ne 0 \\text{ for some }j\\]"
  },
  {
    "objectID": "cb1.html#assumptions",
    "href": "cb1.html#assumptions",
    "title": "CB[1]",
    "section": "",
    "text": "An ANOVA model may be used to analyze data from a CB[1] design if the following requirements are satisfied.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels1\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "cb1.html#degrees-of-freedom",
    "href": "cb1.html#degrees-of-freedom",
    "title": "CB[1]",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nWe can use our understanding of inside vs. outside factors to determine the degrees of freedom (df) for the grand mean, treatment factor, blocks, and residual errors. We start with 24 observations - or pieces of information. In other words, we have 24 degrees of freedom that need to be allocated to the factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\nDegrees of Freedom for a factor = Total levels of a factor minus the sum of the degrees of freedom of all outside factors\n\n\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\nThe grand mean has one level and there are no factors outside of grand mean. Therefore, its degrees of freedom equals one. This will always be the case.\nIn this case there are two controlled factors: treatment factor (toothbrush) and blocking factor (participant). For treatment factor, there are four levels of the factor (shown by the four vertically long cells for treatment factor in Figure 2). Since grand mean is the only factor outside of toothbrush, take the number of levels for toothbrush (4) and subtract the degrees of freedom for grand mean (1), which yields 4-1 = 3 degrees of freedom for toothbrush.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the toothbrush effects really contain. Since all observations from the same toothbrush will have the same effect, we only need to know 4 pieces of information: the effect of each toothbrush. But, because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom are 3. As soon as we know effect for 3 factor levels of toothbrush, we can fill in the toothbrush effects for all the observations.\nThough we don’t plan to test for the Block factor, we walk through the steps here to have a complete accounting of the degrees of freedom and variance. To calculate Block degrees of freedom, a similar approach of counting “free numbers” can be used. Namely, after estimating a participant’s effect on plaque, I can fill that effect in for all the observations pertaining to that participant’s partition in the block factor. Therefore, there is just one unique value in each row, meaning one degree of freedom per participant. However, since the sum of effects across participant must equal zero, the degrees of freedom will be equal to one less the number of participants.\nAlternatively, degrees of freedom can be calculated using the general rule. There are 6 levels for participant Blocks, and grand mean is the only outside factor. Since grand mean has 1 degree of freedom, you get 6−1=5 degree of freedom for blocks.\nFinally, the residual degrees of freedom can be found using the general rule. Since the residual error factor is inside of all other factors, this is the same as finding how many degrees of freedom are leftover after calculating degrees of freedom for all other factors. In this example, there were 24 observations total, so we subtract the degrees of freedom for the other factors from 24. This returns 24−(1+3+5)=15 degrees of freedom for residuals."
  },
  {
    "objectID": "cb1.html#factor-effects",
    "href": "cb1.html#factor-effects",
    "title": "CB[1]",
    "section": "Factor Effects",
    "text": "Factor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size of the grand mean, treatment factor, blocks, and residual errors. Recall the general rule for estimating effect size of a factor:\n\n\n\n\n\n\nGeneral Rule for Effect Size\n\n\n\nEffect size = Factor level mean - sum of the effects of all outside factors\n\n\nWe start by calculating factor level means.\n\nFactor Level Means\nFigure 3 shows our data set with partition lines for structural factors in place. We will proceed to calculate the factor level means for each factor.\n\n\n\nFigure 3: Partitioned CB[1] Toothbrush Data\n\n\nThe grand mean is the mean of all the observations\n\\[\n\\hat{\\mu} = \\bar{y}_{\\cdot\\cdot} = \\frac{19.12 + 18.56 + 25.58 + 24.39 + 24.21 + ... + 23.42}{24} = 22.76\n\\]\nNow find the mean for each level of toothbrush type.\n\\[\n\\bar{y}_\\text{manual} = \\bar{y}_{\\cdot 1} = \\frac{19.12 + 24.21 + 26.88 + 21.6 + 23.4 + 23.35}{6} = 23.10\n\\]\n\\[\n\\bar{y}_\\text{oscillating} = \\bar{y}_{\\cdot 2} = \\frac{18.56 + 20.00 + 19.87 + 22.09 + 17.62 + 21.72}{6} = 19.98\n\\]\n\\[\n\\bar{y}_\\text{sonic} = \\bar{y}_{\\cdot 3} = \\frac{25.58 + 23.31 + 18.99 + 23.09 + 23.81 + 21.27}{6} = 22.68\n\\]\n\\[\n\\bar{y}_\\text{ultrasonic} = \\bar{y}_{\\cdot 4} = \\frac{24.39 + 21.45 + 32.74 + 24.21 + 25.67 + 23.42}{6} = 25.31\n\\]\n\n\nNote the effects for grand mean and toothbrush are the same as they are in the BF[2].\nNow find the mean for each level of block (only the first two blocks are illustrated here).\n\\[\n\\bar{y}_\\text{Block1} = \\bar{y}_{1\\cdot} = \\frac{19.12 + 18.56 + 25.58 + 24.39}{4} = 21.91\n\\tag{2}\\]\n\\[\n\\bar{y}_\\text{Block2} = \\bar{y}_{2\\cdot} = \\frac{24.21 + 20.00 + 23.31 + 21.45}{4} = 22.24\n\\]\nThe mean for each residual error factor level is the observed value itself since there is just 1 observation per level. Therefore, there are no calculations to show.\nFigure 4 displays the factor levels means associated with each observation.\n\n\n\n\nFigure 4: Factor Level Means\n\n\n\n\n\nFactor Level Effects\nNow that we have calculated means for the levels of each factor, we can calculate the effects of the factor levels2.\nThere is only one level of grand mean and there are no outside factors. Therefore, the effect due to grand mean is 22.76 (equivalent to its mean) and this effect is applied to all 24 observations.\nThe toothbrush factor has four levels: one for each brush type. We will use the general rule for calculating factor level effects. To calculate the effect of a toothbrush, take the toothbrush mean and subtract the grand mean (the only factor outside of toothbrush) from it. For the manual brush, this looks like:\n\\[ 23.09 - 22.76 = 0.33 \\]\nUsing the manual brush has the effect of increasing a person’s plaque area percentage by 0.33 percentage points on average compared to the grand mean. In a similar way you can find the effect for the oscillating brush: \\(19.98−22.76=−2.79\\). This means the amount of plaque decreased by 2.79 on average with this brush compared to the grand mean. For a sonic toothbrush, the effect is \\(22.68−22.76=−0.09\\). For an ultrasonic brush the effect is \\(25.31−22.76=2.55\\).\nCalculating the effects for the block factor in the experiment follows a similar pattern and also uses the general rule for calculating effect sizes. Block is not outside or inside of toothbrush, but grand mean is outside of block. To calculate the effect an of individual participant (i.e. block), take the participant’s mean across all 4 treatments (see Equation 2 as an example) and subtract the grand mean from it:\n\\[ 21.91 - 22.76 = -0.85\\]\nA similar calculation is done to find the estimated effect for participant 2 (i.e. block 2):\n\\[ 22.24 - 22.76 = -0.52\\]\nSimilar calculations are performed for the remaining four blocks (i.e. participants).\nYou can think of the last term in the model as residual effects, but we usually refer to them simply as residuals. Residual means “left over” or “remaining”. After adding all the other effects together, the residual is the remaining effect, or deviation, needed to arrive at the observed value.\nMore simply, the residual is the actual observed value minus the predicted value.\nThe observed plaque coverage for Participant 1 using the manual brush is 19.12. The sum of the other factor effect represents the predicted value for this factor level combination:\n\\[\n\\begin{align}\n\\hat{y}_{11} &= \\hat{\\mu} + \\hat{\\alpha}_1 + \\hat{\\beta}_1 \\\\\n22.24 &= 22.76 + \\text{-}0.85 + 0.33\n\\end{align}\n\\]\nThe residual then, is\n\\[\n\\begin{align*}\ne_{11} &= y_{11} - \\hat{y}_{11} \\\\\n&= 19.12 - 22.24 \\\\\n&= -3.12\n\\end{align*}\n\\]\nThe residual can be interpreted to mean that this participant’s plaque measurement was 3.12 percentage points lower than we would have predicted.\nA similar calculation is done to find the residual for participant 1 with the oscillating brush. Here we condense a couple of the steps:\n\\[\n\\begin{align}\ne_{ij} &= y_{12} - \\hat{y}_{12} \\\\\n&= y_{12} - (\\hat{\\mu} + \\hat{\\alpha}_1 + \\hat{\\beta}_2) \\\\\n&= 18.56 - (22.76 + \\text{-}0.85 + \\text{-}2.79) \\\\\n&= 18.56 - 19.12 \\\\\n&= -0.56\n\\end{align}\n\\]\nAfter using the oscillating toothbrush, Participant 1’s percent of teeth surface area with plaque is 0.56 percentage points lower than the model predicts.\nWe perform these calculations for every observation. Figure 5 shows the effects that make up each observation3.\n\n\n\n\nFigure 5: Factor Level Effects"
  },
  {
    "objectID": "cb1.html#completing-the-anova-table",
    "href": "cb1.html#completing-the-anova-table",
    "title": "CB[1]",
    "section": "Completing the ANOVA Table",
    "text": "Completing the ANOVA Table\nNow that we have calculated degrees of freedom and effects for each factor, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. A completed ANOVA summary table contains the information we need for a hypothesis test of the treatment effect.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n\n\n\n\n\n\nParticipant\n5\n\n\n\n\n\n\nBrush\n3\n\n\n\n\n\n\nResidual Error\n15\n\n\n\n\n\n\nTotal\n24\n\n\n\n\n\n\n\n\n\n\n\nTo get the sum of squares (SS) of a factor, the effects of the factor must be squared, and then summed. Figure 5 shows the effects, while Figure 6 shows the squared effects.\n\n\n\n\nFigure 6: Squared Effects\n\n\n\nThe total sum of squares is obtained by summing the squared observations as shown in Equation 3 . This represents the total variability in the dataset that will then be allocated or partitioned to the various factors, starting with the grand mean.\n\\[\nSS_\\text{total}= 365.6 + 344.5 + 654.3 + ... + 452.4 + 548.2 = 12,674.30\n\\tag{3}\\]\nFor grand mean, the squared effect of 518.2 is listed 24 times, once for each observation. Summing the squared effects gets:\n\\[\nSS_\\text{Grand Mean}= 518.2 * 24 = 12,437.43\n\\]\nSimilarly, we get the sum of squares for participant, toothbrush, and residuals.\n\\[\n\\begin{align}\nSS_\\text{Participant} &= 4*0.73 + 4*0.27 + ... + 4*0.11 = 18.27 \\\\\n\\\\\nSS_\\text{Brush} &= 6 * 0.11 + 6 * 7.77 + 6*0.01 + 6*6.5 = 86.31 \\\\\n\\\\\nSS_\\text{Residual} &= 9.74 + 0.32 + 14.12 + 0.01 + 2.69 + ... + 2.46 = 132.29\n\\end{align}\n\\]\nPutting this information into the ANOVA table gets us the result shown in Table 1.\n\n\n\n\nTable 1: Sums of Squares\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n12437.43\n\n\n\n\n\nParticipant\n5\n18.27\n\n\n\n\n\nBrush\n3\n86.31\n\n\n\n\n\nResidual Error\n15\n132.29\n\n\n\n\n\nTotal\n24\n12674.30\n\n\n\n\n\n\n\n\n\n\n\nTo calculate a mean square (MS), simply divide a factor’s sum of squares by its degrees of freedom. The mean square calculations are:\n\\[\nMS_\\text{Grand Mean} = \\frac{SS_\\text{Grand Mean}}{df_\\text{Grand Mean}} = \\frac{12437.43}{1} = 12437.43\n\\]\n\n\\[\nMS_\\text{Participant} = \\frac{SS_\\text{Participant}}{df_\\text{Participant}} = \\frac{18.27}{5} = 3.654\n\\]\n\n\\[\nMS_\\text{Brush} = \\frac{SS_\\text{Brush}}{df_\\text{Brush}} = \\frac{86.31}{3} = 28.77\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{132.29}{15} = 8.82\n\\]\n\n\n\n\n\nTable 2: Mean Squares\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n12437.43\n12437.43\n\n\n\n\nParticipant\n5\n18.27\n3.65\n\n\n\n\nBrush\n3\n86.31\n28.77\n\n\n\n\nResidual Error\n15\n132.29\n8.82\n\n\n\n\nTotal\n24\n12674.30\n\n\n\n\n\n\n\n\n\n\n\nFor the structural factors in the design there are a set of hypothesis we can test using the F statistic. Specifically, we will want to test whether toothbrush type has an effect on plaque coverage.\n\n\n\n\n\n\nNote\n\n\n\nWe may or may not be interested in testing Block. Because Block is usually a nuisance factor, testing its effect is not a priority. On the other hand, curiosity about whether the blocks were a significant source of variation may help us plan future experiments and improve the current analysis. In fact, if Block is not significant, we may consider removing it from the model so that the Residual factor has more degrees of freedom - which may result in a lower mean squared error. A lower mean squared increases the ability to detect significance of the treatment factor.\n\n\nWe will proceed with a test of the toothbrush type, represented as \\(\\beta\\) in Equation 1.\n\\[H_0: \\beta_j = 0 \\text{ for all }j\\]\n\\[H_a: \\beta_j \\ne 0 \\text{ for some }j\\]\nTo test the hypothesis, we need to compare the mean square (MS) for toothbrush to the mean square for residual error (abbreviated as MSE). This ratio of variances is called an F statistic. The F statistic calculation is\n\\[\nF_\\text{Brush} = \\frac{MS_\\text{Brush}}{MS_\\text{Error}} = \\frac{28.77}{8.82} = 3.26\n\\]\nAn F distribution is defined by two parameters: a numerator degrees of freedom and a denominator degrees of freedom. The denominator in the F statistic calculation was the mean squared error, which has a degrees of freedom of 15. The numerator degrees of freedom is the degrees of freedom for toothbrush.\nIn practice, statistical software computes all the components of the ANOVA table, including the p-value. To complete the decomposition of variance in a manual way, the p-value is calculated in R using the pf() function.\n1 - pf(test statistic, df of Treatment, df of Residual error)\nIn this example, for toothbrush we get a p-value of:\n1 - pf(3.26, 3, 15) = 0.051\nThe completed ANOVA table for this CB[1] toothbrush study, blocked on participant is shown below:\n\n\n\n\nTable 3: Toothbrush F Test ANOVA Table\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n12437.43\n12437.43\n\n\n\n\nParticipant\n5\n18.27\n3.65\n\n\n\n\nBrush\n3\n86.31\n28.77\n3.26\n0.051\n\n\nResidual Error\n15\n132.29\n8.82\n\n\n\n\nTotal\n24\n12674.30\n\n\n\n\n\n\n\n\n\n\n\nThe p-value for brush indicates the effects of brush are marginally significant. When (in)significance is borderline, rather than making bold statements based on a small amount of (in)significance, it is helpful to dig a little deeper. Consider things like sample size, effect size (practical significance), outliers, and how closely assumptions are met. After weighing those considerations carefully, take a stance and state your belief about the role of the factor on the response. Explain your rationale, then keep an open mind and stay curious.\nIn this case, the biggest difference in means exists between Oscillating and Ultrasonic brushes. The presence of an outlier for the Ultrasonic brush gives birth to additional questions and skepticism. Given the small sample sizes and the outlier, collecting more evidence before making major decisions is recommended."
  },
  {
    "objectID": "cb1.html#describe-the-data",
    "href": "cb1.html#describe-the-data",
    "title": "CB[1]",
    "section": "Describe the Data",
    "text": "Describe the Data\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Interactive code and additional explanations of numerical summaries and plots in R are found at R Instructions-&gt;Descriptive Summaries section of the book.\n\nNumerical Summaries\nAfter loading required packages, we will read in the data and calculate summary statistics for each factor level separately.\n\n\nCode\ncb1 &lt;- read_csv(\"data/toothpaste_CB1.csv\") %&gt;% \n  mutate(ParticipantID = as.factor(PersonID))\n\n\n\n\nCode\n#Descriptive stats for levels of Brush\nfavstats(Plaque~Brush, data = cb1) |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n#Descriptive stats for levels of Participant\nfavstats(Plaque~ParticipantID, data = cb1) |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\nTable 4: Numerical Summary for Each Factor\n\n\n\n\n(a) Brush\n\n\nBrush\nmin\nQ1\nmedian\nQ3\nmax\nmean\nsd\nn\nmissing\n\n\n\n\nManual\n19.12\n22.04\n23.38\n24.01\n26.88\n23.09\n2.60\n6\n0\n\n\nOscillating\n17.62\n18.89\n19.94\n21.29\n22.09\n19.98\n1.74\n6\n0\n\n\nSonic\n18.99\n21.73\n23.20\n23.68\n25.58\n22.67\n2.27\n6\n0\n\n\nUltrasonic\n21.45\n23.62\n24.30\n25.35\n32.74\n25.31\n3.90\n6\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Block: Participant\n\n\nParticipantID\nmin\nQ1\nmedian\nQ3\nmax\nmean\nsd\nn\nmissing\n\n\n\n\n1\n18.56\n18.98\n21.76\n24.69\n25.58\n21.91\n3.59\n4\n0\n\n\n2\n20.00\n21.09\n22.38\n23.53\n24.21\n22.24\n1.89\n4\n0\n\n\n3\n18.99\n19.65\n23.38\n28.34\n32.74\n24.62\n6.46\n4\n0\n\n\n4\n21.60\n21.97\n22.59\n23.37\n24.21\n22.75\n1.16\n4\n0\n\n\n5\n17.62\n21.95\n23.60\n24.27\n25.67\n22.62\n3.48\n4\n0\n\n\n6\n21.27\n21.61\n22.54\n23.37\n23.42\n22.44\n1.11\n4\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Ultrasonic brush has the highest mean plaque amount, while Oscillating brush has the lowest.\nWith the exception of Participant 3, all the participants mean plaque values are very similar. The standard deviation for Participant 3 is also higher than all the others.\n\n\nGraphical Summaries\nYou could also gain insight about your data by investigating the response by cutting the data by each factor separately, as shown in Figure 7. The plot reinforces what was seen in the numerical summary. The mean plaque for each person is roughly similar, Block factor does not look to be statistically significant. There could be some significant variation in plaque due to toothbrush.\n\n\n\n\nCode\ndotplot(Plaque ~Brush, data = cb1, main = \"% of Teeth Surface Area Covered by Plaque\")\ndotplot(Plaque ~ParticipantID, data = cb1, main = \"% of Teeth Surface Area Covered by Plaque\", xlab = \"Participant\")\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Graphical Summaries for Controlled Factors\n\n\nTo reveal an example of combining the 2 plots into one, click here\n\n\n\n\n\nCode\nggplot(data = cb1, aes(x = ParticipantID, y = Plaque, color = Brush)) +\n  geom_text(aes(label = Brush)) +\n  scale_color_brewer(type = \"qual\", palette = \"Set1\") +\n  theme_classic() +\n  theme(legend.position = \"none\") +\n  labs(x = \"Participant\", y = \"Plaque Coverage (%)\", title = \"% of Teeth Surface Area Covered by Plaque\")\n\n\n\n\n\n\nHere it is easy to see that Oscillating had the lowest, or nearly the lowest, amount of plaque left for every individual. For all but one person, Ultrasonic was the worst, or nearly the worst, performing brush. Manual tended to be high. Interestingly, Sonic was all over the place. Perhaps Sonic is more sensitive to a way someone brushes or to different types of plaque build up."
  },
  {
    "objectID": "cb1.html#create-the-model",
    "href": "cb1.html#create-the-model",
    "title": "CB[1]",
    "section": "Create the Model",
    "text": "Create the Model\nCreate the model using the aov() function. To see results of the T-test, you can feed your model into a summary() or anova() function.\n\ncb_aov &lt;- aov(Y ~ block + treatment, data = YourDataSet)\nsummary(cb_aov)\n\n\ncb_aov is the user defined name in which the results of the aov() model are stored\nY is the name of a numeric variable in your dataset which represents the quantitative response variable.\ntreatment and block are names of qualitative variables in your dataset. They should have class() equal to factor or character. If that is not the case, use factor(X) inside the aov(Y ~ factor(treatment)...) command.\nYourDataSet is the name of your data set.\n\nThe results using R code should match the results show in the Decomposition section in Table 3.\n\n\nCode\ncb_aov &lt;- aov(Plaque ~ ParticipantID + Brush, data=cb1) #note the + instead of *\nsummary(cb_aov)\n\n\n              Df Sum Sq Mean Sq F value Pr(&gt;F)  \nParticipantID  5  18.27   3.653   0.414 0.8316  \nBrush          3  86.31  28.769   3.262 0.0511 .\nResiduals     15 132.29   8.820                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe marginal significance of toothbrush (p-value = 0.051) was discussed at the end of the the Decomposition section of this page.\nThough ParticipantID (the Block factor) was not the main purpose of our study, R gives us output for its hypothesis test anyway. We may be curious about it. Because the p-value for ParticipantID (p-value = 0.83) is high, we fail to reject the null hypothesis. There is insufficient evidence to say the variety in participants had an effect on plaque coverage4.\nIn order to trust these hypothesis test results we need to verify that the assumptions are met."
  },
  {
    "objectID": "cb1.html#check-assumptions",
    "href": "cb1.html#check-assumptions",
    "title": "CB[1]",
    "section": "Check Assumptions",
    "text": "Check Assumptions\nFor a more detailed explanation of the code, output, and theory behind these assumptions visit the Assumptions page.\n\nConstant Error Variance\nThere needs to be constant variance across the factor levels. To verify this assumption is met, check the residual plot.\n\nplot(cb_aov, which = 1)\n\n\n\n\nIf the constant variance assumption is violated, the points in this graph will show a wedge or megaphone shape. In other words, the vertical spread of the points would noticeably increase/decrease as we moved along the x-axis. There does not appear to be a trend like that in this plot. Points 15 and 21, which are both on the right side of the plot, are farther away than the rest of the points. However, point 21 seems more like an outlier than a continuation of a trend. This assumption appears to be met\n\n\nNormally Distributed Error Term\nWe check the assumption that residuals are normally distributed with a QQ plot. Since all the points in the plot below are in the shaded regions around the line, we conclude this assumption is met.\n\nplot(cb_aov, which = 2)\n\n\n\n\n\n\nIndependent Residuals\nThe dataset we are analyzing does not include information about the order in which the data was collected. In fact, it may be there were multiple teams of researchers collecting the data simultaneously and there is no specific order. From what we know, there is no reason to think there is a potential order bias. Nevertheless, the order plot below can be used to investigate trends in residuals by row number in the dataset. This plot does not show any patterns or trends. The assumption of independent residuals seems to be satisfied.\n\nplot(cb_aov$residuals)\n\n\n\n\n\n\nAssumptions Summary\nThe assumptions all appear to be met, suggesting that an ANOVA model is appropriate to use in this example."
  },
  {
    "objectID": "cb1.html#footnotes",
    "href": "cb1.html#footnotes",
    "title": "CB[1]",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nComparing the largest and smallest standard deviation tends to be too stringent for designs other than a BF[1]. In addition, there is only 1 observation for factor level combination and so no standard deviation can be computed. This is also the problem with applying Levene’s test.↩︎\nThe values used in calculations here and throughout this page are rounded for a cleaner display. However, you should use unrounded values for these calculations. Rounded values and significant digits is the reason the arithmetic in some of these calculations appears off by one one-hundredth.↩︎\nThe values used in calculations here and throughout this page are rounded for a cleaner display. However, you should use unrounded values for these calculations. Rounded values and significant digits is the reason the arithmetic in some of these calculations appears off in the hundreths place.↩︎\nIn this case, because of its lack of significance, we could remove ParticipantID from the model. This would give more degrees of freedom to the Residuals factor, thereby reducing the MSE and enabling us to better detect significance in the treatment. In fact, treating the study as a BF[1] (i.e. ignoring blocks) returns a p-value of 0.0258 for Brush!↩︎"
  },
  {
    "objectID": "bf3.html",
    "href": "bf3.html",
    "title": "BF[3]",
    "section": "",
    "text": "This section will extend a factorial design with two factors to a full factorial design with three factors. The design and analysis of a fully factorial experiment with three factors is very similar to the two factor design. The one notable exception is that now there is the potential for higher order interactions. Instead of just a single two-way interaction to be considered, three-way interactions, as well as all possible two-way interactions, are included in the model\nTo illustrate this design and analysis we will use a fictitious dataset that closely mirrors the real experiment conducted by Robert Kaplan. The experiment’s goal was to show how the halo effect due to attractiveness effects influences an assessment. More precisely, how does an author’s attractiveness, their sex, and the sex of the reader impact the reader’s assessment of the author’s talent as a writer.\nTo carry out the experiment, a participant is treated as the reader. There were 48 readers total, 24 male and 24 female. The participant is asked to read an essay. Though all participants read the same essay, the sex of the author and the attractiveness of the author was varied. This was accomplished by attaching a picture of the author to the essay. There were 3 levels of attractiveness for each author sex: attractive, unattractive, and the control group (where no picture was attached). Each reader was randomly assigned to an author sex and attractiveness level such that for every combination of reader sex, author sex, and author attractiveness there were exactly 4 observations gathered, resulting in a total of 48 observations.\nIt is cleaner and easier to show the data in a different format than has been used up to this point. In Table 1, each factor has a column dedicated to show what factor level the observations in that row belong to. There are 12 unique factor level combinations, and therefore 12 rows in the table There are 4 observations per factor level combination, and they are displayed to the right of factor level combination designation.\n\n\nCode\nattractiveness &lt;- rep(c(\"attractive\", \"unattractive\", \"no-pic\"), 16)\nreader &lt;- rep( rep(c(\"male\", \"female\"), each = 3), 8)\nauthor &lt;- rep(rep(c(\"male\", \"female\"), each = 6), 4)\nround &lt;- rep(1:4, each = 12)\n\nthe_means &lt;- c(80, 60, 70, 70, 70 , 70, 90, 50, 70, 50, 90, 70)\n\nset.seed(20)\ntalent &lt;- c(round(rnorm(12, the_means, 5),0),\n        round(rnorm(12, the_means, 5),0),\n        round(rnorm(12, the_means, 5),0),\n        round(rnorm(12, the_means, 5),0))\n\ndf &lt;- tibble(attractiveness) %&gt;% add_column(author, reader, talent, round) %&gt;% arrange(attractiveness, author, reader)\ndf %&gt;% pivot_wider(id_cols = c(\"reader\", \"author\", \"attractiveness\"),\n                   names_from = round,\n                   values_from = talent) %&gt;% \n  arrange(reader, author, attractiveness) %&gt;% add_column(row = 1:12) %&gt;% relocate(row) %&gt;% \n  pander()\n\n\n\n\nTable 1: Table of Means for Each Factor Level Combination\n\n\n\n\n\n\n\n\n\n\n\n\nrow\nreader\nauthor\nattractiveness\n1\n2\n3\n4\n\n\n\n\n1\nfemale\nfemale\nattractive\n47\n49\n56\n50\n\n\n2\nfemale\nfemale\nno-pic\n69\n72\n61\n74\n\n\n3\nfemale\nfemale\nunattractive\n90\n94\n85\n94\n\n\n4\nfemale\nmale\nattractive\n63\n68\n64\n72\n\n\n5\nfemale\nmale\nno-pic\n73\n70\n67\n62\n\n\n6\nfemale\nmale\nunattractive\n68\n75\n58\n66\n\n\n7\nmale\nfemale\nattractive\n76\n90\n89\n93\n\n\n8\nmale\nfemale\nno-pic\n68\n71\n78\n65\n\n\n9\nmale\nfemale\nunattractive\n46\n52\n58\n48\n\n\n10\nmale\nmale\nattractive\n86\n77\n79\n75\n\n\n11\nmale\nmale\nno-pic\n79\n62\n67\n70\n\n\n12\nmale\nmale\nunattractive\n57\n67\n53\n66\n\n\n\n\n\n\n\n\nWe can still partition the observations, but with 3 factors the partitions become harder to show with just lines. Instead, the partitions will be described and a table of factor levels will be shown below.\n\n\nIn the appendix, partitioning is done using shading/coloring of cells. Though it is possible, the result is a bit overwhelming to the eye.\nIn this experiment there are 3 controlled factors. Observations can be partitioned according to what group they belong to for any one of the 3 controlled factors. This allows us to create 3 structural factors, 1 for each controlled factor:\n\nreader’s sex: 2 levels.\nauthor’s sex: 2 levels, and\nattractiveness (of the essay author): 3 levels,\n\nThe partition associated with each of these factors will allow us to calculate main effects.\nThe data can also be partitioned according to a shared factor level combination on a pair of factors. There are 3 possible factor pairs. In other words, three two-way interactions are created by partitioning the data this way:\n\nreader’s gender \\(\\times\\) author’s gender: 4 levels\nreader’s gender \\(\\times\\) author’s attractiveness: 6 levels\nauthor’s gender \\(\\times\\) author’s attractiveness: 6 levels\n\nFinally, data values can be partitioned according to what combination of the 3 treatment factors the observation belongs to. This results in a 3-way interaction factor:\n\nreader’s gender \\(\\times\\) author’s gender \\(\\times\\) author’s attractiveness: 12 levels\n\nThe table below summarizes the 7 structural factors in the model:\n\n\n\n\n\n\n\n\n\n\n\n\nreader\n# of levels :============: 2\nPartitions: Row ID #’s of Table 1 belonging to each level ==============================================================+ female: 1-6 | | male:    7-12 |\n\n\nauthor\n2\nfemale: 1-3, 7-10\nmale:    4-6, 11-12\n\n\n\nattractiveness\n3\nattractive:    1, 4, 7, 10\nno-pic:        2, 5, 8, 11\nunattractive: 3, 6, 9, 12\n\n\n\nreader \\(\\times\\) author\n4\n\n\n\n\n\n\n\nfemale reader\nmale reader\n\n\n\n\nfemale author: 1-3\nmale author:   4-6\nfemale author: 7-9\nmale author:   10-12\n\n\n\n\n\n\nreader \\(\\times\\) attractiveness\n6\n\n\n\n\n\n\n\nfemale reader\nmale reader\n\n\n\n\nattractive: 1, 4\nno-pic: 2, 5\nunattractive: 3, 6\nattractive: 7, 10\nno-pic: 8, 11\nunattractive: 9, 12\n\n\n\n\n\n\nauthor \\(\\times\\) attractiveness\n6\n\n\n\n\n\n\n\nfemale author\nmale author\n\n\n\n\nattractive: 1, 7\nno-pic: 2, 8\nunattractive: 3, 9\nattractive: 4, 10\nno-pic: 5, 11\nunattractive: 6, 12\n\n\n\n\n\n\nreader \\(\\times\\) author \\(\\times\\) attractiveness\n12\nfemale, female, attractive: 1\nfemale, female, no-pic: 2\nfemale, female, unattractive: 3\nfemale, male, attractive: 4\nfemale, male, no-pic: 5\nfemale, male, unattractive: 6\nmale, female, attractive: 7\nmale, female, no-pic:      8\nmale, female, unattractive: 9\nmale, male, attractive: 10\nmale, male, no-pic: 11\nmale, male, unattractive: 12\n\n\n\n\n\n\n\nEach factor (i.e. meaningful partition of the data) corresponds to a term in Equation 1:\n\\[\ny_\\text{ijkl} = \\mu + \\alpha_i + \\beta_j + \\gamma_k + (\\alpha\\beta)_\\text{ij} + (\\alpha\\gamma)_\\text{ik} + (\\beta\\gamma)_\\text{jk} + (\\alpha\\beta\\gamma)_\\text{ijk} + \\epsilon_\\text{ijkl}\n\\tag{1}\\]\nWhere\n\n\\(y_{ijkl}\\) is the \\(l^{th}\\) observation from the factor level combination of \\(\\alpha_i\\), \\(\\beta_j\\), and \\(\\gamma_k\\).\n\\(\\mu\\) is the grand mean of all the observations.\n\\(\\alpha\\) is the effect of reader’s gender, and \\(i\\) has 2 levels: i=1 for female, i=2 for male\n\\(\\beta\\) is the effect of author’s gender, and \\(j\\) has 2 levels: i=1 for female, i=2 for male\n\\(\\gamma\\) is the effect of author’s attractiveness, and \\(k\\) has 3 levels: k=1 for attractive, k=2 for neutral, and k=3 for unattractive\nThe \\((\\alpha\\beta)_\\text{ij}\\) is the interaction effect for reader gender with author gender on perceived talent level.\nThe \\((\\alpha\\gamma)_\\text{ik}\\) is the interaction effect for reader gender with author attractiveness on perceived talent.\nThe \\((\\beta\\gamma)_\\text{jk}\\) is the interaction effect for author gender with attractiveness on perceived talent.\nThe \\((\\alpha\\beta\\gamma)_\\text{ijk}\\) is the interaction effect for reader gender, author gender, and attractiveness on perceived talent.\n\\(\\epsilon\\) is the residual error term, and \\(l\\) is the replicate count within a factor level combination.\n\nThough we have seen two factor interactions and know how to deal with them, the three factor interaction is something new. Including this term in the model means that the impact of any of the three variables depends on the levels of the other two. Stated another way, the nature of the two-way interaction depends on the level of a third variable.\nThe main effects and two-way interactions are tested just as they were in the BF[2] model. The hypothesis for the 3-way interaction is\n\\[\nH_0: (\\alpha\\beta\\gamma)_\\text{ijk} = 0 \\text{ for all } ijk\n\\]\n\\[\nH_a: (\\alpha\\beta\\gamma)_\\text{ijk} \\ne 0 \\text{ for some } ijk\n\\]\n\n\n\nA three-way ANOVA model may be used to analyze data from a BF[3] design if the following requirements are satisfied. Note that these requirements are identical to the requirements of a BF[2] two-way ANOVA.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "bf3.html#factor-structure",
    "href": "bf3.html#factor-structure",
    "title": "BF[3]",
    "section": "",
    "text": "We can still partition the observations, but with 3 factors the partitions become harder to show with just lines. Instead, the partitions will be described and a table of factor levels will be shown below.\n\n\nIn the appendix, partitioning is done using shading/coloring of cells. Though it is possible, the result is a bit overwhelming to the eye.\nIn this experiment there are 3 controlled factors. Observations can be partitioned according to what group they belong to for any one of the 3 controlled factors. This allows us to create 3 structural factors, 1 for each controlled factor:\n\nreader’s sex: 2 levels.\nauthor’s sex: 2 levels, and\nattractiveness (of the essay author): 3 levels,\n\nThe partition associated with each of these factors will allow us to calculate main effects.\nThe data can also be partitioned according to a shared factor level combination on a pair of factors. There are 3 possible factor pairs. In other words, three two-way interactions are created by partitioning the data this way:\n\nreader’s gender \\(\\times\\) author’s gender: 4 levels\nreader’s gender \\(\\times\\) author’s attractiveness: 6 levels\nauthor’s gender \\(\\times\\) author’s attractiveness: 6 levels\n\nFinally, data values can be partitioned according to what combination of the 3 treatment factors the observation belongs to. This results in a 3-way interaction factor:\n\nreader’s gender \\(\\times\\) author’s gender \\(\\times\\) author’s attractiveness: 12 levels\n\nThe table below summarizes the 7 structural factors in the model:\n\n\n\n\n\n\n\n\n\n\n\n\nreader\n# of levels :============: 2\nPartitions: Row ID #’s of Table 1 belonging to each level ==============================================================+ female: 1-6 | | male:    7-12 |\n\n\nauthor\n2\nfemale: 1-3, 7-10\nmale:    4-6, 11-12\n\n\n\nattractiveness\n3\nattractive:    1, 4, 7, 10\nno-pic:        2, 5, 8, 11\nunattractive: 3, 6, 9, 12\n\n\n\nreader \\(\\times\\) author\n4\n\n\n\n\n\n\n\nfemale reader\nmale reader\n\n\n\n\nfemale author: 1-3\nmale author:   4-6\nfemale author: 7-9\nmale author:   10-12\n\n\n\n\n\n\nreader \\(\\times\\) attractiveness\n6\n\n\n\n\n\n\n\nfemale reader\nmale reader\n\n\n\n\nattractive: 1, 4\nno-pic: 2, 5\nunattractive: 3, 6\nattractive: 7, 10\nno-pic: 8, 11\nunattractive: 9, 12\n\n\n\n\n\n\nauthor \\(\\times\\) attractiveness\n6\n\n\n\n\n\n\n\nfemale author\nmale author\n\n\n\n\nattractive: 1, 7\nno-pic: 2, 8\nunattractive: 3, 9\nattractive: 4, 10\nno-pic: 5, 11\nunattractive: 6, 12\n\n\n\n\n\n\nreader \\(\\times\\) author \\(\\times\\) attractiveness\n12\nfemale, female, attractive: 1\nfemale, female, no-pic: 2\nfemale, female, unattractive: 3\nfemale, male, attractive: 4\nfemale, male, no-pic: 5\nfemale, male, unattractive: 6\nmale, female, attractive: 7\nmale, female, no-pic:      8\nmale, female, unattractive: 9\nmale, male, attractive: 10\nmale, male, no-pic: 11\nmale, male, unattractive: 12"
  },
  {
    "objectID": "bf3.html#hypothesis-and-model",
    "href": "bf3.html#hypothesis-and-model",
    "title": "BF[3]",
    "section": "",
    "text": "Each factor (i.e. meaningful partition of the data) corresponds to a term in Equation 1:\n\\[\ny_\\text{ijkl} = \\mu + \\alpha_i + \\beta_j + \\gamma_k + (\\alpha\\beta)_\\text{ij} + (\\alpha\\gamma)_\\text{ik} + (\\beta\\gamma)_\\text{jk} + (\\alpha\\beta\\gamma)_\\text{ijk} + \\epsilon_\\text{ijkl}\n\\tag{1}\\]\nWhere\n\n\\(y_{ijkl}\\) is the \\(l^{th}\\) observation from the factor level combination of \\(\\alpha_i\\), \\(\\beta_j\\), and \\(\\gamma_k\\).\n\\(\\mu\\) is the grand mean of all the observations.\n\\(\\alpha\\) is the effect of reader’s gender, and \\(i\\) has 2 levels: i=1 for female, i=2 for male\n\\(\\beta\\) is the effect of author’s gender, and \\(j\\) has 2 levels: i=1 for female, i=2 for male\n\\(\\gamma\\) is the effect of author’s attractiveness, and \\(k\\) has 3 levels: k=1 for attractive, k=2 for neutral, and k=3 for unattractive\nThe \\((\\alpha\\beta)_\\text{ij}\\) is the interaction effect for reader gender with author gender on perceived talent level.\nThe \\((\\alpha\\gamma)_\\text{ik}\\) is the interaction effect for reader gender with author attractiveness on perceived talent.\nThe \\((\\beta\\gamma)_\\text{jk}\\) is the interaction effect for author gender with attractiveness on perceived talent.\nThe \\((\\alpha\\beta\\gamma)_\\text{ijk}\\) is the interaction effect for reader gender, author gender, and attractiveness on perceived talent.\n\\(\\epsilon\\) is the residual error term, and \\(l\\) is the replicate count within a factor level combination.\n\nThough we have seen two factor interactions and know how to deal with them, the three factor interaction is something new. Including this term in the model means that the impact of any of the three variables depends on the levels of the other two. Stated another way, the nature of the two-way interaction depends on the level of a third variable.\nThe main effects and two-way interactions are tested just as they were in the BF[2] model. The hypothesis for the 3-way interaction is\n\\[\nH_0: (\\alpha\\beta\\gamma)_\\text{ijk} = 0 \\text{ for all } ijk\n\\]\n\\[\nH_a: (\\alpha\\beta\\gamma)_\\text{ijk} \\ne 0 \\text{ for some } ijk\n\\]"
  },
  {
    "objectID": "bf3.html#assumptions",
    "href": "bf3.html#assumptions",
    "title": "BF[3]",
    "section": "",
    "text": "A three-way ANOVA model may be used to analyze data from a BF[3] design if the following requirements are satisfied. Note that these requirements are identical to the requirements of a BF[2] two-way ANOVA.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "bf3.html#factor-effects",
    "href": "bf3.html#factor-effects",
    "title": "BF[3]",
    "section": "Factor Effects",
    "text": "Factor Effects\nThe first step in performing a decomposition is to calculate the factor level means. The grand mean is 69.1458333.\nThe mean for each factor and its corresponding levels is displayed below.\n\n\nTable 3: Means for Each Factor Level Combination\n\n\n\n\n(a) Mean Talent by Reader Gender\n\n\n\n\n\n\nreader\nmean\n\n\n\n\nfemale\n68.62\n\n\nmale\n69.67\n\n\n\n\n\n\n(b) Mean Talent by Author Gender\n\n\n\n\n\n\nauthor\nmean\n\n\n\n\nfemale\n69.79\n\n\nmale\n68.5\n\n\n\n\n\n\n(c) Mean Talent by Author Attractiveness\n\n\n\n\n\n\nattractiveness\nmean\n\n\n\n\nattractive\n70.88\n\n\nno-pic\n69.25\n\n\nunattractive\n67.31\n\n\n\n\n\n\n\n\n(d) Mean Talent by Reader Gender x Author Gender\n\n\n\n\n\n\n\nreader\nauthor\nmean\n\n\n\n\nfemale\nfemale\n70.08\n\n\nfemale\nmale\n67.17\n\n\nmale\nfemale\n69.5\n\n\nmale\nmale\n69.83\n\n\n\n\n\n\n(e) Mean Talent by Reader Gender x Author Attractiveness\n\n\n\n\n\n\n\nreader\nattractiveness\nmean\n\n\n\n\nfemale\nattractive\n58.62\n\n\nfemale\nno-pic\n68.5\n\n\nfemale\nunattractive\n78.75\n\n\nmale\nattractive\n83.12\n\n\nmale\nno-pic\n70\n\n\nmale\nunattractive\n55.88\n\n\n\n\n\n\n(f) Mean Talent by Author Gender x Author Attractiveness\n\n\n\n\n\n\n\nauthor\nattractiveness\nmean\n\n\n\n\nfemale\nattractive\n68.75\n\n\nfemale\nno-pic\n69.75\n\n\nfemale\nunattractive\n70.88\n\n\nmale\nattractive\n73\n\n\nmale\nno-pic\n68.75\n\n\nmale\nunattractive\n63.75\n\n\n\n\n\n\n\n\n(g) Mean Talent by Reader Gender x Author Gender x Author Attractiveness\n\n\n\n\n\n\n\n\nreader\nauthor\nattractiveness\nmean\n\n\n\n\nfemale\nfemale\nattractive\n50.5\n\n\nfemale\nfemale\nno-pic\n69\n\n\nfemale\nfemale\nunattractive\n90.75\n\n\nfemale\nmale\nattractive\n66.75\n\n\nfemale\nmale\nno-pic\n68\n\n\nfemale\nmale\nunattractive\n66.75\n\n\nmale\nfemale\nattractive\n87\n\n\nmale\nfemale\nno-pic\n70.5\n\n\nmale\nfemale\nunattractive\n51\n\n\nmale\nmale\nattractive\n79.25\n\n\nmale\nmale\nno-pic\n69.5\n\n\nmale\nmale\nunattractive\n60.75\n\n\n\n\n\n\nWe will now compute the factor level effects. A couple of example computations for the interaction factors are shown below. The general rule for factor level effects is implemented, it states that the size of an effect is equal to the factor level mean minus the sum of the effects of all outside factors. The computation for each effect of each factor will not be shown.\nThe full factorial model, as defined in Equation 1, will be used to describe the calculations.\nFirst, let’s compute the effect of a male reader \\(\\times\\) attractive author on perceived talent.\n\\[\\begin{align}\n(\\hat{\\alpha\\gamma})_\\text{male reader, attractive author} &= \\bar{y}_\\text{male reader, attractive author} - (\\hat{\\mu} + \\hat{\\alpha}_\\text{male reader} + \\hat{\\gamma}_\\text{attractive author}) \\\\\n\n\\hat{(\\alpha\\gamma)}_{2, 1} &= \\bar{y}_{2 \\cdot 1 \\cdot} - (y_{\\cdot\\cdot\\cdot\\cdot} + \\hat{\\alpha_2} + \\hat{\\gamma_1}) \\\\\n\n&= 83.12 - (69.15  + 0.52 + 1.73) \\\\\n&= 11.72\n\n\\end{align}\\]\nThus, as we saw earlier in Figure 1, the effect of being attractive is made greater when the reader is a male. Specifically, the mean talent ratings is 11.72 points higher predicted by adding the effect of male reader and the effect of attractive author to the grand mean separately.\nTo calculate the effect of a three-way interaction, the general rule is again applied. This time though, there are more calculations since all two-way interactions are inside of the 3 way interaction. Below, the effect of male reader \\(\\times\\) female author \\(\\times\\) attractive author is calculated.\n\\[\\begin{align}\n\\hat{(\\alpha\\beta\\gamma)}_{2,1,1} &= \\bar{y}_{211\\cdot} - (\\hat{\\mu} + \\hat{\\alpha_2} + \\hat{\\beta_1} + \\hat{\\gamma_1} + \\hat{\\alpha\\beta}_{21} + \\hat{\\alpha\\gamma}_{21} + \\hat{\\beta\\gamma}_{11}) \\\\\n\n&= 87 - (69.15  + 0.52 + .64 + 1.73 + -.81 + 11.72 + -2.77) \\\\\n&= 6.82\n\n\\end{align}\\]\nThus, their appears to be a synergistic effect on perceived talent when all three of the levels male reader \\(\\times\\) female author \\(\\times\\) attractive author are present together. Specifically, the mean talent rating is 6.82 points higher than the partial fit (which only includes main effects and two-way interaction effects) would have predicted.\nSimilar calculations can be done for every factor level effect."
  },
  {
    "objectID": "bf3.html#degrees-of-freedom",
    "href": "bf3.html#degrees-of-freedom",
    "title": "BF[3]",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nDegrees of freedom can also be calculated using the general rule: degrees of freedom for a factor is equal to the levels of that factor minus the sum of degrees of freedom for all outside factors. The degrees of freedom calculations are only shown for two factors, leaving it up to the reader to calculate/verify the degrees of freedom for the other factors as presented in the ANOVA summary table in XXX.\nThe degrees of freedom calculation for the reader by attractiveness interaction factor is shown below. There are 2 reader gender levels \\(\\times\\) 3 attractiveness levels = 6 total levels for this interaction factor.\n\\[\\begin{align}\ndf_\\text{reader, attractiveness} &= levels_\\text{reader, attractiveness} - (df_{\\mu} + df_\\text{reader} + df_\\text{attractiveness}) \\\\\n\ndf_{\\alpha\\gamma} &= levels_{\\alpha\\gamma} - (df_\\text{grand mean} + df_\\alpha + df_\\gamma \\\\\n\n&= 6 - (1  + 1 + 2) \\\\\n&= 2\n\n\\end{align}\\]\nThere are 2 degrees of freedom for the reader \\(\\times\\) attractiveness factor.\nThe degrees of freedom calculation for the 3 way interaction is shown below.\n\\[\\begin{align}\ndf_\\text{reader, author, attractiveness} &= levels_\\text{reader, author, attractiveness} - (df_{\\mu} + df_\\text{reader} + df_\\text{author} + df_\\text{attractiveness} + df_\\text{reader, author} + df_\\text{reader, attractiveness} + df_\\text{author, attractiveness}) \\\\\n\ndf_{\\alpha\\beta\\gamma} &= levels_{\\alpha\\beta\\gamma} - (df_\\mu + df_\\alpha + df_\\beta + df_\\gamma + df_{\\alpha\\beta} + df_{\\alpha\\gamma} + df_{\\beta\\gamma} \\\\\n\n&= 12 - (1  + 1 + 1 + 2 + 1 + 2 + 2 ) \\\\\n&= 2\n\n\\end{align}\\]\nThe three way interaction also has two degrees of freedom."
  },
  {
    "objectID": "bf3.html#completing-the-anova-table",
    "href": "bf3.html#completing-the-anova-table",
    "title": "BF[3]",
    "section": "Completing the ANOVA Table",
    "text": "Completing the ANOVA Table\nAfter degrees of freedom and effects for each factor are calculated, the remaining pieces of the ANOVA table can also be calculated.\nTo calculate sum of squares for a factor, the effects of each factor level associated with that factor are squared and then multiplied by the number of replicates in that level.1 These products are then summed across levels to get the total sum of squares for the factor.\nTo obtain the mean squares for a factor, the factor’s sum of squares is divided by the factor’s degrees of freedom.\nFinally, the F-statistic is obtained by computing the ratio of a factor’s mean square to the mean squared error. The degrees of freedom associated with this F statistic are the degrees of freedom for the factor and the degrees of freedom for error. The p-value is obtained by finding the area under the F distribution to the right of the F statistic."
  },
  {
    "objectID": "bf3.html#describe-the-data",
    "href": "bf3.html#describe-the-data",
    "title": "BF[3]",
    "section": "Describe the Data",
    "text": "Describe the Data\nWhen working with a dataset you should get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots, scatterplots, and/or interaction plots with the means displayed.\nInteractive code and additional explanations of numerical summaries and plots in R are found at R Instructions-&gt;Descriptive Summaries section of the book.\nSo far, we have already seen various numerical and graphical summaries of the data on this page. This summaries below would be a good starting point if you are taking a look at the data for the first time.\n\nNumerical Summaries\nA good place to start is calculating summary statistics like mean, standard deviation and sample size for the factor levels of each experimental factor.\n\n\nCode\n#Note: the df data frame was created in the first R chunk in the Overview section of this page\ndf %&gt;% group_by(reader) %&gt;% summarise(mean = mean(talent),\n                                      n = n(),\n                                      std_dev = sd(talent),\n                                      .groups = 'keep') %&gt;% \n  pander(caption = \"Numerical Summary by Reader Gender\")\ndf %&gt;% group_by(author) %&gt;% summarise(mean = mean(talent),\n                                      n = n(),\n                                      std_dev = sd(talent),\n                                      .groups = 'keep') %&gt;% \n  pander(caption = \"Numerical Summary by Author Gender\")\ndf %&gt;% group_by(attractiveness) %&gt;% summarise(mean = mean(talent),\n                                      n = n(),\n                                      std_dev = sd(talent),\n                                      .groups = 'keep') %&gt;% \n  pander(caption = \"Numerical Summary by Attractiveness Gender\")\n\n\n\nTable 4: Numerical Summaries of Experimental Factors\n\n\n\n\n(a) Numerical Summary by Reader Gender\n\n\n\n\n\n\n\n\nreader\nmean\nn\nstd_dev\n\n\n\n\nfemale\n68.62\n24\n12.79\n\n\nmale\n69.67\n24\n13.18\n\n\n\n\n\n\n(b) Numerical Summary by Author Gender\n\n\n\n\n\n\n\n\nauthor\nmean\nn\nstd_dev\n\n\n\n\nfemale\n69.79\n24\n16.67\n\n\nmale\n68.5\n24\n7.684\n\n\n\n\n\n\n(c) Numerical Summary by Attractiveness Gender\n\n\n\n\n\n\n\n\nattractiveness\nmean\nn\nstd_dev\n\n\n\n\nattractive\n70.88\n16\n15.02\n\n\nno-pic\n69.25\n16\n5.31\n\n\nunattractive\n67.31\n16\n16.04\n\n\n\n\n\n\n\nMuch of the above information can also be seen in an effective visual.\n\n\nGraphical Summaries\nBelow are some basic boxplots talent perception, grouped by levels of each experimental factor. Jittered points of the response are overlayed on each boxplot. The effect of attractiveness is detectable, but the impact of reader gender and author gender are not obvious since they exist as part of an interaction. Interaction plots can be investigated at any time in the analysis process. However, sometimes the number of interactions to check can large, and may not be something to start with. In such cases, you may run the model first and then spend energy trying to understand only those interactions that look to be significant.\n\n\nCode\n#Note: the df data frame was created in the first R chunk in the Overview section of this page\n\n# Chart 1\ndf %&gt;% ggplot(aes(x = reader, y = talent)) + \n  geom_boxplot(outlier.shape = NA) +\n  geom_jitter() +\n  labs(title = \"Reader Gender\") +\n  theme(axis.title = element_blank(),\n        plot.title = element_text(hjust = .5))\n\n# Chart 2\ndf %&gt;% ggplot(aes(x = author, y = talent)) + \n  geom_boxplot(outlier.shape = NA) +\n  geom_jitter() +\n  labs(title = \"Author Gender\") +\n  theme(axis.title = element_blank(),\n        plot.title = element_text(hjust = .5))\n\n# Chart 3\ndf %&gt;% ggplot(aes(x = attractiveness, y = talent)) + \n  geom_boxplot(outlier.shape = NA) +\n  geom_jitter() +\n  labs(title = \"Author Attractiveness\") +\n  theme(axis.title = element_blank(),\n        plot.title = element_text(hjust = .5))\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\n\n\n(c)\n\n\n\n\nFigure 2: Graphical Summaries of Experimental Factors"
  },
  {
    "objectID": "bf3.html#create-the-model",
    "href": "bf3.html#create-the-model",
    "title": "BF[3]",
    "section": "Create the Model",
    "text": "Create the Model\nThe 3-way Basic Factorial model is created in R just as the 2-way model was: using the aov() function. To see results of the F-test you can feed your model into a summary() or anova() function.\n\nmyaov &lt;- aov(Y ~ X1 * X2 * X3, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is the user defined name in which the results of the aov() model are stored\nY is the name of a numeric variable in your dataset which represents the quantitative response variable.\nX1, X2, and X3 are names of qualitative variables in your dataset. They represent the independent variables in the study. They should have class(X) equal to factor or character. If that is not the case, use factor(X) inside the aov(Y ~ factor(X1)*...) command.\nYourDataSet is the name of your data set.\n\nThe * in the code above is a shortcut for writing out the whole model. It can be read as, “include each term by itself, and all possible interaction terms”. The long way of writing out the model uses a colon, :, to define interaction terms and is shown below. When writing it this way each term must be explicitly stated.\n\nmyaov &lt;- aov(Y ~ X1 + X2 + X3 + X1:X2 + X1:X3 + X2:X3 + X1:X2:X3, data=YourDataSet)\nsummary(myaov)\n\nFigure 3 shows the results for the full BF[3] model for the study of halo effect on perception of talent. The 3-way interaction is significant here (p-value - 1.081e-7). Two of the two-way interactions are significant. None of the main effects show significance.\n\n\nCode\nhalo_aov &lt;- aov(talent ~ reader * author * attractiveness, data = df)\nsummary(halo_aov) %&gt;% pander()\n\n\n\n\n\nAnalysis of Variance Model\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nreader\n1\n13.02\n13.02\n0.4004\n0.5309\n\n\nauthor\n1\n20.02\n20.02\n0.6156\n0.4378\n\n\nattractiveness\n2\n101.8\n50.9\n1.565\n0.223\n\n\nreader:author\n1\n31.69\n31.69\n0.9744\n0.3302\n\n\nreader:attractiveness\n2\n4490\n2245\n69.03\n4.793e-13\n\n\nauthor:attractiveness\n2\n259.3\n129.6\n3.987\n0.02729\n\n\nreader:author:attractiveness\n2\n1683\n841.7\n25.88\n1.081e-07\n\n\nResiduals\n36\n1171\n32.52\nNA\nNA\n\n\n\n\nFigure 3: BF[3] ANOVA summary table\n\n\n\n\n\n\n\n\n\nKeeping Lower Order Effects\n\n\n\nWhen a significant interaction is discovered, all lower order interactions and main effects should remain in the model - even if they are not significant.\n\n\nWhen a 2-way interaction is found to be significant, then both of the simple factors (or main effects factors) should be included in the model. If a 3-way interaction is found to be significant, then the 3 main effects and all corresponding 2-way interactions should all be included in the ANOVA model - even if they are not statistically significant.\nInterpreting lower order interactions and main effects in the presence of a significant higher order interaction should be done with caution. One should investigate the interaction plots in order to describe how the effect of one variable may depend on the value of another. Simply comparing marginal means2 and interpreting main effects is not sufficient and may lead to incorrect conclusions.\nIn this example, we will not interpret any of the main effects or two-way interactions alone, since the 3-way interaction is significant. In the Interaction section of this page, an interpretation of the interaction was already discussed. To recap that section, we saw in Figure 1 that for male readers, attractiveness of author tended to correspond to higher perceptions of talent of the author - regardless of the author’s gender. However, for female readers, the impact of author attractiveness depended on author gender: attractive female authors were perceived as less talented than unattractive female authors, whereas attractiveness had negligible effect on perceived talent of male authors.\nIn order to trust these hypothesis test results we need to verify that ANOVA model assumptions are met."
  },
  {
    "objectID": "bf3.html#check-assumptions",
    "href": "bf3.html#check-assumptions",
    "title": "BF[3]",
    "section": "Check Assumptions",
    "text": "Check Assumptions\nFor a more detailed explanation of the code, output, and theory behind these assumptions visit the Assumptions page.\n\nConstant Variance of Residuals\nThere needs to be constant variance of residuals across the factor level combinations. First, we can check the residual plot.\n\n\nCode\nplot(halo_aov, which = 1)\n\n\n\n\n\nFigure 4: Checking constant variance\n\n\n\n\nIn the residual plot, Figure 4, the vertical spread of the points is roughly constant as one moves from left to right across the x-axis of the plot. It is clear that the assumption of constant variance of the residuals is met.3 Rarely does a plot look better than this.\n\n\nNormally Distributed Residuals\nWe check the assumption that residuals are normally distributed in Figure 5. All the points are in the shaded region, so we conclude this assumption is met.\n\n\nCode\ncar::qqPlot(halo_aov$residuals, id = FALSE)\n\n\n\n\n\nFigure 5: Checking normality of residuals\n\n\n\n\n\n\nIndependent Residuals\nThe dataset we are analyzing does not include information about the order in which the data was collected. Independence of observations often becomes a concern when there is re-use of equipment, researcher(s) making multiple measurements over time, or any other process that is repeated in each experimental run. Those types of situations can lead to order bias, which can make residuals time/order dependent rather than independent.\nNothing in this experiment suggests a potential for order bias. If we assume that random selection of participants has taken place, and that participants have randomly been assigned to treatments as indicated, there is little reason to doubt that observations (and consequently residuals too) are independent. There is no need to provide a plot in this case.\n\n\nAssumptions Summary\n\n\nRarely are assumptions so clearly and obviously met. In this case, the data was simulated in order to replicate effects and interactions similar to what the original study found. Real data does not usually behave as nicely as simulated data.\nThe assumptions appear to be met, meaning the p-values should be valid and reliable."
  },
  {
    "objectID": "bf3.html#footnotes",
    "href": "bf3.html#footnotes",
    "title": "BF[3]",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis assumes a balanced design. Formulas/calculations for unbalanced designs may need adjustments, depending on the sum of square type that is desired.↩︎\nA marginal mean is a mean calculated in the “margins” (or on the endges) of a two-way table. In other words, it is a mean of a factor level without considering the other factors in the model. Stated another way, it is averaging over all the observations that belong to reader=Male, without breaking out the observations into separate groups to account for the author’s gender.↩︎\nIf it was questionable, Levene’s test may help with the decision of whether the assumption was met or not. In reality though, this is about as nice of a residual plot as one could hope for.↩︎"
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html",
    "href": "BasicFactorial_quarto_boat.html",
    "title": "BF[1]",
    "section": "",
    "text": "In a basic one-way factorial design (BF[1]), only one factor is purposefully varied.1 Each experimental unit is assigned to exactly one factor level. (In the case of an observational study, only one independent factor is under consideration.)\n\n\nThe factor structure for the model resulting from a completely randomized, one factor design is:\n\n\n\n\nFigure 1: Example of BF1 Factor Structure\n\n\n\nFigure 1 illustrates a factor with 4 levels, 6 replications at each level.\n\n\n\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from factor level \\(i\\)\n\\(\\mu\\): the grand mean of the data set.\n\\(\\alpha_i\\): effect of factor level \\(i\\)\n\\(\\epsilon_{ij}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its factor level mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\]\n\\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\n\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nRule of thumb comparing standard deviations\n\\(max(s) &lt; 2*min(s)\\)\n\n\n\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#factor-structure",
    "href": "BasicFactorial_quarto_boat.html#factor-structure",
    "title": "BF[1]",
    "section": "",
    "text": "The factor structure for the model resulting from a completely randomized, one factor design is:\n\n\n\n\nFigure 1: Example of BF1 Factor Structure\n\n\n\nFigure 1 illustrates a factor with 4 levels, 6 replications at each level."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#hypothesis-and-model",
    "href": "BasicFactorial_quarto_boat.html#hypothesis-and-model",
    "title": "BF[1]",
    "section": "",
    "text": "A more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from factor level \\(i\\)\n\\(\\mu\\): the grand mean of the data set.\n\\(\\alpha_i\\): effect of factor level \\(i\\)\n\\(\\epsilon_{ij}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its factor level mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\]\n\\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]"
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#assumptions",
    "href": "BasicFactorial_quarto_boat.html#assumptions",
    "title": "BF[1]",
    "section": "",
    "text": "A one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nRule of thumb comparing standard deviations\n\\(max(s) &lt; 2*min(s)\\)\n\n\n\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#lifeboat-training-example",
    "href": "BasicFactorial_quarto_boat.html#lifeboat-training-example",
    "title": "BF[1]",
    "section": "Lifeboat Training Example",
    "text": "Lifeboat Training Example\nConsider the following example. An experiment was done to assess different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included:\n\nLecture/Materials (Control)\nMonitor/Keyboard\nHead Monitor Display/Joypad, and\nHead Monitor Display/Wearables.\n\nThe response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test). There is just one controlled factor, training method, which has 4 levels: the four training methods. An experimental unit in this study is each of the individuals being trained, 16 in all.\nWe want to assign each treatment to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\n\nCode\n#Repeat the sequence of 1 to 4, four times\nTreatment &lt;- rep(1:4,4) \n\n#Create a sequence from 1 to 16\n#Paste the word \"Subject \" in front of each id #\nSubject &lt;- paste(\"Subject\", seq(1:16), sep = \" \")\n\n#Combine the vector of treatment numbers and Subject ID's into 1 tibble/data frame\nassignment_table &lt;- tibble(Subject, Treatment)\n\n#print the table, pander() makes it look nice\npander(assignment_table) \n\n\n\n\n\n\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\n\n\nThen we randomly shuffle the Treatment column to get the following assignments. Check out the R-code to see how this is done.\n\n\nCode\n#set.seed() allows us to get the same random sample each time\nset.seed(42) \n\n#sample() will randomly select from the Treatment vector 16 times without replacement\n# %&gt;% is called a pipe. It simply takes the output from the command on the left\n# and sends it to the command on the right\ntibble(Subject, sample(Treatment, 16)) %&gt;% pander()\n\n\n\n\n\n\n\n\n\nSubject\nsample(Treatment, 16)\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n1\n\n\nSubject 3\n4\n\n\nSubject 4\n1\n\n\nSubject 5\n2\n\n\nSubject 6\n4\n\n\nSubject 7\n2\n\n\nSubject 8\n2\n\n\nSubject 9\n4\n\n\nSubject 10\n3\n\n\nSubject 11\n3\n\n\nSubject 12\n1\n\n\nSubject 13\n3\n\n\nSubject 14\n4\n\n\nSubject 15\n3\n\n\nSubject 16\n2\n\n\n\n\n\nWe can see here that subject 1 should get treatment 1. Subject 2 also gets treatment 1, Subject 3 gets treatment 4, and so on."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#degrees-of-freedom",
    "href": "BasicFactorial_quarto_boat.html#degrees-of-freedom",
    "title": "BF[1]",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nWe can use our understanding of inside vs. outside factors to determine the degrees of freedom (df) for the grand mean, treatment, and residual errors factors. We start with 24 observations - or pieces of information. In other words, we have 24 degrees of freedom that need to be allocated to the 3 factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf\\(_\\text{factor}\\) = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the lifeboat example, grand mean has one level (shown by the one cell in Figure 1) and there are no factors outside of grand mean. Therefore, its degrees of freedom equals one.\nRemember, the degrees of freedom represent the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as you estimate the grand mean for just one of the observations, you know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for the grand mean effect were also known. Therefore, there is just one unique piece of information in the grand mean factor. Grand mean has just 1 degree of freedom.\nFor treatment factor, there are four levels of the factor (shown by the four vertically long cells for treatment factor in Figure 1). Grand mean is the only factor outside of training method. Take the number of levels for training method (4) and subtract the degrees of freedom for grand mean (1), which yields 4-1 = 3 degrees of freedom for training method.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the training method effects really contain. Since all observations from the same training method will have the same effect, we only need to know 4 pieces of information: the effect of each training method. But the answer is actually less than that! Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom are 3. As soon as we know 3 of the effects for training method, we can fill in the training method effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of Figure 1). Both grand mean and training method are outside of the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for grand mean and training method (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the residual factor effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 levels of training method is 20 observations, or in other words, 20 degrees of freedom."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#factor-effects",
    "href": "BasicFactorial_quarto_boat.html#factor-effects",
    "title": "BF[1]",
    "section": "Factor Effects",
    "text": "Factor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size of the grand mean, training methods, and residual errors factors in the lifeboat training study. In other words, we can estimate the terms in the one-way ANOVA model.\n\n\n\n\n\n\nGeneral Rule for Effect Size\n\n\n\nEffect size = factor level mean - the sum of the effects of all outside factors\n\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the grand mean factor and the means for each level of training method.\nTo get the grand mean, average all 24 observations. The mean for all the observations is 6.5846. There is only one level for grand mean so this number is placed into each of the cells for the grand mean factor in Figure 2.\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. In Figure 2 these means are placed in the respective training method column.\nWe do not need to calculate means for residual error factor because for two reasons. First, there is only one observation per level of residual error, so the mean is the observation itself. Second, nothing is inside of residual error. It is the last step in the process and its mean is not needed to calculate factor effects.\n\n\n\n\nFigure 2: Raw data and means for grand mean and training factors\n\n\n\n\n\nCalculate effects\nNow that we have calculated means for each level of each factor, we can move on to calculate the effects of the factor levels. We will use the general formula for calculating effect size.\nFor the grand mean, there is only one level and there are no outside factors. Therefore, the effect due to grand mean is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nThe training method factor has four levels: one for each method. To calculate the effect of a training method, take the training method mean and subtract it from the effect due to the grand mean factor. For the “Control” method, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the grand mean. In a similar way you can find the effect for Monitor/Keyboard \\(7.8492 - 6.5846 = 1.2645\\). This means the student performance scores increased by 1.2645 on average in this training method compared to the grand mean. For Head Monitor Display/Joypad, the effect is \\(6.5789 - 6.5846 = -0.0058\\). For Head Monitor Display/Wearables the effect is \\(7.1616 - 6.5846 = 0.5770\\) (see below).\n\n\n\n\nFigure 3: Training Method Effects\n\n\n\nTo calculate the residual error effects remember that there are 24 levels of the residual error factor. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for grand mean and the effect for whichever training method that particular observation received. For instance, for the observation located in the top left of our data set the value is 4.5614. Subtract the sum of the effects of outside factors (grand mean and training). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual error effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was 0.1875 less than the mean of the control group. This individual’s performance was lower than the mean of his/her peers who received the same type of training.\nWe can repeat the residual calculation for the first observation in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to grand mean and its respective training (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in Figure 4.\n\n\n\n\nFigure 4: Residual Effects"
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#completing-the-anova-table",
    "href": "BasicFactorial_quarto_boat.html#completing-the-anova-table",
    "title": "BF[1]",
    "section": "Completing the ANOVA table",
    "text": "Completing the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA summary table contains the information we need for a hypothesis test of a treatment factor.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n\n\n\n\n\n\nFactor\n3\n\n\n\n\n\n\nResidual Error\n20\n\n\n\n\n\n\nTotal\n24\n\n\n\n\n\n\n\n\n\n\n\nTo get the sum of squares (SS) for a factor, the factor’s effect needs to be squared. This is done for each observation. Then all the squared values are summed up to get the sum of squares.\nFor grand mean, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to grand mean.\n\\[\nSS_\\text{Grand Mean} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor, training method, has four different effects: one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to training method. For instance, for the control group, the effect is -1.8358. That value is squared, and then the squared values is multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Factor} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the grand mean factor, treatment factor, and residual error factor.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n1040.57\n\n\n\n\n\nFactor\n3\n31.81\n\n\n\n\n\nResidual Error\n20\n100.49\n\n\n\n\n\nTotal\n24\n1172.87\n\n\n\n\n\n\n\n\n\n\nRecall that SS is a measure of total variability. Comparing factors on total variability isn’t exactly fair.\nConsider for a moment 2 classes that were competing in a canned food drive. One class collected 150 cans. The other class collected 3,000 cans. The second class seems to have one. But is it a fair comparison? What if the first class had 10 students and the second class had 300 students. If we are interested in determining which class was more effective at getting canned food donations, we should somehow account for the difference in class size. If we divide the total cans by the number of students, we get the mean number of cans collected per student. We see the first class collected 15 cans per student, and the second class only collected 10 cans per student.\nLike the canned food drive example, differences in SS for a factor may be due in part to differences in number of levels for each factor. (For example, the residual factor has 24 factor levels, while toothbrush only has 4). We will convert this total variability (sum of squares) into a mean variability (mean square) measure to properly account for differences in number of factor levels. This allows us to compare the factors’ variability on a standardized scale.\nWe calculate the mean squared error column, or mean square (MS), by dividing the sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total (the sum of squares) into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation). The MS is calculated in this manner for each of the effects.\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. This works when looking at SS, since it is the total variance due to each factor. Mean squares is then the average variability for each effect and clearly shows which factor is a bigger source of variability.\nThe mean square calculations are:\n\\[\nMS_\\text{Grand Mean} = \\frac{SS_\\text{Grand Mean}}{df_\\text{Grand Mean}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Factor} = \\frac{SS_\\text{Factor}}{df_\\text{Factor}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n1040.57\n1040.57\n\n\n\n\nFactor\n3\n31.81\n10.60\n\n\n\n\nResidual Error\n20\n100.49\n5.02\n\n\n\n\nTotal\n24\n1172.87\n\n\n\n\n\n\n\n\n\n\nThe treatment factor, in this case training method, is the primary factor of interest so the F test statistic is only calculated for that factor. To get the F test statistic for the treatment factor take the mean square (MS) due to treatment factor and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of the F statistics as the ratio of variance between treatment means over the variance of the distances for observed values to their respective treatment mean. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Factor} = \\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for the treatment factor is calculated based on the F statistic and the degrees of freedom for both treatment factor and residual error. In practice, statistical software computes all the components of the ANOVA table, including the p-value. To complete the decomposition of variance in a manual way, the p-value is calculated in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to the treatment factor are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n1040.57\n1040.57\n\n\n\n\nFactor\n3\n31.81\n10.60\n2.11\n0.131\n\n\nResidual Error\n20\n100.49\n5.02\n\n\n\n\nTotal\n24\n1172.87"
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#describe-the-data",
    "href": "BasicFactorial_quarto_boat.html#describe-the-data",
    "title": "BF[1]",
    "section": "Describe the Data",
    "text": "Describe the Data\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots or scatterplots with the means displayed.\nInteractive code and additional explanations of numerical summaries and plots in R are found at R Instructions-&gt;Descriptive Summaries section of the book.\n\nNumerical Summaries\nAfter loading required packages, we will read in the data and do some wrangling.\n\n\nCode\n## Reduced data to match decomposition example\nvirtual &lt;- read_csv(\"data/virtual_training_redux.csv\") \n\n#A bit of data wrangling\nvirtual &lt;- virtual |&gt;\n   mutate(\n         Treatment = case_when(\n           grp.trt %in% 1  ~ \"Control\",\n           grp.trt %in% 2  ~ \"Monitor/Keyboard\",\n           grp.trt %in% 3  ~ \"Joypad\",\n           grp.trt %in% 4  ~ \"Wearables\"\n          )\n        )\n\n\nWe then calculate summary statistics for each level of training method, in Table 1. Monitor/Keyboard has the highest mean (7.16) and median (8.33). It appears to be the best training method. Our ANOVA will seek to know if differences between training methods are statistically significant.\n\n\nCode\nfavstats(procKnow~Treatment, data = virtual) |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\n\nTable 1: Numerical Summary\n\n\nTreatment\nmin\nQ1\nmedian\nQ3\nmax\nmean\nsd\nn\nmissing\n\n\n\n\nControl\n0.33\n4.64\n5.25\n6.24\n6.66\n4.75\n2.32\n6\n0\n\n\nJoypad\n1.88\n6.25\n6.61\n8.25\n9.45\n6.58\n2.65\n6\n0\n\n\nMonitor/Keyboard\n5.45\n6.78\n8.33\n8.78\n9.78\n7.85\n1.65\n6\n0\n\n\nWearables\n4.94\n5.21\n7.03\n8.91\n9.83\n7.16\n2.22\n6\n0\n\n\n\n\n\n\n\n\n\n\nGraphical Summaries\nYou should also visualize the data. Since there are only six data point, a scatter plot may be preferred over a boxplot.\n\n\nCode\nggplot(data = virtual, \n       mapping = aes(x=Treatment, y = procKnow, group = 1)) +\n  geom_point() +\n  stat_summary(fun = mean, \n               geom= \"line\") +\n  labs(x = \"Training Method\", y = \"Process Knowledge Test Score\",\n       title = \"Process Knowledge Scores by Training Method\",\n       subtitle = \"Group Means Connected with a Line\")\n\n\n\n\n\nFigure 5: Graphical Summary\n\n\n\n\nThis plot reinforces the conclusion that Monitor/Keyboard tends to have higher scores. The outliers in the Control and Joypad method also become very apparent."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#create-the-model",
    "href": "BasicFactorial_quarto_boat.html#create-the-model",
    "title": "BF[1]",
    "section": "Create the Model",
    "text": "Create the Model\nYou then create the model using the aov() function. To see results of the F-test you can feed your model into a summary() function.\n\nmyaov &lt;- aov(Y ~ X, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is the user defined name in which the results of the aov() model are stored\nY is the name of a numeric variable in your dataset which represents the quantitative response variable.\nX is the name of a qualitative variable in your dataset. It should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\nYourDataSet is the name of your data set.\n\nExample Code\n\n\n method_aovA name you come up with for your model  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  procKnow The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Treatment, The independent variable containing the names for the 4 training methods  data = virtual Tell the model to look in the dataset named “virtual” for procKnow and Treatment variables  ) Functions always end with a closing parenthesis  summary( Give important information about an object. When called on an aov object the default is to print the ANOVA summary table  method_aov  Whatever you named your ANOVA model in the previous line   )  Functions always end with a closing parenthesis  Click to toggle output Click to toggle output. \n\n\n\n\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)\nTreatment    3  31.81  10.604   2.111  0.131\nResiduals   20 100.49   5.024               \n\n\n\nWe then interpret the results. Training method does not appear to be a significant factor since the p-value (0.131) is higher than our significance level of 0.05. Therefore, we cannot conclude that any of the 4 training methods has more of an effect on test score than another. In other words, there is insufficient evidence to suggest a non-zero effect for any method."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#check-assumptions",
    "href": "BasicFactorial_quarto_boat.html#check-assumptions",
    "title": "BF[1]",
    "section": "Check assumptions",
    "text": "Check assumptions\nNow that the model is created the assumptions need to be checked. Interactive code and additional explanation for assumption checking can be found in the Model Diagnostics and Assumptions sections of the book respectively.\nBelow, we find that all assumptions of our lifeboat training method model are met and we can trust the hypothesis test that was just conducted.\n\nConstant Error Variance\nWe first check to see if the levels of training method have constant variance. The points in Figure 5 have similar spread, with the exception of the particularly low outlier scores in the Control and Joypad groups. Furthermore, in Table 1 we see that the largest standard deviation (2.65 for Joypad) is not more than double the smallest standard deviation (1.65 for Monitor/Keyboard). Therefore, the assumption of constant variance appears to be met.\n\n\nNormally Distributed Error Term\nA QQ-plot of the residuals is shown in Figure 6. Since none of the points are outside of the boundary it is safe to conclude that residuals are normally distributed.\n\n\nCode\ncar::qqPlot(method_aov$residuals)\n\n\n[1] 13  6\n\n\n\n\n\nFigure 6: QQplot of Model Residuals\n\n\n\n\n\n\nIndependent Residuals\nNothing about the study suggests a lack of independence among the residuals. The data was obtained second hand. If possible, you should ask the principal researcher more about how the data was collected. For our purposes, we will assume the row number in the dataset does not represent the order in which the data was originally collected. Therefore, an order plot would not be helpful in detecting order bias. Thus, based on everything we know about the study, we have no reason to suspect the independent residuals assumption is violated."
  },
  {
    "objectID": "BasicFactorial_quarto_boat.html#footnotes",
    "href": "BasicFactorial_quarto_boat.html#footnotes",
    "title": "BF[1]",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt can be argued that this design is not technically a factorial design because only one experimental factor is involved. However, we categorize it with the other basic factorial designs because the assignment of subjects to factor levels is done completely at random, just as it is for the other basic factorial designs covered in this course.↩︎"
  },
  {
    "objectID": "BasicFactorial_intro.html",
    "href": "BasicFactorial_intro.html",
    "title": "Basic Factorial Designs Overview",
    "section": "",
    "text": "A factorial design refers to how/which factor level combinations are chosen for inclusion in the study.\nBasic Factorial designs have some key characteristics in common, notably:\nTo assign something completely at random means that each experimental unit has a known and equal chance of being selected for a particular treatment and that no other considerations are taken into account when making treatment assignments.\nThe decomposition and formulas presented for each of the specific designs assumes the design is balanced, meaning each factor level combination has the same number of observations. In the case of unbalanced designs, formulas would need to be adjusted to account for the differences. Additional explanation of how to approach analysis for unbalanced data is found under broad topics&gt;unbalanced."
  },
  {
    "objectID": "BasicFactorial_intro.html#footnotes",
    "href": "BasicFactorial_intro.html#footnotes",
    "title": "Basic Factorial Designs Overview",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFactorial crossing is defined in BF[2] and in the Factor Structure page.↩︎\nOnce the factor level combinations are decided upon using factorial crossing, there are multiple ways to perform the random assignment of experimental units to factor levels. In this book though, all of the BF models will be treated as using completely randomized assignment. Strategies such as blocking and repeated measures are treated as separate designs.↩︎"
  },
  {
    "objectID": "Anova_F-test.html",
    "href": "Anova_F-test.html",
    "title": "ANOVA and the F-Test",
    "section": "",
    "text": "With the effects model defined we will want to test whether the treatment factor(s) has a statistically significant effect on the response variable. In other words we are interested in testing the hypotheses:\n\\[\nH_0: \\alpha_1 = \\alpha_2 = ... = 0\n\\]\n\\[\nH_a: \\alpha_i \\ne 0 \\text{ for at least one i}\n\\tag{1}\\]\nWhere \\(\\alpha_i\\) represents the effect of a factor level.\n\n\nTesting whether the effects are all equal to each other is incomplete, you must include the zero. Since all level effects must sum to zero for a given factor, the only way all effects can be equal is if they are all zero.\nAnalysis of variance (ANOVA) is a statistical technique that allows us to simultaneously test all factor level effects at the same time.\nBy the end of this section you should be able to state a hypothesis for each term in an ANOVA effects model, calculate and explain the meaning of all the pieces of an ANOVA summary table output, and use the ANOVA summary table to conduct a test of the stated hypothesis."
  },
  {
    "objectID": "Anova_F-test.html#multiple-t-tests",
    "href": "Anova_F-test.html#multiple-t-tests",
    "title": "ANOVA and the F-Test",
    "section": "Multiple t-tests",
    "text": "Multiple t-tests\nAt this point it is reasonable to ask if we couldn’t arrive at the same conclusion by simply conducting multiple t-tests. For example, you could do a t-test for each factor level to determine if the effect is significantly different from zero. Or you might consider testing each combination of factor level effects to see if they are equal to each other.\nThe multiple t-test approach has a couple of a drawbacks. The first drawback is that it becomes a real burden to run, present and interpret a lot of tests if there are many levels to a factor. If there are only 3 or 4 factor levels and only 1 or 2 factors in the analysis, conducting many tests may simply be an annoyance. However, if many factors and/or many factor levels are involved the magnitude of tests may bog down your analysis.\nThe other main drawback of using multiple t-tests is more substantive and has to do with the probability of a Type I error. Suppose the treatment factor in our study has 3 levels. The null hypothesis associated with an ANOVA that tests all factor level effects simultaneously is:\n\\[\nH_0: \\alpha_1 = \\alpha_2 =  \\alpha_3 = 0\n\\]\nTesting at a 0.05 significance level means there is a 0.05 probability we will incorrectly reject this null hypothesis (i.e. commit a Type I error). Conversely, there is 0.95 probability we will NOT commit a Type I error.\nIf we attempt to approach the problem by conducting multiple t-tests, we would test the following set of null hypotheses:\n\\(H_0: \\alpha_1 = 0\\) and \\(H_0: \\alpha_2 = 0\\) and \\(H_0: \\alpha_3 = 0\\).\nWe may conduct each of these tests at the 0.05 significance level. Incorrectly rejecting the null hypothesis on any one of these tests would result in the same Type 1 error as incorrectly rejecting the null hypothesis of our ANOVA test of all the effects simultaneously.\nSo what is the probability of committing a Type 1 error in at least 1 of these 3 tests? The simplest way to find the probability of committing at least one Type 1 error in the 3 tests is to calculate \\(1 – P(\\text{no Type 1 errors in all three tests})\\). As previously stated, the significance level (0.05) of each test represents the probability of a Type 1 error. Therefore, the probability of not committing a Type 1 error on each test is 0.95. If we treat the tests as independent, we can find the probability of NOT committing a Type 1 error in all of the tests by multiplying the probabilities:\n\\[\n0.95 * 0.95 * 0.95 = 0.857\n\\]\nWe can subsequently find \\(1-0.857 = .143\\) is the probability of committing a Type 1 error in at least one of the tests, assuming all the null hypotheses are true. This is often referred to as the family wise error rate. The Type 1 error probability (0.143) in this family of t-tests is almost 3 times higher than the ANOVA Type 1 probability of 0.05.\nIn summary, ANOVA allows us to keep the number of tests manageable and it greatly simplifies how Type 1 error is addressed.\nIf we consider a study with more than 1 factor, there are additional advantages of ANOVA. Unlike a multiple t-test approach, while testing one factor’s effects the ANOVA test can account for the other factors’ impact on the response. In this regard, ANOVA is similar to regression."
  },
  {
    "objectID": "Anova_F-test.html#regression",
    "href": "Anova_F-test.html#regression",
    "title": "ANOVA and the F-Test",
    "section": "Regression",
    "text": "Regression\nANOVA and linear regression are more similar than they are different. ANOVA and linear regression each have their own vocabulary because they were developed under different circumstances. ANOVA was developed to deal with agricultural experiments where the independent variables were primarily categorical. Linear regression tends to be introduced as a tool to analyze data where independent variables are quantitative. Though the language and output associated with each technique may appear different on the surface, the underlying “math” (i.e. the linear algebra) for both techniques is identical. It is not uncommon to have a study where there are multiple quantitative independent variables and multiple categorical independent variables. Thus, the differences between the two lie more in the problems they tend to be applied to and the vocabulary of the researcher than in any meaningful difference in results."
  },
  {
    "objectID": "Anova_F-test.html#mean-squares-ms",
    "href": "Anova_F-test.html#mean-squares-ms",
    "title": "ANOVA and the F-Test",
    "section": "Mean Squares (MS)",
    "text": "Mean Squares (MS)\nYou can think of Mean Squares (MS) as synonymous with variance. The F statistic is a ratio of variances:\n\\[\nF = \\frac{\\text{Variation between factor levels}}{\\text{Variation within factor levels}} = \\frac{\\text{Mean squares of treatment factor means}}{\\text{Mean squares of residual errors}}\n\\]\nWith this is mind, we can fill in the F column of the ANOVA table for Treatment Factor.\n\n\nTable 2: Blank ANOVA summary table for an experiment with 1 treatment factor\n\n\n\n\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nF\np-value\n\n\n\n\nGrand Mean\n\n\n\n\n\n\n\nTreatment Factor\n\n\n\n\\(\\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}}\\)\n\n\n\nResidual Error\n\n\n\n\n\n\n\nTotal\n\n\n\n\n\n\n\n\n\nTo find the variation between factor level means, calculate the sample variance of factor level means and multiply it by the number of replicates in each factor level. (In the case of unbalanced data where you do not have the same number of replicates in each factor level, weighting by sample size is needed).\nThe Mean Squares of the residual error factor (i.e. Mean Squared Error, MSE) represents the within factor level variation. To calculate it you can find the sample variance within each factor level and then take the mean of those variances. (In the case of unbalanced data where you do not have the same number of replicates in each factor level, you would take a weighted average).\nFigure 4 (a) and Figure 4 (b) below show deviations necessary to calculate the between group and within group variance (or in other words the mean squares treatment and the mean squares error). The figures are based on data from an experiment with 3 factor levels. Figure 4 (a) shows variation between factor level means. It shows the factor level means plotted as blue lines and the grand mean as a red line. In this chart we see the deviation from each factor level mean to the grand mean represented as a gray dashed line. As mentioned above, the mean squares for treatment could be computed as the variance of the 3 factor level means2, and multiplied by 15 (the number of replicates in each factor level).\n\n\n\n\n\n\n\n(a) Deviations to Get MS Treatment Factor\n\n\n\n\n\n\n\n(b) Deviations to Get MS Error\n\n\n\n\nFigure 4: Between Group vs. Within Group\n\n\nFigure 4 (b) shows variation within factor levels. Each point is plotted in a cluster according to the factor level it belongs to. The deviation from each point to its respective factor level mean is depicted with a gray dashed line. The mean square error could be computed by finding the sample variance within each group3 and then taking the mean of those 3 variance estimates.\nThinking about things in this way is helpful to understand conceptually what is happening. However, the ANOVA summary table captures interim steps for calculating mean squares slightly different. Since Mean Squares is synonymous with variance, now is a good time to review the sample variance formula.\n\\[\ns^2 = \\frac{\\sum{(y_i - \\bar{y})}^2}{n-1}\n\\tag{2}\\]\nUpon closer examination of Equation 2 you can see that this formula is essentially a mean. In fact, you can think of variance as a mean of squared deviations (a.k.a. errors). Any mean is built using 2 parts:\n\n\nRecall that an effect is defined as a deviation from the mean.\n\nnumerator: a sum or total\ndenominator: the number of pieces of information used to create the sum in the numerator\n\nTherefore, in a mean square calculation, the numerator is the sum of squares and the denominator is the degrees of freedom.\n\n\n\n\n\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nF\np-value\n\n\n\n\nGrand Mean\n\n\n\n\n\n\n\nTreatment Factor\n\n\n\\(\\frac{SS_\\text{Treatment Factor}}{df_\\text{Treatment Factor}}\\)\n\\(\\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}}\\)\n\n\n\nResidual Error\n\n\n\\(\\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}}\\)\n\n\n\n\nTotal"
  },
  {
    "objectID": "Anova_F-test.html#sum-of-squares-ss",
    "href": "Anova_F-test.html#sum-of-squares-ss",
    "title": "ANOVA and the F-Test",
    "section": "Sum of Squares (SS)",
    "text": "Sum of Squares (SS)\nLet’s talk about the numerator first, this will be the sum of squared deviations, or Sum of Squares for short. The Sum of Squares (SS) is a measure of the total variability in a dataset. A naïve approach to calculating total variability in a dataset is to measure the distance from each value to the mean of the dataset. The problem with this approach is that those distance measures will always sum to zero.\nTo avoid this problem, statisticians square the distances before summing them. This results in a value that summarizes the total amount of spread in the dataset. This quantity, the Sum of Squares, is important and so it has its own column in the ANOVA summary table.\nIn the table below an equation for each factor’s SS is listed using terms from the factor effects model. We’ll walk through the meaning of each of those equations.\n\n\n\n\n\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nF\np-value\n\n\n\n\nGrand Mean\n\n\\(n*\\bar{y}_\\text{..}^2\\)\n\n\n\n\n\nTreatment Factor\n\n\\[ \\sum (\\hat{\\alpha}_i^2*n_i)\\]\n\\(\\frac{SS_\\text{Treatment Factor}}{df_\\text{Treatment Factor}}\\)\n\\(\\frac{MS_\\text{Treatment Factor}}{MS_\\text{Residual Error}}\\)\n\n\n\nResidual Error\n\n\\[ \\sum \\hat{\\epsilon}_\\text{ij}^2 \\]\n\\(\\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}}\\)\n\n\n\n\nTotal\n\n\\(\\sum y_\\text{ij}^2\\)\n\n\n\n\n\n\n\n\nA deviation from the mean can be thought of as an effect. That is why the symbols for factor effects are used in the SS column in the ANOVA summary table.\nFirst, let’s review the factor effects model to better understand the equations in the SS column above.\n\\[\ny_\\text{ij} = \\mu + \\alpha_i + \\epsilon_\\text{ij}\n\\]\nWe can walk through each equation in the SS column, one by one.\n\nGrand Mean SS: \\(\\bar{y}_\\text{..}\\) is the grand mean. Its value should be squared and then multiplied by \\(n\\), which is the total number of observations in the study.\nTreatment Factor SS: Recall that \\(\\hat{\\alpha}_i\\) is the estimated effect of each factor level. After squaring each effect, multiply it by the number of observations in that level, \\(n_i\\). Finally, the \\(\\sum\\) symbol means to add all those products together.\nResidual Error SS: \\(\\hat\\epsilon_\\text{ij}\\) is the symbol for an observed residual. Each residual must be squared and then all those squared residuals are summed together.\nTotal SS: This is the sum of all the other sums of squares. Or it can be found by squaring each observed value and then adding up all those squared observations."
  },
  {
    "objectID": "Anova_F-test.html#degrees-of-freedom",
    "href": "Anova_F-test.html#degrees-of-freedom",
    "title": "ANOVA and the F-Test",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nDegrees of freedom can be thought of as the number of unique pieces of information that contributed to the variance estimate, mean squares.\n\n\n\n\n\n\nDegrees of Freedom\n\n\n\nThe number of unique pieces of information that contributed to the variance estimate.\n\n\nIn our dataset we have a certain number of observations. All those observations can be used to estimate the variance in the dataset. But you will notice in Equation 2 the data has already been used to estimate the grand mean (\\(\\bar{y}\\) estimates \\(\\mu\\)). In other words, before we can estimate the variance we must use the data to estimate the mean. Estimating the mean “uses up” one degree of freedom. This is why the denominator of the sample variance formula divides by \\(n-1\\) instead of by \\(n\\).\nFor additional explanation, consider this simple example. There are three data points and you know that the mean of these 3 data points is 10. The value of the first data point could be any number, it is free to vary. The value of the second data point could also be any number, it is free to vary. The third number’s value is not free to vary. It is constrained by the fact that the mean of the 3 data points must be 10. The values of the first two datapoints will determine the value of the third under the constraint of a known (or estimated) mean.\nThe example described above is summarized in Table 3. The first number is represented as an \\(a\\) and the second number if represented with a \\(b\\).\n\n\nTable 3: Only n-1 values are free to vary when the mean of the values is known\n\n\n\n\n\n\n\n\n\nvalue 1\nvalue 2\nvalue 3\n\nMean of 3 Values\n\n\n\n\na\nb\n\\(3*10 - (a+b)\\)\n-&gt;\n10\n\n\nfree to vary\nfree to vary\ndepends on other two values\n\n\n\n\n\n\nHow does this apply to the analysis of variance? Initially you have \\(n\\) observations, or in other words \\(n\\) unique pieces of information that can be used to estimate variance of the dataset. As you try to break the dataset’s variance into its component pieces, you will need to reallocate the \\(n\\) pieces of information to each factor (grand mean, treatment factor, residual error) for use in estimating each factor’s mean square. To paraphrase the law of the conservation of mass, “the number of observations can neither be created nor destroyed”. The sum of degrees of freedom for all the factors must equal the number of observations in the dataset.\nWe will reason through the degrees of freedom calculation for each of the 3 sources in the ANOVA table. Keep in mind, we are using the simplest experiment, just one treatment factor, to illustrate these concepts. In more complex designs, there will be additional factors listed in the “sources” column.\nAs was mentioned, every time we use the data to estimate a parameter we use a degree of freedom. Or in other words, every time we use the data to estimate a parameter we lose a degree of freedom for our mean square error estimate. To find the grand mean we average over all the values in the dataset; that uses up one degree of freedom because we have estimated one mean, the grand mean.\nWhen calculating the degrees of freedom for the treatment factor you might be tempted to think that the degrees of freedom is equal to the number of factor levels because you have to estimate a mean for each level. But, remember the simple example depicted in figure Table 3. Because I have already estimated the grand mean, the last factor level is not free to vary and therefore is not estimated directly. The mean of the last factor level will have to be a number that satisfies the constraint that the mean of all the factor level means is the grand mean.\nExplained another way, consider the fact that all the factor level effects must sum to zero. If there are \\(i\\) factor levels, you only need to estimate effects for \\(i-1\\) levels. The last level’s effect is a function of the other factor level effects, it does not need to be estimated and therefore does not need a degree of freedom.\nFinally, consider the residual error factor. The non-technical definition of the term residual means “left over”. The degrees of freedom for the residual error factor is whatever degrees of freedom are left over after calculating degrees of freedom for all other factors.\nIn summary, to estimate the degrees of freedom for a factor, start with its number of levels and then subtract the number of means that need to be calculated in order to calculate the factor’s level effects. That may sound a bit confusing, luckily the general rule states the exact same thing in a simpler, more understandable way.\n\n\n\n\n\n\nGeneral rule to find degrees of freedom for a factor\n\n\n\n\\[\n\\text{df} = \\text{number of levels} - \\text{sum of df of outside factors}\n\\]"
  },
  {
    "objectID": "Anova_F-test.html#footnotes",
    "href": "Anova_F-test.html#footnotes",
    "title": "ANOVA and the F-Test",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nF is a random variable. This means we never know exactly what the value of F will be based on random selection/assignments. However, we do know that under the null hypothesis some values of F are more likely than others. Specifically, if the null hypothesis were true then values of 1 are more likely and large values tend to be less likely. The F distribution represents a probability distribution of the variance ratios. In a given study just one random sample is taken and one variance ratio (F) is calculated. However, a different selection of experimental units (or different assignment to factor levels) would result in different estimates of variances, and consequently different F statistics. The F distribution represents all possible F statistics under the null hypothesis that a factor has no significant effect.\nWhen a treatment factor has no significant effect on the response variable, the expected F statistic is 1. This is because there are two sources of variability contributing to our estimate of the treatment factor variance: 1) variance in factor level means and 2) variance within a factor level. The denominator of the F statistic is simply the variance within a factor level (since each factor level has a slightly different variance, it is actually the average or pooled variance within factor levels). So the F statistic looks like this:\n\\[\nF = \\frac{\\text{variance in factor level means} + \\text{variance within factor levels}}{\\text{variance within factor levels}}\n\\]\nIf there really is no significant effect across factor levels, then the variance in factor level means goes to zero and we are left with:\n\\[\nF = \\frac{\\text{variance within factor levels}}{\\text{variance within factor levels}} = 1\n\\]\nThe values for degrees of freedom affect the shape and the spread of the F distribution. Visit this applet to learn more and interact with the family of F distributions.↩︎\nThe variance would be calculated by squaring the deviations, summing them up and then dividing by the degrees of freedom, which is 2 in this case.↩︎\nThe variance is calculated by squaring the deviations, and then summing them together and dividing by the degrees of freedom, which in this case is 14 for each group.↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "ancova.html",
    "href": "ancova.html",
    "title": "ANCOVA",
    "section": "",
    "text": "So far, we have only considered experiments that use categorical factors as independent variables, and a quantitative response. It is not hard to imagine scenarios where quantitative variables serve as the independent variable. This type of analysis, where the response and the independent variable(s) are both quantitative is called regression. Students can get a review of simple linear regression from the freely available BYU-Idaho Math221 textbook. A deeper dive can be found in the BYU-Idaho Math325 textbook under Multiple Regression.\nIf a combination of categorical and quantitative variables are used to predict a quantitative response it could be called ANOVA or regression. Both terms are used to describe an approach or application of the generalized linear model.\nIn reality, the main difference between regression and ANOVA is the vocabulary associated with them and the paradigm or perspective the researcher has. The ANOVA technique originated in the early 1900’s by Ronald Fisher. It’s initial use was primarily agricultural experiments and independent variables were categorical.\nRegression has been around much longer. It incorporates categorical variables through dummy coding.\nThough the underlying linear algebra for both techniques is the same and the same results can be obtained regardless of the technique, the paradigm, purpose, or vocabulary for selecting a tool tends to differ. Historical precedence and inertia is driving much of the researcher’s paradigm, purpose and vocabulary.\nWhy not just do away with ANOVA if they are fundamentally the same? There are some that argue ANOVA provides a valuable way to describe, to teach, and to talk about how variables are related. In particular, ANOVA can be useful for “summarizing complex high-dimensional inferences and for exploratory data analysis”. For a brief introduction to the discussion, you can read this exachange..\nANOVA is used in this text for its “ease of teaching/applying the tool”1 (especially to a non-statistician audience) and to prepare students for the vocabulary many of them will encounter in their field. These same students should also seek exposure to regression and the generalized linear model."
  },
  {
    "objectID": "ancova.html#example-benefits-of-ancova",
    "href": "ancova.html#example-benefits-of-ancova",
    "title": "ANCOVA",
    "section": "Example: Benefits of ANCOVA",
    "text": "Example: Benefits of ANCOVA\nA company wanted to study how distributing a coupon could effect sales. The company randomly selected 4 stores and distributed coupons for those stores. For another 4 stores the company would not distribute coupons, but would still track sales.\nInitial analysis of the results, contained in Figure 1 (a), surprised the company. The difference in mean sales between the coupon group and the non-coupon group was small (only $2,500) relative to the variability within each group. A hypothesis test of the difference revealed no statistically significant results.\nThe company’s BYU-Idaho intern realized that the research team had not accounted for the fact that some stores were in smaller cities than others. He noticed that the “no coupon” stores tended to be located in larger cities, with potential for more sales. The “coupon” group of stores tended to be located in smaller cities. This can be seen in Figure 1 (b), notice the “no coupon” group tends to be located farther to the right on the x-axis.\nThe relationship between city size and sales revenue was accounted for with a regression line for each group (see Figure 1 (b)). Researchers adjusted for the difference in city size between the two groups and found the difference in predicted revenue between “coupon” and “no coupon” groups was actually $6,400. This difference is considered significant at the \\(\\alpha = 0.10\\) level.\n\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n(b)\n\n\n\n\n\nFigure 1: Benefit of a Covariate\n\n\nNotice the straight, parallel lines in panel (b) of the above plot. This is a visual indicator that there is no interaction between the covariate and the independent treatment factor. In other words, the effect of the treatment does not change depending on the value of the covariate (city size).\nSituations where there is a significant interaction between the coviarate and the treatment factor are valid and common. However, when an interaction is present, the situation is generally called regression rather than ANCOVA.\nThere are a couple key advantages to using a covariate in the analysis. Much like blocking, a covariate can reduce mean squared error; thereby increasing our ability to detect a significant treatment effect. It can also reduce bias caused by differences in treatment groups, as we saw in the coupon example above.\nBeware of using ANCOVA to adjust for differences in groups of observational data. Doing so may require you to extrapolate from the line to a region where there are no (or few) observations. Consider a study that investigated the effect of a fertilizer on two types of trees: palm trees and pine trees. Researchers also considered the effect that air temperature could have on the way the fertilizer worked. They randomly selected nurseries from across the state of California to participate in the study. The nurseries applied the fertilizer to a mature tree and then measured the growth after 12 months.\nThe covariate in this case is the temperature of the surrounding area. The factor is the tree type (it is an observational factor, not an experiment). The problem lies in the fact that palm trees are all found in a warmer climate and the pine trees tend to be found in cooler climate. It is not appropriate to extrapolate the relationship of temperature and growth to predict how either tree would do in the other climate since we don’t have data in those conditions.\nIn addition, the covariate value should not be affected by the treatment. Nor should the covariate effect the random assignment. This is an experimental design assumption, not an analysis assumption. If you were doing an observational study, random assignment does not occur, and the ANCOVA analysis can be quite help in isolating the effect of each variable in the presence of the other. In an observational study you could commonly see correlation between an independent factor and a continuous covariate."
  },
  {
    "objectID": "ancova.html#describe-the-data",
    "href": "ancova.html#describe-the-data",
    "title": "ANCOVA",
    "section": "Describe the Data",
    "text": "Describe the Data\nA scatterplot of the proportion of initial weight lost and initial weight is presented below, with each point colored according to their age group. A numeric summary of the data by age group is also presented.\n\n\nCode\nbl_data %&gt;% \n  ggplot(aes(x = initial_weight_at_start_show, y = prop_initial_weight_lost,\n             color = ymo, shape = ymo), size = 3) +\n  geom_point()  +\n  theme_classic() + \n#  theme(legend.position = \"top\") +\n  scale_y_continuous(labels = scales::label_percent(scale = 1)) +\n#  scale_shape_manual(values = c(16, 17, 18))+\n  labs(y = \"Total Weight Lost (as a % of Initial Weight)\", x = \"Initial Weight (lbs)\", title = \"Biggest Loser Contestants\", color = \"Age Group\", shape = \"Age Group\")\n#  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\nFigure 2: Graphical Summary\n\n\n\n\n\n\nCode\nfavstats(initial_weight_at_start_show~ymo, data = bl_data) %&gt;% select(-missing) %&gt;% pander()\nfavstats(prop_initial_weight_lost ~ ymo, data = bl_data) %&gt;% select(-missing) %&gt;% pander()\n\n\n\nTable 1: Numerical Summary by Age Group\n\n\n\n\n(a) Initial Weight (lbs)\n\n\n\n\n\n\n\n\n\n\n\n\n\nymo\nmin\nQ1\nmedian\nQ3\nmax\nmean\nsd\nn\n\n\n\n\nYoungest\n167\n252.5\n289.5\n367.2\n526\n311\n75.48\n160\n\n\nMiddle\n217\n254.5\n309\n365\n462\n317.3\n65.99\n83\n\n\nOldest\n216\n245.8\n295\n327.5\n430\n298.1\n60.61\n34\n\n\n\n\n\n\n\n\n(b) Percent of Initial Weight Lost\n\n\n\n\n\n\n\n\n\n\n\n\n\nymo\nmin\nQ1\nmedian\nQ3\nmax\nmean\nsd\nn\n\n\n\n\nYoungest\n7.37\n28.98\n35.84\n43.24\n59.62\n35.6\n9.952\n160\n\n\nMiddle\n17.08\n31.68\n38.63\n45.41\n55.58\n38.34\n9.057\n83\n\n\nOldest\n13.81\n27.95\n33.35\n40.95\n48.83\n33.46\n9.035\n34\n\n\n\n\n\n\n\nThe scatterplot and table make it apparent that the Oldest group tends to loose a smaller percentage of their initial weight than their older counterparts. Furthermore, the maximum and the mean initial weight of Oldest contestants is lower than the maximum and mean initial weight of the other two age groups respectively."
  },
  {
    "objectID": "ancova.html#create-and-test-the-model",
    "href": "ancova.html#create-and-test-the-model",
    "title": "ANCOVA",
    "section": "Create and Test the Model",
    "text": "Create and Test the Model\n\nGeneric Code\nCreate the model using the aov() function.\n\ncov_mod &lt;- lm(Y ~ covariate + treatment, data = YourDataSet, \n              contrast = list(treatment = contr.sum))\n\n\ncov_mod is the user defined name in which the results of the aov() model are stored\nlm stands for linear model. It is like an aov object, but it is better suited to working with models that have continuous covariates (i.e. continuous independent variables) , rather than strictly factors.\nY is the name of a numeric variable in your dataset which represents the quantitative response variable.\ncovariate is the name of the covariate in your dataset.\ntreatment is the name of the controlled factor in your dataset. It should have class() equal to factor or character. If that is not the case, use factor(X) inside the lm(Y ~ factor(treatment)...) command.\ncontrast is an argument that allows you to specify how factor variables should be set-up in R. When dealing with factor variables, R actually changes each factor variable into a group of “dummy” variables to represent the individual factor levels. The default contrast in R does not work well with the Type 3 sums of squares, which is what we need when working with continuous covariates. Therefore, we specify a different contrast. The term contrast is referring to the columns in the X matrix that are used to represent the dummy variables.\nYourDataSet is the name of your data set.\n\nThe model above assumes that the interaction between the covariate and the treatment factor is zero. Rather than assuming that is the case, it is advisable to include the interaction term in the model and test the significance of the interaction. If the interaction is significant it can be removed; if it is not, then it should remain in the model. To include the interaction in the model the following code would be used.\n\ncov_mod &lt;- lm(Y ~ covariate + treatment + covariate:treatment, data = YourDataSet)\n\nAfter creating the model, results of the hypothesis tests for each term in the model can be seen using the Anova() command from the car package. Don’t forget to specify type = 3 in the Anova() command, since a Type 1 Sum of Squares is not appropriate when a covariate is in the model.\n\nlibrary(car)\nAnova(cov_mod, type = 3)\n\nCode for checking model assumptions is found on the diagnostics page, under the “R Instructions” menu of this book.\n\n\nBiggest Loser\nWe first create the model, with proportion of initial weight lost as the response, initial weight (in pounds) as the covariate, and age group as our factor of interest. We will also include the interaction between initial weight and age group in the model to see if it is significant.\nThis model equates to fitting a separate best-fit line for each group, each line having the potential for a unique slope - as depicted in Figure 3.\n\n\nCode\nbl_data %&gt;% \n  ggplot(aes(x = initial_weight_at_start_show, y = prop_initial_weight_lost,\n             color = ymo, shape = ymo), size = 3) +\n  geom_point()  +\n  theme_classic() + \n  scale_y_continuous(labels = scales::label_percent(scale = 1)) +\n  labs(y = \"Total Weight Lost (as a % of Initial Weight)\", x = \"Initial Weight (lbs)\", title = \"Biggest Loser Contestants\", color = \"Age Group\", shape = \"Age Group\") +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\nFigure 3: Interaction Term Included Allows for Unique Slopes\n\n\n\n\nThe slope of the lines for Middle and Oldest appear nearly identical. The slope for Youngest appears different, but we will create the model and run the hypothesis test on the interaction term to be sure.\n\n\nCode\nbl_data2 &lt;- bl_data %&gt;% rename(`Age groups` = ymo, `Initial weight` = initial_weight_at_start_show)\n\nbl_mod_with_interaction &lt;- lm(prop_initial_weight_lost ~ `Initial weight` + `Age groups` + `Initial weight`:`Age groups`, \n                              data = bl_data2,\n                              contrast = list(`Age groups` = contr.sum))\n\npander(Anova(bl_mod_with_interaction, type = 3))\n\n\n\nAnova Table (Type III tests)\n\n\n\n\n\n\n\n\n\n \nSum Sq\nDf\nF value\nPr(&gt;F)\n\n\n\n\n(Intercept)\n6090\n1\n68.65\n5.477e-15\n\n\nInitial weight\n455.8\n1\n5.138\n0.0242\n\n\nAge groups\n84.36\n2\n0.4755\n0.6221\n\n\nInitial weight:Age groups\n33.6\n2\n0.1894\n0.8276\n\n\nResiduals\n24042\n271\nNA\nNA\n\n\n\n\n\nWith a p-value of 0.8276, there is insufficient evidence to claim the interaction is not zero. We therefore remove it from the model and proceed with the analysis.\n\n\n\n\n\n\nNote\n\n\n\nDo not forget to verify the model requirements are met before trusting the conclusion that the interaction term is not significant. This can be done with plot(bl_mod_with_interaction, which = 1:2).\n\n\nThe ANCOVA model (i.e. covariate included without an interaction term) is created.\n\nymo_ancova &lt;- lm(prop_initial_weight_lost ~ `Initial weight` + `Age groups`, \n                  data = bl_data2,\n                 contrast = list(`Age groups` = contr.sum))\n\nThe model is graphically depicted in Figure 4.\n\n\nCode\nb &lt;- ymo_ancova$coefficients\n\nbl_data %&gt;% \n  ggplot(aes(x = initial_weight_at_start_show, y = prop_initial_weight_lost,\n             color = ymo, shape = ymo)) +\n  geom_point() +\n  stat_function(fun = function(x) b[1] + b[2]*x, color = \"red\", size = 1) +\n  stat_function(fun = function(x) (b[1]+b[3]) + b[2]*x, color = \"forestgreen\", size = 1) +\n  stat_function(fun = function(x) (b[1]+b[4]) + b[2]*x, color = \"blue\", size = 1)  +\n  theme_classic() + \n  scale_y_continuous(labels = scales::label_percent(scale = 1)) +\n  labs(y = \"Total Weight Lost (as a % of Initial Weight)\", x = \"Initial Weight (lbs)\", title = \"Biggest Loser Contestants\", color = \"Age Group\", shape = \"Age Group\") \n\n\n\n\n\nFigure 4: ANCOVA, Equal Slopes Model\n\n\n\n\nThe hypothesis test for the treatment factor is\n\\[H_0: \\beta_\\text{Youngest} = \\beta_\\text{Middle} = \\beta_\\text{Oldest} = 0\\]\n\\[H_a: \\beta_j \\ne 0 \\text{ for some }j \\in \\{\\text{Youngest, Middle, Oldest}\\}\\]\nWe will use a significance level of \\(\\alpha = 0.05\\).\nThe results of the ANOVA test are shown below.\n\npander(Anova(ymo_ancova, type = 3))\n\n\nAnova Table (Type III tests)\n\n\n\n\n\n\n\n\n\n \nSum Sq\nDf\nF value\nPr(&gt;F)\n\n\n\n\n(Intercept)\n9920\n1\n112.5\n3.113e-22\n\n\nInitial weight\n1091\n1\n12.37\n0.00051\n\n\nAge groups\n566\n2\n3.209\n0.04193\n\n\nResiduals\n24075\n273\nNA\nNA\n\n\n\n\n\n\nsummary provides a different set of output, but does not include an F test for the factor. Rather, it provides unadjusted t-tests of whether each factor level mean is equal to the mean of the reference factor level’s mean.\n\nThe p-value for age groups is .04193, which is lower than our significance level. This means that, after accounting for the impact of a person’s initial weight, the person’s age group has a significant effect on proportion of weight lost. From Figure 4, we see that the Middle group (green line) and Young roup (red line) seem to loose a higher percentage of weight, while the Oldest (blue line) tends to loose less.\nIncidentally, the low p-value (p = .00051) associated with Initial weight is an indicator that a lot of the variation associated with the response variable is explained by initial weight and is probably important to keep in the model.\nNotice that with the first model, the interaction term was included. Including it in the model seemed to make all the other terms also non-significant. The interaction term seemed to be hiding the significance of the other variables. Removing it allowed us to uncover the true relationships between the variables. It is important to include the right terms in your model rather than blindly leaving everything in. The process of model building is a complicated topic and a whole course could be dedicated to it. The purpose of this discussion is simply to point out that selecting the right terms of the model is important."
  },
  {
    "objectID": "ancova.html#check-assumptions",
    "href": "ancova.html#check-assumptions",
    "title": "ANCOVA",
    "section": "Check Assumptions",
    "text": "Check Assumptions\nThe first two assumptions (linear relationship of response and covariate, and constant variance of the error term) can be checked with a residual vs. fitted plot. If the plot appears to be a random scatter with no patterns or trends, then both assumptions are considered met.\n\nplot(ymo_ancova, which = 1)\n\n\n\n\nFigure 5: ?(caption)\n\n\n\n\n\nLinear Relationship Between Response and Covariate\nTo verify the response variable and the covariate have a linear relationship we check the residual vs. fitted plot, Figure 5. No major patterns or trends or evident so we consider this assumption satisfied.\nIn addition, R adds the red line to the plot. The red line is very flat, an additional indicator the assumption is met. Sometimes, when sample sizes are small, the red line can be confusing. In the case of small sample sizes the red line becomes very sensitive and bounces around a lot - becoming more of a distraction than an aid.\n\n\nConstant Error Variance\nTo verify that the assumption of a constant error term is valid, the residual vs. fitted plot should not show trends or patterns. In particular, if the points in the residual vs. fitted plot created a megaphone, wedge, or triangle shape we would conclude this assumption is violated. In other words, instead of having constant variance, the vertical spread of the points on the plot increase (or decrease) as you move from the left to the right side of the plot. Since Figure 5 does not have this problem, the constant error variance assumption is considered met.\n\n\nNormally Distributed Error Term\nWe check the assumption that residuals are normally distributed with a QQ plot. The QQ plot below shows there may be some skew to the residuals. The points on the right side of the plot are trending away from the line and outside of the shaded bounds. The skew does not appear to be severe however, and if the other assumptions are solidly met, we may continue to use the model output as is.\n\ncar::qqPlot(ymo_ancova$residuals)\n\n\n\n\n[1] 106  16\n\n\n\n\nIndependent Residuals\nThis assumption is not easily checked with the data. Usually, an understanding of how the data was generated and what it represents is the best way to check this assumption. With some research about the show, one can come to know that each observation comes from a particular season. In each season, the contestant is assigned to 1 of 2 trainers (or 1 of 2 teams of trainers). Thus, contestants belonging to the same season and the same trainer may have residuals that are related. Plots of residuals by trainer within a season may reveal patterns in the data. If a plot of residuals by trainer/season looks like a random scatter then we can feel assured this assumption is met. If a trend is discovered, we will want to somehow incorporate trainer/season into the model.\nAs you can see, some expert judgement and understanding of context will drive you to know which variables are worth investigating or could threaten the independence assumption.\n\n\nAssumptions Summary\nAside from the potential violation of independent residuals, the diagnostic plots look good enough to trust the model results."
  },
  {
    "objectID": "ancova.html#footnotes",
    "href": "ancova.html#footnotes",
    "title": "ANCOVA",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nhttps://stats.stackexchange.com/questions/555/why-is-anova-taught-used-as-if-it-is-a-different-research-methodology-compared↩︎\nGeorge W. Cobb. Introduction to Design and Analysis of Experiments. Wiley, 2014. pp 681.↩︎"
  },
  {
    "objectID": "assumptions.html",
    "href": "assumptions.html",
    "title": "ANOVA Assumptions",
    "section": "",
    "text": "For our ANOVA F test results and model predictions to be trusted, certain assumptions, or requirements must be met.1\n\n\nThe terms “requirements” and “assumptions” are often used interchangeably when referring to the set of conditions that must be met for the model to be a valid representation of the data.\nBy way of review, here is the mathematical expression of the model for 1 structural factor. If we incorporated more factors into our study we would need to add additional terms to the model to represent that factor’s effects, as well as any interaction effects.\n\\[\ny_\\text{ij} = \\mu + \\alpha_i + \\epsilon_\\text{ij}\n\\tag{1}\\]\nWhere\n\n\\(y_\\text{ij}\\) is an observation\n\\(\\mu\\) is the grand mean\n\\(\\alpha_i\\) represents the effect of factor level \\(i\\)\n\\(\\epsilon_\\text{ij}\\) is the residual error for the \\(j^\\text{th}\\) observation in factor level \\(i\\)\n\n\\(\\epsilon_\\text{ij}\\) is a random variable and most of the assumptions are focused on defining the distribution of this random variable. Namely, we assume that each residual comes from the same normal distribution, with mean 0 and standard deviation \\(\\sigma\\). Figure 1 illustrates the same residual distribution visually applied to three distinct factor levels. The assumptions and how to check them are explained in more detail below.\n\n\nCode\nset.seed(15)\ny &lt;- data.frame(yi = rnorm(30,rep(c(12,14,18),each=10),2), g = rep(1:3,each=10)) \n\nplot(yi~g, data=y, pch=16, xaxt='n', xlim=c(0.25,3.75), ylab=expression(y[ik]), xlab=\"\", cex=.8, yaxt='n')\naxis(1, at=c(1,2,3), labels=paste(\"Group\",1:3))\n\nmu &lt;- mean(c(12,14,18))\nmyi &lt;- mean(y$yi)\nmai &lt;- mean(yi ~ g, data=y)\nai &lt;- c(12,14,18)\nyval &lt;- seq(7,23, length.out=100)\n\ndy1 &lt;- dnorm(yval, 12, 2)\ndy2 &lt;- dnorm(yval, 14, 2)\ndy3 &lt;- dnorm(yval, 18, 2)\nlines(dy1+1, yval, col='darkgray')\nlines(rep(1,100), yval, col='darkgray')\n\nlines(dy2+2, yval, col='darkgray')\nlines(rep(2,100), yval, col='darkgray')\n\nlines(dy3+3, yval, col='darkgray')\nlines(rep(3,100), yval, col='darkgray')\n\n#lines(c(.75,3.5), rep(mu, 2), lty=2)\n#text(.65,mu, expression(mu))\n\n#lines(rep(1+.21,2), c(ai[1],mu), lty=2, col='firebrick')\nlines(c(1-.2,1+.21), rep(ai[1],2), lty=2)\ntext(1-.4,ai[1], expression(mu[1]))\n#text(1+.21, (ai[1]+mu)/2, expression(alpha[1]), pos=4, cex=0.8)\n\n#lines(rep(2+.21,2), c(ai[2],mu), lty=2, col='firebrick')\nlines(c(2-.2,2+.21), rep(ai[2],2), lty=2)\ntext(2-.4,ai[2], expression(mu[2]))\n#text(2+.21, (ai[2]+mu)/2, expression(alpha[2]), pos=4, cex=0.8)\n\n#lines(rep(3+.21,2), c(ai[3],mu), lty=2, col='firebrick')\nlines(c(3-.2,3+.21), rep(ai[3],2), lty=2)\ntext(3-.4,ai[3], expression(mu[3]))\n#text(3+.21, (ai[3]+mu)/2, expression(alpha[3]), pos=4, cex=0.8)\n\nlines(rep(3-.1,2), c(ai[3],y$yi[25]), lty=2, col='firebrick')\nlines(c(3-.2,3), rep(y$yi[25],2), lty=2)\n#text(3-.21,y$yi[25], expression(y[3][\",\"][5] == mu[3]+epsilon[3][\",\"][5]), pos=2, cex=0.8)\ntext(3-.1, (y$yi[25]+ai[3])/2, expression(epsilon[3][\",\"][5]), pos=2, cex=0.8)\n\n\n\n\n\nFigure 1: Same distribution can be used to describe the residuals from each factor level"
  },
  {
    "objectID": "assumptions.html#introduction",
    "href": "assumptions.html#introduction",
    "title": "ANOVA Assumptions",
    "section": "",
    "text": "For our ANOVA F test results and model predictions to be trusted, certain assumptions, or requirements must be met.1\n\n\nThe terms “requirements” and “assumptions” are often used interchangeably when referring to the set of conditions that must be met for the model to be a valid representation of the data.\nBy way of review, here is the mathematical expression of the model for 1 structural factor. If we incorporated more factors into our study we would need to add additional terms to the model to represent that factor’s effects, as well as any interaction effects.\n\\[\ny_\\text{ij} = \\mu + \\alpha_i + \\epsilon_\\text{ij}\n\\tag{1}\\]\nWhere\n\n\\(y_\\text{ij}\\) is an observation\n\\(\\mu\\) is the grand mean\n\\(\\alpha_i\\) represents the effect of factor level \\(i\\)\n\\(\\epsilon_\\text{ij}\\) is the residual error for the \\(j^\\text{th}\\) observation in factor level \\(i\\)\n\n\\(\\epsilon_\\text{ij}\\) is a random variable and most of the assumptions are focused on defining the distribution of this random variable. Namely, we assume that each residual comes from the same normal distribution, with mean 0 and standard deviation \\(\\sigma\\). Figure 1 illustrates the same residual distribution visually applied to three distinct factor levels. The assumptions and how to check them are explained in more detail below.\n\n\nCode\nset.seed(15)\ny &lt;- data.frame(yi = rnorm(30,rep(c(12,14,18),each=10),2), g = rep(1:3,each=10)) \n\nplot(yi~g, data=y, pch=16, xaxt='n', xlim=c(0.25,3.75), ylab=expression(y[ik]), xlab=\"\", cex=.8, yaxt='n')\naxis(1, at=c(1,2,3), labels=paste(\"Group\",1:3))\n\nmu &lt;- mean(c(12,14,18))\nmyi &lt;- mean(y$yi)\nmai &lt;- mean(yi ~ g, data=y)\nai &lt;- c(12,14,18)\nyval &lt;- seq(7,23, length.out=100)\n\ndy1 &lt;- dnorm(yval, 12, 2)\ndy2 &lt;- dnorm(yval, 14, 2)\ndy3 &lt;- dnorm(yval, 18, 2)\nlines(dy1+1, yval, col='darkgray')\nlines(rep(1,100), yval, col='darkgray')\n\nlines(dy2+2, yval, col='darkgray')\nlines(rep(2,100), yval, col='darkgray')\n\nlines(dy3+3, yval, col='darkgray')\nlines(rep(3,100), yval, col='darkgray')\n\n#lines(c(.75,3.5), rep(mu, 2), lty=2)\n#text(.65,mu, expression(mu))\n\n#lines(rep(1+.21,2), c(ai[1],mu), lty=2, col='firebrick')\nlines(c(1-.2,1+.21), rep(ai[1],2), lty=2)\ntext(1-.4,ai[1], expression(mu[1]))\n#text(1+.21, (ai[1]+mu)/2, expression(alpha[1]), pos=4, cex=0.8)\n\n#lines(rep(2+.21,2), c(ai[2],mu), lty=2, col='firebrick')\nlines(c(2-.2,2+.21), rep(ai[2],2), lty=2)\ntext(2-.4,ai[2], expression(mu[2]))\n#text(2+.21, (ai[2]+mu)/2, expression(alpha[2]), pos=4, cex=0.8)\n\n#lines(rep(3+.21,2), c(ai[3],mu), lty=2, col='firebrick')\nlines(c(3-.2,3+.21), rep(ai[3],2), lty=2)\ntext(3-.4,ai[3], expression(mu[3]))\n#text(3+.21, (ai[3]+mu)/2, expression(alpha[3]), pos=4, cex=0.8)\n\nlines(rep(3-.1,2), c(ai[3],y$yi[25]), lty=2, col='firebrick')\nlines(c(3-.2,3), rep(y$yi[25],2), lty=2)\n#text(3-.21,y$yi[25], expression(y[3][\",\"][5] == mu[3]+epsilon[3][\",\"][5]), pos=2, cex=0.8)\ntext(3-.1, (y$yi[25]+ai[3])/2, expression(epsilon[3][\",\"][5]), pos=2, cex=0.8)\n\n\n\n\n\nFigure 1: Same distribution can be used to describe the residuals from each factor level"
  },
  {
    "objectID": "assumptions.html#center",
    "href": "assumptions.html#center",
    "title": "ANOVA Assumptions",
    "section": "Center",
    "text": "Center\nThe model assumes the mean of the residuals equals zero. The residual is the distance from an observation to its respective factor level mean, or predicted value. This assumption is the reason calculating a mean of observations makes sense as an estimate of the true mean of a factor level. Each observation is made up of two parts: a true part and some random error. If we have 3 observations all from the first factor level (the first subscript is always one because the observations all come from the first factor level):\n\n\\(y_{11} = \\text{true factor level mean} + \\text{error}_{11}\\)\n\\(y_{12} = \\text{true factor level mean} + \\text{error}_{12}\\)\n\\(y_{13} = \\text{true factor level mean} + \\text{error}_{13}\\)\n\nWe estimate the true mean of the factor level by taking the mean of the 3 values:\n\\[\n\\text{Mean of observations} = \\frac{y_{11} + y_{12} + y_{13}}{3} = \\frac{\\text{truth} + \\text{error}_{11} + \\text{truth} + \\text{error}_{12} + \\text{truth} + \\text{error}_{13}}{3}\n\\]\nRearranging terms gets:\n\\[\n\\text{Mean of observations} = \\text{truth} + \\frac{\\text{error}_{11} + \\text{error}_{12} + \\text{error}_{13}}{3}\n\\]\nSince the mean of the residual errors is assumed zero, the second term goes to zero and the mean of observations is the best estimate of the true value. Of course, the more observations we average over the better our estimate of the truth will be.\nThis requirement does not need to be checked since we are guaranteed this will occur based on how we calculate factor level effects. This is evident with the level effects for a factor summing to zero."
  },
  {
    "objectID": "assumptions.html#constant-variance",
    "href": "assumptions.html#constant-variance",
    "title": "ANOVA Assumptions",
    "section": "Constant Variance",
    "text": "Constant Variance\nThe spread of the distribution of residuals is expressed in terms of the variance, \\(\\sigma^2\\). Hypothesis tests of the factors assume that the variance of residuals will be the same regardless of the factor level. Consider the conveyor belt analogy. All the observations go down the same conveyor belt. The conveyor belt does not split into multiple branches just before the last, random station. All the residuals come from the same distribution.\nIn the F-statistic calculation the denominator is a pooled variance; or in other words, an average of the within factor level variances. When factor level sample sizes are unequal, then the average variance is biased toward the factor level with the largest sample size. Thus, it becomes important to show that the variance estimate within each factor level is (relatively) equal when sample sizes are not equal. The greater disparity in sample sizes, the more important it is to have similar within factor levels variances. (Inflation of Type I error tends to be worse if the smallest group has the largest variance.) The F-distribution used to calculate p-values is based on the assumption of equal variances. When there is non-constant variance, the ratio of between group variance to within group variance no longer follows the F-distribution and the p-value calculations will be off.\n\n\nType I error mean rejecting a true \\(H_o\\)\nThe simplest, quickest, and most common way to check this assumption is a visual assessment of a residual plot. A residual plot shows the residuals on the y-axis and the predicted values on the x-axis. (In the case of just one structural factor, the factor levels are sometimes shown on the x-axis instead). The assumption is satisfied when the vertical spread of the data points within each factor level is roughly the same. This is called homogeneity of variance or homoscedasticity. When the spread is not the same it is called heterogeneity of variance, or heteroscedasticity.\nFigure 2 shows the residual plot in our toothbrush example where the effectiveness of 4 different types of toothbrush were studied.\n\n\nCode\nbf2 &lt;- read_csv(\"data/toothpaste_BF2.csv\")\nbrush_aov &lt;- aov(Plaque~Brush, data = bf2)\nwhich = plot(brush_aov, which = 1)\n\n\n\n\n\nFigure 2: Residual vs. Fitted plot to check constant variance assumption\n\n\n\n\n\n\n\n\n\n\nRed Line in the Residual Plot\n\n\n\nIgnore the red line in the residual plot. It can trick your eyes and draw your attention to the wrong thing. It is not meant to gauge constant variance.\nWith a little extra coding you can get a residual plot without the red line. Additional code is required to clean up the labeling.\n\n\nCode\nbf2 &lt;- read_csv(\"data/toothpaste_BF2.csv\")\nbrush_aov &lt;- aov(Plaque~Brush, data = bf2)\nplot(brush_aov$fitted.values, brush_aov$residuals)\n\n\n\n\n\nFigure 3: Residual vs. Fitted plot without a red line\n\n\n\n\n\n\nThe points in Figure 2 are in 4 vertical groupings corresponding to the factor levels of toothbrush. This is to be expected because the x-axis shows predicted, a.k.a. fitted, values. Each toothbrush has a different predicted plaque value. The group of points on the far left appears less vertically spread out than the group of points on the far right.\nOf course, the factor levels will never all have exactly equal variance. How different does the spread in this plot need to be to conclude that the assumption is met or is violated? It is subjective and experience will help you spot trouble in the plot. You can also employ additional methods to help detect non-constant variance.\n\nRules of Thumb for One-way ANOVA\nAs a rule of thumb, in one-way ANOVA (i.e. just one independent factor) you can check to see if the largest standard deviation is more than double the smallest standard deviation. Table 1 shows summary statistics for the toothbrush example. The smallest standard deviation of 1.7 belongs to the oscillating brush. The largest standard deviation of 3.9 belongs to the ultrasonic brush. Because \\(2*1.74 = 3.48 &lt; 3.90\\), by this rule of thumb the constant variance assumption appears to be violated.\nThe rule of thumb is too stringent, and therefore not recommended, for anything but a one-way ANOVA.\n\n\nCode\nfavstats(Plaque~Brush, data = bf2) |&gt; kable(digits = 2)\n\n\n\n\nTable 1: Summary statistics for each toothbrush\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBrush\nmin\nQ1\nmedian\nQ3\nmax\nmean\nsd\nn\nmissing\n\n\n\n\nManual\n19.12\n22.04\n23.38\n24.01\n26.88\n23.09\n2.60\n6\n0\n\n\nOscillating\n17.62\n18.89\n19.94\n21.29\n22.09\n19.98\n1.74\n6\n0\n\n\nSonic\n18.99\n21.73\n23.20\n23.68\n25.58\n22.67\n2.27\n6\n0\n\n\nUltrasonic\n21.45\n23.62\n24.30\n25.35\n32.74\n25.31\n3.90\n6\n0\n\n\n\n\n\n\n\n\nLevene’s Test\nThere are formal hypothesis tests that can help determine if variance is equal across factor levels. One such test is the Brown-Forsythe test, also known as Modified Levene’s test or sometimes shortened to Levene’s test.2 The hypothesis for this test is\n\\[\nH_0: \\sigma_1 = \\sigma_2 = … = \\sigma_i \\\\\n\\]\n\\[\nH_a: \\text{At least one sigma is different from the rest}\n\\]\nThe test essentially runs an ANOVA F-test on the factor level variances to determine if the variances are equal. If the p-value of the test is low and the null is rejected, then you would consider the assumption violated. As the researcher, you are hoping to fail to reject the null hypothesis so that you may continue on with your analysis.\nUse the following code from the car package to run Levene’s test in R.\n\nleveneTest(model_name)\n\nWhere leveneTest is the name of the function that will run the test, and model_name is the name you assigned the model created with the aov() function.\nLevene’s test requires a full model. All factor levels and interactions need to be present in the model. Levene’s test also requires at least 2 observations in each factor level combination since it needs to calculate a variance. For this reason, Levene’s test cannot be used on some designs, like complete block or latin squares, without some adjustments.\n\n\n\n\n\n\nDon’t Forget to Think\n\n\n\nIt is tempting to turn off your brain and simply run the test or use a rule without looking at the data or thinking of the impact. Do NOT do this. In fact, you can often get by without running this test at all. It is better to consider the sample sizes, outliers, general shapes of the distributions, and effect sizes relative to variance within each factor level. Think about how different the groups of residuals really are rather than blindly trusting a rule.\n\n\n\n\nCode\nleveneTest(brush_aov) |&gt; kable()\n\n\n\n\nTable 2: Levene’s test output for the toothbrush example\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\n\ngroup\n3\n0.2498376\n0.8604884\n\n\n\n20\nNA\nNA\n\n\n\n\n\n\nFor the toothbrush example, the p-value of Levene’s F-test in Table 2 is .8605, indicating the null hypothesis of constant variance cannot be rejected. (It is not uncommon for this hypothesis test to disagree with the rule of thumb.) It appears that one outlier in the upper right portion of Figure 2 is the main reason the rule of thumb approach indicated the assumption had been violated. If that point is ignored, the groups do look more alike and the rule of thumb agrees with the Levene’s test.\nThis is not to suggest the point be removed from the analysis; rather, to recognize the impact an outlier can have on the assumptions. This is especially true when the methods of checking the assumption don’t agree.\n\nMore than 1 structural factor\nConsider the slightly more complicated example where researchers investigated toothpaste brand (name brand vs. off brand), toothbrush type, and their interaction.\nIn this case, the residual vs. fitted plot has 8 different vertical groupings - one for each factor level combination of brush and paste. Look for overall trends or megaphone shapes in the residual plot as indicators that the assumption of constant error variance may be violated. For example, does the spread of the residuals increase as the fitted value increases? Or, does the spread of the residuals decrease as the fitted value decreases?\n\n\nCode\nbrush_aov2 &lt;- aov(Plaque~Brush*Toothpaste, data = bf2)\nwhich = plot(brush_aov2, which = 1)\n\n\n\n\n\nFigure 4: Residual vs. Fitted plot to check constant variance assumption for the 2-factor example\n\n\n\n\nFigure 4 shows a slight megaphone shape. As we move from left to right along the x-axis the spread of the points increases (with the exception of the points at x=24.5). We can use a Levene’s test to help us determine if heterogeneity of variance is a problem. The result is shown in Table 3.\n\n\nCode\nleveneTest(brush_aov2) |&gt; kable()\n\n\n\n\nTable 3: Levene’s test output for the 2-factor example\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\n\ngroup\n7\n0.8834329\n0.5409189\n\n\n\n16\nNA\nNA\n\n\n\n\n\n\nWith a p-value of .541 we fail to reject the null hypothesis. It appears the constant variance assumption is met."
  },
  {
    "objectID": "assumptions.html#shape-normal-residual-distribution",
    "href": "assumptions.html#shape-normal-residual-distribution",
    "title": "ANOVA Assumptions",
    "section": "Shape: normal residual distribution",
    "text": "Shape: normal residual distribution\nThe ANOVA model assumes that residuals will follow a (approximately) normal distribution. To check this assumption we use a Q-Q plot.\n\n\nThere are statistical tests for normality as well, but each come with their own set of drawbacks. Due to the robust nature of the F test, a visual assessment is usually sufficient.\nThe “Q” in Q-Q plot stands for quantile. For an explanation of quantiles and their relationship to percentiles go here. There are many variations of Q-Q plots and each software computes it slightly differently. The general concept is to plot two quantities on a scatter plot:\n\nResidual from the model3\nThe value from the standard normal distribution (i.e. Z distribution) associated with the sample quantile.\n\nClick to show/hide detailed explanation of Q-Q plot construction\n\n\nThe Q-Q plot is actually just a scatterplot created from ordered pairs. Each ordered pair consists of a residual from the model (that’s easy to find!) and the quantile from the normal distribution associated with that residual.\nBut how do you find a quantile from the normal distribution? To get this, each residual is converted into a sample quantile, then the theoretical Z score from the normal distribution associated with that quantile is calculated. For example, if I had 20 residuals I would calculate the 1/20 quantile (a.k.a. fifth percentile) from the z-distribution. From Figure 5 (a) I can see the 5th percentile of the Z distribution is -1.645. My first ordered pair on the scatterplot would be the smallest residual and the value -1.645.\n\n\nCode\nxqnorm(.05, return = \"plot\")\n\nxqnorm(.10, return = \"plot\")\n\n\n\n\n\n\n\n\n(a) 5th percentile\n\n\n\n\n\n\n\n(b) 10th percentile\n\n\n\n\nFigure 5: Z-score calculations from desired percentile\n\n\n\nThe next point on the Q-Q plot would be my second smallest residual on the y-axis and the \\(2/20 = .10\\) quantile from the Z distribution on the x-axis. The 0.10 quantile is -1.282 as seen in Figure 5 (b).\nThis process would be repeated for all 20 residuals.\n\n\nIf the sample data is normally distributed then the resulting plot of the two quantities will roughly be a straight line. The residuals will never be exactly normal, of course. Some amount of “wiggle” should be allowed.\nFigure 6 is a Q-Q plot for the toothbrush example.\n\n\nCode\nplot(brush_aov, which = 2)\n\n\n\n\n\nFigure 6: Q-Q plot of residuals for tootbrush 1-factor ANOVA example\n\n\n\n\nIt can be difficult to tell if the line is straight enough. qqPlot from the car package (see Figure 7) adds boundary lines to help you determine if the points are out of bounds4. If sections of the plot are out of bounds the assumption of normally distributed residuals can be considered violated.\n\n\nCode\n#The envelope argument controls whether the region between the lines is shaded or not\ncar::qqPlot(brush_aov, envelope = list(style = \"lines\"), id = FALSE)\n\n\n\n\n\nFigure 7: Boundaries added to Q-Q plot of residuals for tootbrush 1-factor ANOVA example\n\n\n\n\nA point on the far right is clearly out of the dashed boundary. It is not uncommon for 1 or 2 points at either end of the x-axis to stray far from the line. Overall, however, the points in this plot tend to follow the line and stay in bounds. We can conclude that the assumption of normally distributed residuals is met.\n\n\n\n\n\n\nNotation\n\n\n\nSo far we have shown the residuals come from a normal distribution, with mean zero and a standard deviation (sigma). This is expressed mathematically as \\(\\epsilon\\) ~ N( 0, \\(\\sigma\\) ).\n\nThe epsilon, \\(\\epsilon\\), refers to the residuals.\nThe ‘N(0, \\(\\sigma\\))’ stands for normal distribution with a mean of zero and a standard deviation of sigma.\nThe tilde, ~, means the residuals come from that distribution."
  },
  {
    "objectID": "assumptions.html#independent-observations",
    "href": "assumptions.html#independent-observations",
    "title": "ANOVA Assumptions",
    "section": "Independent observations",
    "text": "Independent observations\nIn addition to making assumptions about the distribution of residuals, we also make an assumption regarding individual observations, or realizations, from the distribution of errors. Specifically, we assume each observation from the error distribution is independent of the rest. In other words, the residuals are not correlated with each other in any way.\nThis is violated when something is affecting the response that was not adequately randomized, controlled for, or included in the model. Not adequately accounting for treatment order in time or space is often a culprit. For example, suppose you run an experiment where respondents were given a task to complete under 3 distinct conditions. If you did not randomize the order of the conditions or neglected to account for the fact the same respondent provided 3 observations, you would have violated this assumption.\nSometimes looking at the data can provide a clue this requirement is violated, sometimes it cannot. Looking at the Residual vs. Fitted plot is a good place to start. For example, when a model over predicts all observations in condition 1 and under predicted all observations in condition 3 it may be an indicator that you neglected to address something important (i.e. subject identification, or order of conditions) in your experiment.\nAn order plot can also be useful in detecting a violation of this assumption. The order plot shows each residual on the y-axis and the chronological order in which the observation was made/collected along the x-axis. Figure 8 contains the order plot for our simple toothbrush example, assuming the row number indicates the order in which each observation was actually made.\n\n\nCode\nplot(brush_aov$residuals)\n\n\n\n\n\nFigure 8: Order plot for 1-factor toothbrush example\n\n\n\n\nIt is interesting to see in this plot that the very first observation is a bit of an outlier. Perhaps the technology wasn’t working right or the assistant had not yet learned the correct procedure for measuring percent area with plaque. As the researcher, this is something you would want to dig deeper into. An equally plausible explanation for the outlying value is that the person really did have more plaque. Throwing out the datapoint simply because it doesn’t meet your expectations or messes up your analysis is not good research.\n\n\n\n\n\n\nCaution\n\n\n\nYou should not throw out data points based alone on the fact that they appear anomalous.\n\n\nNo other trends are evident in Figure 8. If patterns/trends are evident, you may have violated the assumption of independent observations. Perhaps a tool lost calibration over time, or subjects/researchers experienced fatigue. Whatever the cause, you will want to investigate, fix the issue, and potentially redo the experiment. It really comes down to your ability/inability to defend the validity of your study in the minds of your audience. Bias in your design or execution will lead to violating this assumption.\nIn many cases, the data will not indicate there is bias unless you know exactly what to look for. These unknown sources of bias are particularly difficult to detect. Planning the study in great detail, thinking critically about your results, being familiar with the protocols of the experiment, and getting help from others to provide fresh perspectives is ultimately the best way to check this assumption and ensure bias does not affect your results."
  },
  {
    "objectID": "assumptions.html#assumptions-summary",
    "href": "assumptions.html#assumptions-summary",
    "title": "ANOVA Assumptions",
    "section": "Assumptions Summary",
    "text": "Assumptions Summary\n\n\n\n\n\n\n\nResidual Assumption\nMethod for Checking\n\n\n\n\nMean is zero\nDoesn’t need to be checked. This will be a direct result of how we create the model.\n\n\nConstant variance across factor levels\n\nResidual vs. fitted plot\nLevene’s Test (for some designs / analyses)\nRule of thumb comparing standard deviations (for BF[1] only)\n\n\n\nNormally distributed residuals\nNormal Q-Q plot\n\n\nIndependent of each other\n\nCritical thinking\nOrder plot"
  },
  {
    "objectID": "assumptions.html#what-to-do-if-assumptions-are-violated",
    "href": "assumptions.html#what-to-do-if-assumptions-are-violated",
    "title": "ANOVA Assumptions",
    "section": "What To Do If Assumptions Are Violated?",
    "text": "What To Do If Assumptions Are Violated?\n\nPrinciples For How To Proceed\nYou now have some tools to help assess whether the ANOVA assumptions have been met. It is extremely common in practice to be faced with data that is in the “gray area”, and making this determination is not always easy. There are a couple of principles to keep in mind as you decide whether to proceed with the analysis or try to address potential assumption violations.\nFirst, your p-value and test statistic values will be wrong proportional to the degree your assumptions are violated. For example, a minor violation of the homogeneity of variance assumption slightly degrades the accuracy, or truthfulness, of your F statistic. If the F statistic is quite extreme, then being off a little bit will not change the conclusions of your study.\nIn fact, ANOVA is robust to minor/moderate violations of the assumptions. This is the second principle to keep in mind. This means that you can still obtain reasonably trustworthy results even when there are minor or moderate violations of the assumptions. If the sample size is large and balanced, ANOVA tends to be more robust (especially with regard to the normal distribution of errors assumption). The case where skew is present and data is unbalanced is another story, and becomes particularly problematic if you plan to do one-tailed t-tests of contrasts.\nANOVA’s robustness to the mathematical assumptions does not minimize the adverse impacts of bias in a study.\nThird, take into account the purpose and context of the study in the broader context. If violated assumptions can be easily fixed with a few extra lines of code, there is no reason you should not try to improve the situation. As the remedy becomes more difficult/requires more effort, the cost-benefit analysis of trying something else changes. Think about deadlines, project cost, degree of assumption violation, desired precision, and severity of consequences if a wrong conclusion is reached as you decide how to pursue solutions to violated assumptions.\n\n\nLack of time due to procrastination is not a good reason to violate assumptions.\nRather than simply stating if the assumption is met or not met, it is wise to consider the pros and cons of proceeding with the analysis and then document and explain your decision. Consider sample sizes, effect sizes, outliers, and the degree to which assumptions are met when interpreting your results. ANOVA is just one family of models, there are alternative ways to approach a problem. If the ANOVA model does not seem like a good fit, do not be afraid to ask for help or learn a new technique.\n\n\nRemedial Measures\nThe strategy to address violated assumptions depends on how and which assumptions were violated. But beware, none of the suggested measures below can correct bias in sampling or random assignment.\nIf an outlier or two are the source of trouble, investigate the outlier to ensure it is valid, belongs in the study, and does not represent an error in some way.\nTo address non-normality of residuals you will want to know what the distribution of residuals looks like. If a histogram of residuals reveals a multi-modal distribution, that is often an indicator that there are additional populations (i.e. subgroups) that your model did not take into account. Try to identify what variable is causing the multiple modes (e.g. gender) and include it in your model.\nTransforming the data is a technique that can help with the normal distribution assumption and with heteroscedasticity (lack of constant variance) simultaneously. The transformation is applied to the response variable and then the ANOVA analysis is run as usual with the new, transformed variable as the response. Though the analysis is performed using the transformed variable, you can interpret the results in terms of the original units of the response variable. Groups that differ on the transformed response tend to differ on the untransformed response variable as well.\nKnowing what transformation to apply to the response variable can be a challenge. A square root, log transformation, or taking the reciprocal of the response variable are common transformations to use, especially if the response variable represents a count during a defined interval or a time until something occurs. If the response is a proportion (e.g. proportion of quiz questions answered correctly), this transformation may prove useful: \\(Y_\\text{transformed} = log(\\frac{y}{1-y})\\). If you have the data used to calculate the proportion, each “failure or”success” as it were, a logistic regression may be a more powerful tool than an ANOVA on the summarized percent.5\nThe Box-Cox is a more algorithmic way of choosing a transformation.\nIt is important to recognize that ANOVA is just one of many analysis tools available6. Kruskal-Wallis is an example of an alternative test with less stringent assumptions that can be used when there is just one structural factor present. Unfortunately, many of these alternative tests, like Kruska-Wallis, cannot be extended to more complex designs.\nOne other approach is to emphasize the tests of contrasts and comparisons rather than omnibus F-tests. These more specific tests can handle non-constant variances and non-normal residuals, but at the expense of increased complexity or forfeiting a broader perspective/test. In fact, many researchers skip the omnibus ANOVA F-test and will go directly to testing the specific comparisons that motivated the experiment in the first place."
  },
  {
    "objectID": "assumptions.html#footnotes",
    "href": "assumptions.html#footnotes",
    "title": "ANOVA Assumptions",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nMuch of this material is summarized nicely by Keppel, G & Wickens, T (2004). Design and Analysis: A Researcher’s Handbook, Fourth Edition. New Jersey: Pearson/Prentice Hall.↩︎\nLevene’s original 1960 paper proposed using the mean of factor levels in calculation of his test statistic. Brown and Forsythe (1974) investigated using the median or trimmed mean. Overtime, most statisticians have converged on using the median in the test statistic calculation if the shape of the distribution of errors is not known beforehand. This is the default in R’s car package for the Levene test. Going forward, references to Levene’s test actually refer to the Brown-Forsythe test (a.k.a Modified Levene’s Test).↩︎\nThe name “Q-Q plot” (with 2 q’s) comes from the fact you can plot the sample quantile of the residuals instead of plotting the residual itself: sample quantiles on the y-axis and theoretical quantiles on the x-axis. The plots we will be creating in R put the residual on the y-axis. This is simpler to interpret and to calculate because it removes the need to store the sample quantile values.↩︎\nqqPlot also does a few other calculations differently, most notably it uses studentized residuals instead of standardized residuals.↩︎\nSee Warton, David I., and Francis K. C. Hui. “The arcsine is asinine: the analysis of proportions in ecology.” Ecology: Ecological Society of America, vol. 92, no. 1, 2011, pp. 3-10, https://doi.org/10.1890/10-0340.1↩︎\nFor additional alternatives consult Coombs, W. A., Algina, J., & Oltman, D. O. (1996). Univariate and multivariate omnibus hypothesis tests selected to control type I error rates when population variances are not necessarily equal. Review of Educational Research, 66, 137-179. A generalized linear model may also be helpful.↩︎"
  },
  {
    "objectID": "BasicFactorial_quarto.html#overview",
    "href": "BasicFactorial_quarto.html#overview",
    "title": "Basic Factorial",
    "section": "Overview",
    "text": "Overview\nIn a basic one-way factorial design (BF[1]), only one factor is purposefully varied. Each experimental unit is assigned to exactly one factor level. (In the case of an observational study, only one independent factor is under consideration.)\n\nFactor Structure\nThe factor structure for the model resulting from a completely randomized, one factor design is:\n\n\n\n\nFigure 1: Example of BF1 Factor Structure\n\n\n\nFigure 1 illustrates a factor with 4 levels, 6 replications at each level.\n\n\nHypothesis and Model\nA more detailed description of the model for an ANOVA with just one factor:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\n\\(y_{ij}\\): the \\(j^{th}\\) observation from factor level \\(i\\)\n\\(\\mu\\): the grand mean of the data set.\n\\(\\alpha_i\\): effect of factor level \\(i\\)\n\\(\\epsilon_{ij}\\): the error term, or residual term of the model. There are j replicates for each treatment. It represents the distance from an observation to its factor level mean (or predicted value).\nThe null and alternative hypotheses can be expressed as:\n\\[\nH_o: \\alpha_1 = \\alpha_2 = ... = 0\n\\]\n\\[\nH_a: \\alpha_i \\neq 0 \\quad \\text{for at least one }\\ \\alpha_i\n\\]\n\n\nAssumptions\nA one-way ANOVA model may be used to analyze data from a BF[1] design if the following requirements are satisfied:\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nRule of thumb comparing standard deviations\n\\(max(s) &lt; 2*min(s)\\)\n\n\n\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "BasicFactorial_quarto.html#design",
    "href": "BasicFactorial_quarto.html#design",
    "title": "Basic Factorial",
    "section": "Design",
    "text": "Design\nIn a one factor design, one factor is purposely varied and all other factors are controlled in order to isolate the effect of just the factor under study. Each level of the factor is considered a treatment.\nIn a completely randomized design, each experimental unit is randomly assigned to exactly 1 treatment. In this example we expect a balanced design (i.e. each factor level has the same number of observations). This can be done by listing all the subjects, then listing the treatments, as seen below:\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n1\n\n\nSubject 2\nA\n2\n\n\nSubject 3\nB\n3\n\n\nSubject 4\nB\n4\n\n\nSubject 5\nC\n5\n\n\nSubject 6\nC\n6\n\n\n\nThen you randomly shuffle the treatment column. (You should also be paying attention to the order in which subjects and treatments are being experimented on as this could be a potential source of bias. In a BF[1], you randomize the order also.) The result might look something like this.\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n4\n\n\nSubject 2\nB\n3\n\n\nSubject 3\nC\n6\n\n\nSubject 4\nC\n5\n\n\nSubject 5\nA\n1\n\n\nSubject 6\nB\n2\n\n\n\nYou may notice in the above example that, even with randomization, treatment C occurs in the last 2 observations. If we were truly concerned about the order we could be more strategic and implement a blocked design to prevent “unlucky” ordering and pairing.\n\nLifeboat Training Example\nConsider the following example. An experiment was done to assess different modes of virtual training in how to launch a lifeboat. Sixteen students in the maritime safety training institute were a part of the study, and each of the students were assigned one of four possible virtual training experiences. The four experiences included:\n\nLecture/Materials (Control)\nMonitor/Keyboard\nHead Monitor Display/Joypad, and\nHead Monitor Display/Wearables.\n\nThe response variable was the student’s performance on a procedural knowledge assessment (performance is defined as their level of improvement from pre to post test). There is just one controlled factor, training method, which has 4 levels: the four training methods. An experimental unit in this study is each of the individuals being trained, 16 in all.\nWe want to assign each treatment to four students. We could get 16 pieces of paper and write “Treatment 1” on 4 pieces, “Treatment 2” on another 4 pieces, and so on until each treatment has 4 pieces of paper. We could then put them in a hat, mix them up and then randomly draw out a piece of paper to assign it to a subject. Intuitively this makes sense, but writing and cutting paper is slow and inefficient. We could implement a similar process in R to assign treatments.\nFirst, we list all the possible treatments, and repeat that listing until it is the same size as our count of subjects. (Note, if your number of subjects is not an exact multiple of the number of treatments, you may need to decide which treatments deserve fewer observations)\n\n\nCode\n#Repeat the sequence of 1 to 4, four times\nTreatment &lt;- rep(1:4,4) \n\n#Create a sequence from 1 to 16\n#Paste the word \"Subject \" in front of each id #\nSubject &lt;- paste(\"Subject\", seq(1:16), sep = \" \")\n\n#Combine the vector of treatment numbers and Subject ID's into 1 tibble/data frame\nassignment_table &lt;- tibble(Subject, Treatment)\n\n#print the table, pander() makes it look nice\npander(assignment_table) \n\n\n\n\n\n\n\n\n\nSubject\nTreatment\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n2\n\n\nSubject 3\n3\n\n\nSubject 4\n4\n\n\nSubject 5\n1\n\n\nSubject 6\n2\n\n\nSubject 7\n3\n\n\nSubject 8\n4\n\n\nSubject 9\n1\n\n\nSubject 10\n2\n\n\nSubject 11\n3\n\n\nSubject 12\n4\n\n\nSubject 13\n1\n\n\nSubject 14\n2\n\n\nSubject 15\n3\n\n\nSubject 16\n4\n\n\n\n\n\nThen we randomly shuffle the Treatments column to get the following assignments. Check out the R-code to see how this is done.\n\n\nCode\n#set.seed() allows us to get the same random sample each time\nset.seed(42) \n\n#sample() will randomly select from the Treatment vector 16 times without replacement\n# %&gt;% is called a pipe. It simply takes the output from the command on the left\n# and sends it to the command on the right\ntibble(Subject, sample(Treatment, 16)) %&gt;% pander()\n\n\n\n\n\n\n\n\n\nSubject\nsample(Treatment, 16)\n\n\n\n\nSubject 1\n1\n\n\nSubject 2\n1\n\n\nSubject 3\n4\n\n\nSubject 4\n1\n\n\nSubject 5\n2\n\n\nSubject 6\n4\n\n\nSubject 7\n2\n\n\nSubject 8\n2\n\n\nSubject 9\n4\n\n\nSubject 10\n3\n\n\nSubject 11\n3\n\n\nSubject 12\n1\n\n\nSubject 13\n3\n\n\nSubject 14\n4\n\n\nSubject 15\n3\n\n\nSubject 16\n2\n\n\n\n\n\nWe can see here that subject 1 should get treatment 2. Subject 2 gets treatment 4, Subject 3 gets treatment 1, and so on."
  },
  {
    "objectID": "BasicFactorial_quarto.html#decomposition",
    "href": "BasicFactorial_quarto.html#decomposition",
    "title": "Basic Factorial",
    "section": "Decomposition",
    "text": "Decomposition\nThis section serves as a bridge between the design and the analysis of an experiment. It is equivalent to doing the analysis by hand. The primary goal is to see how the design decisions impact the analysis; including a deeper understanding of what the numbers in an ANOVA table mean and how they are calculated.\nThe factor structure diagram of an experimental design is an effective way to organize and plan for the type of data needed for an experiment. Recall that in our lifeboat example there were four levels of training method with six replicates for each (the actual study used 16 observations per treatment). The diagram below gives the factor structure of the design, and the accompanying mathematical model.\n\n\n\n\nExample of BF1 Factor Structure\n\n\n\nA basic one-way factorial design has three analysis factors: the grand mean, treatment, and residual. The effects of these factors can be summed together to find each observed value.\n\nThe observed values on the left show that there are 24 distinct observations of performance score, represented by the 24 cells - one for each of the observed values.\nThe grand mean factor represents the grand mean. The single large cell indicates that there is only one grand mean and it is part of every observation.\nThe treatment factor involves the four levels of the treatment represented by the four vertically long cells. Each treatment may have a distinct mean and effect.\nThe residual error represents the difference between the observed value and the predicted value. The predicted value, also called the fitted value, is the sum of the grand mean and treatment effect. Each of the cells represent a distinct value for the residual error.\n\n\nDegrees of Freedom\nWe can use our understanding of inside vs. outside factors to determine the degrees of freedom (df) for the grand mean, treatment, and residual errors factors. We start with 24 observations - or pieces of information. In other words, we have 24 degrees of freedom that need to be allocated to the 3 factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the lifeboat example, grand mean has one level (shown by the one cell in Figure 1) and there are no factors outside of grand mean. Therefore, its degrees of freedom equals one.\nRemember, the degrees of freedom represent the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as you estimate the grand mean for just one of the observations, you know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for the grand mean effect were also known. Therefore, there is just one unique piece of information in the grand mean factor. Grand mean has just 1 degree of freedom.\nFor treatment factor, there are four levels of the factor (shown by the four vertically long cells for treatment in Figure 1). Grand mean is the only factor outside of treatment. Take the number of levels for treatment factor (4 training methods) and subtract the degrees of freedom for grand mean (1), which yields 4-1 = 3 degrees of freedom for treatment.\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information the treatment effects really contain. Since all observations from the same treatment will have the same treatment effect applied, we only need to know 4 pieces of information: the effect of each treatment. But the answer is actually less than that. Because we know that the effects must all sum to zero, only 3 of the effects are free to vary and the 4th one is constrained to be whatever value will satisfy this mathematical condition. Thus, the degrees of freedom are 3. As soon as we know 3 of the treatment effects, we can fill in the treatment effects for all the observations.\nFor residual errors, there are 24 levels of the factor (as shown by the 24 cells for residual error on the far right of Figure 1). Both grand mean and treatment are outside of the residual errors factor. Take the number of levels for the residual error (24) and subtract the sum of the degrees of freedom for grand mean and treatment (3+1=4). The residual error has 24 - (3+1) = 20 degrees of freedom.\nThe approach of counting unique pieces of information can be applied here as well. In this case, we use the fact that the residual factor effects must sum to zero within each treatment. So within each treatment, 5 of the observations are free to vary, but the 6th will be determined by the fact that their sum must be zero. Five observations multiplied by 4 treatments is 20 observations, or in other words, 20 degrees of freedom.\n\n\nFactor Effects\nWe can use our understanding of inside vs. outside factors to estimate the effect size of the grand mean, treatment, and residual errors factors in the lifeboat training study. In other words, we can estimate the terms in the one-way ANOVA model.\n\n\n\n\n\n\nGeneral Rule for Effect Size\n\n\n\nEffect size = factor level mean - the sum of the effects of all outside factors\n\n\n\nCalculate means\nTo estimate all the factor effects we must first calculate the mean for the grand mean factor and the means for each level of training method.\nTo get the grand mean, average all 24 observations. The mean for all the observations is 6.5846. There is only one level for grand mean so this number is placed into each of the cells for the grand mean factor in Figure 2.\nFor the treatment factor, calculate the mean of each of the four levels. To calculate the mean for Control:\n\\[\n\\frac{4.5614 + 6.6593 + 5.6427 + 6.4394 + 4.8635 + 0.3268}{6} = 4.7489\n\\]\nYou can similarly find the mean for monitor keyboard is 7.8492, the mean for head monitor display/joypad is 6.5789, and the mean for head monitor display/wearables is 7.1616. In Figure 2 these means are placed in the respective training method column.\n\n\n\n\nFigure 2: Raw data and means for grand mean and training factors\n\n\n\n\n\nCalculate effects\nNow that we have calculated means for each level of each factor, we can move on to calculate the effects of the factor levels. We will use the general formula for calculating effect size.\nFor the grand mean, there is only one level and there are no outside factors. Therefore, the effect due to grand mean is 6.5846 (equivalent to its mean) and this affect is applied to all 24 observations.\nThe training method factor has four levels: one for each method. To calculate the effect of a training method, take the training method mean and subtract it from the effect due to the grand mean factor. For the “Control” method, this looks like:\n\\[\n4.789 - 6.5846 = -1.8358\n\\]\nBeing in the control group has the effect of reducing the student’s performance by 1.8358 on average compared to the grand mean. In a similar way you can find the effect for Monitor/Keyboard \\(7.8492 - 6.5846 = 1.2645\\). This means the student performance scores increased by 1.2645 on average in this training method compared to the grand mean. For Head Monitor Display/Joypad, the effect is \\(6.5789 - 6.5846 = -0.0058\\). For Head Monitor Display/Wearables the effect is \\(7.1616 - 6.5846 = 0.5770\\) (see below).\n\n\n\n\nFigure 3: Training Method Effects\n\n\n\nTo calculate the residual error effects remember that there are 24 levels of the residual error factor. Therefore, the factor level mean for a residual is simply the observed value itself. This means the residual effect can be calculated by taking an observed value and subtracting the effects for grand mean and the effect for whichever training method that particular observation received. For instance, for the observation located in the top left of our data set the value is 4.5614. Subtract the sum of the effects of outside factors (grand mean and training). This observation was from the control group so we get:\n\\[\n4.5614 - (6.5846 + -1.8358) = -0.1875\n\\]\nThe value for the top left cell in residual error effects is -0.1875. This means the observed value of 4.5614 was lower than we would have expected it to be. In other words, the performance score of 4.5614 was 0.1875 less than the mean of the control group. This individual’s performance was lower than the mean of his/her peers who received the same type of training.\nWe can repeat the residual calculation for the first observation in the second column. Take the observed value (5.4532) and subtract the sum of the effect due to grand mean and its respective training (in this case monitor/keyboard). The residual is\n\\[\n5.4523 - (6.5846 + 1.2645) = -2.3960\n\\]\nRepeat this process for all the remaining 22 residual values. The result is shown in Figure 4.\n\n\n\n\nFigure 4: Residual Effects\n\n\n\n\n\n\nCompleting the ANOVA table\nNow that we have calculated degrees of freedom and effects for each factor in a basic one-way factorial design, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. An ANOVA table essentially steps through the variance calculation that is needed to calculate the F statistics of an ANOVA test. In other words, a completed ANOVA summary table contains the information we need for a hypothesis test of a treatment factor.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n\n\n\n\n\n\nFactor\n3\n\n\n\n\n\n\nResidual Error\n20\n\n\n\n\n\n\nTotal\n24\n\n\n\n\n\n\n\n\n\n\n\nTo get the sum of squares (SS) for a factor, for each observation the effect for that factor first needs to be squared. Then all the squared values are summed up to get the sum of squares.\nFor grand mean, the effect of 6.5845 is listed 24 times, once for each observation. The value of 6.5845 will be squared. This squaring will be done 24 times and the squared values will then be added together to get the sum of squares due to grand mean.\n\\[\nSS_\\text{Grand Mean} = (6.5845)^2 + (6.5845)^2 + ... + (6.5845)^2 = 24*(6.5845)^2 = 1040.57\n\\]\n\nThe treatment factor has four different effects, one for each level of the factor. For each effect, the value is squared and then multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to treatment. For instance, for the control group, the effect is -1.8358. The value is then squared, and then multiplied by six due to the six observations within the control group. This is done for the other three levels as well and then the resulting values from the four levels are added.\n\\[\nSS_\\text{Factor} = 6*(-1.8358)^2 + 6*(1.2645)^2 + 6*(-0.0058)^2 + 6*(0.5770)^2 = 31.81\n\\] \nThe effect for the residual error factor has 24 unique values. Each of those residuals are squared and then the squared values are summed together.\n\\[\nSS_\\text{Residuals} = (-0.1875)^2 + (1.9105)^2 + (0.8939)^2 + (1.6906)^2 + ... + (-2.0157)^2 = 100.49\n\\] \nTo get the total sum of squares, we can either square all the observations and then add the squared values,\n\\[\nSS_\\text{Total} = (4.5614)^2 + (6.6593)^2 + (5.6427)^2 + (6.4394)^2 + ... + (5.1459)^2 = 1172.87\n\\]\n-OR- we can get the same result if we add together the sum of squares for the grand mean factor, treatment factor, and residual error factor.\n\\[\nSS_\\text{Total} = 1040.57 + 31.81 + 100.49 = 1172.87\n\\]\n \n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n1040.57\n\n\n\n\n\nFactor\n3\n31.81\n\n\n\n\n\nResidual Error\n20\n100.49\n\n\n\n\n\nTotal\n24\n1172.87\n\n\n\n\n\n\n\n\n\n\nWe can now calculate the mean squared error column, or mean square (MS), by dividing the sum of squares by the number of unique pieces of information that make up the factor. In this way we convert a total (the sum of squares) into an average; or in other words we change a sum into a mean. The mean squared error is the same as a variance. (The Root Mean Squared Error is equivalent to a standard deviation). The MS is calculated in this manner for each of the effects.\nThe purpose of the ANOVA table is to partition or break apart the variability in the dataset to its component pieces. This works when looking at SS, since it is the total variance due to each factor. MS is then the average variability for each effect. We can then see clearly which factor is a bigger source of variability by comparing their mean squares.\nThe mean square calculations are:\n\\[\nMS_\\text{Grand Mean} = \\frac{SS_\\text{Grand Mean}}{df_\\text{Grand Mean}} = \\frac{1040.57}{1} = 1040.57\n\\]\n\n\\[\nMS_\\text{Factor} = \\frac{SS_\\text{Factor}}{df_\\text{Factor}} = \\frac{31.81}{3} = 10.60\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{100.49}{20} = 5.02\n\\]\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n1040.57\n1040.57\n\n\n\n\nFactor\n3\n31.81\n10.60\n\n\n\n\nResidual Error\n20\n100.49\n5.02\n\n\n\n\nTotal\n24\n1172.87\n\n\n\n\n\n\n\n\n\n\nThe treatment factor is the primary factor of interest so the F test statistic is only calculated for that factor. To get the F test statistic for the treatment factor take the mean square (MS) due to treatment factor and divide by the mean square (MS) due to the residual error. Since the mean square error is equivalent to a variance, you can think of this as calculating the variance in treatment factor level means in the numerator and the variance of the distances for an observed value to its respective treatment factor level mean in the denominator. Simply put, it is the between groups variance divided by the within group variance.\n\\[\nF_\\text{Factor} = \\frac{MS_\\text{Factor}}{MS_\\text{Residual Error}} = \\frac{10.6}{5.02} = 2.11\n\\]\n\nTo complete the ANOVA, table, the p-value for the treatment factor is calculated based on the F statistic and the degrees of freedom for both treatment factor and residual error. In practice, statistical software computes all the components of the ANOVA table, including the p-value. To complete the decomposition of variance in a manual way, the p-value is calculated in R using the pf() function: 1 - pf(test statistic, df of Treatment, df of Residual error).\nIn this example, we get\n\n1 - pf(2.11, 3, 20)\n\n[1] 0.1310051\n\n\nThis p-value, 0.1310, is greater than a typical level of significance (0.05), so we would fail to reject the null hypothesis that all the effects due to the treatment factor are equal to zero. Meaning, we have insufficient evidence to say that any of the training methods had an impact on procedural knowledge test scores regarding launching a life boat.\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n1040.57\n1040.57\n\n\n\n\nFactor\n3\n31.81\n10.60\n2.11\n0.131\n\n\nResidual Error\n20\n100.49\n5.02\n\n\n\n\nTotal\n24\n1172.87"
  },
  {
    "objectID": "BasicFactorial_quarto.html#analysis-in-r",
    "href": "BasicFactorial_quarto.html#analysis-in-r",
    "title": "Basic Factorial",
    "section": "Analysis in R",
    "text": "Analysis in R\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots or scatterplots with the means displayed. Instructions for how to calculate numerical summaries and create these plots in R are found at R Instructions-&gt;Descriptive Summaries section of the book.\nYou then create the model using the aov() function. To see results of the F-test you can feed your model into a summary() function.\n\nmyaov &lt;- aov(Y ~ X, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is the user defined name in which the results of the aov() model are stored\nY is the name of a numeric variable in your dataset which represents the quantitative response variable.\nX is the name of a qualitative variable in your dataset. It should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\nYourDataSet is the name of your data set.\n\nExample Code\n\n\n df A name you come up with for your dataset  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv( a command from the tidyverse to read in csv files  “data/toothpaste_BF2.csv” The path to the csv file containing the data  ) Functions always end with a closing parenthesis  plaque_aovA name you come up with for your model  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  summary( Give important information about an object. When called on an aov object the default is to print the ANOVA table  plaque_aov  Whatever you named your ANOVA model in the previous line   )  Functions always end with a closing parenthesis  Click to view output Click to View Output. \n\n\n\n\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nWe then interpret the results. Toothbrush appears to be a significant factor. Since the p-value in this case is significant we may be able to look at the graphical summaries to understand which factor level effects are significant. We may also want to do some pairwise tests of the means or contrasts.\nNow that the model is created the assumptions need to be checked. Code and explanation for assumption checking can be found in the Model Diagnostics and Assumptions sections of the book respectively."
  },
  {
    "objectID": "BasicFactorial_quarto.html#resources",
    "href": "BasicFactorial_quarto.html#resources",
    "title": "Basic Factorial",
    "section": "Resources",
    "text": "Resources\n\nExamples\nLifeboat launch training\nMosquito\n\n\nLinks to outside resources\nPopulate this section yourself with links to good examples, definitions, other sections within this textbook, or anything else you think will be interesting/helpful."
  },
  {
    "objectID": "bf2.html",
    "href": "bf2.html",
    "title": "BF[2]",
    "section": "",
    "text": "When researchers want to study the effects of two factors on the same response variable a factorial design can be considered. Factorial experiments involve two or more factors that are crossed.\n\n\n\n\n\n\nTip\n\n\n\nFull factorial crossing occurs when each combination of factor levels is present in the study.\n\n\nCompare a factorial design with the one-at-a-time approach. In a one-at-a-time approach, each factor would be investigated in a separate experiment. Each experiment would evaluate the effect of just one factor on the response.\nFactorial designs are a way to simultaneously study the effects of multiple factors using just one experiment. Factorial designs have a couple of major advantages over one-factor-at-a-time studies.\n\nThey are a more efficient use of our time and material: I can get information about both of my factors from just one observation\nThey allow the random error to be allocated across a greater number of factors, thereby reducing unexplained variance (i.e. mean square error) and increasing the statistical power of the F-test.\nThey allow the estimation of interaction effects. Or in other words, we can observe how one factor’s effect on the response changes for different levels of the other factor.\n\nWe will expand on the simple toothpaste example to illustrate BF[2] concepts. The study is summarized here.\nResearchers wanted to know which of 4 types of toothbrushes was best at reducing plaque: manual (this is the traditional/usual type of brush), oscillating bristles, sonic, and ultrasonic. The response variable was the percent of teeth surface area covered with plaque. Four teeth (first molar in each quadrant of the mouth) were measured on each person to calculate the total percent area covered. Six subjects were assigned to each type of brush.\nResearchers also wanted to study the effect of name brand tooth paste compared to its off brand equivalent. This is the second controlled factor in the experiment. It has two levels (name brand and off brand). Twelve subjects used name brand paste, and a different 12 subjects used the off brand. Toothpaste brand is crossed with toothbrush type to create a BF[2].\n\n\nBased on the description above, the factor structure for this experiment is displayed in Figure 1:\n\n\n\n\nFigure 1: Factor Structure Diagram\n\n\n\nTwo levels of toothpaste multiplied by 4 levels of toothbrush results in 8 factor level combinations total. This is represented by the 8 partitions in the interaction factor. These 8 factor level combinations are obtained by overlaying the 2 controlled factor partitions. When the toothbrush factor and toothpastepaste partitions are overlayed, they cross each other and create new, meaningful partitions: the interaction factor. Since there were 24 subjects and the study is balanced, we end up with \\(24\\div 8 = 3\\) replicates in each factor level combination.\n\n\n\nEach factor (i.e. meaningful partition of the data) in Figure 1 corresponds to a term in Equation 1:\n\\[\ny_\\text{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_\\text{ij} + \\epsilon_\\text{ijk}\n\\tag{1}\\]\nWhere\n\n\\(y_{ijk}\\) is the \\(k^{th}\\) observation from the factor level combination of \\(\\alpha_i\\) and \\(\\beta_j\\).\n\\(\\mu\\) is the grand mean of all the observations.\n\\(\\alpha\\) is the effect of toothbrush, and \\(i\\) goes from 1 to 4 since there are 4 toothbrush types\n\\(\\beta\\) is the effect of toothpaste, and \\(j\\) is either 1 or 2 since there are 2 levels (Name brand and off brand).\nThe \\((\\alpha\\beta)_\\text{ij}\\) is called the interaction effect.\n\\(\\epsilon\\) is the residual error term, and \\(k\\) is the replicate count within a factor level combination.\n\nThere are at least three hypotheses to test with this model. A hypothesis for each main effect, and a hypothesis for the interaction effect.\nA hypothesis for the main effect of toothbrush type:\n\\[H_0: \\alpha_\\text{i} = 0 \\text{ for all } i\\]\n\\[H_a: \\alpha_\\text{i} \\ne 0 \\text{ for some } i\\]\nA hypothesis for the main effect of toothpaste brand:\n\\[H_0: \\beta_\\text{j} = 0 \\text{ for all } j\\]\n\\[H_a: \\beta_\\text{j} \\ne 0 \\text{ for some } j\\]\nA hypothesis for the interaction of toothbrush and toothpaste.\n\\[\nH_0: (\\alpha\\beta)_\\text{ij} = 0 \\text{ for all } ij\n\\]\n\\[\nH_a: (\\alpha\\beta)_\\text{ij} \\ne 0 \\text{ for some } ij\n\\]\nWhen the interaction term is not significant a predicted value for an observation can be obtained by simply adding the grand mean to the main effects \\(\\hat{\\alpha}_i\\) and \\(\\hat{\\beta}_j\\). This is equivalent to treating the effect of \\((\\alpha\\beta)_\\text{ij} = 0\\) for all values of \\(i\\) and \\(j\\).\nWhen the interaction effect is significant reject the null hypothesis and accept the alternative hypothesis: at least one factor level combination has a none zero effect.\n\n\n\nA two-way ANOVA model may be used to analyze data from a BF[2] design if the following requirements are satisfied. Note that these requirements are identical to the requirements of a BF[1] one-way ANOVA.\n\n\nThe BF[] designation refers to the design of the experiment. The reference to one- or two-way ANOVA refers to the analysis technique applied to the resulting data.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "bf2.html#factor-structure",
    "href": "bf2.html#factor-structure",
    "title": "BF[2]",
    "section": "",
    "text": "Based on the description above, the factor structure for this experiment is displayed in Figure 1:\n\n\n\n\nFigure 1: Factor Structure Diagram\n\n\n\nTwo levels of toothpaste multiplied by 4 levels of toothbrush results in 8 factor level combinations total. This is represented by the 8 partitions in the interaction factor. These 8 factor level combinations are obtained by overlaying the 2 controlled factor partitions. When the toothbrush factor and toothpastepaste partitions are overlayed, they cross each other and create new, meaningful partitions: the interaction factor. Since there were 24 subjects and the study is balanced, we end up with \\(24\\div 8 = 3\\) replicates in each factor level combination."
  },
  {
    "objectID": "bf2.html#hypothesis-and-model",
    "href": "bf2.html#hypothesis-and-model",
    "title": "BF[2]",
    "section": "",
    "text": "Each factor (i.e. meaningful partition of the data) in Figure 1 corresponds to a term in Equation 1:\n\\[\ny_\\text{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_\\text{ij} + \\epsilon_\\text{ijk}\n\\tag{1}\\]\nWhere\n\n\\(y_{ijk}\\) is the \\(k^{th}\\) observation from the factor level combination of \\(\\alpha_i\\) and \\(\\beta_j\\).\n\\(\\mu\\) is the grand mean of all the observations.\n\\(\\alpha\\) is the effect of toothbrush, and \\(i\\) goes from 1 to 4 since there are 4 toothbrush types\n\\(\\beta\\) is the effect of toothpaste, and \\(j\\) is either 1 or 2 since there are 2 levels (Name brand and off brand).\nThe \\((\\alpha\\beta)_\\text{ij}\\) is called the interaction effect.\n\\(\\epsilon\\) is the residual error term, and \\(k\\) is the replicate count within a factor level combination.\n\nThere are at least three hypotheses to test with this model. A hypothesis for each main effect, and a hypothesis for the interaction effect.\nA hypothesis for the main effect of toothbrush type:\n\\[H_0: \\alpha_\\text{i} = 0 \\text{ for all } i\\]\n\\[H_a: \\alpha_\\text{i} \\ne 0 \\text{ for some } i\\]\nA hypothesis for the main effect of toothpaste brand:\n\\[H_0: \\beta_\\text{j} = 0 \\text{ for all } j\\]\n\\[H_a: \\beta_\\text{j} \\ne 0 \\text{ for some } j\\]\nA hypothesis for the interaction of toothbrush and toothpaste.\n\\[\nH_0: (\\alpha\\beta)_\\text{ij} = 0 \\text{ for all } ij\n\\]\n\\[\nH_a: (\\alpha\\beta)_\\text{ij} \\ne 0 \\text{ for some } ij\n\\]\nWhen the interaction term is not significant a predicted value for an observation can be obtained by simply adding the grand mean to the main effects \\(\\hat{\\alpha}_i\\) and \\(\\hat{\\beta}_j\\). This is equivalent to treating the effect of \\((\\alpha\\beta)_\\text{ij} = 0\\) for all values of \\(i\\) and \\(j\\).\nWhen the interaction effect is significant reject the null hypothesis and accept the alternative hypothesis: at least one factor level combination has a none zero effect."
  },
  {
    "objectID": "bf2.html#assumptions",
    "href": "bf2.html#assumptions",
    "title": "BF[2]",
    "section": "",
    "text": "A two-way ANOVA model may be used to analyze data from a BF[2] design if the following requirements are satisfied. Note that these requirements are identical to the requirements of a BF[1] one-way ANOVA.\n\n\nThe BF[] designation refers to the design of the experiment. The reference to one- or two-way ANOVA refers to the analysis technique applied to the resulting data.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "bf2.html#conceptual-understanding",
    "href": "bf2.html#conceptual-understanding",
    "title": "BF[2]",
    "section": "Conceptual Understanding",
    "text": "Conceptual Understanding\nThe concept behind an interaction should feel quite familiar. It is something we deal with everyday and is very common in science. You may have experienced an interaction effect in something as simple as your daily commute:\n\nConsider a factor to indicate which route you take to work. Route has two levels: using the main roads and using back roads. The time to reach your destination is the response. During rush hour, the main roads are clogged with traffic and result in a longer commute time than taking the back roads. However, in non-rush hour times, the main roads result in a faster commute time. Thus, the effect of taking main roads depends on whether you are traveling during rush hour or not.\n\nThe effect of route was reversed for different levels of rush hour. Not all interactions work this way. Some interactions increase/decrease the magnitude of an effect without completely changing its direction. We can tweak the situation of the commute time example to illustrate this:\n\nDuring non-rush hour periods, on average back roads result in a commute time that is 5 minutes faster than main roads. During rush hour periods however, the benefit of taking back rounds compared to main roads increases to 15 minutes. Thus, the size of the effect of back roads increased (is amplified) for rush hour compared to non-rush hour.\n\nThe above descriptions cover just two possible outcomes for this commute time experiment. It may be helpful to visualize the possible outcome scenarios for this two factor (route and rush hour) study. This can effectively be done with an interaction plot. An interaction plot shows the means for each factor level combination and usually connects the means from the same factor level with a line to help the reader visually group means and detect effects.\nFigure 2 shows four possible outcomes of the traffic study where NO interaction is present. The upper left panel of the plot shows a situation where there are no main effects or interactions apparent. The mean is the same regardless of the factor level combination. The upper right panel of the plot shows a large route effect but no effect due to rush hour. This can be seen because the commute time for back roads is high but commute time for main roads is low; however, for a given route there is no difference in the mean for rush hour vs. not rush hour.\nThe bottom left panel shows a non-zero effect for the rush hour factor, as seen by the sizable difference between the levels of rush hour within a route. However, the flat lines indicate that the mean commute time for route is not changing and therefore route has no effect on commute time. Lastly, the bottom right panel is a situation where both main effects appear to be present - but there is still no interaction apparent.\n\n\nR code instructions to create interaction plots are at the bottom of the R Instructions&gt;Descriptive Summaries page.\n\n\nWarning: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\n\n\n\nFigure 2: Scenarios with NO Interaction Present\n\n\n\n\nThe line segments within each graph of Figure 2 are parallel (or coincide), which is a visual indicator that no interaction is present.\n\n\n\n\n\n\nTip\n\n\n\nFactors with no interaction will have (nearly) parallel line segments in the interaction plot.\n\n\nSo what does an interaction plot look like when there is an interaction present? The key things to notice is that the line segments in the plot are not parallel. Figure 3 contains 3 examples of interaction plots that show the presence of an potential interaction.\n\n\n\n\n\nFigure 3: Scenarios Indicative of an Interaction\n\n\n\n\nPanel A of Figure 3 illustrates an example where the effect of Route reverses, depending on the value for Rush Hour. In Panel B, the effect of Rush Hour is much greater when using main roads than for back roads. In Panel C, main roads take longer regardless of time of day, but the effect of switching from back roads to main roads is much larger during rush hour than in non-rush hour times.\nThere are a few key points to remember when working with interactions.\nFirst, exercise caution when interpreting a main effect if an interaction is present. The definition of an interaction is that a factor level’s effect changes for different values of the other factor. Therefore, it does not make sense to interpret the hypothesis test of a controlled factor if it is part of a significant interaction. Instead, get in the habit of describing the nature of the interaction.\nTo illustrate the danger of interpreting main effect hypothesis tests when the interaction is significant consider Panel A of Figure 3. If the hypothesis test for Route had a large p-value, it is tempting to say there is insufficient evidence that Route has an effect on commute time. However, the interaction plot shows quite the opposite. Route has an important effect on the response, since the level of Route drastically changes the impact of Rush Hour on commute times. Even though the mean commute time for “back” and “main” may be similar in this scenario, Route is indirectly having an effect on commute time through its interaction with Rush Hour.\nConversely, imagine a scenario where Route’s main effect had a small p-value and the Route - Rush Hour interaction was also significant. If the interaction is like that depicted in Panel C of Figure 3, simply stating that Route is a significant factor does not tell the whole story. The effect of Route in during rush hour is large and may be significant (steep blue line), but the effect of Route in non-rush hour times may not be large enough to reach significance (the nearly flat red line).\n\n\n\n\n\n\nInterpreting Main Effects and Interactions\n\n\n\nWhen a significant interaction is present, do not interpret the hypothesis tests of its main effects without providing additional information.\n\n\nSecond, don’t rely on interaction plots alone to detect the presence/absence of interactions. Though interaction plots are a a helpful tool, they do not adequately show the repsonse variability in each factor level combination. In other words, even when line segments are not parallel a hypothesis test is still needed to determine if an interaction is real or just due to random error. Furthermore, two lines may look nearly parallel but could actually represent a significant interaction.\nLastly, beware of a common mistake that students make. Students commonly state an interaction means that the level of one factor affects the values of another factor. This is a lie from Satan! The key misunderstanding here is thinking that the value of one factor affects the other factor. In reality, it is the factor’s effect on the response that changes for different levels of the other factor. The two factors do not affect each other."
  },
  {
    "objectID": "bf2.html#factor-effects",
    "href": "bf2.html#factor-effects",
    "title": "BF[2]",
    "section": "Factor Effects",
    "text": "Factor Effects\nHow can an interaction affect be estimated? Like all factor effects, its estimate is calculated using the general rule.\n\n\n\n\n\n\nGeneral Rule for Calculating Factor Level Effect\n\n\n\nFactor level effect = mean of the factor level - Sum(effects of all outside factors)\n\n\nFrom the general rule we can see that before we estimate the interaction effect we first need to estimate the outside factor effects (i.e. main effects). Factor level means need to be calculated in order to calculate estimated effects.\nIt is also important to recall that the grand mean factor is outside of all other factors, while the residual error factor is inside of all other factors.\n\nFactor Level Means\nFigure 6 shows our data set with partition lines for structural factors in place. We will now proceed to calculate the factor level means for each factor.\n\n\n\nFigure 6: Full data set with partitions\n\n\nThe grand mean is the mean of all the observations:\n\\[\n\\hat{\\mu} = \\bar{y}_\\cdots = \\frac{19.12 + 18.56 + 25.58 + 24.39 + 24.21 + ... + 23.42}{24} = 22.76\n\\]\nNow find the mean for each level of toothbrush type.\n\\[\n\\bar{y}_\\text{manual} = \\bar{y}_{1\\cdot\\cdot} = \\frac{19.12 + 24.21 + 26.88 + 21.6 + 23.4 + 23.35}{6} = 23.10\n\\]\n\\[\n\\bar{y}_\\text{oscillating} = \\bar{y}_{2\\cdot\\cdot} = \\frac{18.56 + 20.00 + 19.87 + 22.09 + 17.62 + 21.72}{6} = 19.98\n\\]\n\\[\n\\bar{y}_\\text{sonic} = \\bar{y}_{3\\cdot\\cdot} = \\frac{25.58 + 23.31 + 18.99 + 23.09 + 23.81 + 21.27}{6} = 22.68\n\\]\n\\[\n\\bar{y}_\\text{ultrasonic} = \\bar{y}_{4\\cdot\\cdot} = \\frac{24.39 + 21.45 + 32.74 + 24.21 + 25.67 + 23.42}{6} = 25.31\n\\]\nNow find the mean for each level of toothpaste brand.\n\\[\n\\bar{y}_\\text{name brand} = \\bar{y}_{\\cdot 1 \\cdot} = \\frac{19.12 + 18.56 + \\cdots + 18.99 + 32.74}{12} = 22.93\n\\]\n\\[\n\\bar{y}_\\text{off brand} = \\bar{y}_{\\cdot 2 \\cdot} = \\frac{21.60 + 22.09 + \\cdots + 21.27 + 23.42}{12} = 22.60\n\\]\nThere are 8 different combinations of toothbrush type and toothpaste, so the interaction factor has 8 levels total. We calculate a mean for each one, but will only show the calculation for the first 3.\n\\[\n\\bar{y}_\\text{manual and name brand} = \\bar{y}_{11\\cdot} = \\frac{19.12 + 24.21 + 26.88}{3} = 23.40\n\\]\n\\[\n\\bar{y}_\\text{manual and off brand} = \\bar{y}_{12\\cdot} = \\frac{21.60 + 23.40 + 23.35}{3} = 22.78\n\\]\n\\[\n\\bar{y}_\\text{oscillating and name brand} = \\bar{y}_{21\\cdot} = \\frac{18.56 + 20.00 + 19.87}{3} = 19.48\n\\]\nThe means for the residual error factor levels is the observed value itself since there is just 1 observation per level. Therefore, there are no calculations to show.\nFigure 7 displays all the factor level means inside the factor structure.\n\n\n\n\nFigure 7: Factor level means\n\n\n\n\n\nFactor Level Effects\n\nGrand mean effect\nNow that we have calculated means for each level of each factor, we can move on to calculate the effects of the factor levels.1\nFor the grand mean, there is only one level and there are no outside factors. Therefore, the effect due to grand mean is 22.76 (equivalent to its mean) and this affect is applied to all 24 observations.\n\n\nToothbrush effects\nThe toothbrush factor has four levels: one for each brush type. We will use the general rule for calculating factor level effects. To calculate the effect of a toothbrush, take the toothbrush mean and subtract it from the grand mean factor’s effect. For the manual brush, this looks like:\n\\[\n23.09 - 22.76 = 0.33\n\\]\nUsing the manual brush has the effect of increasing a person’s plaque area percentage by 0.33 percentage points on average compared to the grand mean. In a similar way2 you can find the effect for the oscillating brush \\(19.98 - 22.76 = -2.79\\). This means the amount of plaque decreased by 2.79 on average with this brush compared to the grand mean. For a sonic toothbrush, the effect is \\(22.68 - 22.76 = -0.09\\). For an ultrasonic brush the effect is \\(25.31 - 22.76 = 2.55\\).\n\n\nIt is interesting to note that the factor effects for brush type are the same, whether toothpaste brand is included in the analysis or not.\n\n\nToothpaste effects\nCalculating the effects for the second controlled factor in the experiment follows a similar pattern and also uses the general rule for calculating effect sizes. Remember that toothbrush is not outside or inside of toothpaste, rather the two factors are crossed. To calculate the effect of using the name brand toothpaste, take the name brand mean and subtract it from the grand mean factor’s effect:\n\\[\n22.93 - 22.76 = 0.16\n\\]\nA similar calculation is performed for off the brand toothpaste.\n\\[\n22.60 - 22.76 = -0.16\n\\]\nWith only two levels, it becomes obvious that the effects of a factor’s levels will always sum to zero. You may want to go back to the toothbrush level effects and verify this is true.\n\n\nInteraction effects\nThe general rule says that effects of outside factors must be subtracted from the factor level mean. We pause to review the relationship of the other factors to the interaction factor to determine if they are inside, outside, or crossed with each other.\n\n\n\n\n\n\n\n(a) Interaction inside of brush\n\n\n\n\n\n\n\n(b) Interaction inside of toothpaste\n\n\n\n\nFigure 8: Interaction Effects\n\n\nIn Figure 8 (a) you can see that each level of the interaction will fit nicely within a level of toothbrush, this means toothbrush is outside of interaction (equivalently, interaction is inside of toothbrush). The same holds true for the relationship of toothpaste brand and interaction, as shown in Figure 8 (b).\nTherefore, to calculate the interaction effect for using an ultrasonic brush with name brand toothpaste we will subtract the effects of the grand mean factor, ultrasonic brush, and name brand paste from the “ultrasonic, name brand” level mean.\n\\[\n26.19 - (22.76 + 2.55 + 0.16) = .15\n\\]\nLet’s take a deeper look to understand why this works. It can be helpful to remember our assembly line analogy. We will walk through this assembly line, showing a graph to illustrate how the effects are added at each station.\nAn observation from the “ultrasonic brush, name brand paste” group starts with the grand mean value of 22.76. The observation belongs to the ultrasonic group, where plaque tends to be higher, specifically 2.55 higher on average (2.55 is the effect of ultrasonic). Figure 9 show the starting point of the grand mean and the addition of the brush effect.\n\n\n\n\n\nFigure 9: Grand mean + brush effect\n\n\n\n\nAt the next step, because the observation belongs to the Name Brand Toothpaste group we would tack on an additional 0.16 of plaque coverage, as shown in Figure 10.\n\n\n\n\n\nFigure 10: Grand mean + brush effect + paste effect\n\n\n\n\nWhat we haven’t accounted for yet is the fact that the ultrasonic brush and name brand toothpaste have appeared together. If the interaction is significant then we can expect a synergistic effect (in either direction) and will need to add/subtract more to the response. Otherwise, the interaction effects will be small (relative to the error variance).\nThere is an old saying, “the whole is greater than the sum of its parts”. In a way, the interaction effect is the measure of how much greater. Figure 11 shows that after summing the main effects of each controlled factor, the remaining distance to the mean of the factor level combination is the interaction effect. We calculated this above using the general rule and found the distance to be 0.15.\n\n\n\n\n\nFigure 11: Interaction effect is remaining distance to factor level mean\n\n\n\n\nThe previous 3 figures are placed side by side below in the figure below so that the additive progression of the effects can more easily be seen.\n\n\n\n\n\n\n\n\n(a) ?(caption)\n\n\n\n\n\n\n\n(b) ?(caption)\n\n\n\n\n\n\n\n(c) ?(caption)\n\n\n\n\nFigure 12: Additive Effects\n\n\nAdditive Effects\n\nLastly, the residuals (or residual effects) need to be calculated. The mean for each level of residual is simply the observation itself. Effects associated with that observation’s factor levels are subtracted from the observed value. Whatever is left over is considered the residual. In other words, we have applied the general rule for calculating effect size. For the residual factor, the effect can concisely be stated as “observed value - predicted value”.\nAs an example, the residual in the top left corner of the residual factor was obtained with this calculation:\n\\[\n19.12 - (22.76 + 0.329 + 0.16 + 0.15) = -4.28\n\\]\nAll other residuals were similarly obtained. Ultimately, Figure 13 displays all the factor level effects that are summed to obtain each observation.\n\n\n\n\nFigure 13: Factor level effects"
  },
  {
    "objectID": "bf2.html#degrees-of-freedom",
    "href": "bf2.html#degrees-of-freedom",
    "title": "BF[2]",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nWe can use our understanding of inside vs. outside factors to determine the degrees of freedom (df) for the grand mean, treatment factors, interaction and residual errors. We start with 24 observations - or pieces of information. In other words, we have 24 degrees of freedom that need to be allocated to the factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf\\(_\\text{factor}\\) = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the toothbrush and toothpaste example, grand mean has one level and there are no factors outside of grand mean. Therefore, its degrees of freedom equals one. This will always be the case.\nRemember, the degrees of freedom represent the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as you estimate the grand mean for just one of the observations, you know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for the grand mean effect were also known. Therefore, there is just one unique piece of information in the grand mean factor. Grand mean has just 1 degree of freedom.\nIn this case there are two controlled factors, or treatment factors: toothbrush and toothpaste. For toothbrush there are four levels of the factor. Grand mean is the only factor outside of toothbrush. Take the number of levels for toothbrush (4) and subtract the degrees of freedom for grand mean (1), which yields 4-1 = 3 degrees of freedom.\n\n\nThe degrees of freedom for toothbrush is it the same here as it was for the BF[1].\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information. Upon examining the factor for toothbrush in Figure 13 you can see there are 4 unique numbers. We know the effects for toothbrush must sum to zero, so the 4th effect is not free to vary. As soon as I know the effect for 3 of the brushes, I can fill in all the effects for the toothbrush factor.\nA similar approach is taken for toothpaste. Here it is even more obvious that the effects for toothpaste sum to zero. After estimating the toothbrush effect for one observation, I can fill in the toothpaste effects for all the other observations. Therefore, the degrees of freedom for toothpaste is 1.\nUsing the general rule, I know there are 2 levels for toothpaste and grand mean is the only outside factor. Since grand mean has 1 degree of freedom, I get \\(2-1 = 1\\) degree of freedom for toothpaste.\nNow we must calculate degrees of freedom for the interaction term. Take a closer look at the interaction effects in Figure 13. You can see that the numbers repeat within each cell. There are 8 cells total. You can also see that the effects inside a column of values sum to zero, as do the values in a row. Therefore, I really only need to know a value in 3 of the cells of the interaction factor before I can fill in the effects for all the other cells in that factor.\nThis is in perfect harmony with an application of the general rule. The interaction factor has 8 factor levels. Factors outside of the interaction include: grand mean (1 df), toothbrush (3 df), and toothpaste (1 df). Applying the general rule with these values yields \\(8 - (1 + 3 + 1) = 3\\) degrees of freedom for the interaction factor.\nPerhaps the easiest way to find the degrees of freedom for an interaction that is created by crossing two other factors is to multiply the degrees of freedom of the two other factors. In this case, toothbrush and toothpaste are crossed, so you would get \\(3*1 = 3\\), which matches the answer found using other methods.\nFinally, the residual degrees of freedom can be found using the general rule. Since the residual error factor is inside of all other factors, this is the same as finding how many degrees of freedom are leftover after calculating degrees of freedom for all other factors. In this example, there were 24 observations total, so we subtract the degrees of freedom for the other factors from 24. This returns \\(24 - (1+3+1+3) = 16\\) degrees of freedom for residuals.\nThe other approach to finding the degrees of freedom for residuals is to group the residuals by the smallest structural factor partitions (in this case the interaction). Inside each of those partitions the residuals sum to zero. For example, applying the interaction partition to residuals gives the values \\(-4.28\\), \\(0.81\\), and \\(3.48\\). Since we know the 3 residuals sum to zero in each partition, we only need to know 2 values per partition in order to fill in the third residual effect. With 8 partitions applied to the residuals, we have \\(2x8 = 16\\) degrees of freedom for residual error."
  },
  {
    "objectID": "bf2.html#completing-the-anova-table",
    "href": "bf2.html#completing-the-anova-table",
    "title": "BF[2]",
    "section": "Completing the ANOVA Table",
    "text": "Completing the ANOVA Table\nNow that we have calculated degrees of freedom and effects for each factor , we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. A completed ANOVA summary table contains the information we need for a hypothesis test of the main effects (for controlled factors) and their interaction.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n\n\n\n\n\n\nBrush\n3\n\n\n\n\n\n\nToothpaste\n1\n\n\n\n\n\n\nBrush:Toothpaste\n3\n\n\n\n\n\n\nResidual Error\n16\n\n\n\n\n\n\nTotal\n24\n\n\n\n\n\n\n\n\n\n\n\nTo get the sum of squares (SS) of a factor, each value displayed in that particular factor first needs to be squared. Figure 13 shows the effects, while Figure 14 shows the squared effects.\n\n\n\n\n\n\n\n\nFigure 14: Squared factor level effects\n\n\nThen, for each factor, all the squared values are summed up to get the sum of squares. The total sum of squares is obtained by summing the squared observations as shown in Equation 3. This represents the total variability in the dataset that will then be allocated or partitioned to the various factors, starting with the grand mean.\n\\[\nSS_\\text{total} = 365.6 + 344.5 + 654.3 + ... + 452.4 + 548.2  = 12,674.30\n\\tag{3}\\]\nFor grand mean, the squared effect of 518.2 is listed 24 times, once for each observation. Summing the squared effects gets:\n\\[\nSS_\\text{Grand Mean} = 518.2* 24 = 12,437.43\n\\]\n\n\n\n\n\n\nNote\n\n\n\nThe rounded numbers are displayed throughout this section, but all calculations are done using the unrounded numbers.\n\n\nThe toothbrush factor has four different effects: one for each level of the factor. For each effect, the squared value is multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to toothbrush.\n\\[\nSS_\\text{toothbrush} = 6*(0.11) + 6*(7.77) + 6*(0.01) + 6*(6.50) = 86.31\n\\tag{4}\\] \nThe sum of squares is similarly calculated for toothpaste brand (Equation 5) and brush by paste interaction (Equation 4).\n\\[\nSS_\\text{toothpaste} = 12*(0.03) + 12*(0.03) = 0.62\n\\tag{5}\\]\n\\[\nSS_\\text{brush x paste} = 3*(0.02) + 3*(0.44) + 3*(0.04) + 3*(0.52) +3*(0.02) + 3*(0.44) + 3*(0.04) + 3*(0.52)  = 6.12\n\\]\nThe effect for the residual error factor has 24 unique values. The squared residuals are summed together in Equation 6.\n\\[\nSS_\\text{residual} = 18.35 + 0.84 + 8.72 + ... + 2.11 + 1.03  = 143.82\n\\tag{6}\\]\nYou can check that the sums of squares (SS) has been allocated to the factors correctly by adding up the SS for each factor and verifying that it also equals the result found in Equation 3.\nPutting this information into the ANOVA table gets us the result shown in Table 1.\n\n\n\n\nTable 1: Sums of squares\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n12437.43\n\n\n\n\n\nBrush\n3\n86.31\n\n\n\n\n\nToothpaste\n1\n0.62\n\n\n\n\n\nBrush:Toothpaste\n3\n6.12\n\n\n\n\n\nResidual Error\n16\n143.82\n\n\n\n\n\nTotal\n24\n12674.30\n\n\n\n\n\n\n\n\n\n\n\nRecall that SS is a measure of total variability. Of the three structural factors (brush, toothpaste, and their interaction) it is clear to see that brush is contributing the most variability. Some of the difference in SS may be due to difference in number of levels for each factor. Adding levels to a factor allows more variability to be attributed to that factor. We will convert this total variability (sum of squares) into a mean variability (mean square) measure to properly account for differences in number of factor levels. This allows us to compare the factors’ variability on a standardized scale.\nTo calculate a mean square (MS), simply divide SS by degrees of freedom for a factor. The mean square calculations are:\n\\[\nMS_\\text{Grand Mean} = \\frac{SS_\\text{Grand Mean}}{df_\\text{Grand Mean}} = \\frac{12437.43}{1} = 12437.43\n\\]\n\n\\[\nMS_\\text{Brush} = \\frac{SS_\\text{Brush}}{df_\\text{Brush}} = \\frac{86.31}{3} = 28.77\n\\]\n\n\\[\nMS_\\text{Toothpaste} = \\frac{SS_\\text{Toothpaste}}{df_\\text{Toothpaste}} = \\frac{0.62}{1} = 0.62\n\\]\n\n\\[\nMS_\\text{Brush:Toothpaste} = \\frac{SS_\\text{Brush:Toothpaste}}{df_\\text{Brush:Toothpaste}} = \\frac{6.12}{3} = 2.04\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{143.82}{16} = 8.99\n\\]\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n12437.43\n12437.43\n\n\n\n\nBrush\n3\n86.31\n28.77\n\n\n\n\nToothpaste\n1\n0.62\n0.62\n\n\n\n\nBrush:Toothpaste\n3\n6.12\n2.04\n\n\n\n\nResidual Error\n16\n143.82\n8.99\n\n\n\n\nTotal\n24\n12674.30\n\n\n\n\n\n\n\n\n\n\nFor each structural factor in the design there are a set of hypothesis we want to test using the F statistic.\nSpecifically, we will want to test whether toothbrush type has an effect on plaque coverage, whether toothpaste brand has an effect on plaque coverage, and whether the interaction between brush and paste has an effect on plaque coverage.\nMore specifically, for each factor we test whether the factor level effects are all equal to zero. We can express the hypotheses mathematically using the terms of Equation 2.\nA hypothesis for the main effect of toothbrush type:\n\\[H_0: \\alpha_\\text{i} = 0 \\text{ for all } i\\]\n\\[H_a: \\alpha_\\text{i} \\ne 0 \\text{ for some } i\\]\nA hypothesis for the main effect of toothpaste brand:\n\\[H_0: \\beta_\\text{j} = 0 \\text{ for all } j\\]\n\\[H_a: \\beta_\\text{j} \\ne 0 \\text{ for some } j\\]\nA hypothesis for the interaction of toothbrush and toothpaste.\n\\[\nH_0: (\\alpha\\beta)_\\text{ij} = 0 \\text{ for all } ij\n\\]\n\\[\nH_a: (\\alpha\\beta)_\\text{ij} \\ne 0 \\text{ for some } ij\n\\]\nTo test these hypotheses we need to compare the mean square (MS) for a factor to the mean square for residual error (abbreviated as MSE). The MSE is the estimate of unexplained, random error. If a factor’s MS is similar in size to the MSE, the variance in that factor may just be random error; and the effect of the factor levels are zero. On the other hand, if the variability in the factor, as measured by its MS, is much larger than the random error observed in the experiment (represented by MSE), then it is reasonable to believe the factor levels have a non-trivial contribution to the variability. In other words, the factor has a significant effect on the response.\nThe F statistic is a ratio of these two errors and is obtained by dividing the factor’s mean square (MS) by the MSE. The F statistic calculations are\n\n\\(F_\\text{brush} = 28.77/8.99 = 3.20\\)\n\\(F_\\text{toothpaste} = 0.62/8.99 = 0.07\\)\n\\(F_\\text{brush:toothpaste} = 2.04 / 8.99 = .23\\)\n\nThis F statistic follows a well defined distribution, called the F distribution. The F distribution is defined by two values for degrees of freedom3:\n\nthe numerator degrees of freedom, which is the degrees of freedom for the factor being tested\nthe denominator degrees of freedom, which is the degrees of freedom for residual error\n\nThe area under this distribution curve to the right of our F statistic is called the p-value. The p-value represents the probability of getting an F statistic at least as large as the one obtained, assuming the null hypothesis (of no effect) is true.\nThe F statistic, numerator degrees of freedom, and denominator degrees of freedom are the 3 required inputs to calculate a p-value. P-values can be obtained manually using the applet mentioned above, the f.dist.rt()4 function in excel or the pf() function in R5. Usually though, R will show p-values as part of the standard output of the ANOVA model/table and it is recommended you stick to those values when reporting answers.\nThe completed ANOVA table for this BF[2] toothbrush and toothpaste example is shown in\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n12437.43\n12437.43\n\n\n\n\nBrush\n3\n86.31\n28.77\n3.20\n0.051\n\n\nToothpaste\n1\n0.62\n0.62\n0.07\n0.800\n\n\nBrush:Toothpaste\n3\n6.12\n2.04\n0.23\n0.876\n\n\nResidual Error\n16\n143.82\n8.99\n\n\n\n\nTotal\n24\n12674.30\n\n\n\n\n\n\n\n\n\n\nBecause the p-value for the interaction (p-value = 0.876) is much higher than any traditional level of significance threshold we might have chosen (0.01, 0.05, or 0.1), we fail to reject the null hypothesis. There is insufficient evidence to say the interaction effect has an effect on plaque coverage. Because the interaction is NOT significant, we can proceed to interpret the main effects test results.\n\n\n\n\n\n\nSignificant Interaction Effects\n\n\n\nIf the interaction effect is significant, great caution should be taken when interpreting the hypothesis test results for the factors involved in the interaction; it may not be valid to interpret the hypothesis test results. Instead, if the interaction is significant, it is better to describe the nature of the interaction with graphs, numbers, and words.\n\n\nToothpaste’s p-value is high (p-value = 0.8), indicating no evidence that toothpaste brand has an effect on plaque coverage. The p-value for brush is marginally significant (p-value = 0.051). When (in)significance is borderline, rather than making bold statements based on a small amount of (in)significance, it is helpful to dig a little deeper. Consider things like sample size, effect size (practical significance), outliers, and how closely assumptions are met. After weighing those considerations carefully, take a stance and state your belief about the role of the factor on the response. Explain your rationale, then keep an open mind and stay curious."
  },
  {
    "objectID": "bf2.html#describe-the-data",
    "href": "bf2.html#describe-the-data",
    "title": "BF[2]",
    "section": "Describe the Data",
    "text": "Describe the Data\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots, scatterplots, and/or interaction plots with the means displayed.\nInteractive code and additional explanations of numerical summaries and plots in R are found at R Instructions-&gt;Descriptive Summaries section of the book.\n\nNumerical Summaries\nAfter loading required packages, we will read in the data and do some wrangling.\n\n\nCode\nbf2 &lt;- read_csv(\"data/toothpaste_BF2.csv\") \n\n\nWe then calculate summary statistics for each factor level separately.\n\n\nCode\n#Descriptive stats for levels of Brush\nfavstats(Plaque~Brush, data = bf2) |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n#Descriptive stats for levels of Toothpaste\nfavstats(Plaque~Toothpaste, data = bf2) |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\nTable 2: Numerical Summary for Each Factor\n\n\n\n\n(a) Brush\n\n\nBrush\nmin\nQ1\nmedian\nQ3\nmax\nmean\nsd\nn\nmissing\n\n\n\n\nManual\n19.12\n22.04\n23.38\n24.01\n26.88\n23.09\n2.60\n6\n0\n\n\nOscillating\n17.62\n18.89\n19.94\n21.29\n22.09\n19.98\n1.74\n6\n0\n\n\nSonic\n18.99\n21.73\n23.20\n23.68\n25.58\n22.67\n2.27\n6\n0\n\n\nUltrasonic\n21.45\n23.62\n24.30\n25.35\n32.74\n25.31\n3.90\n6\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Toothpaste\n\n\nToothpaste\nmin\nQ1\nmedian\nQ3\nmax\nmean\nsd\nn\nmissing\n\n\n\n\nNameBrand\n18.56\n19.68\n22.38\n24.69\n32.74\n22.92\n4.18\n12\n0\n\n\nOffBrand\n17.62\n21.69\n23.22\n23.52\n25.67\n22.60\n2.00\n12\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn Table 2 (a) we see that the oscillating brush has lowest mean plaque (19.98). Table 2 (b) shows the mean plaque for the two types of toothpaste is very close, 22.92 for Name Brand and 22.60 for Off Brand.\nYou can also look at descriptive statistics for factor level combinations. This is only advisable if there is sufficient sample size at each combination and the number of combinations is manageable. Table 3 shows what that looks like for our current example. Due to the many combinations, it is a bit difficult to interpret the output. Furthermore, using a 5 number summary on a sample size of 3 observations is not advisable so some of the summary statistics have been dropped.\nThe combination of Oscillating with Name Brand has the lowest mean (19.48) and the lowest standard deviation (0.80).\n\n\nCode\nfavstats(Plaque~Brush+Toothpaste, data = bf2) |&gt; \n  select(Brush.Toothpaste, mean, sd, n) |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = FALSE)\n\n\n\n\nTable 3: Numerical Summary\n\n\nBrush.Toothpaste\nmean\nsd\nn\n\n\n\n\nManual.NameBrand\n23.40\n3.94\n3\n\n\nOscillating.NameBrand\n19.48\n0.80\n3\n\n\nSonic.NameBrand\n22.63\n3.35\n3\n\n\nUltrasonic.NameBrand\n26.19\n5.86\n3\n\n\nManual.OffBrand\n22.78\n1.03\n3\n\n\nOscillating.OffBrand\n20.48\n2.48\n3\n\n\nSonic.OffBrand\n22.72\n1.31\n3\n\n\nUltrasonic.OffBrand\n24.43\n1.14\n3\n\n\n\n\n\n\n\n\n\n\nGraphical Summaries\nGraphs are also valuable tools to help you get to know your data. Since there are only 3 observation in each factor level combination, a dotplot/scatterplot is more appropriate than a boxplot. This is shown in Figure 15\n\n\nCode\n#Note, I have to turn Brush into a factor because it started out as a character variable\ndotplot(Plaque~factor(Brush)|factor(Toothpaste), data = bf2, \n        xlab = \"\")\n\n\n\n\n\nFigure 15: Graphical Summary\n\n\n\n\nYou could also gain insight about the main effects by cutting the data by each factor separately, as shown in Figure 16.\n\n\n\n\n\n\n\n(a) Brush\n\n\n\n\n\n\n\n(b) Toothpaste\n\n\n\n\nFigure 16: Data cut by one factor at a time\n\n\nFinally, an interaction plot is ideal for investigating a BF[2]. The plot only shows factor level means. Therefore, it does not give a good sense of the underlying distribution of data and should not be used as the only visual assessment of your data. However, it is extremely good at providing insight into possible interactions.\nIn Figure 17 the lines are not parallel. In fact, they cross twice. Though this seems to suggest an interaction is present, our ability to claim an interaction exists will depend on the results of a hypothesis test. The hypothesis test is greatly influenced by sample size and the variability at each of the factor level means presented in the plot.\n\n\n\n\n\nFigure 17: Interaction plot for Brush vs. Toothpaste"
  },
  {
    "objectID": "bf2.html#create-the-model",
    "href": "bf2.html#create-the-model",
    "title": "BF[2]",
    "section": "Create the Model",
    "text": "Create the Model\nYou then create the model using the aov() function. To see results of the F-test you can feed your model into a summary() or anova() function.\n\n\nsummary() and anova() functions give the same output with some slight differences in formatting when called on a model created with aov(). The summary() function is more general; it can also take linear regression models created with 'lm() as inputs. The output provided by summary() will change based on the type of object it is called on. This is discussed in more detail at the bottom of the Unbalanced page.\n\nmyaov &lt;- aov(Y ~ X1*X2, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is the user defined name in which the results of the aov() model are stored\nY is the name of a numeric variable in your dataset which represents the quantitative response variable.\nX1 and X2 are names of qualitative variables in your dataset. They should have class(X) equal to factor or character. If that is not the case, use factor(X) inside the aov(Y ~ factor(X1)*...) command.\nYourDataSet is the name of your data set.\n\nThe * in the code above is a shortcut for writing out the whole model. It can be read as, “include each term by itself, and all possible interaction terms”. The long way of writing out the model uses a colon, :, to define interaction terms and is shown below. When writing it this way each term must be explicitly stated.\n\nmyaov &lt;- aov(Y ~ X1+X2+X1:X2, data=YourDataSet)\nsummary(myaov)\n\nBelow are the results for the full BF[2] model using the toothbrush and toothpaste example. You should notice that these results match what we got when we performed the decomposition manually to build the ANOVA summary table. Even though the interaction plot showed crossing lines, we see the interaction between Brush and Toothpaste is not significant (p-value = .8763). This means we can interpret the hypothesis tests for each of the main effects.\nToothpaste is not significant (p-value = .7966) and Brush is marginally significant (p-value = .0517, which is close to the traditional alpha level of 0.05). Our exploratory analysis showed that oscillating brush resulted in the lowest amount of plaque and the ultrasonic brush resulted in the highest plaque measure.\n\n\nCode\nbf2_aov &lt;- aov(Plaque~Brush*Toothpaste,data=bf2)\nsummary(bf2_aov)\n\n\n                 Df Sum Sq Mean Sq F value Pr(&gt;F)  \nBrush             3  86.31  28.769   3.201 0.0517 .\nToothpaste        1   0.62   0.618   0.069 0.7966  \nBrush:Toothpaste  3   6.12   2.040   0.227 0.8763  \nResiduals        16 143.82   8.989                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn order to trust these hypothesis test results we need to verify that the assumptions are met."
  },
  {
    "objectID": "bf2.html#check-assumptions",
    "href": "bf2.html#check-assumptions",
    "title": "BF[2]",
    "section": "Check Assumptions",
    "text": "Check Assumptions\nFor a more detailed explanation of the code, output, and theory behind these assumptions visit the Assumptions page.\n\nConstant Variance of Residuals\nThere needs to be constant variance of residuals across the factor level combinations. First, we can check the residual plot.\n\n\nCode\nplot(bf2_aov, which = 1)\n\n\n\n\n\nFigure 18: Checking constant variance\n\n\n\n\nIn Figure 18 there are 8 distinct vertical groupings of points, one for each factor level combination. There are 3 observations, and so 3 residuals also, for each factor level combination. There does seem to be a slight trend for points with larger predicted values to be more spread out. On the far left of the plot the points appear closer together, as you move to the right the points tend to be more spread out (thought not always). This phenomenon raises the concern that the assumption of constant variance across factor level combinations may be violated.\nLevene’s test can provide insight on whether the trend in the residual plot is drastic enough to constitute a violation of the constant variance assumption.\nRecall that the null hypothesis for Levene’s test is that the variance of residuals is equal for each and every factor level combination. The results of the test below shows a p-value of 0.5409. We therefore fail to reject a null hypothesis of equal variances and proceed with the analysis (assuming the other assumptions are met).\n\n\nCode\nleveneTest(bf2_aov) %&gt;% kable(digits = 2)\n\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\n\ngroup\n7\n0.88\n0.54\n\n\n\n16\n\n\n\n\n\n\n\n\n\n\n\nNormally Distributed Residuals\nWe check the assumption that residuals are normally distributed in Figure 19. Most of the points are in the shaded region. Row 1 of the dataset appears in the upper right corner, far away from the boundaries. A couple of other points are very close, but just outside of the boundary. Due to the robust nature of ANOVA, the mild violation of this assumption is not a concern.\n\n\nCode\ncar::qqPlot(bf2_aov$residuals, id = FALSE)\n\n\n\n\n\nFigure 19: Checking normality of residuals\n\n\n\n\n\n\nIndependent Residuals\nThe dataset we are analyzing does not include information about the order in which the data was collected. In fact, it may be possible there were multiple teams of researchers collecting the data simultaneously and there is no specific order. From what we know, there is no reason to think there is a potential order bias. Nevertheless, the order plot in Figure 20 can be used to investigate trends in residuals by row number in the dataset. This plot does not show any patterns or trends. The assumption of independent residuals seems to be satisfied.\n\n\nCode\nplot(bf2_aov$residuals)\n\n\n\n\n\nFigure 20: Checking independent residuals assumption\n\n\n\n\n\n\nAssumptions Summary\nThe assumptions appear to be met, meaning the p-values should be valid and reliable. However, since the F-test for toothbrush is such a close call, mild-moderate assumption violations may cause the p-value of the test to be slightly off. Even after attempting various transformations of the response variable, Plaque, the degree to which assumptions are met does not improve (in fact, in some cases it gets worse).\nRather than fuss about the whether F-test assumptions are met or not, you can recognize the F-test for Brush is close enough to merit further investigation. In this case, it is recommended to proceed with contrasts/pairwise tests of toothbrush type which do not require constant variance. (You should be aware of what assumption are required for those tests and be sure to check them).\n\n\nCode\nTukeyHSD(bf2_aov, which = \"Brush\")\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Plaque ~ Brush * Toothpaste, data = bf2)\n\n$Brush\n                             diff       lwr       upr     p adj\nOscillating-Manual     -3.1166667 -8.069047  1.835714 0.3089079\nSonic-Manual           -0.4183333 -5.370714  4.534047 0.9948323\nUltrasonic-Manual       2.2200000 -2.732381  7.172381 0.5864034\nSonic-Oscillating       2.6983333 -2.254047  7.650714 0.4280732\nUltrasonic-Oscillating  5.3366667  0.384286 10.289047 0.0324891\nUltrasonic-Sonic        2.6383333 -2.314047  7.590714 0.4469155\n\n\nIn the above output results for all pairwise comparisons with Tukey’s HSD adjustment for multiple comparisons are displayed. Only the Ultrasonic-Oscillating comparison is significantly different, with a p-value of .03. Therefore, we can state that the ultrasonic brush performs significantly worse than the oscillating brush at plaque reduction."
  },
  {
    "objectID": "bf2.html#notation-for-estimated-effects",
    "href": "bf2.html#notation-for-estimated-effects",
    "title": "BF[2]",
    "section": "Notation for Estimated Effects",
    "text": "Notation for Estimated Effects\nHere are symbolic representations for the estimated effects in the BF[2] model, as shown in Equation 1.\n\\[\n\\hat{\\alpha}_i = \\bar{y}_{i \\cdot \\cdot} - \\bar{y}_{\\cdots}\n\\]\n\\[\n\\hat{\\beta}_j = \\bar{y}_{\\cdot j \\cdot} - \\bar{y}_{\\cdots}\n\\]\n\\[\n\\begin{align}\n\\hat{\\alpha}\\hat{\\beta}_{ij} & = \\bar{y}_{i j \\cdot} - (\\bar{y}_{\\cdot \\cdot \\cdot} + \\hat{\\alpha}_i  + \\hat{\\beta}_j ) \\\\\n&= \\bar{y}_{i j \\cdot} - (\\bar{y}_{\\cdot \\cdot \\cdot} + (\\bar{y}_{i \\cdot \\cdot} - \\bar{y}_{\\cdot \\cdot \\cdot})  + (\\bar{y}_{\\cdot j \\cdot} - \\bar{y}_{\\cdot \\cdot \\cdot}) ) \\\\\n& = \\bar{y}_{i j \\cdot} - (\\bar{y}_{i \\cdot \\cdot} + \\bar{y}_{\\cdot j \\cdot} - \\bar{y}_{\\cdot \\cdot \\cdot})\n\\end{align}\n\\]"
  },
  {
    "objectID": "bf2.html#unreplicated-or-single-observation-per-cell",
    "href": "bf2.html#unreplicated-or-single-observation-per-cell",
    "title": "BF[2]",
    "section": "Unreplicated or Single Observation per Cell",
    "text": "Unreplicated or Single Observation per Cell\nWhat can be done in the case of an experiment where there is only one observation per factor level combination?\nUnder construction."
  },
  {
    "objectID": "bf2.html#footnotes",
    "href": "bf2.html#footnotes",
    "title": "BF[2]",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThere are symbolic/mathematical representations of the factor effect formulas located in the appendix.↩︎\nThe values used in calculations here and throughout this page are rounded for a cleaner display. However, you should use unrounded values for these calculations. Rounded values and significant digits is the reason the arithmetic in some of these calculations appears off by one one-hundredth.↩︎\nYou can explore behavior of the F distribution for various combinations of degrees of freedom using this applet↩︎\nThis is the formula used in Excel to obtain the p-values for brush, toothpaste, and brush:toothpaste interaction respectively:\n\nbrush: `=f.dist.rt(3.20054, 3, 16)\ntoothpaste: =f.dist.rt(0.06871, 1, 16)\nbrush:toothpaste : =f.dist.rt(.226924, 3, 16)\n\n↩︎\nThis is the formula used in R to obtain the p-values for brush, toothpaste, and brush:toothpaste interaction respectively:\n\nbrush: 1-pf(3.2005, 3, 16)\ntoothpaste: 1-pf(0.06871, 1, 16)\nbrush:toothpaste : 1-pf(0.2269, 3, 16)\n\n↩︎"
  },
  {
    "objectID": "block_intro.html",
    "href": "block_intro.html",
    "title": "Blocking Introduction",
    "section": "",
    "text": "In the chapter that describes BF[1], a very simple example was used to assign 3 treatments to 6 subjects completely at random. In that example, treatment C was assigned to the last experimental runs (order number 5 and 6). In some experiments, we would not expect order to matter much and this would not concern us. But in other experiments, if we thought order could affect the response, we may be confounding treatment C with the fact that it was only applied in the last two experimental runs.\n\n\n\nSubject\nTreatment\nOrder\n\n\n\n\nSubject 1\nA\n4\n\n\nSubject 2\nB\n3\n\n\nSubject 3\nC\n6\n\n\nSubject 4\nC\n5\n\n\nSubject 5\nA\n1\n\n\nSubject 6\nB\n2\n\n\n\nFor example, the experimental units may change (melt, or become more brittle) as it waits its turn to receive a treatment. Or, in an experiment that requires the reuse of tools (such as a cutting tool, or measurement tool) to do the experiment, the calibration or sharpness of the tool may change gradually with each run of the experiment. If people are somehow involved in the administration of the experiment, fatigue or learning may slightly change the way in which the experiment is conducted. In any of these examples, a difference in the response may be due to the order of the experimental run rather than the treatment itself.\nTo prevent confounding due to an “unlucky” treatment randomization, we can implement a more strategic approach to random assignment. Since there are 3 treatments and 6 experimental runs, we can break the 6 experimental runs into two groups, called blocks. Each block will have 3 experimental runs: one for each treatment. Assignment of treatment to experimental run will be done completely at random within each block. In this way, it is like conducting 2 mini-experiments and each treatment is guaranteed to be represented in each phase of the data collection: once in the first 3 runs, and once in the second three runs.\nIn this example order was identified as a source of variation in the response. We are not interested in the effect of order, but wanted to ensure it did not cause confounding with the treatment effect. This type of factor can be called a nuisance factor. Levels of a nuisance factors are often used as blocks.\nIn addition to order in which treatments are applied, the experimental unit itself represents a nuisance source of variation we need to deal with. For example, when studying a new method of teaching, the IQ of the student (i.e. experimental unit) could be considered a nuisance factor. We could assign treatment to students completely at random. But what would happen if, simply by random chance, all the people with low IQ’s were assigned to the control group, and all people with high IQ’s were assigned to receive the new teaching method? The effect of the teaching method would be confounded with the effect of the students’ high IQ.\nAnother common nuisance factor used for blocking is a characteristic of the environment in which the experiment is conducted. For example, researchers desire to study the yield of different types of seeds. The larger field may be divided into smaller subplots. Each subplot is assigned one of the different seeds under development. Each plant in the subplot is then measured. The location of the subplot in which the seeds are planted may be a nuisance factor. Nuisance factors are often general factors that are easily identified, but are actually proxies for other more complex factors that we don’t both to identify or measure. In this case, subplot is a nuisance factor that really represents a lot of other things: soil chemistry, sun exposure, water received, etc.\n\n\nUp to this point, randomization has been our primary tool for dealing with these nuisance factors: we assign subjects to treatment completely at random. However, as we have seen, making assignments completely at random may lead to “unlucky” scenarios that create confounding or bias.\nFurthermore, in some cases, it may not be practical or possible to completely randomize the nuisance factor.\nLast but not least, in a completely randomized design, variation from the uncontrolled and unmeasured nuisance factor is lumped in with the unexplained variation, thereby increasing variance of the residual errors and making it more difficult to find statistical significance.\nInstead of treating the nuisance factor as something not controlled and not measured, with blocking the nuisance factor is incorporated into the design and becomes a factor that is measured during the experiment. Thus, variation in the response due to the nuisance factor is converted from unexplained variance to explained variance. In other words, the mean squared error will decrease. The F statistic for testing significance of treatment effects will increase since it represents the ratio of mean squares for treatments (which remains unchanged) to mean squares for error (which is smaller due to blocking)."
  },
  {
    "objectID": "block_intro.html#blocking-as-an-alternative-to-assignment-completely-at-random",
    "href": "block_intro.html#blocking-as-an-alternative-to-assignment-completely-at-random",
    "title": "Blocking Introduction",
    "section": "",
    "text": "Up to this point, randomization has been our primary tool for dealing with these nuisance factors: we assign subjects to treatment completely at random. However, as we have seen, making assignments completely at random may lead to “unlucky” scenarios that create confounding or bias.\nFurthermore, in some cases, it may not be practical or possible to completely randomize the nuisance factor.\nLast but not least, in a completely randomized design, variation from the uncontrolled and unmeasured nuisance factor is lumped in with the unexplained variation, thereby increasing variance of the residual errors and making it more difficult to find statistical significance.\nInstead of treating the nuisance factor as something not controlled and not measured, with blocking the nuisance factor is incorporated into the design and becomes a factor that is measured during the experiment. Thus, variation in the response due to the nuisance factor is converted from unexplained variance to explained variance. In other words, the mean squared error will decrease. The F statistic for testing significance of treatment effects will increase since it represents the ratio of mean squares for treatments (which remains unchanged) to mean squares for error (which is smaller due to blocking)."
  },
  {
    "objectID": "block_intro.html#block-by-sorting",
    "href": "block_intro.html#block-by-sorting",
    "title": "Blocking Introduction",
    "section": "Block by Sorting",
    "text": "Block by Sorting\nWe return to the above example regarding a study aimed at measuring the effect of a new teaching method. In the section above, we already exposed the potential risks of assigning treatments to people completely at random because differences in starting IQ could get in the way of detecting the true effect of the new teaching method.\nTo block by sorting we would sort the study participants according to their IQ. The treatment factor has two levels: a control group and the new teaching method. Therefore, each block will have just 2 individuals. The people with the top two IQ’s would form the first block, the next two highest IQ individuals would form the second block, and so on until the 2 people with the lowest IQ’s form the last block. Inside each of those blocks, one person will be randomly assigned to receive the control and the other person will receive the new teaching method. This study is blocked on IQ.\nFigure 1 shows the process of assigning treatments to blocks created by sorting.\n\n\n\nFigure 1: Process of Blocking by Sorting\n\n\nThis is also the technique that was used to address the concern about run order in the example at the top of the page. We sorted and grouped the units based on run order."
  },
  {
    "objectID": "block_intro.html#block-by-subdividing-the-experimental-material-into-smaller-sections",
    "href": "block_intro.html#block-by-subdividing-the-experimental-material-into-smaller-sections",
    "title": "Blocking Introduction",
    "section": "Block by Subdividing the Experimental Material into Smaller Sections",
    "text": "Block by Subdividing the Experimental Material into Smaller Sections\nA seed company is experimenting with developing seeds for a new variety of cabbage. Specifically, 3 different seeds have made it to this final stage of testing. The company has fields in multiple states in the United States. They use these fields to test out their new seeds. Though researchers try to treat each field similarly, each field is different in terms of elevation, rain fall, soil chemistry, etc. To address these differences, the researchers decided to treat each field as a block. Each field is divided into 3 subplots. Then each variety of seed is randomly assigned to a subplot in that field. In this way, the researchers have blocked on field; the effect of field is measured and accounted for.\nFigure 21 illustrates this seed example.\n\n\n\nFigure 2: Block by Subdividing"
  },
  {
    "objectID": "block_intro.html#block-by-reusing-experimental-units",
    "href": "block_intro.html#block-by-reusing-experimental-units",
    "title": "Blocking Introduction",
    "section": "Block by Reusing Experimental Units",
    "text": "Block by Reusing Experimental Units\nOur toothbrush example can be tweaked to use blocking. In the basic factorial examples, each person received one treatment. If researchers were concerned that a person’s style and quality of brushing may have a substantial impact on the results of the study, this could be addressed by ensuring that each person tried each brush. The experiment could be set up such that a person uses a particular brush for a set period. Their plaque amount would be measured, their teeth cleaned, and then they would use a different brush for the same set amount of time. The process would repeat until the person had used all 4 brushes. For each person, the order of the brushes would be determined randomly (see Figure 3). In this example, the researchers have blocked on person.\n\n\n\nFigure 3: Block by Reusing Experimental Units"
  },
  {
    "objectID": "block_intro.html#footnotes",
    "href": "block_intro.html#footnotes",
    "title": "Blocking Introduction",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOutline of the United States, by unknown author, is licensed under CC-BY-NC-ND↩︎"
  },
  {
    "objectID": "contrast.html",
    "href": "contrast.html",
    "title": "Contrasts",
    "section": "",
    "text": "The ANOVA F test is considered an omnibus test, meaning it tests all the factor levels of a factor at once. If the test suggests the null hypothesis should be rejected it seems to give rise to more questions than answers. Specifically, you will want to know which factor levels are significantly different from which other factor levels.\nUsually during the design of an experiment, the researcher has specific comparisons in mind that are of particular interest. For example, they may be interested in comparing treatment effects for two dosing levels. These pre-planned comparisons usually drive the experimental design. When it comes time for analysis, an omnibus F-test test may be skipped entirely in favor of jumping directly to the planned comparisons. Or, if the F-test finds statistical significance, the researcher may follow-up with focused post-hoc tests of specific factor levels.\nWhen one factor level mean is compared to another, it is called a pairwise comparison, or simple contrasts. For example, in our toothbrush experiment we may be interested in comparing the oscillating brush to the control group (manual brush). Or we may be especially interested in comparing sonic to ultra sonic.\nLess commonly, the comparison of interest may involve averages of two or more factor level means. This is most likely to occur when the factor levels lend themselves to natural groupings that may be of particular interest to compare. For example, we may want to compare the mean of the sonic and ultrasonic groups to the mean of the oscillating group. Another example might include a comparison of the average of all the “treatment” toothbrushes vs. the control group (manual). When an average across groups is involved, this is called a complex comparison, or linear contrast.\nWe can represent the null hypotheses of these 4 example contrasts as:\n\n\nThough contrast and comparison are technically synonomous, “comparison” most often refers to simple, pairwise comparisons; and “contrast” refers to complex comparisons.\n\n\n\n\nVenn Diagram\n\n\n\n\\(\\begin{aligned} H_0: \\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\nThe above hypotheses can all be expressed as a sum, where each factor level mean is multiplied by a coefficient. When a factor level is not a part of the hypotheses, it has a coefficient of zero.\n\n\nTable 1: Expanded Hypotheses\n\n\n\n\n\n\nFour Null Hypotheses\nLeft Hand Side of Hypotheses Expressed as a Sum of Means and Coefficients\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(-1*\\mu_\\text{man} + 1*\\mu_\\text{osc} + 0*\\mu_\\text{sonic} + 0*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 0*\\mu_\\text{osc} + 1*\\mu_\\text{sonic} + -1*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 1*\\mu_\\text{osc} + -\\frac{1}{2}*\\mu_\\text{sonic} + -\\frac{1}{2}*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\n\\(1*\\mu_\\text{man} + -\\frac{1}{3}*\\mu_\\text{osc} + -\\frac{1}{3}*\\mu_\\text{sonic} + -\\frac{1}{3}*\\mu_\\text{ultra}\\)\n\n\n\n\nThe contents in the right column of Table 1 are referred to as contrasts. We will use the symbol \\(\\psi\\) to represent the contrast. A contrast is formed by multiplying each factor level mean by a coefficient. Simply put, it is a weighted sum. The above hypotheses are all examples of valid contrasts. To be considered a valid contrast, the only restriction is that the sum of the coefficients must be zero. We will often write coefficients used in a contrast as a set, in curly braces as shown in Table 2. Thinking of a contrast in terms of its set of coefficients is helpful for identifying orthogonality of contrasts. Also, when calculating/testing a contrast with software, you are required to input the set (or vector) of coefficients to define the contrast.\n\n\nTable 2: Contrast Coefficients\n\n\n\n\n\n\n\n\\(H_0\\)\nContrast (\\(\\psi\\)) Tested in \\(H_0\\)\nSet of Contrast Coefficients\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(-1*\\mu_\\text{man} + 1*\\mu_\\text{osc} + 0*\\mu_\\text{sonic} + 0*\\mu_\\text{ultra}\\)\n\\(\\{ -1, 1, 0, 0 \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 0*\\mu_\\text{osc} + 1*\\mu_\\text{sonic} + -1*\\mu_\\text{ultra}\\)\n\\(\\{ 0, 0, 1, -1 \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 1*\\mu_\\text{osc} + -\\frac{1}{2}*\\mu_\\text{sonic} + -\\frac{1}{2}*\\mu_\\text{ultra}\\)\n\\(\\{ 0, 1, -\\frac{1}{2}, -\\frac{1}{2} \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\n\\(1*\\mu_\\text{man} + -\\frac{1}{3}*\\mu_\\text{osc} + -\\frac{1}{3}*\\mu_\\text{sonic} + -\\frac{1}{3}*\\mu_\\text{ultra}\\)\n\\(\\{ 1, -\\frac{1}{3}, -\\frac{1}{3}, -\\frac{1}{3} \\}\\)\n\n\n\n\nThere are an infinite number of contrasts that could be tested. Realistically though, the contrasts that make sense to test are generally obvious and depend on your understanding/context of the experiment. Testing pairwise comparisons (i.e. simple contrasts where the coefficients are either -1, 0, or 1) is quite common; averaging across certain factor level means as part of the comparison is less common, but is still something you should be prepared to do. Contrasts can get quite complicated, especially for experiments with complicated designs. In this class though we will stick to relatively simple situations."
  },
  {
    "objectID": "contrast.html#what-is-a-contrast",
    "href": "contrast.html#what-is-a-contrast",
    "title": "Contrasts",
    "section": "",
    "text": "The ANOVA F test is considered an omnibus test, meaning it tests all the factor levels of a factor at once. If the test suggests the null hypothesis should be rejected it seems to give rise to more questions than answers. Specifically, you will want to know which factor levels are significantly different from which other factor levels.\nUsually during the design of an experiment, the researcher has specific comparisons in mind that are of particular interest. For example, they may be interested in comparing treatment effects for two dosing levels. These pre-planned comparisons usually drive the experimental design. When it comes time for analysis, an omnibus F-test test may be skipped entirely in favor of jumping directly to the planned comparisons. Or, if the F-test finds statistical significance, the researcher may follow-up with focused post-hoc tests of specific factor levels.\nWhen one factor level mean is compared to another, it is called a pairwise comparison, or simple contrasts. For example, in our toothbrush experiment we may be interested in comparing the oscillating brush to the control group (manual brush). Or we may be especially interested in comparing sonic to ultra sonic.\nLess commonly, the comparison of interest may involve averages of two or more factor level means. This is most likely to occur when the factor levels lend themselves to natural groupings that may be of particular interest to compare. For example, we may want to compare the mean of the sonic and ultrasonic groups to the mean of the oscillating group. Another example might include a comparison of the average of all the “treatment” toothbrushes vs. the control group (manual). When an average across groups is involved, this is called a complex comparison, or linear contrast.\nWe can represent the null hypotheses of these 4 example contrasts as:\n\n\nThough contrast and comparison are technically synonomous, “comparison” most often refers to simple, pairwise comparisons; and “contrast” refers to complex comparisons.\n\n\n\n\nVenn Diagram\n\n\n\n\\(\\begin{aligned} H_0: \\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\nThe above hypotheses can all be expressed as a sum, where each factor level mean is multiplied by a coefficient. When a factor level is not a part of the hypotheses, it has a coefficient of zero.\n\n\nTable 1: Expanded Hypotheses\n\n\n\n\n\n\nFour Null Hypotheses\nLeft Hand Side of Hypotheses Expressed as a Sum of Means and Coefficients\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(-1*\\mu_\\text{man} + 1*\\mu_\\text{osc} + 0*\\mu_\\text{sonic} + 0*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 0*\\mu_\\text{osc} + 1*\\mu_\\text{sonic} + -1*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 1*\\mu_\\text{osc} + -\\frac{1}{2}*\\mu_\\text{sonic} + -\\frac{1}{2}*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\n\\(1*\\mu_\\text{man} + -\\frac{1}{3}*\\mu_\\text{osc} + -\\frac{1}{3}*\\mu_\\text{sonic} + -\\frac{1}{3}*\\mu_\\text{ultra}\\)\n\n\n\n\nThe contents in the right column of Table 1 are referred to as contrasts. We will use the symbol \\(\\psi\\) to represent the contrast. A contrast is formed by multiplying each factor level mean by a coefficient. Simply put, it is a weighted sum. The above hypotheses are all examples of valid contrasts. To be considered a valid contrast, the only restriction is that the sum of the coefficients must be zero. We will often write coefficients used in a contrast as a set, in curly braces as shown in Table 2. Thinking of a contrast in terms of its set of coefficients is helpful for identifying orthogonality of contrasts. Also, when calculating/testing a contrast with software, you are required to input the set (or vector) of coefficients to define the contrast.\n\n\nTable 2: Contrast Coefficients\n\n\n\n\n\n\n\n\\(H_0\\)\nContrast (\\(\\psi\\)) Tested in \\(H_0\\)\nSet of Contrast Coefficients\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(-1*\\mu_\\text{man} + 1*\\mu_\\text{osc} + 0*\\mu_\\text{sonic} + 0*\\mu_\\text{ultra}\\)\n\\(\\{ -1, 1, 0, 0 \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 0*\\mu_\\text{osc} + 1*\\mu_\\text{sonic} + -1*\\mu_\\text{ultra}\\)\n\\(\\{ 0, 0, 1, -1 \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 1*\\mu_\\text{osc} + -\\frac{1}{2}*\\mu_\\text{sonic} + -\\frac{1}{2}*\\mu_\\text{ultra}\\)\n\\(\\{ 0, 1, -\\frac{1}{2}, -\\frac{1}{2} \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\n\\(1*\\mu_\\text{man} + -\\frac{1}{3}*\\mu_\\text{osc} + -\\frac{1}{3}*\\mu_\\text{sonic} + -\\frac{1}{3}*\\mu_\\text{ultra}\\)\n\\(\\{ 1, -\\frac{1}{3}, -\\frac{1}{3}, -\\frac{1}{3} \\}\\)\n\n\n\n\nThere are an infinite number of contrasts that could be tested. Realistically though, the contrasts that make sense to test are generally obvious and depend on your understanding/context of the experiment. Testing pairwise comparisons (i.e. simple contrasts where the coefficients are either -1, 0, or 1) is quite common; averaging across certain factor level means as part of the comparison is less common, but is still something you should be prepared to do. Contrasts can get quite complicated, especially for experiments with complicated designs. In this class though we will stick to relatively simple situations."
  },
  {
    "objectID": "contrast.html#testing-a-contrast",
    "href": "contrast.html#testing-a-contrast",
    "title": "Contrasts",
    "section": "Testing a Contrast",
    "text": "Testing a Contrast\n\nt-test for Pairwise Comparisons\nPairwise comparisons (i.e. simple contrasts) of means using a t-test is something you are probably familiar with from previous statistics classes. The procedure was most likely called something like, “independent samples t-test of two means”. We can build on that understanding to come up with a more general approach that will allow us to test any contrast.\nRecall, that a t-test for one sample has the general form:\n\\[\nt = \\frac{\\bar{y} - \\mu_0}{s_\\bar{y}}\n\\]\nWhere \\(\\bar{y}\\) is the sample mean, \\(\\mu_0\\) is the value from the null hypothesis, and \\(s_\\bar{y}\\) is the standard error of the mean. We can expand this to test whether a difference of two means is zero, in other words an independent samples t-test of two means. Recall, that in ANOVA we assume constant variance across factor levels. (This is a slightly different assumption, resulting in a slightly different calculation than the independent samples t-tests presented in Math221 and Math3251).\n\n\nStandard error of the mean is equal to standard deviation of the individual observations divided by square root of the sample size, \\(s_\\bar{y} = \\frac{s_y}{\\sqrt{n}}\\). See Math221 text for review.\nIn our toothbrush experiment, if we want to test whether the mean of manual brushes is equal to the mean of oscillating brushes we have for our null hypothesis:\n\\[\nH_0: \\mu_\\text{man} - \\mu_\\text{osc} = 0\n\\]\nWe use a t statistic:\n\\[\nt = \\frac{(\\bar{y}_\\text{man} - \\bar{y}_\\text{osc})}{\\sqrt{s^2_p*(\\frac{1}{n_1} + \\frac{1}{n_2})}}\n\\tag{1}\\]\nThe difference in the numerator is calculated directly from the contrast (multiplying the set of coefficients by their respective factor level mean). In the denominator, the pooled variance (\\(s^2_p\\)) is identical to the mean squared error from the ANOVA summary table. The degrees of freedom for this test statistic are equivalent to the residual degrees of freedom.\n\n\n\n\n\n\nNote, by using the MSE from the ANOVA summary table we are taking advantage of information about residual errors contained in the observations of sonic and ultrasonic brushes as well as the observations from manual and oscillating. This leads to a better estimate of the size of random error.\n\n\n\nFor our study on toothbrushes we have the model:\n\\[\ny_\\text{ij} = \\mu + \\alpha_i + \\epsilon_\\text{ij}\n\\tag{2}\\]\nWhere\n\n\\(y_\\text{ij}\\) is an observation\n\\(\\mu\\) is the grand mean\n\\(\\alpha_i\\) represents the effect of factor level \\(i\\)\n\\(\\epsilon_\\text{ij}\\) is the residual error for the \\(j^\\text{th}\\) observation in factor level \\(i\\)\n\nBelow is the table of factor level means and the ANOVA summary table.\n\n\nCode\n```{r}\n#| label: tbl-brush_analysis\n#| message: false\n#| tbl-cap: \"Toothbrush Experiment Results\"\n#| tbl-subcap:\n#| - \"Factor Level Means\"\n#| - \"ANOVA Summary Table\"\n#| layout-ncol: 2\n#| code-fold: true\n\nbf2 &lt;- read_csv(\"data/toothpaste_BF2.csv\") \n\nmeans_tbl &lt;- bf2 |&gt; group_by(Brush) |&gt; summarise(mean = mean(Plaque),\n                                    `sample size` = n())\nmeans_tbl |&gt; pander::pander()\n\n\nbrush_aov &lt;- aov(Plaque~Brush, data = bf2)\nsummary(brush_aov) |&gt; pander::pander()\n\n#These lines store values in variables so that I can write them in\n#the latex equation below programmatically rather than hardcoding them\nmean_man &lt;- means_tbl[[1,2]]\nmean_osc &lt;- means_tbl[[2,2]]\nnsize &lt;- means_tbl[[1,3]]\nmse &lt;- summary(brush_aov)[[1]][2,3] #This gets the number from the summary table\ntstat &lt;- (mean_man - mean_osc)/sqrt(mse*(1/nsize + 1/nsize))\npprob &lt;- pt(q=tstat, df=brush_aov$df.resid, lower.tail=FALSE) * 2\n```\n\n\n\nTable 3: Toothbrush Experiment Results\n\n\n\n\n(a) Factor Level Means\n\n\n\n\n\n\n\nBrush\nmean\nsample size\n\n\n\n\nManual\n23.09\n6\n\n\nOscillating\n19.98\n6\n\n\nSonic\n22.67\n6\n\n\nUltrasonic\n25.31\n6\n\n\n\n\n\n\n(b) ANOVA Summary Table\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nBrush\n3\n86.31\n28.77\n3.822\n0.02583\n\n\nResiduals\n20\n150.6\n7.528\nNA\nNA\n\n\n\n\n\n\n\nWith that information we can proceed with our whether the mean of manual brushes is equal to the mean of oscillating brushes. Plugging the values from Table 3 into Equation 1 we can calculate the t statistic:\n\\[\nt = \\frac{ 3.11 }{\\sqrt{ 7.53 * (\\frac{1}{ 6 } + \\frac{1}{ 6 })}} = 1.97\n\\tag{3}\\]\nA t statistic of 1.97 leads to a p-value of 0.063. Since the p-value is greater than our traditional alpha of 0.05, we fail to reject the null hypothesis of equality. In other words, there is insufficient evidence to claim that the manual brush and the oscillating brush have different mean values for percent area of teeth with plaque.\n\n\nt-test for Any Contrast\nThis same t-test approach can be extended so that we can test any contrast, not just pairwise comparisons. To extend the approach, recognize that the \\(1's\\) in Equation 3 appearing directly above each sample size actually represent the squared coefficient of the contrast (see Table 1). Thus, Equation 1 used to compare two factor level means, is actually just a special case of a more general formula, Equation 4, which allows us to perform a hypothesis test of any contrast. This equation continues with the general structure of a t statistic: the numerator contains a sample estimate of the difference, the denominator is the standard error of that difference.\n\\[\nt = \\frac{\\hat{\\psi}}{s_\\hat{\\psi}} = \\frac{\\hat{\\psi}}{\\sqrt{MSE * \\sum(c^2_i / n_i)}}\n\\tag{4}\\]\nWhere,\n\n\\(\\hat{\\psi}\\) is an estimate of the contrast, obtained by multiplying each factor level mean by its respective contrast coefficient. For a simple pairwise comparison, it is just the difference in means.\n\\(MSE\\) is the mean squares of residuals obtained from the ANOVA summary table\n\\(c_i\\) is the contrast coefficient for the \\(i^\\text{th}\\) factor level and\n\\(n_i\\) is the sample size of the \\(i^\\text{th}\\) factor level.\n\nThe degrees of freedom for \\(t\\) will be equal to the degrees of freedom for residual error in the ANOVA summary table.\nLet’s use this more general approach in Equation 4 to test the fourth hypothesis contained in Table Table 1. Our alternative hypothesis will be the contrast is not equal to zero. Though you can use directional (i.e. 1-tailed) tests of a contrast, the default is to use a two-tailed alternative hypothesis of “not equal to zero”.\nPlugging the values from Table 3 into Equation 4 we can calculate the t statistic:\nNumerator: \\[\n\\hat{\\psi} = 1 * 23.09 + -\\frac{1}{3} * 19.98 + -\\frac{1}{3} * 22.67 + -\\frac{1}{3} * 25.31 = 0.438\n\\]\nDenominator: \\[\ns_\\hat{\\psi} = \\sqrt{MSE * \\sum(c^2_j / n_j)} = \\sqrt{ 7.53 * \\left( \\frac{1^2}{6} + \\frac{-\\frac{1}{3}^2}{6} + \\frac{-\\frac{1}{3}^2}{6} + \\frac{-\\frac{1}{3}^2}{6} \\right) } = 1.294\n\\]\nt statistic: \\[\nt = \\frac{\\hat{\\psi}}{s_\\hat{\\psi}} = \\frac{0.438}{1.294} = .34\n\\tag{5}\\]\nA test statistic \\(t_\\text{20} = .34\\) is not large enough to be significant.\n\n\n\n\n\n\nCaution\n\n\n\nActually, it does not make a lot of sense to compare the control group (manual brush) to the average of the other three brushes. For a contrast of the control mean vs. average of the treatments to make sense, the treatments would need to have more commonality. For example, if there were two treatments and both used oscillating toothbrushes: one oscillated in a clockwise fashion and the other oscillated in a counter-clockwise. In that case it would make sense to combine the treatment factor levels since they could be interpreted generally as “oscillating brush”. Then you could compare the average of the oscillating groups against the average of the control group (manual brush).\n\n\n\n\nF-test vs. t-test\nWe could have reached exactly the same conclusions by conducting an appropriate F test for the contrast instead of a t-test2. It can be shown that \\(F = t^2\\). When t is based on the degrees of freedom for residuals, and F has \\(df_\\text{numerator}\\) = 1 and \\(df_\\text{denominator} = df_\\text{residuals}\\) , the two tests given identical p-values and thus lead to the same conclusion.\n\n\nR Instructions\nThis section illustrates just one way to test custom contrasts in R. There are many packages, each with their unique syntax, for computing and testing contrasts. As you work more in the field, you may find another package better suits your needs.\nThere are sets of comparisons (a.k.a. contrasts) that are commonly done in practice. The calculation of these sets can be obtained with simpler code than what is shown here but may require other R packages. In addition, when testing multiple contrasts simultaneously there are potentially other adjustments that should be made. Please read “Multiple Comparisons” to understand what other adjustments to consider as well as the R code for conducting these common sets of comparisons.\n\nCaution, the contrasts() function from the stats package in base R will produce the correct p-value for the test of a contrast, but without extra work will not produce the correct estimate of the contrast itself. For this reason, we illustrate estimating and testing the contrast with the emmeans package, which stands for “estimated marginal means”.\nThe first step is to create the model. Then use the emmeans() command to create a grid of factor level summary statistics, including: means, standard deviations, standard error, degrees of freedom associated with the standard error estimate, and confidence intervals around the mean. Unlike a summarize() or favstats() command, emmeans() has the output structured so that it can easily be used in the next step. Store the grid of means into a new object.\n\nmyaov &lt;- aov(Y ~ X, data = df)\nmymeans &lt;- emmeans(myaov, \"X\")\n\n\nmyaov is some name you come up with to store the results of the aov() model.\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\ndf is the name of your data set.\nmymeans is some name you come up with to store the results of the emmeans() command.\n\nDefine the contrasts you are interested in testing inside the contrast() function, which returns the hypothesis test results. You can also feed the result into a confint() function if you prefer confidence intervals over p-values.\n\ncontrast(mymeans,list(name_of_contrast1 = coefficient vector,\n                       name_of_contrast2 = another coefficient vector))) \n\nname_of_contrast are descriptive names you should give to the contrast to help you remember what it represents. The coefficient vector is how you define the contrast.\nWe will repeat the contrasts we did by hand in the sections above, but this time using R.\nExample Code Using Toothbrush Experiment:\n\n\n df The name you want for your dataset  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv(“../data/toothpaste_BF2.csv”) A tidyverse command to read the data in from the specified path  plaque_aov Name you want for your ANOVA model  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  brush_means The name you want for the output of the emmeans command  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left   emmeans(  Function to calculate stats about marginal means  plaque_aov, aov model created in previous step  “Brush” Factor for whose levels you want to calculate means  ) Functions always end with a closing parenthesis  contrast_results Name you want to store contrast results in  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  contrast( Function to define and test contrasts  brush_means, Grid of stats about marginal means you named in the previous step list( create a list object, which allows you to pass multiple contrast coefficient vectors  man_v_osc = A descriptive name to help you remember what the contrast represents  c(1,-1,0,0) Vector of coefficients used to define the contrast  , Seperator to allow additional inputs to the list     man_v_others = A descriptive name to help you remember what the contrast represents  c(1,-(1/3),-(1/3),-(1/3)) Vector of coefficients used to define the contrast  ), A list is closed with a parenthesis  adjust = Specify what type of adjustment (if any) to make for multiple testing. Default is “none” if this argument is not included.  “none” Read help at ?summary.emmGrid for other acceptable values  ) Functions always end with a closing parenthesis  contrast_results View the test results stored in this object in the previous step  confint( Function to create confidence intervals around contrasts  contrast_results Name of object where you stored contrasts  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n contrast     estimate   SE df t.ratio p.value\n man_v_osc       3.117 1.58 20   1.967  0.0632\n man_v_others    0.438 1.29 20   0.339  0.7382\n\n\n\n\n contrast     estimate   SE df lower.CL upper.CL\n man_v_osc       3.117 1.58 20   -0.188     6.42\n man_v_others    0.438 1.29 20   -2.260     3.14\n\nConfidence level used: 0.95"
  },
  {
    "objectID": "contrast.html#othogonal-contrast",
    "href": "contrast.html#othogonal-contrast",
    "title": "Contrasts",
    "section": "Othogonal Contrast",
    "text": "Othogonal Contrast\nStay tuned…Under Construction"
  },
  {
    "objectID": "contrast.html#footnotes",
    "href": "contrast.html#footnotes",
    "title": "Contrasts",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nt-tests of pairwise comparisons with non-constant variance would result in the independent samples t-test presented in Math221 and Math325. More complicated contrasts assuming non-constant variance is explained in Design and Analysis: A Researcher’s Handbook by Keppel, G. and Wickens T.D. (2004, Pearson), starting on page 156.↩︎\nThe appropriate F-test consists of calculating the mean squares of the contrast and dividing by the mean squared error. In most cases, the contrast has 1 degree of freedom, so the contrast sum of squares is equal to the contrast mean squares. The formula to calculate a contrast sum of squares is\n\\[\nSS_{\\psi} = \\frac{n*\\hat{\\psi}^2}{\\sum{c_j^2}}\n\\]\nThe contrast has just 1 degree of freedom because it compares just two sets of observations. This is true even for complex comparisons: each set of observations may come from one factor level, or from a combination of factor levels.↩︎"
  },
  {
    "objectID": "diagnostics.html",
    "href": "diagnostics.html",
    "title": "Model Diagnostics",
    "section": "",
    "text": "A key assumption for ANOVA tests is that the error, or residual term, has a constant variance across all factor levels. This is sometimes call homogeneity of variance, or homoscedasticity.\nWe explain three ways to check the assumption: rule of thumb when comparing standard deviations for each factor level, a visual assessment of the residual vs. fitted plot, and Levene’s test. These methods may not always agree. You should be aware of the underlying data. Understanding why this assumption is important and how it will affect results when violated will help you decide how to proceed after checking these diagnostics. It is also worth noting that the ANOVA F-test is robust in the face of mild to moderate violation of this assumption.\nWe will use the pre-loaded dataset ToothGrowth. To learn more about the dataset, run ?ToothGrowth in the console. len will be our response variable, supp is an independent factor, and dose is the other independent factor. We will analyze this as a two-way, basic factorial design. Because dose is stored as a numeric variable, we will convert it to a categorical variable and rename it dose_f before including it in the model. Don’t forget to load the tidyverse in order to use mutate().\nThe second line in the code below creates an ANOVA model, named aov2th.\n\n\n tg The name you want for your modified dataset  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  ToothGrowth A preloaded dataset in R  |&gt; The result on the left is piped into the first argument of the function on the right  mutate( A tidyverse function to compute a new column for a dataset  dose_f = The name you want to give to the new column  factor( A function to convert a variable from numeric to quantitative  dose A numeric variable in ToothGrowth  )) Functions always end with a closing parenthesis  aov2th A name you come up with for your model  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  len The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  dose_f Column in the tg dataset where doese is stored as a factor  * Crosses two factors. Both simple factors and the interaction factor are included in the model   supp variable with 2 levels of delivery method: orange juice or asorbic acid (vc)  , Seperates multiple input arguments to a function.  data = tg Tell the model that the variable names come from the tg dataset  ) Functions always end with a closing parenthesis \n\n\n\n\n\n\n\n\nA quick rule of thumb to check this assumption is to compare standard deviations across factor levels. If the largest standard deviation is no more than double the smallest standard deviation, then the standard deviations (and the variances) are close enough to be considered equal. Check the R Instructions&gt;Describing Data&gt;Numerical Summaries section of the textbook on how to calculate standard deviations for each factor level.\nIn cases with more than 1 factor, you can compare the standard deviation of each factor level combination (i.e. the interaction factor). Sometimes though, looking at the interaction results in a very small sample size at each level or you may be concerned about a particular factor level of an experimental factor. In that case you may want to apply this rule of thumb to each factor individually. When faced with a situation where the rule of thumb is met for some factors but not for others use your best judgement. An understanding of how a violation may affect your results is critical. You can see that this approach can be tricky to implement, especially as you go beyond studies with just two factors.\n\n\n\nAnother informal approach to checking the constant variance assumption is looking at a residual vs. fitted plot. Similar to the rule of thumb, in situations with more than 1 factor, you can either create a plot that shows all factor level combinations OR look at multiple plots, one for each experimental factor. In order to view this plot, you must first create the ANOVA model. Once the model is created, there are a couple of ways to get a residual vs. fitted plot.\nConstruct the plot manually from vectors within the aov object\nThe plot can be constructed using the vector of residuals and vector of fitted values contained in the aov object.\n\nmyaov &lt;- aov(Y~X*Z, data = YourDataSet)\nplot(myaov$fittedvalues, myaov$residuals)\n\nNote: If you want to know all the named items in an R object, you can run names(object). In this case we have an aov object called myaov. To see what it contains we can run names(myaov) in the console.\nExample code:\n\n\n\n plot( Base R function to create a scatterplot  aov2th$  Look in the aov2th object for the item named on the right of the $  fitted.values  This vector, stored in the aov object, contains the fitted, or predicted, values.  , Seperates multiple input arguments to a function  aov2th$ Look in the aov2th object for the item names on the right of the $  residuals Vector in the aov object that contains model residuals  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\nNote the resulting plot show 6 vertical groupings, one for each factor level combination. (3 dose levels x 2 levels of supp = 6 factor level combinations)\n\n\n\n\n\n\n\nConstruct the plot with a shortcut\nWhen the function plot() is called on an aov object, 4 diagnostic plots are produced. Instead of viewing all four, chose which ones to see with the which= argument. The first of the four plots is the residual vs. fitted plot.\n\nmyaov &lt;- aov(Y~X*Z, data = YourDataSet)\nplot(myaov, which = 1)\n\nExample code:\n\n\n\n plot( Base R function, when fed an aov object it produces 4 diagnostic plots  aov2th,  The aov object for our model  which = Which of the four diagnostic plots do we want  1 The first of the 4 plots is the residual vs. fitted plot  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\nIgnore the red line on the plot. It does not measure variance and so can be distracting.\n\n\n\n\n\n\n\n\n\n\nLevene’s test is a formal hypothesis test to determine if the variances are equal. In essence, this is an ANOVA F-test comparing sample variances across factor levels (as opposed to comparing sample means). A large p-value for the test indicates there is insufficient evidence to conclude one of the variances is different; and therefore the assumption of constant variance is met.\nThis test comes in handy when there are multiple factors in a study and it is burdensome to informally evaluate all their factor level combinations.\n\nmyaov &lt;- aov(Y~X*Z, data = YourDataSet)\ncar::leveneTest(myaov)\n\nExample code:\n\n\n\n car Levene’s test comes from the car package.   :: Allows you to reference functions from the package named on the left without having to load the entire package.  leveneTest( function to run Levene’s test  aov2th name of the aov object to run the test on  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  5  1.7086 0.1484\n      54"
  },
  {
    "objectID": "diagnostics.html#constant-variance-assumption",
    "href": "diagnostics.html#constant-variance-assumption",
    "title": "Model Diagnostics",
    "section": "",
    "text": "A key assumption for ANOVA tests is that the error, or residual term, has a constant variance across all factor levels. This is sometimes call homogeneity of variance, or homoscedasticity.\nWe explain three ways to check the assumption: rule of thumb when comparing standard deviations for each factor level, a visual assessment of the residual vs. fitted plot, and Levene’s test. These methods may not always agree. You should be aware of the underlying data. Understanding why this assumption is important and how it will affect results when violated will help you decide how to proceed after checking these diagnostics. It is also worth noting that the ANOVA F-test is robust in the face of mild to moderate violation of this assumption.\nWe will use the pre-loaded dataset ToothGrowth. To learn more about the dataset, run ?ToothGrowth in the console. len will be our response variable, supp is an independent factor, and dose is the other independent factor. We will analyze this as a two-way, basic factorial design. Because dose is stored as a numeric variable, we will convert it to a categorical variable and rename it dose_f before including it in the model. Don’t forget to load the tidyverse in order to use mutate().\nThe second line in the code below creates an ANOVA model, named aov2th.\n\n\n tg The name you want for your modified dataset  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  ToothGrowth A preloaded dataset in R  |&gt; The result on the left is piped into the first argument of the function on the right  mutate( A tidyverse function to compute a new column for a dataset  dose_f = The name you want to give to the new column  factor( A function to convert a variable from numeric to quantitative  dose A numeric variable in ToothGrowth  )) Functions always end with a closing parenthesis  aov2th A name you come up with for your model  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  len The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  dose_f Column in the tg dataset where doese is stored as a factor  * Crosses two factors. Both simple factors and the interaction factor are included in the model   supp variable with 2 levels of delivery method: orange juice or asorbic acid (vc)  , Seperates multiple input arguments to a function.  data = tg Tell the model that the variable names come from the tg dataset  ) Functions always end with a closing parenthesis \n\n\n\n\n\n\n\n\nA quick rule of thumb to check this assumption is to compare standard deviations across factor levels. If the largest standard deviation is no more than double the smallest standard deviation, then the standard deviations (and the variances) are close enough to be considered equal. Check the R Instructions&gt;Describing Data&gt;Numerical Summaries section of the textbook on how to calculate standard deviations for each factor level.\nIn cases with more than 1 factor, you can compare the standard deviation of each factor level combination (i.e. the interaction factor). Sometimes though, looking at the interaction results in a very small sample size at each level or you may be concerned about a particular factor level of an experimental factor. In that case you may want to apply this rule of thumb to each factor individually. When faced with a situation where the rule of thumb is met for some factors but not for others use your best judgement. An understanding of how a violation may affect your results is critical. You can see that this approach can be tricky to implement, especially as you go beyond studies with just two factors.\n\n\n\nAnother informal approach to checking the constant variance assumption is looking at a residual vs. fitted plot. Similar to the rule of thumb, in situations with more than 1 factor, you can either create a plot that shows all factor level combinations OR look at multiple plots, one for each experimental factor. In order to view this plot, you must first create the ANOVA model. Once the model is created, there are a couple of ways to get a residual vs. fitted plot.\nConstruct the plot manually from vectors within the aov object\nThe plot can be constructed using the vector of residuals and vector of fitted values contained in the aov object.\n\nmyaov &lt;- aov(Y~X*Z, data = YourDataSet)\nplot(myaov$fittedvalues, myaov$residuals)\n\nNote: If you want to know all the named items in an R object, you can run names(object). In this case we have an aov object called myaov. To see what it contains we can run names(myaov) in the console.\nExample code:\n\n\n\n plot( Base R function to create a scatterplot  aov2th$  Look in the aov2th object for the item named on the right of the $  fitted.values  This vector, stored in the aov object, contains the fitted, or predicted, values.  , Seperates multiple input arguments to a function  aov2th$ Look in the aov2th object for the item names on the right of the $  residuals Vector in the aov object that contains model residuals  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\nNote the resulting plot show 6 vertical groupings, one for each factor level combination. (3 dose levels x 2 levels of supp = 6 factor level combinations)\n\n\n\n\n\n\n\nConstruct the plot with a shortcut\nWhen the function plot() is called on an aov object, 4 diagnostic plots are produced. Instead of viewing all four, chose which ones to see with the which= argument. The first of the four plots is the residual vs. fitted plot.\n\nmyaov &lt;- aov(Y~X*Z, data = YourDataSet)\nplot(myaov, which = 1)\n\nExample code:\n\n\n\n plot( Base R function, when fed an aov object it produces 4 diagnostic plots  aov2th,  The aov object for our model  which = Which of the four diagnostic plots do we want  1 The first of the 4 plots is the residual vs. fitted plot  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\nIgnore the red line on the plot. It does not measure variance and so can be distracting.\n\n\n\n\n\n\n\n\n\n\nLevene’s test is a formal hypothesis test to determine if the variances are equal. In essence, this is an ANOVA F-test comparing sample variances across factor levels (as opposed to comparing sample means). A large p-value for the test indicates there is insufficient evidence to conclude one of the variances is different; and therefore the assumption of constant variance is met.\nThis test comes in handy when there are multiple factors in a study and it is burdensome to informally evaluate all their factor level combinations.\n\nmyaov &lt;- aov(Y~X*Z, data = YourDataSet)\ncar::leveneTest(myaov)\n\nExample code:\n\n\n\n car Levene’s test comes from the car package.   :: Allows you to reference functions from the package named on the left without having to load the entire package.  leveneTest( function to run Levene’s test  aov2th name of the aov object to run the test on  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n      Df F value Pr(&gt;F)\ngroup  5  1.7086 0.1484\n      54"
  },
  {
    "objectID": "diagnostics.html#normal-distribution",
    "href": "diagnostics.html#normal-distribution",
    "title": "Model Diagnostics",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nAnother key assumption for ANOVA tests is that the error, or residual, term follows a normal distribution. We use the Q-Q plot to check this assumption. There are two ways to create the Q-Q plot.\nWe will continue to use the aov2th model that was created at the beginning of the Constant Variance section.\nConstruct the Q-Q plot with a shortcut\nWhen the function plot() is called on an aov object, 4 diagnostic plots are produced. Instead of viewing all four, chose which ones to see with the which= argument. The second of the four plots is a normal Q-Q plot.\nExample code:\n\n\n\n plot( Base R function, when fed an aov object it produces 4 diagnostic plots  aov2th,  The aov object for our model  which = Which of the four diagnostic plots do we want  2 The second of the 4 plots is the normal Q-Q plot  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n\n\n\n\n\n\nThe advantage of this method is that you can easily get the residual vs. fitted plot and the normal Q-Q plot with one command by providing the which = argument a vector containing the values 1 and 2. (The : is shorthand to create a vector that starts at the value of the left of the : and increments by 1 until reaching the value on the right side of the :.)\n\nmyaov &lt;- aov(Y~X*Z, data = YourDataSet)\nplot(myaov, which = 1:2)\n\nThe disadvantage of this method is that it can be difficult to determine if the points follow the line closely enough. To help with this decision, you may prefer to use the Q-Q plot from the car package.\nConstruct the Q-Q plot from the car package\nThe Q-Q plot from the car package provides boundary lines. When points are out of the boundaries that is evidence that the normal residual assumption is violated.\nYou can customize the way the acceptable region for points is designated. The default is shading a region. Below is code to draw dashed-line boundary.\nExample code:\n\n\n\n car qqPlot comes from the car package.   :: Allows you to reference functions from the package named on the left without having to load the entire package.  qqPlot( function to a Q-Q plot from the car package  aov2th, name of the aov object  envelope = Argument to control the formatting for the acceptable region for points  list( There are potentially many arguments to affect the envelope, so they are provided as a list.  style = “filled” shading, boundary “lines”, or none  “lines” designate the acceptable region with lines  ) Functions always end with a closing parenthesis  , A comma separates the inputs to a function, in this case the qqPlot function  id = FALSE This argument tells R to display the row number of the 2 most extreme vertical values or not.  ) Functions always end with a closing parenthesis  Toggle output Toggle Output."
  },
  {
    "objectID": "diagnostics.html#independent-errors",
    "href": "diagnostics.html#independent-errors",
    "title": "Model Diagnostics",
    "section": "Independent Errors",
    "text": "Independent Errors\nAn order plot can serve as a partial check of the assumption that the residuals are independent. If there are patterns/trends in the plot that may be grounds to say the assumption is violated.\nThe plot assumes that the dataset is sorted in the same order the data was recorded. If the data has been re-sorted or is from an observational study (i.e. the chronology of collection is unknown or irrelevant) the order plot does not make sense as a check of independence.\nExample code:\n\n\n\n plot( A function to plot the data  aov2th Name you gave your model  $ Access a named object within an object  residuals residuals of the model  ) Functions always end with a closing parenthesis  Toggle output Toggle Output."
  },
  {
    "objectID": "examples/mosquito.html",
    "href": "examples/mosquito.html",
    "title": "Mosquitos",
    "section": "",
    "text": "Code\nlibrary(mosaic)\nlibrary(DT)\nlibrary(pander)\nlibrary(car)\nlibrary(tidyverse)\n\n## Data from original article:\nmosquito &lt;- read_csv(\"../data/mosquito_patch.csv\")"
  },
  {
    "objectID": "examples/mosquito.html#background",
    "href": "examples/mosquito.html#background",
    "title": "Mosquitos",
    "section": "Background",
    "text": "Background\nFive pre-treated patches were compared to to see which material did the best in reducing mosquito human contact for the Armed Forces in India. The five treatments included Odomos(1), Deltamethrin (2), Cyfluthrin(3), D+O(4), C+O(5) Each of the treatments included 30 replicates per treatment\nSource: A. Bhatnagar and V.K. Mehta (2007). “Efficacy of Deltamethrin and Cyfluthrin Impregnated Cloth Over Uniform Against Mosquito Bites,” Medical Journal Armed Forces India, Vol. 63, pp. 120-122"
  },
  {
    "objectID": "examples/mosquito.html#analysis",
    "href": "examples/mosquito.html#analysis",
    "title": "Mosquitos",
    "section": "Analysis",
    "text": "Analysis\nApplying a one-way ANOVA to this study, we have the following model:\n\\[\ny_{ij} = \\mu + \\alpha_i + \\epsilon_{ij}\n\\]\nWhere \\(y_{ij}\\) is the \\(j^{th}\\) observation from treatment \\(i\\)\n\\(\\mu\\) is the grand mean of the dataset.\n\\(\\alpha_i\\) is the effect of the treatment as described in the background.\n\\(\\epsilon_{ik}\\): the error term, or residual term of the model. Since there are 30 subjects for each treatment, \\(j\\) ranges from 1 to 30.\nApplying a one-way ANOVA to this study, we have the null hypothesis that the effect of human mosquito contact, represented by α, is equal for each of the factors. This is formally written as follows. \\[ H_0:\\alpha_\\text{Odomos} = \\alpha_\\text{Deltamethrin} = \\alpha_\\text{Cyfluthrin} = \\alpha_\\text{D+O} = \\alpha_\\text{C+O} = 0 \\] The alternative hypothesis states that at least one of the effects due to material is different than zero \\[ H_a: \\text{at least one } \\alpha \\text{ is different than 0} \\] Using these hypotheses will allow for us to address the question whether any of the materials are better at minimizing mosquito-human contact.\n\nHypothesis test\nWe will use a level of significance of α = 0.05 for the analysis.\nFor the analysis, we perform the following one-way ANOVA\n\n\nCode\nmosquito &lt;- mosquito %&gt;% \n   mutate(\n         Treatment = case_when(\n           trt.mosq %in% 1  ~ \"Odomos\",\n           trt.mosq %in% 2  ~ \"Deltamethrin\",\n           trt.mosq %in% 3  ~ \"Cyfluthrin\",\n           trt.mosq %in% 4  ~ \"D+O\",\n           trt.mosq %in% 5  ~ \"C+O\"\n          )\n        )\n\nmosquito.aov &lt;- aov(y.mosq ~ Treatment, data=mosquito)\nsummary(mosquito.aov) %&gt;% pander()\n\n\n\nAnalysis of Variance Model\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nTreatment\n4\n184.6\n46.16\n4.48\n0.001924\n\n\nResiduals\n145\n1494\n10.3\nNA\nNA\n\n\n\n\n\nThe p-value for this test is significant (p = 0.001924). Based on this result, the null hypothesis is rejected and we have sufficient evidence that at least one of the effects due to material is different for human mosquito contact.\nThe requirements of equal variances for ANOVA is met. This is shown by the residual versus fitted plot, which shows roughly a constant variance within each vertical group of dots. The QQ-plot of residuals on the right shows some non-normality as evidenced by some of the points outside of the dashed line boundaries. However, it is not severe and we will move forward with the analysis.\n\n\nCode\npar(mfrow=c(1,2))\nplot(mosquito.aov, which=1, pch=16)\nqqPlot(mosquito.aov, id=FALSE)\n\n\n\n\n\nThe following plot shows which types of material minimize the human mosquito contact.\n\n\nCode\nboxplot(y.mosq ~ as.factor(Treatment), data=mosquito, main=\"Human Mosquito Contact Based on Type of Material\", xlab =\"Treatment\", ylab = \"Amount of Mosquito Human Contact\")\n\n\n\n\n\nThe averages are illustrated with the blue line in the plot above and the table below shows the means, standard deviations, and sample sizes for each of the five different materials.\n\n\nCode\nfavstats(y.mosq ~ Treatment, data=mosquito) %&gt;% \n  select(Treatment,mean,sd,n) %&gt;% \n  arrange(mean) %&gt;% \n  pander()\n\n\n\n\n\n\n\n\n\n\n\nTreatment\nmean\nsd\nn\n\n\n\n\nC+O\n5.367\n3.068\n30\n\n\nD+O\n6.333\n3.121\n30\n\n\nOdomos\n7.901\n3.366\n30\n\n\nCyfluthrin\n8.033\n3.01\n30\n\n\nDeltamethrin\n8.133\n3.46\n30\n\n\n\n\n\n\n\nPairwise comparisons\nWe now that smallest mean (C+O) must be different than the largest mean (Deltamethrin) because the F-test was significant above. In order to better understand which treatments perform better than which other treatments we will look at all pairwise comparisons and apply Tukey’s correction to the family error rate.\n\n\nCode\n#This code would work, but...\n# TukeyHSD(mosquito.aov, \"Treatment\")\n\n#I want to do this fancy stuff below to sort the output\nTukeyHSD(mosquito.aov, \"Treatment\")$Treatment %&gt;% \n  as_tibble(rownames = \"id\") %&gt;% \n  arrange(`p adj`) %&gt;% #Have to put the column name in back ticks since it has a space\n  pander() \n\n\n\n\n\n\n\n\n\n\n\n\nid\ndiff\nlwr\nupr\np adj\n\n\n\n\nDeltamethrin-C+O\n2.766\n0.4764\n5.056\n0.009359\n\n\nCyfluthrin-C+O\n2.666\n0.3761\n4.955\n0.01367\n\n\nOdomos-C+O\n2.534\n0.2441\n4.823\n0.02204\n\n\nDeltamethrin-D+O\n1.8\n-0.4899\n4.089\n0.1965\n\n\nD+O-Cyfluthrin\n-1.699\n-3.989\n0.5902\n0.2477\n\n\nOdomos-D+O\n1.567\n-0.7222\n3.857\n0.3268\n\n\nD+O-C+O\n0.9663\n-1.323\n3.256\n0.7707\n\n\nOdomos-Deltamethrin\n-0.2323\n-2.522\n2.057\n0.9986\n\n\nOdomos-Cyfluthrin\n-0.132\n-2.422\n2.158\n0.9999\n\n\nDeltamethrin-Cyfluthrin\n0.1003\n-2.189\n2.39\n1\n\n\n\n\n\nC+O is significantly lower than 3 of the treatments at the 0.05 level; and no other treatment has a sample mean lower than C+O’s."
  },
  {
    "objectID": "examples/mosquito.html#interpretation",
    "href": "examples/mosquito.html#interpretation",
    "title": "Mosquitos",
    "section": "Interpretation",
    "text": "Interpretation\nIt appears the the best type of material is the C+O material to minimize the amount of mosquito human contact. The lowest mean came from the C+O material where the average amount of mosquito/human contact was 5.367. With a mean of 6.333, D+O was not significantly different than C+O and could also be an option. Conducting a new experiment that focuses on the difference between C+O and D+O and gives them a larger sample size in order to better detect significant would be reasonable.\nA future study could look into other types of material as well as doing this analysis at different locations throughout the world."
  },
  {
    "objectID": "experimental_units.html",
    "href": "experimental_units.html",
    "title": "Experimental Units",
    "section": "",
    "text": "The experimental unit is the subject of the experiment. It is the entity to which the treatment factor levels are assigned. The observational unit is the entity on which the response measurements are taken. It is important to differentiate between the two, in cases in which they are different. It is important to consider the research objectives when determining the experimental unit and observational unit. Research objectives need to be revised when the experimental and observational units are not clearly defined. We will illustrate this importance by using two different examples.\nThe first example will study to see if a specific SAT prep class improves individual’s SAT math scores. Twenty randomly selected students are randomly divided into two groups. One group will take the prep class and the other group will not take the class. In this case the experimental unit is the student because factor level assignments were made for each student. The observational unit is also the student because the math scores are measured for each student.\nThe next example will be slightly, but distinctly different. In this case, we will be applying a new teaching method to a math classroom to see if it improves math scores. Six randomly selected classrooms are randomly divided into 2 groups. One group will be randomly assigned the new teaching method and the other group will be randomly assigned the standard method. Within each classroom there are 25 students and math scores will be taken from each student. In this case, the classrooms are the experimental unit because the factor levels are assigned to each classroom. The students are the observational unit because the scores are measured for each student. The new teaching method will have 75 observations (3 classrooms with 25 students in each). However, the research objectives are concerning the classroom, and assignments of the teaching method are made at the classroom level, so the number of experimental units for each teaching method is just 3 for this analyses. Even though there were many observations, the limited number of experimental units limits the ability to make convincing inference to the broader population. We would like more classrooms involved be be more sure the succes/failure of the new teaching method was not due to a few particularly good/bad teachers. The researcher needs to be aware when this type of sampling is occurring so that a more complex analysis technique can be used to tease out the effect of teachers vs. method - and enhance our ability to make inference. This technique is discussed in further detail with the Nested Factor Designs.\nNow let’s apply this to the toothbrush study. Each person will be assigned to use one type of toothbrush, so person is the experimental unit. The measurements will be taken from teeth, so the observational unit will be tooth. If measurements are taken from multiple teeth, then a more complex design, like the Nested Factor designs should be considered."
  },
  {
    "objectID": "hoveRmd/BF1_R_Instructions.html",
    "href": "hoveRmd/BF1_R_Instructions.html",
    "title": "BF1 R Instructions",
    "section": "",
    "text": "df A name you come up with for your dataset  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv( a command from the tidyverse to read in csv files  “data/toothpaste_BF2.csv” The path to the csv file containing the data  ) Functions always end with a closing parenthesis  plaque_aovA name you come up with for your model  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  summary( Give important information about an object. When called on an aov object the default is to print the ANOVA table  plaque_aov  Whatever you named your ANOVA model in the previous line   )  Functions always end with a closing parenthesis  Click to view output Click to View Output. \n\n\n\n\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "hoveRmd/contrast_R_instructions.html",
    "href": "hoveRmd/contrast_R_instructions.html",
    "title": "Math326 Notebook",
    "section": "",
    "text": "Caution, the contrasts() function from the stats package in base R will produce the correct p-value for the test of a contrast, but without extra work will not produce the correct estimate of the contrast itself. For this reason, we illustrate estimating and testing the contrast with the emmeans package, which stands for “estimated marginal means”.\nThe first step is to create the model. Then use the emmeans() command to create a grid of factor level summary statistics, including: means, standard deviations, standard error, degrees of freedom associated with the standard error estimate, and confidence intervals around the mean. Unlike a summarize() or favstats() command, emmeans() has the output structured so that it can easily be used in the next step. Store the grid of means into a new object.\n\nmyaov &lt;- aov(Y ~ X, data = df)\nmymeans &lt;- emmeans(myaov, \"X\")\n\n\nmyaov is some name you come up with to store the results of the aov() model.\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\ndf is the name of your data set.\nmymeans is some name you come up with to store the results of the emmeans() command.\n\nDefine the contrasts you are interested in testing inside the contrast() function, which returns the hypothesis test results. You can also feed the result into a confint() function if you prefer confidence intervals over p-values.\n\ncontrast(mymeans,list(name_of_contrast1 = coefficient vector,\n                       name_of_contrast2 = another coefficient vector))) \n\nname_of_contrast are descriptive names you should give to the contrast to help you remember what it represents. The coefficient vector is how you define the contrast.\nWe will repeat the contrasts we did by hand in the sections above, but this time using R.\nExample Code Using Toothbrush Experiment:\n\n\n df The name you want for your dataset  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv(“../data/toothpaste_BF2.csv”) A tidyverse command to read the data in from the specified path  plaque_aov Name you want for your ANOVA model  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  brush_means The name you want for the output of the emmeans command  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left   emmeans(  Function to calculate stats about marginal means  plaque_aov, aov model created in previous step  “Brush” Factor for whose levels you want to calculate means  ) Functions always end with a closing parenthesis  contrast_results Name you want to store contrast results in  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  contrast( Function to define and test contrasts  brush_means, Grid of stats about marginal means you named in the previous step list( create a list object, which allows you to pass multiple contrast coefficient vectors  man_v_osc = A descriptive name to help you remember what the contrast represents  c(1,-1,0,0) Vector of coefficients used to define the contrast  , Seperator to allow additional inputs to the list     man_v_others = A descriptive name to help you remember what the contrast represents  c(1,-(1/3),-(1/3),-(1/3)) Vector of coefficients used to define the contrast  ), A list is closed with a parenthesis  adjust = Specify what type of adjustment (if any) to make for multiple testing. Default is “none” if this argument is not included.  “none” Read help at ?summary.emmGrid for other acceptable values  ) Functions always end with a closing parenthesis  contrast_results View the test results stored in this object in the previous step  confint( Function to create confidence intervals around contrasts  contrast_results Name of object where you stored contrasts  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n contrast     estimate   SE df t.ratio p.value\n man_v_osc       3.117 1.58 20   1.967  0.0632\n man_v_others    0.438 1.29 20   0.339  0.7382\n\n\n\n\n contrast     estimate   SE df lower.CL upper.CL\n man_v_osc       3.117 1.58 20   -0.188     6.42\n man_v_others    0.438 1.29 20   -2.260     3.14\n\nConfidence level used: 0.95"
  },
  {
    "objectID": "contrast.html#othogonal-contrasts",
    "href": "contrast.html#othogonal-contrasts",
    "title": "Contrasts",
    "section": "Othogonal Contrasts",
    "text": "Othogonal Contrasts\nIn ANOVA, the variability in a dataset is decomposed, or allocated, to the various factors contributing to that variance. This total variability is called Sums of Squares. The Sums of Squares for a particular factor can further be decomposed, or allocated. Most of the time the variability is allocated to simple contrasts (i.e. a comparison of factor level means). Sometimes however, there is a desire to create a more complex contrast as we have seen above. When two contrasts do not share any information, or have any overlap in how their sums of squares are calculated, they are said to be orthogonal. Stated another way, the variability in one contrast is not correlated with the variability in another. This means that the information gained from one contrast is completely independent of the information gained in another, orthogonal contrast.\nYou can use a set of orthogonal contrasts to split the Sums of Squares for a factor into pieces, one piece for each contrast. There is a limit to how many contrasts can be tested for a given factor. That limit is the factor’s degrees of freedom. Testing sets of non-orthogonal contrasts can effect your Type I family error rate because the information contained in the contrasts is not independent.\n\nAssess Orthogonality\nTwo contrasts are orthogonal if the dot product of the coefficient vectors equals zero. The term “dot product” means that corresponding elements of a vector are multiplied, and then those products are summed together.\nLet’s determine if the contrasts listed in Table 2 are orthogonal to one another. On the right hand side of Table 2 the coefficient vector of the contrast is listed. We will investigate 2 of the 6 pairs of contrasts.\nFirst, we will assess whether the contrast \\(\\mu_{osc} - \\mu_{man}\\) is orthogonal to \\(\\mu_{sonic}- \\mu_{ultra}\\).\n\n\nTable 4: First Pair of Contrasts Showing Orthogonal Contrasts\n\n\n\n\n\n\n\n\n\n\nContrast\nSet of Contrast Coefficients\nman. coef.\nosc. coef.\nsonic coef.\nultra coef.\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} \\end{aligned}\\)\n\\(\\{ -1, 1, 0, 0 \\}\\)\n-1\n1\n0\n0\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} \\end{aligned}\\)\n\\(\\{ 0, 0, 1, -1 \\}\\)\n0\n0\n1\n-1\n\n\n\nProduct of Coefficients\n\\(-1 \\times 0 = 0\\)\n\\(1 \\times 0 = 0\\)\n\\(0 \\times 1 = 0\\)\n\\(0 \\times -1 = 0\\)\n\n\n\n\nIn the last row of Table 4, the product of the elements of the coefficient vectors are calculated. The sum of these products \\(0 + 0 + 0 + 0 = 0\\). Because the sum of the products is zero, we conclude the first two contrasts listed in Table 2 are orthogonal.\nNext, we will assess whether the contrast \\(\\mu_{osc} - \\mu_{man}\\) is orthogonal to \\(\\mu_{osc}- \\frac{\\mu_{sonic} + \\mu_{ultra}}{2}\\).\n\n\nTable 5: Comparing a Different Set of Contrasts that Are NOT Orthogonal Contrasts\n\n\n\n\n\n\n\n\n\n\nContrast\nSet of Contrast Coefficients\nman. coef.\nosc. coef.\nsonic coef.\nultra coef.\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} \\end{aligned}\\)\n\\(\\{ -1, 1, 0, 0 \\}\\)\n-1\n1\n0\n0\n\n\n\\(\\begin{aligned}\\mu_{osc}- \\frac{\\mu_{sonic} + \\mu_{ultra}}{2} \\end{aligned}\\)\n{ 0, 1, \\(-\\frac{1}{2}\\), \\(-\\frac{1}{2}\\) }\n0\n1\n\\(-\\frac{1}{2}\\)\n\\(-\\frac{1}{2}\\)\n\n\n\nProduct of Coefficients\n\\(-1 \\times 0 = 0\\)\n\\(1 \\times 1 = 1\\)\n\\(0 \\times -\\frac{1}{2} = 0\\)\n\\(0 \\times -\\frac{1}{2} = 0\\)\n\n\n\n\nIn Table 5 the product of the elements of the coefficient vectors are calculated in the last row. The sum of these products is \\(0 + 1 + 0 + 0 = 1\\). Because the sum of the products is NOT zero, we conclude that these two contrasts are NOT orthogonal.\nIt has been shown how to determine orthogonality for the contrasts contained in first two rows of Table 6 below. The orthogonality of the other contrast pairs is left to the reader to work through. However, the answers are displayed so that you may check your work.\n\n\nTable 6: Orthogonality of Contrasts from Table 2\n\n\n\n\n\n\n\nContrast Row #’s from Table 2\n\nOrthogonality\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man}\\end{aligned}\\)\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra}\\end{aligned}\\)\northogonal\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man}\\end{aligned}\\)\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} \\end{aligned}\\)\nnot orthogonal\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man}\\end{aligned}\\)\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3}\\end{aligned}\\)\nnot orthogonal\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra}\\end{aligned}\\)\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} \\end{aligned}\\)\northogonal\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra}\\end{aligned}\\)\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3}\\end{aligned}\\)\northogonal\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} \\end{aligned}\\)\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3}\\end{aligned}\\)\nnot orthogonal"
  },
  {
    "objectID": "multiple_comparisons.html",
    "href": "multiple_comparisons.html",
    "title": "Multiple Comparison",
    "section": "",
    "text": "In this page, the approach to dealing with multiple contrasts is explained. Specifically, whether and how to adjust the tests of multiple contrasts to account for an inflated family wise error rate. A few techniques are described, with a focus on when to use which technique. Lastly, instructions and example code is provided for carrying out each technique in R.\nIn most good experiments, researchers are interested in more than just one contrast. Conducting multiple tests on the levels of a factor can inflate the family wise Type I error rate, as illustrated in the “Multiple T-tests” section of the ANOVA page. There is considerable disagreement among statisticians about how to approach the issue of multiple tests. The debate primarily focuses on whether to proactively take steps that will mitigate the inflated family wise error rate or not. To further complicate matters, if an adjustment is desired, there are multiple techniques to choose from. An exhaustive presentation of the arguments on either side is not attempted in this text. Though, a few of the key ideas will naturally emerge as the different approaches are discussed.\n\n\nThe terms “contrast” and “comparison” are treated here as synonymous. Comparison is used more often to refer to testing a difference in factor level means. Read Contrasts for more explanation of these terms."
  },
  {
    "objectID": "multiple_comparisons.html#bonferroni",
    "href": "multiple_comparisons.html#bonferroni",
    "title": "Multiple Comparison",
    "section": "Bonferroni",
    "text": "Bonferroni\nThe Bonferroni adjustment is best for a handful of pre-planned contrasts. As the number of contrasts grows, the adjustment quickly becomes too conservative (i.e. makes it too hard to find significance). In that case, other methods may strike a better balance between Type I and Type II errors.\n\n\nType I error occurs when a true hypothesis is rejected. Type II error occurs when a false hypothesis is not rejected.\nIt can be shown that in order to not exceed a desired family wise error rate of \\(\\alpha_\\text{fw}\\), for a set of \\(k\\) contrasts, each individual contrast should be tested at a significance level of \\(\\frac{\\alpha_\\text{fw}}{k}\\). For example, if we desire a family wise error rate of 0.05 and plan to do 5 tests, each individual contrast must have a p-value less than \\(\\frac{0.05}{5} = 0.01\\) to be considered significant. The test itself has not changed, only the benchmark p-value for claiming significance. This adjustment is easy to understand and to calculate."
  },
  {
    "objectID": "multiple_comparisons.html#scheffé",
    "href": "multiple_comparisons.html#scheffé",
    "title": "Multiple Comparison",
    "section": "Scheffé",
    "text": "Scheffé\nUsing experimental results to suggest which contrasts to test is often referred to as “data snooping” or exploratory analysis. For example, you may look at graphical and numerical summaries to see which means (or combinations of means) will be promising to test. The problem with this approach is that you have essentially done a quick, informal test of many differences when you looked at descriptive statistics and plots. In other words, you have already tested the means and combinations of the means in your mind. The Type I error rate of the contrasts will be different (higher) than stated because you are only formally applying the test to those that look significant already.\nScheffé’s method is most useful when many contrasts are tested, especially when going beyond pairwise comparisons of factor level means to test combined factor levels (i.e. complex comparisons). In data exploration, there are theoretically an infinite number of contrasts you could test. This is not a problem for Scheffé’s adjustment because, unlike other adjustment techniques, Scheffé’s adjustment does not depend on the number of comparisons to be made. Rather, it is determined only by the number of factor levels and the number of observations.\nThe F statistic used to test a contrast in Scheffé’s adjustment is related to the omnibus F test for the factor itself, and is given by:\n\\[\nF_\\text{Scheffé} = (k-1)*F\n\\]\nWhere \\(F\\) is the statistic for the F test of the factor as usual. \\(k\\) is the number of levels in that factor. \\(F_\\text{Scheffé}\\) has \\(df_\\text{numerator} = k-1\\) and \\(df_\\text{denominator} = df_\\text{residual}\\). Scheffé’s test output is often in terms of a t test. Recall that the t statistic is simply the square root of the F statistic.\nIf you are interested in only a specific set of hypotheses (all pairwise comparisons, or all treatment levels vs. control, or all levels compared to the “best” level, etc.) there may be another adjustment technique that will provide better statistical power. Two of which are mentioned below."
  },
  {
    "objectID": "multiple_comparisons.html#methods-designed-for-all-pairwise-comparisons",
    "href": "multiple_comparisons.html#methods-designed-for-all-pairwise-comparisons",
    "title": "Multiple Comparison",
    "section": "Methods Designed for All Pairwise Comparisons",
    "text": "Methods Designed for All Pairwise Comparisons\nWhether it is an exploratory analysis or a pre-planned set of contrasts, many researchers want to test all factor level means against each other. This is usually referred to as testing all pairwise comparisons. Because this situation is so common, two approaches are described below.\n\nTukey’s HSD\nIf a multiple comparison adjustment is desired for testing all pairwise comparisons, a standard approach is to apply Tukey’s Honest Significant Difference (HSD) technique. Occasionally, in the case of few factor levels, Bonferroni’s adjustment may result in more significant findings. If that is the case, use Bonferroni’s correction instead.\nThe calculation for this test is based on the distribution of \\(Q\\). The test statistic \\(Q\\) is sometimes called the studentized range distribution. “Range” is a reference to the numerator where the difference between a maximum and a minimum is calculated. “Studentized” because we are dividing by the estimated standard error, a technique for standardizing famously employed by Student’s (a.k.a. William Gossett) t test. \\(Q\\) is calculated as:\n\\[\nQ = \\frac{max(T_i) - min(T_i)}{\\sqrt{\\frac{MSE}{n}}}\n\\tag{1}\\]\n\n\\(MSE\\) is an estimate of the random error variance\n\\(n\\) is the number of replicates at each factor level. For unequal sample sizes the formula changes somewhat and the result of this test may have a lower Type I error rate than claimed\nThe observations for each level are generated by a different random variable: \\(k\\) variables total, one for each level. Each random variable is normally distributed with mean zero and standard deviation estimated by the denominator of Equation 1. \\(max(T_i)\\) is the maximum value of the \\(k\\) random variables, \\(min(T_i)\\) is the minimum.\nThe distribution of \\(Q\\) will depend on the number of treatments being compared, \\(k\\), and the number of degrees of freedom for error.\n\n\n\nFisher’s LSD\nMaking adjustments for multiple contrasts is a conservative approach, meaning it is more difficult to claim significance compared to when no adjustment is made. Though these adjustments prevent understating the probability of Type I error, they increase the probability of Type II error for each individual contrast. In exploratory analysis where you are looking for hints of what to study further, a Type II error may be a greater concern than Type I.\nFor example, consider a screening study intended to narrow down the number of factors studied in a future experiment. In this case, accidentally ruling out something early on that actually does have a significant impact on the response is more egregious than letting a non-significant factor through to the next experiment where it’s non-significance will be discovered.\nFisher’s Least Significant Difference (LSD) employs no adjustment at all to the pairwise comparisons. However, before proceeding to test pairwise comparisons, the F test for the factor must be significant. Using the less powerful F test as a gatekeeper to the more powerful pairwise t tests serves as a partial protection against extreme Type I errors inflation.\nIn summary, Fisher’s LSD is a two step process. First, verify the F test for the factor is significant. Second, if it is, proceed with all pairwise comparisons without any adjustment. Fisher’s LSD tends to be used in studies where many factors are present, especially screening/exploratory studies."
  },
  {
    "objectID": "multiple_comparisons.html#bonferonni",
    "href": "multiple_comparisons.html#bonferonni",
    "title": "Multiple Comparison",
    "section": "Bonferonni",
    "text": "Bonferonni\nThere are two ways to implement the Bonferroni adjustment illustrated below using the contrasts that were tested in the R Instructions section of the Contrast page.\n\nRecalculate an Alpha Level by Hand\nFirst, the Bonferroni adjustment is shown using output provided for a test of contrasts without adjustment. The code and output from the R Instructions section of the Contrast page is provided again here for convenience. These two contrasts test the mean of the manual brush against the oscillating brush mean, as well as the manual brush mean against the mean of all the other brushes combined.\n\n\nCode\ncontrast_results &lt;- contrast(brush_means,\n                             list(man_v_osc = c(1,-1,0,0),\n                                  man_v_others = c(1,-(1/3),-(1/3),-(1/3))), \n                             adjust=\"none\")\n\n#kable commands are for formatting the output\ncontrast_results |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nman_v_osc\n3.12\n1.58\n20\n1.97\n0.06\n\n\nman_v_others\n0.44\n1.29\n20\n0.34\n0.74\n\n\n\n\n\n\n\n\nA new alpha level against which to compare the p-values can be calculated by hand. Since there are two tests, if the intent was to keep the family wise error rate of 0.05, the alpha level for each individual test is \\(\\frac{0.05}{2} = 0.025\\). To be considered significant, the contrast’s p-value must be less than 0.025.\nman_v_osc has a p-value of 0.06; man_v_others has a p-value of 0.74. Since neither contrast has a p-value less than 0.025 we conclude that the contrasts are not statistically significant.\n\n\nMake the Adjustment in R\nSecond, the Bonferroni adjustment is applied by changing the value of the adjust = argument in the contrast() function from “none” to “bon”.\n\n\nCode\nbon_results &lt;- contrast(brush_means,\n                        list(man_v_osc = c(1,-1,0,0),\n                             man_v_others = c(1,-(1/3),-(1/3),-(1/3))), \n                        adjust=\"bon\")\n\n#kable commands are for formatting the output\nbon_results |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nman_v_osc\n3.12\n1.58\n20\n1.97\n0.13\n\n\nman_v_others\n0.44\n1.29\n20\n0.34\n1.00\n\n\n\n\n\n\n\n\nIn these results the p-values have simply been multiplied by 2 because there were 2 contrasts in the set being tested. Each test can be compared to our desired family wise error rate as usual. Since each test has a p-value greater than 0.05 we conclude that the contrasts are not statistically significant.\nNote, for man_v_others the p-value is capped at 1.00 since a p-value cannot exceed 1.00."
  },
  {
    "objectID": "multiple_comparisons.html#scheffé-1",
    "href": "multiple_comparisons.html#scheffé-1",
    "title": "Multiple Comparison",
    "section": "Scheffé",
    "text": "Scheffé\nSimilar to how the Bonferroni adjustment was applied, to apply a Scheffé adjustment, change the value of the adjust = argument in the contrast() function from “none” to “scheffe”.\n\n\nCode\ncontrast(brush_means, \n         list(man_v_osc = c(1,-1,0,0),\n              man_v_others = c(1,-(1/3),-(1/3),-(1/3))),\n         adjust=\"scheffe\") |&gt; \n\n  #kable commands are for formatting the output\n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nman_v_osc\n3.12\n1.58\n20\n1.97\n0.17\n\n\nman_v_others\n0.44\n1.29\n20\n0.34\n0.94\n\n\n\n\n\n\n\n Each contrast’s p-value can be compared to our desired family wise error rate of 0.05. Since each test has a p-value greater than 0.05 we conclude that the contrasts are not statistically significant. Notice the p-values with Scheffé’s adjustment are higher than the p-values with Bonferroni’s adjustment. This will always be the case if the number of contrasts being tested is small."
  },
  {
    "objectID": "multiple_comparisons.html#tukey",
    "href": "multiple_comparisons.html#tukey",
    "title": "Multiple Comparison",
    "section": "Tukey",
    "text": "Tukey\nIn our toothbrush example, if we want to compare each factor level mean to the other we can apply Tukey’s HSD (Honest Significant Different) adjustment. To do this, instead of inputting custom contrasts to the contrast() command in R, we alter the method argument to be pairwise. We also need to change the adjust argument to tukey. The output provides an estimate of each pairwise comparison, as well as adjusted p-values.\n\n\nFor Tukey adjustment to all pairwise comparisons, this base R shortcut can also be used. The arguments to the function are the name of the model and the name of the factor whose factor level means should be tested.\n\nTukeyHSD(plaque_aov, \"Brush\")\n\n\n\nCode\ncontrast(brush_means, method = \"pairwise\", adjust = \"tukey\")\n\n\n contrast                 estimate   SE df t.ratio p.value\n Manual - Oscillating        3.117 1.58 20   1.967  0.2332\n Manual - Sonic              0.418 1.58 20   0.264  0.9933\n Manual - Ultrasonic        -2.220 1.58 20  -1.401  0.5130\n Oscillating - Sonic        -2.698 1.58 20  -1.703  0.3480\n Oscillating - Ultrasonic   -5.337 1.58 20  -3.369  0.0149\n Sonic - Ultrasonic         -2.638 1.58 20  -1.666  0.3670\n\nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\nWith a p-value of 0.0149, only the Ultrasonic-Oscillating contrast is significant at the 0.05 level. This significance is driven by the large difference in means between the two levels, Ultrasonic’s mean is 5.337 higher than Oscillating. All other pairwise comparisons have p-values greater than 0.05 and so are not considered significant.\n\n\n\n\n\n\nConfidence Intervals Instead of p-values\n\n\n\nIf confidence intervals are desired instead of p-values, the output of the contrast() command can be saved to an object, which then becomes the input to the confint() command. This is true for ANY contrasts computed with emmeans::contrast(), not just Tukey and not just pairwise comparisons. The adjustment specified in contrast() is then applied to the confidence interval as well.\n\n\nCode\nfor_ci &lt;- contrast(brush_means, method = \"pairwise\", adjust = \"tukey\") \nconfint(for_ci)\n\n\n contrast                 estimate   SE df lower.CL upper.CL\n Manual - Oscillating        3.117 1.58 20    -1.32    7.550\n Manual - Sonic              0.418 1.58 20    -4.02    4.852\n Manual - Ultrasonic        -2.220 1.58 20    -6.65    2.214\n Oscillating - Sonic        -2.698 1.58 20    -7.13    1.735\n Oscillating - Ultrasonic   -5.337 1.58 20    -9.77   -0.903\n Sonic - Ultrasonic         -2.638 1.58 20    -7.07    1.795\n\nConfidence level used: 0.95 \nConf-level adjustment: tukey method for comparing a family of 4 estimates"
  },
  {
    "objectID": "multiple_comparisons.html#sec-fisher",
    "href": "multiple_comparisons.html#sec-fisher",
    "title": "Multiple Comparison",
    "section": "Fisher",
    "text": "Fisher\nFirst, look at the ANOVA summary table to see if the F test for brush is significant.\n\n\nCode\nsummary(plaque_aov)\n\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThe p-value for Brush is significant at the 0.05 level. You can then proceed with an un-adjusted test of all pairwise comparisons for the Brush factor. The adjustment argument in the contrast() command in this case is none.\n\n\nCode\ncontrast(brush_means, method = \"pairwise\", adjust = \"none\")\n\n\n contrast                 estimate   SE df t.ratio p.value\n Manual - Oscillating        3.117 1.58 20   1.967  0.0632\n Manual - Sonic              0.418 1.58 20   0.264  0.7944\n Manual - Ultrasonic        -2.220 1.58 20  -1.401  0.1764\n Oscillating - Sonic        -2.698 1.58 20  -1.703  0.1040\n Oscillating - Ultrasonic   -5.337 1.58 20  -3.369  0.0031\n Sonic - Ultrasonic         -2.638 1.58 20  -1.666  0.1114\n\n\n The p-value for Oscillating - Ultrasonic is 0.0031 and is the only significant pairwise comparison at the 0.05 level; though Manual - Oscillating is close, with a p-value of 0.0632."
  },
  {
    "objectID": "z_multiple_comparisons.html",
    "href": "z_multiple_comparisons.html",
    "title": "Multiple Comparison",
    "section": "",
    "text": "In this page, the approach to dealing with multiple contrasts is explained. Specifically, whether and how to adjust the tests of multiple contrasts to account for an inflated family wise error rate. A few techniques are described, with a focus on when to use which technique. Lastly, instructions and example code is provided for carrying out each technique in R.\nIn most good experiments, researchers are interested in more than just one contrast. Conducting multiple tests on the levels of a factor can inflate the family wise Type I error rate, as illustrated in the “Multiple T-tests” section of the ANOVA page. There is considerable disagreement among statisticians about how to approach the issue of multiple tests. The debate primarily focuses on whether to proactively take steps that will mitigate the inflated family wise error rate or not. To further complicate matters, if an adjustment is desired, there are multiple techniques to choose from. An exhaustive presentation of the arguments on either side is not attempted in this text. Though, a few of the key ideas will naturally emerge as the different approaches are discussed.\n\n\nThe terms “contrast” and “comparison” are treated here as synonymous. Comparison is used more often to refer to testing a difference in factor level means. Read Contrasts for more explanation of these terms."
  },
  {
    "objectID": "z_multiple_comparisons.html#bonferroni",
    "href": "z_multiple_comparisons.html#bonferroni",
    "title": "Multiple Comparison",
    "section": "Bonferroni",
    "text": "Bonferroni\nThe Bonferroni adjustment is best for a handful of pre-planned contrasts. As the number of contrasts grows, the adjustment quickly becomes too conservative (i.e. makes it too hard to find significance). In that case, other methods may strike a better balance between Type I and Type II errors.\n\n\nType I error occurs when a true hypothesis is rejected. Type II error occurs when a false hypothesis is not rejected.\nIt can be shown that in order to not exceed a desired family wise error rate of \\(\\alpha_\\text{fw}\\), for a set of \\(k\\) contrasts, each individual contrast should be tested at a significance level of \\(\\frac{\\alpha_\\text{fw}}{k}\\). For example, if we desire a family wise error rate of 0.05 and plan to do 5 tests, each individual contrast must have a p-value less than \\(\\frac{0.05}{5} = 0.01\\) to be considered significant. The test itself has not changed, only the benchmark p-value for claiming significance. This adjustment is easy to understand and to calculate."
  },
  {
    "objectID": "z_multiple_comparisons.html#scheffé",
    "href": "z_multiple_comparisons.html#scheffé",
    "title": "Multiple Comparison",
    "section": "Scheffé",
    "text": "Scheffé\nUsing experimental results to suggest which contrasts to test is often referred to as “data snooping” or exploratory analysis. For example, you may look at graphical and numerical summaries to see which means (or combinations of means) will be promising to test. The problem with this approach is that you have essentially done a quick, informal test of many differences when you looked at descriptive statistics and plots. In other words, you have already tested the means and combinations of the means in your mind. The Type I error rate of the contrasts will be different (higher) than stated because you are only formally applying the test to those that look significant already.\nScheffé’s method is most useful when many contrasts are tested, especially when going beyond pairwise comparisons of factor level means to test combined factor levels (i.e. complex comparisons). In data exploration, there are theoretically an infinite number of contrasts you could test. This is not a problem for Scheffé’s adjustment because, unlike other adjustment techniques, Scheffé’s adjustment does not depend on the number of comparisons to be made. Rather, it is determined only by the number of factor levels and the number of observations.\nThe F statistic used to test a contrast in Scheffé’s adjustment is related to the omnibus F test for the factor itself, and is given by:\n\\[\nF_\\text{Scheffé} = (k-1)*F\n\\]\nWhere \\(F\\) is the statistic for the F test of the factor as usual. \\(k\\) is the number of levels in that factor. \\(F_\\text{Scheffé}\\) has \\(df_\\text{numerator} = k-1\\) and \\(df_\\text{denominator} = df_\\text{residual}\\). Scheffé’s test output is often in terms of a t test. Recall that the t statistic is simply the square root of the F statistic.\nIf you are interested in only a specific set of hypotheses (all pairwise comparisons, or all treatment levels vs. control, or all levels compared to the “best” level, etc.) there may be another adjustment technique that will provide better statistical power. Two of which are mentioned below."
  },
  {
    "objectID": "z_multiple_comparisons.html#methods-designed-for-all-pairwise-comparisons",
    "href": "z_multiple_comparisons.html#methods-designed-for-all-pairwise-comparisons",
    "title": "Multiple Comparison",
    "section": "Methods Designed for All Pairwise Comparisons",
    "text": "Methods Designed for All Pairwise Comparisons\nWhether it is an exploratory analysis or a pre-planned set of contrasts, many researchers want to test all factor level means against each other. This is usually referred to as testing all pairwise comparisons. Because this situation is so common, two approaches are described below.\n\nTukey’s HSD\nIf a multiple comparison adjustment is desired for testing all pairwise comparisons, a standard approach is to apply Tukey’s Honest Significant Difference (HSD) technique. Occasionally, in the case of few factor levels, Bonferroni’s adjustment may result in more significant findings. If that is the case, use Bonferroni’s correction instead.\nThe calculation for this test is based on the distribution of \\(Q\\). The test statistic \\(Q\\) is sometimes called the studentized range distribution. “Range” is a reference to the numerator where the difference between a maximum and a minimum is calculated. “Studentized” because we are dividing by the estimated standard error, a technique for standardizing famously employed by Student’s (a.k.a. William Gossett) t test. \\(Q\\) is calculated as:\n\\[\nQ = \\frac{max(T_i) - min(T_i)}{\\sqrt{\\frac{MSE}{n}}}\n\\tag{1}\\]\n\n\\(MSE\\) is an estimate of the random error variance\n\\(n\\) is the number of replicates at each factor level. For unequal sample sizes the formula changes somewhat and the result of this test may have a lower Type I error rate than claimed\nThe observations for each level are generated by a different random variable: \\(k\\) variables total, one for each level. Each random variable is normally distributed with mean zero and standard deviation estimated by the denominator of Equation 1. \\(max(T_i)\\) is the maximum value of the \\(k\\) random variables, \\(min(T_i)\\) is the minimum.\nThe distribution of \\(Q\\) will depend on the number of treatments being compared, \\(k\\), and the number of degrees of freedom for error.\n\n\n\nFisher’s LSD\nMaking adjustments for multiple contrasts is a conservative approach, meaning it is more difficult to claim significance compared to when no adjustment is made. Though these adjustments prevent understating the probability of Type I error, they increase the probability of Type II error for each individual contrast. In exploratory analysis where you are looking for hints of what to study further, a Type II error may be a greater concern than Type I.\nFor example, consider a screening study intended to narrow down the number of factors studied in a future experiment. In this case, accidentally ruling out something early on that actually does have a significant impact on the response is more egregious than letting a non-significant factor through to the next experiment where it’s non-significance will be discovered.\nFisher’s Least Significant Difference (LSD) employs no adjustment at all to the pairwise comparisons. However, before proceeding to test pairwise comparisons, the F test for the factor must be significant. Using the less powerful F test as a gatekeeper to the more powerful pairwise t tests serves as a partial protection against extreme Type I errors inflation.\nIn summary, Fisher’s LSD is a two step process. First, verify the F test for the factor is significant. Second, if it is, proceed with all pairwise comparisons without any adjustment. Fisher’s LSD tends to be used in studies where many factors are present, especially screening/exploratory studies."
  },
  {
    "objectID": "z_multiple_comparisons.html#bonferonni",
    "href": "z_multiple_comparisons.html#bonferonni",
    "title": "Multiple Comparison",
    "section": "Bonferonni",
    "text": "Bonferonni\nThere are two ways to implement the Bonferroni adjustment illustrated below using the contrasts that were tested in the R Instructions section of the Contrast page.\n\n\nSee R instructions for Fisher’s LSD for a shortcut to apply Bonferroni adjustment to all pairwise comparisons.\n\nRecalculate an Alpha Level by Hand\nFirst, the Bonferroni adjustment is shown using output provided for a test of contrasts without adjustment. The code and output from the R Instructions section of the Contrast page is provided again here for convenience. These two contrasts test the mean of the manual brush against the oscillating brush mean, as well as the manual brush mean against the mean of all the other brushes combined.\n\n\nCode\nbrush_means &lt;- emmeans(plaque_aov, \"Brush\")\ncontrast_results &lt;- contrast(brush_means,\n                             list(man_v_osc = c(1,-1,0,0),\n                                  man_v_others = c(1,-(1/3),-(1/3),-(1/3))), \n                             adjust=\"none\")\n\n#kable commands are for formatting the output\ncontrast_results |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nman_v_osc\n3.12\n1.58\n20\n1.97\n0.06\n\n\nman_v_others\n0.44\n1.29\n20\n0.34\n0.74\n\n\n\n\n\n\n\n\nA new alpha level against which to compare the p-values can be calculated by hand. Since there are two tests, if the intent was to keep the family wise error rate of 0.05, the alpha level for each individual test is \\(\\frac{0.05}{2} = 0.025\\). To be considered significant, the contrast’s p-value must be less than 0.025.\nman_v_osc has a p-value of 0.06; man_v_others has a p-value of 0.74. Since neither contrast has a p-value less than 0.025 we conclude that the contrasts are not statistically significant.\n\n\nMake the Adjustment in R\nSecond, the Bonferroni adjustment is applied by changing the value of the adjust = argument in the contrast() function from “none” to “bon”.\n\n\nCode\nbon_results &lt;- contrast(brush_means,\n                        list(man_v_osc = c(1,-1,0,0),\n                             man_v_others = c(1,-(1/3),-(1/3),-(1/3))), \n                        adjust=\"bon\")\n\n#kable commands are for formatting the output\nbon_results |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nman_v_osc\n3.12\n1.58\n20\n1.97\n0.13\n\n\nman_v_others\n0.44\n1.29\n20\n0.34\n1.00\n\n\n\n\n\n\n\n\nIn these results the p-values have simply been multiplied by 2 because there were 2 contrasts in the set being tested. Each test can be compared to our desired family wise error rate as usual. Since each test has a p-value greater than 0.05 we conclude that the contrasts are not statistically significant.\nNote, for man_v_others the p-value is capped at 1.00 since a p-value cannot exceed 1.00."
  },
  {
    "objectID": "z_multiple_comparisons.html#scheffé-1",
    "href": "z_multiple_comparisons.html#scheffé-1",
    "title": "Multiple Comparison",
    "section": "Scheffé",
    "text": "Scheffé\nSimilar to how the Bonferroni adjustment was applied, to apply a Scheffé adjustment, change the value of the adjust = argument in the contrast() function from “none” to “scheffe”.\n\n\nCode\ncontrast(brush_means, \n         list(man_v_osc = c(1,-1,0,0),\n              man_v_others = c(1,-(1/3),-(1/3),-(1/3))),\n         adjust=\"scheffe\") |&gt; \n\n  #kable commands are for formatting the output\n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nman_v_osc\n3.12\n1.58\n20\n1.97\n0.17\n\n\nman_v_others\n0.44\n1.29\n20\n0.34\n0.94\n\n\n\n\n\n\n\n Each contrast’s p-value can be compared to our desired family wise error rate of 0.05. Since each test has a p-value greater than 0.05 we conclude that the contrasts are not statistically significant. Notice the p-values with Scheffé’s adjustment are higher than the p-values with Bonferroni’s adjustment. This will always be the case if the number of contrasts being tested is small."
  },
  {
    "objectID": "z_multiple_comparisons.html#tukey",
    "href": "z_multiple_comparisons.html#tukey",
    "title": "Multiple Comparison",
    "section": "Tukey",
    "text": "Tukey\nIn our toothbrush example, if we want to compare each factor level mean to the other we can apply Tukey’s HSD adjustment using a base R function. The arguments to the function are the name of the model and the name of the factor whose means should be tested. Notice the emmeans grid does not have to be created and the contrast coefficients do not explicitly need to be input. The output provides an estimate of each pairwise comparison, as well as adjusted simultaneous confidence intervals and p-values.\n\n\nCode\nTukeyHSD(plaque_aov, \"Brush\") |&gt; pander()\n\n\n\nBrush:\n\n\n\n\n\n\n\n\n\n\n \ndiff\nlwr\nupr\np adj\n\n\n\n\nOscillating-Manual\n-3.117\n-7.55\n1.317\n0.2332\n\n\nSonic-Manual\n-0.4183\n-4.852\n4.015\n0.9933\n\n\nUltrasonic-Manual\n2.22\n-2.214\n6.654\n0.5129\n\n\nSonic-Oscillating\n2.698\n-1.735\n7.132\n0.348\n\n\nUltrasonic-Oscillating\n5.337\n0.9029\n9.77\n0.01487\n\n\nUltrasonic-Sonic\n2.638\n-1.795\n7.072\n0.367\n\n\n\n\n\n\n\nWith a p-value of 0.01, only the Ultrasonic-Oscillating contrast is significant. This significance is driven by the large difference in means between the two levels, Ultrasonic’s mean is 5.337 higher than Oscillating. All other pairwise comparisons have p-values greater than 0.05 and so are not considered significant."
  },
  {
    "objectID": "z_multiple_comparisons.html#sec-fisher",
    "href": "z_multiple_comparisons.html#sec-fisher",
    "title": "Multiple Comparison",
    "section": "Fisher",
    "text": "Fisher\nFirst, look at the ANOVA summary table to see if the F test for brush is significant.\n\n\nCode\nsummary(plaque_aov)\n\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThe p-value for Brush is significant at the 0.05 level. You can then proceed with an unadjusted test of all pairwise comparisons for the Brush factor. The syntax for this function is a bit different. You do not have to create the model first.\nIt requires the response vector as the first argument, the factor vector as the 2nd argument, and an adjustment for multiple comparisons (if any) as the 3rd argument.\n\n\nCode\npairwise.t.test(df$Plaque, df$Brush, p.adjust.method = \"none\") |&gt; \n  pander()\n\n\n\nmethod: t tests with pooled SD\n\ndata.name: df\\(Plaque and df\\)Brush\np.value:\n\n\n\n\n\n\n\n\n\n \nManual\nOscillating\nSonic\n\n\n\n\nOscillating\n0.06315\nNA\nNA\n\n\nSonic\n0.7944\n0.104\nNA\n\n\nUltrasonic\n0.1764\n0.003052\n0.1114\n\n\n\np.adjust.method: none\n\n\n\n\n\n The output is a triangular matrix of p-values. The p-value for Ultrasonic vs. Oscillating is 0.0031 and is the only significant pairwise comparison at the 0.05 level; though Oscillating vs. Manual is close, with a p-value of 0.0632.\n\n\n\n\n\n\nNote\n\n\n\nThe pairwise.t.test() can receive “bon” as an input to the p.adjust.method = argument, which will perform all pairwise comparisons and apply the Bonferroni adjustment. When the number of factor levels is small Bonferroni is preferred over the Tukey’s HSD because it provides more statistical power."
  },
  {
    "objectID": "multiple_comparisons.html#bonus-estimating-and-testing-effect-sizes",
    "href": "multiple_comparisons.html#bonus-estimating-and-testing-effect-sizes",
    "title": "Multiple Comparison",
    "section": "Bonus: Estimating and Testing Effect Sizes",
    "text": "Bonus: Estimating and Testing Effect Sizes\nIf no custom contrasts are provided to the contrast() command, and no argument for method is provided, the default output is an estimate (and test) of each factor level effect, as seen below!\n\n\nCode\n(effect_sizes &lt;- contrast(brush_means)) \n\n\n contrast           estimate   SE df t.ratio p.value\n Manual effect        0.3287 0.97 20   0.339  0.9273\n Oscillating effect  -2.7879 0.97 20  -2.874  0.0323\n Sonic effect        -0.0896 0.97 20  -0.092  0.9273\n Ultrasonic effect    2.5488 0.97 20   2.627  0.0323\n\nP value adjustment: fdr method for 4 tests \n\n\n\n\nNote the behavior of the defaults is a little different than what might be expected. “fdr” stands for “false detection rate”. It makes adjustments to keep the overall proportion of Type I errors fixed (e.g. 5% of tests will be a Type I error). This is somewhat less stringent than keeping the family-wise Type I error rate fixed.\nYou can use confint() to get confidence intervals for the effects (with or without adjustments) as well.\n\n\nCode\nconfint(effect_sizes)\n\n\n contrast           estimate   SE df lower.CL upper.CL\n Manual effect        0.3287 0.97 20   -2.333    2.991\n Oscillating effect  -2.7879 0.97 20   -5.450   -0.126\n Sonic effect        -0.0896 0.97 20   -2.752    2.573\n Ultrasonic effect    2.5488 0.97 20   -0.113    5.211\n\nConfidence level used: 0.95 \nConf-level adjustment: bonferroni method for 4 estimates"
  }
]