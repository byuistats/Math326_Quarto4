[
  {
    "objectID": "bf2.html",
    "href": "bf2.html",
    "title": "BF[2]",
    "section": "",
    "text": "When researchers want to study the effects of two factors on the same response variable a factorial design can be considered. Factorial experiments involve two or more factors that are crossed.\n\n\n\n\n\n\nTip\n\n\n\nFull factorial crossing occurs when each combination of factor levels is present in the study.\n\n\nCompare a factorial design with the one-at-a-time approach. In a one-at-a-time approach, each factor would be investigated in a separate experiment. Each experiment would evaluate the effect of just one factor on the response.\nFactorial designs are a way to simultaneously study the effects of multiple factors using just one experiment. Factorial designs have a couple of major advantages over one-factor-at-a-time studies.\n\nThey are a more efficient use of our time and material: I can get information about both of my factors from just one observation\nThey allow the random error to be allocated across a greater number of factors, thereby reducing unexplained variance (i.e. mean square error) and increasing the statistical power of the F-test.\nThey allow the estimation of interaction effects. Or in other words, we can observe how one factor’s effect on the response changes for different levels of the other factor.\n\nWe will expand on the simple toothpaste example to illustrate BF[2] concepts. The study is summarized here.\nResearchers wanted to know which of 4 types of toothbrushes was best at reducing plaque: manual (this is the traditional/usual type of brush), oscillating bristles, sonic, and ultrasonic. The response variable was the percent of teeth surface area covered with plaque. Four teeth (first molar in each quadrant of the mouth) were measured on each person to calculate the total percent area covered. Six subjects were assigned to each type of brush.\nResearchers also wanted to study the effect of name brand tooth paste compared to its off brand equivalent. This is the second controlled factor in the experiment. It has two levels (name brand and off brand). Twelve subjects used name brand paste, and a different 12 subjects used the off brand. Toothpaste brand is crossed with toothbrush type to create a BF[2].\n\n\nBased on the description above, the factor structure for this experiment is displayed in Figure 1:\n\n\n\n\nFigure 1: Factor Structure Diagram\n\n\n\nTwo levels of toothpaste multiplied by 4 levels of toothbrush results in 8 factor level combinations total. This is represented by the 8 partitions in the interaction factor. These 8 factor level combinations are obtained by overlaying the 2 controlled factor partitions. When the toothbrush factor and toothpastepaste partitions are overlayed, they cross each other and create new, meaningful partitions: the interaction factor. Since there were 24 subjects and the study is balanced, we end up with \\(24\\div 8 = 3\\) replicates in each factor level combination.\n\n\n\nEach factor (i.e. meaningful partition of the data) in Figure 1 corresponds to a term in Equation 1:\n\\[\ny_\\text{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_\\text{ij} + \\epsilon_\\text{ijk}\n\\tag{1}\\]\nWhere\n\n\\(y_{ijk}\\) is the \\(k^{th}\\) observation from the factor level combination of \\(\\alpha_i\\) and \\(\\beta_j\\).\n\\(\\mu\\) is the grand mean of all the observations.\n\\(\\alpha\\) is the effect of toothbrush, and \\(i\\) goes from 1 to 4 since there are 4 toothbrush types\n\\(\\beta\\) is the effect of toothpaste, and \\(j\\) is either 1 or 2 since there are 2 levels (Name brand and off brand).\nThe \\((\\alpha\\beta)_\\text{ij}\\) is called the interaction effect.\n\\(\\epsilon\\) is the residual error term, and \\(k\\) is the replicate count within a factor level combination.\n\nThere are at least three hypotheses to test with this model. A hypothesis for each main effect, and a hypothesis for the interaction effect.\nA hypothesis for the main effect of toothbrush type:\n\\[H_0: \\alpha_\\text{i} = 0 \\text{ for all } i\\]\n\\[H_a: \\alpha_\\text{i} \\ne 0 \\text{ for some } i\\]\nA hypothesis for the main effect of toothpaste brand:\n\\[H_0: \\beta_\\text{j} = 0 \\text{ for all } j\\]\n\\[H_a: \\beta_\\text{j} \\ne 0 \\text{ for some } j\\]\nA hypothesis for the interaction of toothbrush and toothpaste.\n\\[\nH_0: (\\alpha\\beta)_\\text{ij} = 0 \\text{ for all } ij\n\\]\n\\[\nH_a: (\\alpha\\beta)_\\text{ij} \\ne 0 \\text{ for some } ij\n\\]\nWhen the interaction term is not significant a predicted value for an observation can be obtained by simply adding the grand mean to the main effects \\(\\hat{\\alpha}_i\\) and \\(\\hat{\\beta}_j\\). This is equivalent to treating the effect of \\((\\alpha\\beta)_\\text{ij} = 0\\) for all values of \\(i\\) and \\(j\\).\nWhen the interaction effect is significant reject the null hypothesis and accept the alternative hypothesis: at least one factor level combination has a none zero effect.\n\n\n\nA two-way ANOVA model may be used to analyze data from a BF[2] design if the following requirements are satisfied. Note that these requirements are identical to the requirements of a BF[1] one-way ANOVA.\n\n\nThe BF[] designation refers to the design of the experiment. The reference to one- or two-way ANOVA refers to the analysis technique applied to the resulting data.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "bf2.html#factor-structure",
    "href": "bf2.html#factor-structure",
    "title": "BF[2]",
    "section": "",
    "text": "Based on the description above, the factor structure for this experiment is displayed in Figure 1:\n\n\n\n\nFigure 1: Factor Structure Diagram\n\n\n\nTwo levels of toothpaste multiplied by 4 levels of toothbrush results in 8 factor level combinations total. This is represented by the 8 partitions in the interaction factor. These 8 factor level combinations are obtained by overlaying the 2 controlled factor partitions. When the toothbrush factor and toothpastepaste partitions are overlayed, they cross each other and create new, meaningful partitions: the interaction factor. Since there were 24 subjects and the study is balanced, we end up with \\(24\\div 8 = 3\\) replicates in each factor level combination."
  },
  {
    "objectID": "bf2.html#hypothesis-and-model",
    "href": "bf2.html#hypothesis-and-model",
    "title": "BF[2]",
    "section": "",
    "text": "Each factor (i.e. meaningful partition of the data) in Figure 1 corresponds to a term in Equation 1:\n\\[\ny_\\text{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_\\text{ij} + \\epsilon_\\text{ijk}\n\\tag{1}\\]\nWhere\n\n\\(y_{ijk}\\) is the \\(k^{th}\\) observation from the factor level combination of \\(\\alpha_i\\) and \\(\\beta_j\\).\n\\(\\mu\\) is the grand mean of all the observations.\n\\(\\alpha\\) is the effect of toothbrush, and \\(i\\) goes from 1 to 4 since there are 4 toothbrush types\n\\(\\beta\\) is the effect of toothpaste, and \\(j\\) is either 1 or 2 since there are 2 levels (Name brand and off brand).\nThe \\((\\alpha\\beta)_\\text{ij}\\) is called the interaction effect.\n\\(\\epsilon\\) is the residual error term, and \\(k\\) is the replicate count within a factor level combination.\n\nThere are at least three hypotheses to test with this model. A hypothesis for each main effect, and a hypothesis for the interaction effect.\nA hypothesis for the main effect of toothbrush type:\n\\[H_0: \\alpha_\\text{i} = 0 \\text{ for all } i\\]\n\\[H_a: \\alpha_\\text{i} \\ne 0 \\text{ for some } i\\]\nA hypothesis for the main effect of toothpaste brand:\n\\[H_0: \\beta_\\text{j} = 0 \\text{ for all } j\\]\n\\[H_a: \\beta_\\text{j} \\ne 0 \\text{ for some } j\\]\nA hypothesis for the interaction of toothbrush and toothpaste.\n\\[\nH_0: (\\alpha\\beta)_\\text{ij} = 0 \\text{ for all } ij\n\\]\n\\[\nH_a: (\\alpha\\beta)_\\text{ij} \\ne 0 \\text{ for some } ij\n\\]\nWhen the interaction term is not significant a predicted value for an observation can be obtained by simply adding the grand mean to the main effects \\(\\hat{\\alpha}_i\\) and \\(\\hat{\\beta}_j\\). This is equivalent to treating the effect of \\((\\alpha\\beta)_\\text{ij} = 0\\) for all values of \\(i\\) and \\(j\\).\nWhen the interaction effect is significant reject the null hypothesis and accept the alternative hypothesis: at least one factor level combination has a none zero effect."
  },
  {
    "objectID": "bf2.html#assumptions",
    "href": "bf2.html#assumptions",
    "title": "BF[2]",
    "section": "",
    "text": "A two-way ANOVA model may be used to analyze data from a BF[2] design if the following requirements are satisfied. Note that these requirements are identical to the requirements of a BF[1] one-way ANOVA.\n\n\nThe BF[] designation refers to the design of the experiment. The reference to one- or two-way ANOVA refers to the analysis technique applied to the resulting data.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\n\nLevene’s Test\nFail to reject \\(H_0\\)\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "bf2.html#conceptual-understanding",
    "href": "bf2.html#conceptual-understanding",
    "title": "BF[2]",
    "section": "Conceptual Understanding",
    "text": "Conceptual Understanding\nThe concept behind an interaction should feel quite familiar. It is something we deal with everyday and is very common in science. You may have experienced an interaction effect in something as simple as your daily commute:\n\nConsider a factor to indicate which route you take to work. Route has two levels: using the main roads and using back roads. The time to reach your destination is the response. During rush hour, the main roads are clogged with traffic and result in a longer commute time than taking the back roads. However, in non-rush hour times, the main roads result in a faster commute time. Thus, the effect of taking main roads depends on whether you are traveling during rush hour or not.\n\nThe effect of route was reversed for different levels of rush hour. Not all interactions work this way. Some interactions increase/decrease the magnitude of an effect without completely changing its direction. We can tweak the situation of the commute time example to illustrate this:\n\nDuring non-rush hour periods, on average back roads result in a commute time that is 5 minutes faster than main roads. During rush hour periods however, the benefit of taking back rounds compared to main roads increases to 15 minutes. Thus, the size of the effect of back roads increased (is amplified) for rush hour compared to non-rush hour.\n\nThe above descriptions cover just two possible outcomes for this commute time experiment. It may be helpful to visualize the possible outcome scenarios for this two factor (route and rush hour) study. This can effectively be done with an interaction plot. An interaction plot shows the means for each factor level combination and usually connects the means from the same factor level with a line to help the reader visually group means and detect effects.\nFigure 2 shows four possible outcomes of the traffic study where NO interaction is present. The upper left panel of the plot shows a situation where there are no main effects or interactions apparent. The mean is the same regardless of the factor level combination. The upper right panel of the plot shows a large route effect but no effect due to rush hour. This can be seen because the commute time for back roads is high but commute time for main roads is low; however, for a given route there is no difference in the mean for rush hour vs. not rush hour.\nThe bottom left panel shows a non-zero effect for the rush hour factor, as seen by the sizable difference between the levels of rush hour within a route. However, the flat lines indicate that the mean commute time for route is not changing and therefore route has no effect on commute time. Lastly, the bottom right panel is a situation where both main effects appear to be present - but there is still no interaction apparent.\n\n\nR code instructions to create interaction plots are at the bottom of the R Instructions&gt;Descriptive Summaries page.\n\n\n\n\n\nFigure 2: Scenarios with NO Interaction Present\n\n\n\n\nThe line segments within each graph of Figure 2 are parallel (or coincide), which is a visual indicator that no interaction is present.\n\n\n\n\n\n\nTip\n\n\n\nFactors with no interaction will have (nearly) parallel line segments in the interaction plot.\n\n\nSo what does an interaction plot look like when there is an interaction present? The key things to notice is that the line segments in the plot are not parallel. Figure 3 contains 3 examples of interaction plots that show the presence of an potential interaction.\n\n\n\n\n\nFigure 3: Scenarios Indicative of an Interaction\n\n\n\n\nPanel A of Figure 3 illustrates an example where the effect of Route reverses, depending on the value for Rush Hour. In Panel B, the effect of Rush Hour is much greater when using main roads than for back roads. In Panel C, main roads take longer regardless of time of day, but the effect of switching from back roads to main roads is much larger during rush hour than in non-rush hour times.\nThere are a few key points to remember when working with interactions.\nFirst, exercise caution when interpreting a main effect if an interaction is present. The definition of an interaction is that a factor level’s effect changes for different values of the other factor. Therefore, it does not make sense to interpret the hypothesis test of a controlled factor if it is part of a significant interaction. Instead, get in the habit of describing the nature of the interaction.\nTo illustrate the danger of interpreting main effect hypothesis tests when the interaction is significant consider Panel A of Figure 3. If the hypothesis test for Route had a large p-value, it is tempting to say there is insufficient evidence that Route has an effect on commute time. However, the interaction plot shows quite the opposite. Route has an important effect on the response, since the level of Route drastically changes the impact of Rush Hour on commute times. Even though the mean commute time for “back” and “main” may be similar in this scenario, Route is indirectly having an effect on commute time through its interaction with Rush Hour.\nConversely, imagine a scenario where Route’s main effect had a small p-value and the Route - Rush Hour interaction was also significant. If the interaction is like that depicted in Panel C of Figure 3, simply stating that Route is a significant factor does not tell the whole story. The effect of Route in during rush hour is large and may be significant (steep blue line), but the effect of Route in non-rush hour times may not be large enough to reach significance (the nearly flat red line).\n\n\n\n\n\n\nInterpreting Main Effects and Interactions\n\n\n\nWhen a significant interaction is present, do not interpret the hypothesis tests of its main effects without providing additional information.\n\n\nSecond, don’t rely on interaction plots alone to detect the presence/absence of interactions. Though interaction plots are a a helpful tool, they do not adequately show the repsonse variability in each factor level combination. In other words, even when line segments are not parallel a hypothesis test is still needed to determine if an interaction is real or just due to random error. Furthermore, two lines may look nearly parallel but could actually represent a significant interaction.\nLastly, beware of a common mistake that students make. Students commonly state an interaction means that the level of one factor affects the values of another factor. This is a lie from Satan! The key misunderstanding here is thinking that the value of one factor affects the other factor. In reality, it is the factor’s effect on the response that changes for different levels of the other factor. The two factors do not affect each other."
  },
  {
    "objectID": "bf2.html#factor-effects",
    "href": "bf2.html#factor-effects",
    "title": "BF[2]",
    "section": "Factor Effects",
    "text": "Factor Effects\nHow can an interaction affect be estimated? Like all factor effects, its estimate is calculated using the general rule.\n\n\n\n\n\n\nGeneral Rule for Calculating Factor Level Effect\n\n\n\nFactor level effect = mean of the factor level - Sum(effects of all outside factors)\n\n\nFrom the general rule we can see that before we estimate the interaction effect we first need to estimate the outside factor effects (i.e. main effects). Factor level means need to be calculated in order to calculate estimated effects.\nIt is also important to recall that the grand mean factor is outside of all other factors, while the residual error factor is inside of all other factors.\n\nFactor Level Means\nFigure 6 shows our data set with partition lines for structural factors in place. We will now proceed to calculate the factor level means for each factor.\n\n\n\nFigure 6: Full data set with partitions\n\n\nThe grand mean is the mean of all the observations:\n\\[\n\\hat{\\mu} = \\bar{y}_\\cdots = \\frac{19.12 + 18.56 + 25.58 + 24.39 + 24.21 + ... + 23.42}{24} = 22.76\n\\]\nNow find the mean for each level of toothbrush type.\n\\[\n\\bar{y}_\\text{manual} = \\bar{y}_{1\\cdot\\cdot} = \\frac{19.12 + 24.21 + 26.88 + 21.6 + 23.4 + 23.35}{6} = 23.10\n\\]\n\\[\n\\bar{y}_\\text{oscillating} = \\bar{y}_{2\\cdot\\cdot} = \\frac{18.56 + 20.00 + 19.87 + 22.09 + 17.62 + 21.72}{6} = 19.98\n\\]\n\\[\n\\bar{y}_\\text{sonic} = \\bar{y}_{3\\cdot\\cdot} = \\frac{25.58 + 23.31 + 18.99 + 23.09 + 23.81 + 21.27}{6} = 22.68\n\\]\n\\[\n\\bar{y}_\\text{ultrasonic} = \\bar{y}_{4\\cdot\\cdot} = \\frac{24.39 + 21.45 + 32.74 + 24.21 + 25.67 + 23.42}{6} = 25.31\n\\]\nNow find the mean for each level of toothpaste brand.\n\\[\n\\bar{y}_\\text{name brand} = \\bar{y}_{\\cdot 1 \\cdot} = \\frac{19.12 + 18.56 + \\cdots + 18.99 + 32.74}{12} = 22.93\n\\]\n\\[\n\\bar{y}_\\text{off brand} = \\bar{y}_{\\cdot 2 \\cdot} = \\frac{21.60 + 22.09 + \\cdots + 21.27 + 23.42}{12} = 22.60\n\\]\nThere are 8 different combinations of toothbrush type and toothpaste, so the interaction factor has 8 levels total. We calculate a mean for each one, but will only show the calculation for the first 3.\n\\[\n\\bar{y}_\\text{manual and name brand} = \\bar{y}_{11\\cdot} = \\frac{19.12 + 24.21 + 26.88}{3} = 23.40\n\\]\n\\[\n\\bar{y}_\\text{manual and off brand} = \\bar{y}_{12\\cdot} = \\frac{21.60 + 23.40 + 23.35}{3} = 22.78\n\\]\n\\[\n\\bar{y}_\\text{oscillating and name brand} = \\bar{y}_{21\\cdot} = \\frac{18.56 + 20.00 + 19.87}{3} = 19.48\n\\]\nThe means for the residual error factor levels is the observed value itself since there is just 1 observation per level. Therefore, there are no calculations to show.\nFigure 7 displays all the factor level means inside the factor structure.\n\n\n\n\nFigure 7: Factor level means\n\n\n\n\n\nFactor Level Effects\n\nGrand mean effect\nNow that we have calculated means for each level of each factor, we can move on to calculate the effects of the factor levels.1\nFor the grand mean, there is only one level and there are no outside factors. Therefore, the effect due to grand mean is 22.76 (equivalent to its mean) and this affect is applied to all 24 observations.\n\n\nToothbrush effects\nThe toothbrush factor has four levels: one for each brush type. We will use the general rule for calculating factor level effects. To calculate the effect of a toothbrush, take the toothbrush mean and subtract it from the grand mean factor’s effect. For the manual brush, this looks like:\n\\[\n23.09 - 22.76 = 0.33\n\\]\nUsing the manual brush has the effect of increasing a person’s plaque area percentage by 0.33 percentage points on average compared to the grand mean. In a similar way2 you can find the effect for the oscillating brush \\(19.98 - 22.76 = -2.79\\). This means the amount of plaque decreased by 2.79 on average with this brush compared to the grand mean. For a sonic toothbrush, the effect is \\(22.68 - 22.76 = -0.09\\). For an ultrasonic brush the effect is \\(25.31 - 22.76 = 2.55\\).\n\n\nIt is interesting to note that the factor effects for brush type are the same, whether toothpaste brand is included in the analysis or not.\n\n\nToothpaste effects\nCalculating the effects for the second controlled factor in the experiment follows a similar pattern and also uses the general rule for calculating effect sizes. Remember that toothbrush is not outside or inside of toothpaste, rather the two factors are crossed. To calculate the effect of using the name brand toothpaste, take the name brand mean and subtract it from the grand mean factor’s effect:\n\\[\n22.93 - 22.76 = 0.16\n\\]\nA similar calculation is performed for off the brand toothpaste.\n\\[\n22.60 - 22.76 = -0.16\n\\]\nWith only two levels, it becomes obvious that the effects of a factor’s levels will always sum to zero. You may want to go back to the toothbrush level effects and verify this is true.\n\n\nInteraction effects\nThe general rule says that effects of outside factors must be subtracted from the factor level mean. We pause to review the relationship of the other factors to the interaction factor to determine if they are inside, outside, or crossed with each other.\n\n\n\n\n\n\n\n(a) Interaction inside of brush\n\n\n\n\n\n\n\n(b) Interaction inside of toothpaste\n\n\n\n\nFigure 8: Interaction Effects\n\n\nIn Figure 8 (a) you can see that each level of the interaction will fit nicely within a level of toothbrush, this means toothbrush is outside of interaction (equivalently, interaction is inside of toothbrush). The same holds true for the relationship of toothpaste brand and interaction, as shown in Figure 8 (b).\nTherefore, to calculate the interaction effect for using an ultrasonic brush with name brand toothpaste we will subtract the effects of the grand mean factor, ultrasonic brush, and name brand paste from the “ultrasonic, name brand” level mean.\n\\[\n26.19 - (22.76 + 2.55 + 0.16) = .15\n\\]\nLet’s take a deeper look to understand why this works. It can be helpful to remember our assembly line analogy. We will walk through this assembly line, showing a graph to illustrate how the effects are added at each station.\nAn observation from the “ultrasonic brush, name brand paste” group starts with the grand mean value of 22.76. The observation belongs to the ultrasonic group, where plaque tends to be higher, specifically 2.55 higher on average (2.55 is the effect of ultrasonic). Figure 9 show the starting point of the grand mean and the addition of the brush effect.\n\n\n\n\n\nFigure 9: Grand mean + brush effect\n\n\n\n\nAt the next step, because the observation belongs to the Name Brand Toothpaste group we would tack on an additional 0.16 of plaque coverage, as shown in Figure 10.\n\n\n\n\n\nFigure 10: Grand mean + brush effect + paste effect\n\n\n\n\nWhat we haven’t accounted for yet is the fact that the ultrasonic brush and name brand toothpaste have appeared together. If the interaction is significant then we can expect a synergistic effect (in either direction) and will need to add/subtract more to the response. Otherwise, the interaction effects will be small (relative to the error variance).\nThere is an old saying, “the whole is greater than the sum of its parts”. In a way, the interaction effect is the measure of how much greater. Figure 11 shows that after summing the main effects of each controlled factor, the remaining distance to the mean of the factor level combination is the interaction effect. We calculated this above using the general rule and found the distance to be 0.15.\n\n\n\n\n\nFigure 11: Interaction effect is remaining distance to factor level mean\n\n\n\n\nThe previous 3 figures are placed side by side below in the figure below so that the additive progression of the effects can more easily be seen.\n\n\n\n\n\n\n\n\n(a) ?(caption)\n\n\n\n\n\n\n\n(b) ?(caption)\n\n\n\n\n\n\n\n(c) ?(caption)\n\n\n\n\nFigure 12: Additive Effects\n\n\nAdditive Effects\n\nLastly, the residuals (or residual effects) need to be calculated. The mean for each level of residual is simply the observation itself. Effects associated with that observation’s factor levels are subtracted from the observed value. Whatever is left over is considered the residual. In other words, we have applied the general rule for calculating effect size. For the residual factor, the effect can concisely be stated as “observed value - predicted value”.\nAs an example, the residual in the top left corner of the residual factor was obtained with this calculation:\n\\[\n19.12 - (22.76 + 0.329 + 0.16 + 0.15) = -4.28\n\\]\nAll other residuals were similarly obtained. Ultimately, Figure 13 displays all the factor level effects that are summed to obtain each observation.\n\n\n\n\nFigure 13: Factor level effects"
  },
  {
    "objectID": "bf2.html#degrees-of-freedom",
    "href": "bf2.html#degrees-of-freedom",
    "title": "BF[2]",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nWe can use our understanding of inside vs. outside factors to determine the degrees of freedom (df) for the grand mean, treatment factors, interaction and residual errors. We start with 24 observations - or pieces of information. In other words, we have 24 degrees of freedom that need to be allocated to the factors.\n\n\n\n\n\n\nGeneral Rule for Degrees of Freedom\n\n\n\ndf\\(_\\text{factor}\\) = Total levels of a factor minus the sum of the df of all outside factors\nAn alternative way to find degrees of freedom is to count the number of unique pieces of information in a factor.\n\n\nIn the toothbrush and toothpaste example, grand mean has one level and there are no factors outside of grand mean. Therefore, its degrees of freedom equals one. This will always be the case.\nRemember, the degrees of freedom represent the number of unique pieces of information contributing to the estimation of the effects for that factor. In this case, as soon as you estimate the grand mean for just one of the observations, you know it for all the observations. In other words, only 1 value was free to vary. As soon as it was known all the other values for the grand mean effect were also known. Therefore, there is just one unique piece of information in the grand mean factor. Grand mean has just 1 degree of freedom.\nIn this case there are two controlled factors, or treatment factors: toothbrush and toothpaste. For toothbrush there are four levels of the factor. Grand mean is the only factor outside of toothbrush. Take the number of levels for toothbrush (4) and subtract the degrees of freedom for grand mean (1), which yields 4-1 = 3 degrees of freedom.\n\n\nThe degrees of freedom for toothbrush is it the same here as it was for the BF[1].\nWe could just as easily have used the other approach to finding the degrees of freedom: counting the unique pieces of information. Upon examining the factor for toothbrush in Figure 13 you can see there are 4 unique numbers. We know the effects for toothbrush must sum to zero, so the 4th effect is not free to vary. As soon as I know the effect for 3 of the brushes, I can fill in all the effects for the toothbrush factor.\nA similar approach is taken for toothpaste. Here it is even more obvious that the effects for toothpaste sum to zero. After estimating the toothbrush effect for one observation, I can fill in the toothpaste effects for all the other observations. Therefore, the degrees of freedom for toothpaste is 1.\nUsing the general rule, I know there are 2 levels for toothpaste and grand mean is the only outside factor. Since grand mean has 1 degree of freedom, I get \\(2-1 = 1\\) degree of freedom for toothpaste.\nNow we must calculate degrees of freedom for the interaction term. Take a closer look at the interaction effects in Figure 13. You can see that the numbers repeat within each cell. There are 8 cells total. You can also see that the effects inside a column of values sum to zero, as do the values in a row. Therefore, I really only need to know a value in 3 of the cells of the interaction factor before I can fill in the effects for all the other cells in that factor.\nThis is in perfect harmony with an application of the general rule. The interaction factor has 8 factor levels. Factors outside of the interaction include: grand mean (1 df), toothbrush (3 df), and toothpaste (1 df). Applying the general rule with these values yields \\(8 - (1 + 3 + 1) = 3\\) degrees of freedom for the interaction factor.\nPerhaps the easiest way to find the degrees of freedom for an interaction that is created by crossing two other factors is to multiply the degrees of freedom of the two other factors. In this case, toothbrush and toothpaste are crossed, so you would get \\(3*1 = 3\\), which matches the answer found using other methods.\nFinally, the residual degrees of freedom can be found using the general rule. Since the residual error factor is inside of all other factors, this is the same as finding how many degrees of freedom are leftover after calculating degrees of freedom for all other factors. In this example, there were 24 observations total, so we subtract the degrees of freedom for the other factors from 24. This returns \\(24 - (1+3+1+3) = 16\\) degrees of freedom for residuals.\nThe other approach to finding the degrees of freedom for residuals is to group the residuals by the smallest structural factor partitions (in this case the interaction). Inside each of those partitions the residuals sum to zero. For example, applying the interaction partition to residuals gives the values \\(-4.28\\), \\(0.81\\), and \\(3.48\\). Since we know the 3 residuals sum to zero in each partition, we only need to know 2 values per partition in order to fill in the third residual effect. With 8 partitions applied to the residuals, we have \\(2x8 = 16\\) degrees of freedom for residual error."
  },
  {
    "objectID": "bf2.html#completing-the-anova-table",
    "href": "bf2.html#completing-the-anova-table",
    "title": "BF[2]",
    "section": "Completing the ANOVA Table",
    "text": "Completing the ANOVA Table\nNow that we have calculated degrees of freedom and effects for each factor , we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. A completed ANOVA summary table contains the information we need for a hypothesis test of the main effects (for controlled factors) and their interaction.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. Note: the total degrees of freedom are the total number of observations.\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n\n\n\n\n\n\nBrush\n3\n\n\n\n\n\n\nToothpaste\n1\n\n\n\n\n\n\nBrush:Toothpaste\n3\n\n\n\n\n\n\nResidual Error\n16\n\n\n\n\n\n\nTotal\n24\n\n\n\n\n\n\n\n\n\n\n\nTo get the sum of squares (SS) of a factor, each value displayed in that particular factor first needs to be squared. Figure 13 shows the effects, while Figure 14 shows the squared effects.\n\n\n\n\n\n\n\n\nFigure 14: Squared factor level effects\n\n\nThen, for each factor, all the squared values are summed up to get the sum of squares. The total sum of squares is obtained by summing the squared observations as shown in Equation 3. This represents the total variability in the dataset that will then be allocated or partitioned to the various factors, starting with the grand mean.\n\\[\nSS_\\text{total} = 365.6 + 344.5 + 654.3 + ... + 452.4 + 548.2  = 12,674.30\n\\tag{3}\\]\nFor grand mean, the squared effect of 518.2 is listed 24 times, once for each observation. Summing the squared effects gets:\n\\[\nSS_\\text{Grand Mean} = 518.2* 24 = 12,437.43\n\\]\n\n\n\n\n\n\nNote\n\n\n\nThe rounded numbers are displayed throughout this section, but all calculations are done using the unrounded numbers.\n\n\nThe toothbrush factor has four different effects: one for each level of the factor. For each effect, the squared value is multiplied by the number of observations within the level of the factor. Then, the results are added across all levels to get the sum of squares due to toothbrush.\n\\[\nSS_\\text{toothbrush} = 6*(0.11) + 6*(7.77) + 6*(0.01) + 6*(6.50) = 86.31\n\\tag{4}\\] \nThe sum of squares is similarly calculated for toothpaste brand (Equation 5) and brush by paste interaction (Equation 4).\n\\[\nSS_\\text{toothpaste} = 12*(0.03) + 12*(0.03) = 0.62\n\\tag{5}\\]\n\\[\nSS_\\text{brush x paste} = 3*(0.02) + 3*(0.44) + 3*(0.04) + 3*(0.52) +3*(0.02) + 3*(0.44) + 3*(0.04) + 3*(0.52)  = 6.12\n\\]\nThe effect for the residual error factor has 24 unique values. The squared residuals are summed together in Equation 6.\n\\[\nSS_\\text{residual} = 18.35 + 0.84 + 8.72 + ... + 2.11 + 1.03  = 143.82\n\\tag{6}\\]\nYou can check that the sums of squares (SS) has been allocated to the factors correctly by adding up the SS for each factor and verifying that it also equals the result found in Equation 3.\nPutting this information into the ANOVA table gets us the result shown in Table 1.\n\n\n\n\nTable 1: Sums of squares\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n12437.43\n\n\n\n\n\nBrush\n3\n86.31\n\n\n\n\n\nToothpaste\n1\n0.62\n\n\n\n\n\nBrush:Toothpaste\n3\n6.12\n\n\n\n\n\nResidual Error\n16\n143.82\n\n\n\n\n\nTotal\n24\n12674.30\n\n\n\n\n\n\n\n\n\n\n\nRecall that SS is a measure of total variability. Of the three structural factors (brush, toothpaste, and their interaction) it is clear to see that brush is contributing the most variability. Some of the difference in SS may be due to difference in number of levels for each factor. Adding levels to a factor allows more variability to be attributed to that factor. We will convert this total variability (sum of squares) into a mean variability (mean square) measure to properly account for differences in number of factor levels. This allows us to compare the factors’ variability on a standardized scale.\nTo calculate a mean square (MS), simply divide SS by degrees of freedom for a factor. The mean square calculations are:\n\\[\nMS_\\text{Grand Mean} = \\frac{SS_\\text{Grand Mean}}{df_\\text{Grand Mean}} = \\frac{12437.43}{1} = 12437.43\n\\]\n\n\\[\nMS_\\text{Brush} = \\frac{SS_\\text{Brush}}{df_\\text{Brush}} = \\frac{86.31}{3} = 28.77\n\\]\n\n\\[\nMS_\\text{Toothpaste} = \\frac{SS_\\text{Toothpaste}}{df_\\text{Toothpaste}} = \\frac{0.62}{1} = 0.62\n\\]\n\n\\[\nMS_\\text{Brush:Toothpaste} = \\frac{SS_\\text{Brush:Toothpaste}}{df_\\text{Brush:Toothpaste}} = \\frac{6.12}{3} = 2.04\n\\]\n\n\\[\nMS_\\text{Residual Error} = \\frac{SS_\\text{Residual Error}}{df_\\text{Residual Error}} = \\frac{143.82}{16} = 8.99\n\\]\n\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n12437.43\n12437.43\n\n\n\n\nBrush\n3\n86.31\n28.77\n\n\n\n\nToothpaste\n1\n0.62\n0.62\n\n\n\n\nBrush:Toothpaste\n3\n6.12\n2.04\n\n\n\n\nResidual Error\n16\n143.82\n8.99\n\n\n\n\nTotal\n24\n12674.30\n\n\n\n\n\n\n\n\n\n\nFor each structural factor in the design there are a set of hypothesis we want to test using the F statistic.\nSpecifically, we will want to test whether toothbrush type has an effect on plaque coverage, whether toothpaste brand has an effect on plaque coverage, and whether the interaction between brush and paste has an effect on plaque coverage.\nMore specifically, for each factor we test whether the factor level effects are all equal to zero. We can express the hypotheses mathematically using the terms of Equation 2.\nA hypothesis for the main effect of toothbrush type:\n\\[H_0: \\alpha_\\text{i} = 0 \\text{ for all } i\\]\n\\[H_a: \\alpha_\\text{i} \\ne 0 \\text{ for some } i\\]\nA hypothesis for the main effect of toothpaste brand:\n\\[H_0: \\beta_\\text{j} = 0 \\text{ for all } j\\]\n\\[H_a: \\beta_\\text{j} \\ne 0 \\text{ for some } j\\]\nA hypothesis for the interaction of toothbrush and toothpaste.\n\\[\nH_0: (\\alpha\\beta)_\\text{ij} = 0 \\text{ for all } ij\n\\]\n\\[\nH_a: (\\alpha\\beta)_\\text{ij} \\ne 0 \\text{ for some } ij\n\\]\nTo test these hypotheses we need to compare the mean square (MS) for a factor to the mean square for residual error (abbreviated as MSE). The MSE is the estimate of unexplained, random error. If a factor’s MS is similar in size to the MSE, the variance in that factor may just be random error; and the effect of the factor levels are zero. On the other hand, if the variability in the factor, as measured by its MS, is much larger than the random error observed in the experiment (represented by MSE), then it is reasonable to believe the factor levels have a non-trivial contribution to the variability. In other words, the factor has a significant effect on the response.\nThe F statistic is a ratio of these two errors and is obtained by dividing the factor’s mean square (MS) by the MSE. The F statistic calculations are\n\n\\(F_\\text{brush} = 28.77/8.99 = 3.20\\)\n\\(F_\\text{toothpaste} = 0.62/8.99 = 0.07\\)\n\\(F_\\text{brush:toothpaste} = 2.04 / 8.99 = .23\\)\n\nThis F statistic follows a well defined distribution, called the F distribution. The F distribution is defined by two values for degrees of freedom3:\n\nthe numerator degrees of freedom, which is the degrees of freedom for the factor being tested\nthe denominator degrees of freedom, which is the degrees of freedom for residual error\n\nThe area under this distribution curve to the right of our F statistic is called the p-value. The p-value represents the probability of getting an F statistic at least as large as the one obtained, assuming the null hypothesis (of no effect) is true.\nThe F statistic, numerator degrees of freedom, and denominator degrees of freedom are the 3 required inputs to calculate a p-value. P-values can be obtained manually using the applet mentioned above, the f.dist.rt()4 function in excel or the pf() function in R5. Usually though, R will show p-values as part of the standard output of the ANOVA model/table and it is recommended you stick to those values when reporting answers.\nThe completed ANOVA table for this BF[2] toothbrush and toothpaste example is shown in\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n12437.43\n12437.43\n\n\n\n\nBrush\n3\n86.31\n28.77\n3.20\n0.051\n\n\nToothpaste\n1\n0.62\n0.62\n0.07\n0.800\n\n\nBrush:Toothpaste\n3\n6.12\n2.04\n0.23\n0.876\n\n\nResidual Error\n16\n143.82\n8.99\n\n\n\n\nTotal\n24\n12674.30\n\n\n\n\n\n\n\n\n\n\nBecause the p-value for the interaction (p-value = 0.876) is much higher than any traditional level of significance threshold we might have chosen (0.01, 0.05, or 0.1), we fail to reject the null hypothesis. There is insufficient evidence to say the interaction effect has an effect on plaque coverage. Because the interaction is NOT significant, we can proceed to interpret the main effects test results.\n\n\n\n\n\n\nSignificant Interaction Effects\n\n\n\nIf the interaction effect is significant, great caution should be taken when interpreting the hypothesis test results for the factors involved in the interaction; it may not be valid to interpret the hypothesis test results. Instead, if the interaction is significant, it is better to describe the nature of the interaction with graphs, numbers, and words.\n\n\nToothpaste’s p-value is high (p-value = 0.8), indicating no evidence that toothpaste brand has an effect on plaque coverage. The p-value for brush is marginally significant (p-value = 0.051). When (in)significance is borderline, rather than making bold statements based on a small amount of (in)significance, it is helpful to dig a little deeper. Consider things like sample size, effect size (practical significance), outliers, and how closely assumptions are met. After weighing those considerations carefully, take a stance and state your belief about the role of the factor on the response. Explain your rationale, then keep an open mind and stay curious."
  },
  {
    "objectID": "bf2.html#describe-the-data",
    "href": "bf2.html#describe-the-data",
    "title": "BF[2]",
    "section": "Describe the Data",
    "text": "Describe the Data\nWhen working with a dataset the first thing to do is get to know your data through numerical and graphical summaries. Numerical summaries typically consist of means, standard deviations, and sample sizes for each factor level. Graphical summaries most usually are boxplots, scatterplots, and/or interaction plots with the means displayed.\nInteractive code and additional explanations of numerical summaries and plots in R are found at R Instructions-&gt;Descriptive Summaries section of the book.\n\nNumerical Summaries\nAfter loading required packages, we will read in the data and do some wrangling.\n\n\nCode\nbf2 &lt;- read_csv(\"data/toothpaste_BF2.csv\") \n\n\nWe then calculate summary statistics for each factor level separately.\n\n\nCode\n#Descriptive stats for levels of Brush\nfavstats(Plaque~Brush, data = bf2) |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n#Descriptive stats for levels of Toothpaste\nfavstats(Plaque~Toothpaste, data = bf2) |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\nTable 2: Numerical Summary for Each Factor\n\n\n\n\n(a) Brush\n\n\nBrush\nmin\nQ1\nmedian\nQ3\nmax\nmean\nsd\nn\nmissing\n\n\n\n\nManual\n19.12\n22.04\n23.38\n24.01\n26.88\n23.09\n2.60\n6\n0\n\n\nOscillating\n17.62\n18.89\n19.94\n21.29\n22.09\n19.98\n1.74\n6\n0\n\n\nSonic\n18.99\n21.73\n23.20\n23.68\n25.58\n22.67\n2.27\n6\n0\n\n\nUltrasonic\n21.45\n23.62\n24.30\n25.35\n32.74\n25.31\n3.90\n6\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Toothpaste\n\n\nToothpaste\nmin\nQ1\nmedian\nQ3\nmax\nmean\nsd\nn\nmissing\n\n\n\n\nNameBrand\n18.56\n19.68\n22.38\n24.69\n32.74\n22.92\n4.18\n12\n0\n\n\nOffBrand\n17.62\n21.69\n23.22\n23.52\n25.67\n22.60\n2.00\n12\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn Table 2 (a) we see that the oscillating brush has lowest mean plaque (19.98). Table 2 (b) shows the mean plaque for the two types of toothpaste is very close, 22.92 for Name Brand and 22.60 for Off Brand.\nYou can also look at descriptive statistics for factor level combinations. This is only advisable if there is sufficient sample size at each combination and the number of combinations is manageable. Table 3 shows what that looks like for our current example. Due to the many combinations, it is a bit difficult to interpret the output. Furthermore, using a 5 number summary on a sample size of 3 observations is not advisable so some of the summary statistics have been dropped.\nThe combination of Oscillating with Name Brand has the lowest mean (19.48) and the lowest standard deviation (0.80).\n\n\nCode\nfavstats(Plaque~Brush+Toothpaste, data = bf2) |&gt; \n  select(Brush.Toothpaste, mean, sd, n) |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = FALSE)\n\n\n\n\nTable 3: Numerical Summary\n\n\nBrush.Toothpaste\nmean\nsd\nn\n\n\n\n\nManual.NameBrand\n23.40\n3.94\n3\n\n\nOscillating.NameBrand\n19.48\n0.80\n3\n\n\nSonic.NameBrand\n22.63\n3.35\n3\n\n\nUltrasonic.NameBrand\n26.19\n5.86\n3\n\n\nManual.OffBrand\n22.78\n1.03\n3\n\n\nOscillating.OffBrand\n20.48\n2.48\n3\n\n\nSonic.OffBrand\n22.72\n1.31\n3\n\n\nUltrasonic.OffBrand\n24.43\n1.14\n3\n\n\n\n\n\n\n\n\n\n\nGraphical Summaries\nGraphs are also valuable tools to help you get to know your data. Since there are only 3 observation in each factor level combination, a dotplot/scatterplot is more appropriate than a boxplot. This is shown in Figure 15\n\n\nCode\n#Note, I have to turn Brush into a factor because it started out as a character variable\ndotplot(Plaque~factor(Brush)|factor(Toothpaste), data = bf2, \n        xlab = \"\")\n\n\n\n\n\nFigure 15: Graphical Summary\n\n\n\n\nYou could also gain insight about the main effects by cutting the data by each factor separately, as shown in Figure 16.\n\n\n\n\n\n\n\n(a) Brush\n\n\n\n\n\n\n\n(b) Toothpaste\n\n\n\n\nFigure 16: Data cut by one factor at a time\n\n\nFinally, an interaction plot is ideal for investigating a BF[2]. The plot only shows factor level means. Therefore, it does not give a good sense of the underlying distribution of data and should not be used as the only visual assessment of your data. However, it is extremely good at providing insight into possible interactions.\nIn Figure 17 the lines are not parallel. In fact, they cross twice. Though this seems to suggest an interaction is present, our ability to claim an interaction exists will depend on the results of a hypothesis test. The hypothesis test is greatly influenced by sample size and the variability at each of the factor level means presented in the plot.\n\n\n\n\n\nFigure 17: Interaction plot for Brush vs. Toothpaste"
  },
  {
    "objectID": "bf2.html#create-the-model",
    "href": "bf2.html#create-the-model",
    "title": "BF[2]",
    "section": "Create the Model",
    "text": "Create the Model\nYou then create the model using the aov() function. To see results of the F-test you can feed your model into a summary() or anova() function.\n\n\nsummary() and anova() functions give the same output with some slight differences in formatting when called on a model created with aov(). The summary() function is more general; it can also take linear regression models created with 'lm() as inputs. The output provided by summary() will change based on the type of object it is called on. This is discussed in more detail at the bottom of the Unbalanced page.\n\nmyaov &lt;- aov(Y ~ X1*X2, data=YourDataSet)\nsummary(myaov)\n\n\nmyaov is the user defined name in which the results of the aov() model are stored\nY is the name of a numeric variable in your dataset which represents the quantitative response variable.\nX1 and X2 are names of qualitative variables in your dataset. They should have class(X) equal to factor or character. If that is not the case, use factor(X) inside the aov(Y ~ factor(X1)*...) command.\nYourDataSet is the name of your data set.\n\nThe * in the code above is a shortcut for writing out the whole model. It can be read as, “include each term by itself, and all possible interaction terms”. The long way of writing out the model uses a colon, :, to define interaction terms and is shown below. When writing it this way each term must be explicitly stated.\n\nmyaov &lt;- aov(Y ~ X1+X2+X1:X2, data=YourDataSet)\nsummary(myaov)\n\nBelow are the results for the full BF[2] model using the toothbrush and toothpaste example. You should notice that these results match what we got when we performed the decomposition manually to build the ANOVA summary table. Even though the interaction plot showed crossing lines, we see the interaction between Brush and Toothpaste is not significant (p-value = .8763). This means we can interpret the hypothesis tests for each of the main effects.\nToothpaste is not significant (p-value = .7966) and Brush is marginally significant (p-value = .0517, which is close to the traditional alpha level of 0.05). Our exploratory analysis showed that oscillating brush resulted in the lowest amount of plaque and the ultrasonic brush resulted in the highest plaque measure.\n\n\nCode\nbf2_aov &lt;- aov(Plaque~Brush*Toothpaste,data=bf2)\nsummary(bf2_aov)\n\n\n                 Df Sum Sq Mean Sq F value Pr(&gt;F)  \nBrush             3  86.31  28.769   3.201 0.0517 .\nToothpaste        1   0.62   0.618   0.069 0.7966  \nBrush:Toothpaste  3   6.12   2.040   0.227 0.8763  \nResiduals        16 143.82   8.989                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn order to trust these hypothesis test results we need to verify that the assumptions are met."
  },
  {
    "objectID": "bf2.html#check-assumptions",
    "href": "bf2.html#check-assumptions",
    "title": "BF[2]",
    "section": "Check Assumptions",
    "text": "Check Assumptions\nFor a more detailed explanation of the code, output, and theory behind these assumptions visit the Assumptions page.\n\nConstant Variance of Residuals\nThere needs to be constant variance of residuals across the factor level combinations. First, we can check the residual plot.\n\n\nCode\nplot(bf2_aov, which = 1)\n\n\n\n\n\nFigure 18: Checking constant variance\n\n\n\n\nIn Figure 18 there are 8 distinct vertical groupings of points, one for each factor level combination. There are 3 observations, and so 3 residuals also, for each factor level combination. There does seem to be a slight trend for points with larger predicted values to be more spread out. On the far left of the plot the points appear closer together, as you move to the right the points tend to be more spread out (thought not always). This phenomenon raises the concern that the assumption of constant variance across factor level combinations may be violated.\nLevene’s test can provide insight on whether the trend in the residual plot is drastic enough to constitute a violation of the constant variance assumption.\nRecall that the null hypothesis for Levene’s test is that the variance of residuals is equal for each and every factor level combination. The results of the test below shows a p-value of 0.5409. We therefore fail to reject a null hypothesis of equal variances and proceed with the analysis (assuming the other assumptions are met).\n\n\nCode\nleveneTest(bf2_aov) %&gt;% kable(digits = 2)\n\n\n\n\n\n\nDf\nF value\nPr(&gt;F)\n\n\n\n\ngroup\n7\n0.88\n0.54\n\n\n\n16\n\n\n\n\n\n\n\n\n\n\n\nNormally Distributed Residuals\nWe check the assumption that residuals are normally distributed in Figure 19. Most of the points are in the shaded region. Row 1 of the dataset appears in the upper right corner, far away from the boundaries. A couple of other points are very close, but just outside of the boundary. Due to the robust nature of ANOVA, the mild violation of this assumption is not a concern.\n\n\nCode\ncar::qqPlot(bf2_aov$residuals, id = FALSE)\n\n\n\n\n\nFigure 19: Checking normality of residuals\n\n\n\n\n\n\nIndependent Residuals\nThe dataset we are analyzing does not include information about the order in which the data was collected. In fact, it may be possible there were multiple teams of researchers collecting the data simultaneously and there is no specific order. From what we know, there is no reason to think there is a potential order bias. Nevertheless, the order plot in Figure 20 can be used to investigate trends in residuals by row number in the dataset. This plot does not show any patterns or trends. The assumption of independent residuals seems to be satisfied.\n\n\nCode\nplot(bf2_aov$residuals)\n\n\n\n\n\nFigure 20: Checking independent residuals assumption\n\n\n\n\n\n\nAssumptions Summary\nThe assumptions appear to be met, meaning the p-values should be valid and reliable. However, since the F-test for toothbrush is such a close call, mild-moderate assumption violations may cause the p-value of the test to be slightly off. Even after attempting various transformations of the response variable, Plaque, the degree to which assumptions are met does not improve (in fact, in some cases it gets worse).\nRather than fuss about the whether F-test assumptions are met or not, you can recognize the F-test for Brush is close enough to merit further investigation. In this case, it is recommended to proceed with contrasts/pairwise tests of toothbrush type which do not require constant variance. (You should be aware of what assumption are required for those tests and be sure to check them).\n\n\nCode\nTukeyHSD(bf2_aov, which = \"Brush\")\n\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = Plaque ~ Brush * Toothpaste, data = bf2)\n\n$Brush\n                             diff       lwr       upr     p adj\nOscillating-Manual     -3.1166667 -8.069047  1.835714 0.3089079\nSonic-Manual           -0.4183333 -5.370714  4.534047 0.9948323\nUltrasonic-Manual       2.2200000 -2.732381  7.172381 0.5864034\nSonic-Oscillating       2.6983333 -2.254047  7.650714 0.4280732\nUltrasonic-Oscillating  5.3366667  0.384286 10.289047 0.0324891\nUltrasonic-Sonic        2.6383333 -2.314047  7.590714 0.4469155\n\n\nIn the above output results for all pairwise comparisons with Tukey’s HSD adjustment for multiple comparisons are displayed. Only the Ultrasonic-Oscillating comparison is significantly different, with a p-value of .03. Therefore, we can state that the ultrasonic brush performs significantly worse than the oscillating brush at plaque reduction."
  },
  {
    "objectID": "bf2.html#notation-for-estimated-effects",
    "href": "bf2.html#notation-for-estimated-effects",
    "title": "BF[2]",
    "section": "Notation for Estimated Effects",
    "text": "Notation for Estimated Effects\nHere are symbolic representations for the estimated effects in the BF[2] model, as shown in Equation 1.\n\\[\n\\hat{\\alpha}_i = \\bar{y}_{i \\cdot \\cdot} - \\bar{y}_{\\cdots}\n\\]\n\\[\n\\hat{\\beta}_j = \\bar{y}_{\\cdot j \\cdot} - \\bar{y}_{\\cdots}\n\\]\n\\[\n\\begin{align}\n\\hat{\\alpha}\\hat{\\beta}_{ij} & = \\bar{y}_{i j \\cdot} - (\\bar{y}_{\\cdot \\cdot \\cdot} + \\hat{\\alpha}_i  + \\hat{\\beta}_j ) \\\\\n&= \\bar{y}_{i j \\cdot} - (\\bar{y}_{\\cdot \\cdot \\cdot} + (\\bar{y}_{i \\cdot \\cdot} - \\bar{y}_{\\cdot \\cdot \\cdot})  + (\\bar{y}_{\\cdot j \\cdot} - \\bar{y}_{\\cdot \\cdot \\cdot}) ) \\\\\n& = \\bar{y}_{i j \\cdot} - (\\bar{y}_{i \\cdot \\cdot} + \\bar{y}_{\\cdot j \\cdot} - \\bar{y}_{\\cdot \\cdot \\cdot})\n\\end{align}\n\\]"
  },
  {
    "objectID": "bf2.html#unreplicated-or-single-observation-per-cell",
    "href": "bf2.html#unreplicated-or-single-observation-per-cell",
    "title": "BF[2]",
    "section": "Unreplicated or Single Observation per Cell",
    "text": "Unreplicated or Single Observation per Cell\nWhat can be done in the case of an experiment where there is only one observation per factor level combination?\nUnder construction."
  },
  {
    "objectID": "bf2.html#footnotes",
    "href": "bf2.html#footnotes",
    "title": "BF[2]",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThere are symbolic/mathematical representations of the factor effect formulas located in the appendix.↩︎\nThe values used in calculations here and throughout this page are rounded for a cleaner display. However, you should use unrounded values for these calculations. Rounded values and significant digits is the reason the arithmetic in some of these calculations appears off by one one-hundredth.↩︎\nYou can explore behavior of the F distribution for various combinations of degrees of freedom using this applet↩︎\nThis is the formula used in Excel to obtain the p-values for brush, toothpaste, and brush:toothpaste interaction respectively:\n\nbrush: `=f.dist.rt(3.20054, 3, 16)\ntoothpaste: =f.dist.rt(0.06871, 1, 16)\nbrush:toothpaste : =f.dist.rt(.226924, 3, 16)\n\n↩︎\nThis is the formula used in R to obtain the p-values for brush, toothpaste, and brush:toothpaste interaction respectively:\n\nbrush: 1-pf(3.2005, 3, 16)\ntoothpaste: 1-pf(0.06871, 1, 16)\nbrush:toothpaste : 1-pf(0.2269, 3, 16)\n\n↩︎"
  },
  {
    "objectID": "latin_square.html",
    "href": "latin_square.html",
    "title": "Latin Square",
    "section": "",
    "text": "The CB[1] design works well when there is only one variable to block on. What can be done when there are two nuisance factors to block on? If those two blocking factors and the treatment all have the same number of levels, then a latin square design should be used.\n\n\n\n\n\n\nWhen to use Latin Square\n\n\n\nLatin Square designs are appropriate when\n\nTwo blocking factors and one treatment factor\nAll three factors have the same number of levels\nTreatments can be assigned to experimental units\n\n\n\nPreviously, in the CB[1] design we used the toothbrush study and blocked on participant. If we only had 4 participants and we considered “order” a nuisance factor, we could use a Latin Square. By adding “order” as a blocking variable, we can ensure that the order of the treatments does not all become the same by random chance alone.\nBlocking on subjects and order of treatments is one of the most common applications of a Latin Square design in psychology. (Treatments, of course, must be something that can be assigned to experimental units). Be aware that in these types of experiments carry-over effects (such as learning and fatigue) can be problematic. Experimental protocols need to proactively address potential carry-over effects1.\nLatin Square designs are also common in agriculture, where they were originally developed. The field is divided into a square grid and treatments are randomly applied to each cell of the grid. The blocking variables are the row position and column position in the grid respectively.\nFigure 1 shows two images of Latin Square designs in agriculture, pulled from Bailey, Cameron, and Connelly’s 2008 article in American Mathematical Monthly 2. Figure 1 (a) is a picture of a 5×5 forestry experiment on a hill in Beddgelert in Wales. The experiment was “designed by Fisher, laid out in 1929, and photographed in about 1945”. Figure 1 (b) shows “a 6×6 experiment to compare methods of controlling aphids; conducted by Lesley Smart at Rothamsted Research, photographed in 2004.”\n\n\n\n\n\n\n\n(a)\n\n\n\n\n\n\n\n(b)\n\n\n\n\nFigure 1: Agricultural examples of latin squares\n\n\nRegardless of whether the application is psychology, agriculture or something else, the key design feature of a Latin Square design is that each treatment appears exactly once in each row and in each column of the square.\nThere are various extensions to this basic Latin Square idea. Graeco Latin Squares can be used if you have more than 2 variables to block on (provided all factors have the same number of levels, and the number is not 6). Replicated Latin Squares is useful if the number of experimental units is a multiple of (instead of exactly equal to) the number of treatment factor levels. Replicated Latin Squares is discussed briefly here and here.\n\n\nIn the factor diagram, one nuisance factor’s levels are associated with the row partitions of the dataset. The other nuisance factor’s levels are marked by partitioning the dataset by columns. The treatment is assigned a letter inside the factor diagram. Figure 2 is a factor structure diagram for a Latin Square design where the controlled factors all have 4 levels. This is an unrandomized layout of the treatments: each row (and column) follows the same sequence of treatments. In the Design section we will learn to randomize the design.\n\n\n\nFigure 2: Factor Structure for Latin Square Design with 4 Treatment Levels\n\n\n\n\n\nEach factor (i.e. meaningful partition of the data) in Figure 2 corresponds to a term on the right hand side of Equation 1:\n\\[\ny_{ijk} = \\mu + \\alpha_i + \\beta_j + \\gamma_k + \\epsilon_{ijk}\n\\tag{1}\\]\nWhere\n\n\\(y_{ij}\\) is the observation that belongs to level i of \\(\\alpha\\), level j of \\(\\beta\\), and level k of \\(\\gamma\\).\n\\(\\mu\\) is the grand mean of the entire dataset.\n\\(\\alpha\\) is the effect of the block factor partitioned by rows\n\\(\\beta\\) is the effect of the block factor partitioned by columns\n\\(\\gamma\\) is the effect of the treatment factor, designated by a letter value. Each treatment appears exactly once in each row and each column.\n\\(\\epsilon\\) is the residual error term\n\nThe Latin Square is an incomplete block design. In other words, each treatment does not show up in each block. In other words, not all subscript combinations of i, j, and k will be observed. Therefore there are insufficient observations to estimate and test interaction effects.\nThe hypothesis for the treatment is\n\\[H_0: \\gamma_k = 0 \\text{ for all }k\\]\n\\[H_a: \\gamma_k \\ne 0 \\text{ for some }k\\]\n\n\nThe focus of the study is on the treatment factor. However, you can test the block factors in the same way you test the treatment factor.\n\n\n\nAn ANOVA model may be used to analyze data from a CB[1] design if the following requirements are satisfied.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels[^1]\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "latin_square.html#factor-structure",
    "href": "latin_square.html#factor-structure",
    "title": "Latin Square",
    "section": "",
    "text": "In the factor diagram, one nuisance factor’s levels are associated with the row partitions of the dataset. The other nuisance factor’s levels are marked by partitioning the dataset by columns. The treatment is assigned a letter inside the factor diagram. Figure 2 is a factor structure diagram for a Latin Square design where the controlled factors all have 4 levels. This is an unrandomized layout of the treatments: each row (and column) follows the same sequence of treatments. In the Design section we will learn to randomize the design.\n\n\n\nFigure 2: Factor Structure for Latin Square Design with 4 Treatment Levels"
  },
  {
    "objectID": "latin_square.html#model-and-hypotheses",
    "href": "latin_square.html#model-and-hypotheses",
    "title": "Latin Square",
    "section": "",
    "text": "Each factor (i.e. meaningful partition of the data) in Figure 2 corresponds to a term on the right hand side of Equation 1:\n\\[\ny_{ijk} = \\mu + \\alpha_i + \\beta_j + \\gamma_k + \\epsilon_{ijk}\n\\tag{1}\\]\nWhere\n\n\\(y_{ij}\\) is the observation that belongs to level i of \\(\\alpha\\), level j of \\(\\beta\\), and level k of \\(\\gamma\\).\n\\(\\mu\\) is the grand mean of the entire dataset.\n\\(\\alpha\\) is the effect of the block factor partitioned by rows\n\\(\\beta\\) is the effect of the block factor partitioned by columns\n\\(\\gamma\\) is the effect of the treatment factor, designated by a letter value. Each treatment appears exactly once in each row and each column.\n\\(\\epsilon\\) is the residual error term\n\nThe Latin Square is an incomplete block design. In other words, each treatment does not show up in each block. In other words, not all subscript combinations of i, j, and k will be observed. Therefore there are insufficient observations to estimate and test interaction effects.\nThe hypothesis for the treatment is\n\\[H_0: \\gamma_k = 0 \\text{ for all }k\\]\n\\[H_a: \\gamma_k \\ne 0 \\text{ for some }k\\]\n\n\nThe focus of the study is on the treatment factor. However, you can test the block factors in the same way you test the treatment factor."
  },
  {
    "objectID": "latin_square.html#assumptions",
    "href": "latin_square.html#assumptions",
    "title": "Latin Square",
    "section": "",
    "text": "An ANOVA model may be used to analyze data from a CB[1] design if the following requirements are satisfied.\n\n\n\n\n\n\n\n\nRequirements\nMethod for Checking\nWhat You Hope to See\n\n\n\n\nConstant variance across factor levels[^1]\nResidual vs. Fitted Plot\nNo major disparity in vertical spread of point groupings\n\n\nNormally Distributed Residuals\nNormal Q-Q plot\nStraight line, majority of points in boundaries\n\n\nIndependent residuals\nOrder plot\nNo pattern/trend\n\n\n\nFamiliarity with/critical thinking about the experiment\nNo potential source for bias"
  },
  {
    "objectID": "latin_square.html#r-randomization",
    "href": "latin_square.html#r-randomization",
    "title": "Latin Square",
    "section": "R randomization",
    "text": "R randomization\n\nWide format\nIf the design is laid out similar to the factor structure diagram it is considered to be in wider format. This code creates a table in wider format of the unrandomized design.\n\n#First create the unrandomized layout design, labeling the rows and columns as 1, 2, 3, 4\nls_design &lt;- tibble(`1` = c(`1`  = \"A\", `2` =\"B\", `3`=  \"C\", `4` = \"D\"), \n                             `2` = c(\"B\", \"C\", \"D\", \"A\"), \n                             `3` = c(\"C\", \"D\", \"A\", \"B\"), \n                             `4` = c(\"D\", \"A\", \"B\", \"C\"))\nls_design\n\n# A tibble: 4 × 4\n  `1`   `2`   `3`   `4`  \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 A     B     C     D    \n2 B     C     D     A    \n3 C     D     A     B    \n4 D     A     B     C    \n\n\nOne simple way is to carry out the randomization is to use the sample() command in conjunction with the [] notation. The sample() command randomly shuffles the values it is given. The square brackets allow you to reference rows and columns of a matrix. The first argument in the square brackets refers to rows, the second argument refers to columns.\n\n#Then randomize rows\nset.seed(42)\nrow_randomized &lt;- ls_design[sample(nrow(ls_design)), ]\n\nset.seed(42)\n#Then randomize columns\nall_randomized &lt;- row_randomized[ , sample(ncol(row_randomized))]\n\nset.seed(17)\n#The above randomization steps can be combined into one command\nls_design[ sample(nrow(ls_design)), sample(ncol(ls_design))]\n\n# A tibble: 4 × 4\n  `3`   `4`   `1`   `2`  \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 D     A     B     C    \n2 C     D     A     B    \n3 B     C     D     A    \n4 A     B     C     D    \n\n\n\n\nLonger format\nThe R language often wants data in longer format. To create the unrandomized design in longer format, use this code:\n\ntibble(row_blocks = rep(1:4, each = 4), \n       column_blocks = rep(1:4, times = 4),\n       treatment = c(\"A\", \"B\", \"C\", \"D\", \n                     \"B\", \"C\", \"D\", \"A\", \n                     \"C\", \"D\", \"A\", \"B\",\n                     \"D\", \"A\", \"B\", \"C\"))\n\n# A tibble: 16 × 3\n   row_blocks column_blocks treatment\n        &lt;int&gt;         &lt;int&gt; &lt;chr&gt;    \n 1          1             1 A        \n 2          1             2 B        \n 3          1             3 C        \n 4          1             4 D        \n 5          2             1 B        \n 6          2             2 C        \n 7          2             3 D        \n 8          2             4 A        \n 9          3             1 C        \n10          3             2 D        \n11          3             3 A        \n12          3             4 B        \n13          4             1 D        \n14          4             2 A        \n15          4             3 B        \n16          4             4 C        \n\n\nTo randomize the rows and columns, put the vector 1:4 within the sample() command when defining the row blocks and the column blocks, as shown below:\n\n#randomize rows\nset.seed(42)\nrandomized_design &lt;- tibble(row_blocks = rep(sample(1:4), each = 4),\n                            column_blocks = rep(sample(1:4), times = 4),\n                            treatment = c(\"A\", \"B\", \"C\", \"D\", \n                                          \"B\", \"C\", \"D\", \"A\", \n                                          \"C\", \"D\", \"A\", \"B\",\n                                          \"D\", \"A\", \"B\", \"C\"))\nrandomized_design\n\nAfter carrying out the experiment and gathering data, a vector containing the observed values can be added to the dataset using mutate(), cbind(), or dplyr::bind_col() from the tidyverse. Only the cbind() option is shown in the code below.\n\n#Store observed data in a vector. \n# These observed values are copmletely made up\nobserved_values &lt;- c(-1, 2, 6, 11, -5, 2, 7, 5, 4,-2, -3, 8, 8, 2, 1, 0)\ncbind(randomized_design, observed_values)"
  },
  {
    "objectID": "latin_square.html#degrees-of-freedom",
    "href": "latin_square.html#degrees-of-freedom",
    "title": "Latin Square",
    "section": "Degrees of Freedom",
    "text": "Degrees of Freedom\nAs is the case with other designs learned so far, the grand mean factor is outside of all other factors. There is only one grand mean associated with the dataset, so there is just one degree of freedom associated with grand mean.\nThe general rule for calculating degrees of freedom states that the degrees of freedom for a factor are equal to the number of levels of that factor minus the sum of degrees of freedom of all outside factors.\nGrand mean is the only factor outside of intersection (rows), time of day (column), and treatment (algorithm)5. Therefore, for each of these factors we can take their number of levels and subtract one; the degrees of freedom for the 3 structural factors are 4-1 = 3.\nThere is one residual for each observation, therefore the number of factor levels for residual is equal to the sample size, 16. The residual factor is inside of all other factors, so degrees of freedom for residual is 16 – (1 + 3 + 3 + 3) = 66."
  },
  {
    "objectID": "latin_square.html#factor-effects",
    "href": "latin_square.html#factor-effects",
    "title": "Latin Square",
    "section": "Factor Effects",
    "text": "Factor Effects\nTo calculate factor effects, we start by calculating means for each level of every factor.\n\nFactor Means\nBelow is a table that contains observed throughput for the combinations of intersection, time of day, and algorithm (represented as A, B, C or D).\n\nObserved Throughput for Traffic Light Timing Algorithm Experiment\n\n\n\n8am\n11am\n2pm\n5pm\n\n\n\n\nIntersection 1\nA (32)\nB (33)\nC (47)\nD (53)\n\n\nIntersection 2\nB (36)\nD (53)\nA (42)\nC (54)\n\n\nIntersection 3\nC (51)\nA (44)\nD (62)\nB (49)\n\n\nIntersection 4\nD (81)\nC (78)\nB (72)\nA (73)\n\n\n\nThe grand mean and the mean of each factor level will be calculated for the 3 structural factors.\nThe grand mean is simply the mean of all the observations and is equal to 53.8.\nThe calculation to find the mean of an intersection (row) are as follows:\n\\[\n\\bar{y}_\\text{intersection 1} = \\bar{y}_{1\\cdot\\cdot} = \\frac{32 + 33 + 47 +  53}{4} = 41.3\n\\]\n\nSimilar calculations can be applied to obtain the row mean for the other rows.\nNow find the mean for each time of day (column). The calculation for the first column is shown below. Similar calculations can be applied to obtain the mean for each of the other columns as well.\n\\[\n\\bar{y}_\\text{8am} = \\bar{y}_{\\cdot 1 \\cdot} = \\frac{32 + 36 + 51 + 81}{4} = 50\n\\]\nTo find the mean for each algorithm, we add together the 4 observations that belong to each algorithm and divide by four.\n$$ \\[\\begin{align}\n\\bar{y}_A = \\bar{y}_{\\cdot \\cdot 1} &= \\frac{32 + 44 + 42 + 73}{4} = 47.8 \\\\\n\n\\bar{y}_B = \\bar{y}_{\\cdot \\cdot 2} &= \\frac{36 + 33 + 72 + 79}{4} = 47.5 \\\\\n\n\\bar{y}_C = \\bar{y}_{\\cdot \\cdot 3} &= \\frac{51 + 78 + 47 + 54}{4} = 57.5 \\\\\n\n\\bar{y}_D = \\bar{y}_{\\cdot \\cdot 4} &= \\frac{81 + 53 + 62 + 53}{4} = 62.3\n\\end{align}\\] $$\nWe do not need to calculate means for residual error factor for two reasons. First, there is only one observation per level of residual error, so the mean is the observation itself. Second, nothing is inside of residual error. It is the last step in the process and its mean is not needed to calculate factor effects.\nThe means for each factor level are shown in Figure 4.\n\n\n\nFigure 4: Factor Level Means\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe means in the image are rounded to 1 decimal place to save on space, but calculations should take advantage of full decimal precision."
  },
  {
    "objectID": "latin_square.html#factor-effects-1",
    "href": "latin_square.html#factor-effects-1",
    "title": "Latin Square",
    "section": "Factor Effects",
    "text": "Factor Effects\nNow that means for each level of each factor are calculated, we can move on to calculate effects of the factor levels. We will use the general formula for calculating effect size,\n\\[\n\\text{factor level effect} = \\text{factor level mean} - \\text{sum of all outside factor effects}\n\\]\nFor the grand mean, there is only one level and there are no outside factors. Therefore, the effect due to grand mean is 53.8 (equivalent to its mean) and this affect is applied to all 16 observations.\nThe intersection factor has four levels: one for each intersection. To calculate the effect of an intersection, take the intersection mean and subtract it from the effect due to the grand mean factor. For the intersection 1 this looks like:\n\\[\n41.25 - 53.75 = -12.5\n\\]\nThis result indicates that the mean throughput at intersection 1 is 12.5 fewer cars than the grand mean. Effects for the other 3 intersections are found with a similar calcultion.\nTo find the effect of a specific time of day, subtract the grand mean from the level’s mean. For “8am”, the calculation is\n\\[\n50 - 53.75 = -3.75\n\\]\nEffects of the other times of day are similarly calculated.\nTo find the effect of timing algorithm A, subtract the grand mean from the mean of algorithm A:\n\\[\n47.75 - 53.75 = -6\n\\]\nSimilarly, the effect of algorithm B is \\(47.5 - 53.75 = 3.25\\), algorithm C’s effect is \\(57.5 - 53.75 = 3.75\\) and D’s effect is \\(62.26 - 53.75 = 8.5\\).\nLastly, the residuals (or residual effects) need to be calculated. The mean for each level of residual is simply the observation itself. Effects associated with an observation’s factor levels are subtracted from the observed value. Whatever is left over is considered the residual. In other words, we have applied the general rule for calculating effect size. For the residual factor, the effect can concisely be stated as “observed value - predicted value”.\nAs an example, the residual in the top left corner of the residual factor was obtained with this calculation:\n\\[\n32 - (53.75 + -12.5 + -3.25 + -6) = 0.5\n\\]\nFigure 5 uses the factor structure diagram to show the build-up of each observations as the summation of each of its factor level effects.\n\n\n\n\nFigure 5: Factor Effects"
  },
  {
    "objectID": "latin_square.html#completing-the-anova-table",
    "href": "latin_square.html#completing-the-anova-table",
    "title": "Latin Square",
    "section": "Completing the ANOVA Table",
    "text": "Completing the ANOVA Table\nNow that we have calculated degrees of freedom and effects for each factor, we can calculate the remaining pieces of the ANOVA table: Sum of Squares (SS), Mean Squares (MS), F-statistic and p-value. A completed ANOVA summary table contains the information we need for a hypothesis test of the treatment effect.\nIn an ANOVA table, each factor and their associated degrees of freedom are listed on the left. The total degrees of freedom are the total number of observations.\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n\n\n\n\n\n\nIntersection (row)\n3\n\n\n\n\n\n\nTime of day (column)\n3\n\n\n\n\n\n\nAlgorithm (treatment)\n3\n\n\n\n\n\n\nResidual Error\n6\n\n\n\n\n\n\nTotal\n16\n\n\n\n\n\n\n\n\n\n\n\nTo get the sum of squares (SS) of a factor, the effects of the factor must be squared, and then summed. The factor effects were displayed in Figure 5 above. Figure 6 (below) shows squared effects for the factors, excluding the grand mean and the observations.\n\n\n\n\nFigure 6: Squared Factor Effects\n\n\n\nThe total sum of squares ($ SS_{total}$) represents all the squared variability that we will need to allocate to the various factors. It is calculated by squaring each observation and then summing them together:\n\\[\nSS_{total} = 32^2 + 33^2 + … + 73^2 = 49856\n\\]\nTo get the Sum of Squares for the grand mean factor we first square the effect of grand mean, \\(53.75^2 = 2889.0625\\). That value occurs 16 times in the dataset (once for each observation), so $ SS_$ = 2889.0625 * 16 = 46225.\nTo get the sum of squares for each factor, we simply add all the squared effects. Since for intersections, time of day, and timing algorithm, each effect is repeated exactly 4 times, we will use some multiplication to simplify the calculation:\n\\[\\begin{align}\n\nSS_\\text{intersections} &= 4*(156.3 + 56.3 + 5.1 + 495.1) = 2850.5 \\\\\n\nSS_\\text{time of day} &= 4 *(14.1 + 3.1 + 4 + 12.3) = 133.5 \\\\\n\nSS_\\text{algorithm} &= 4 * (36 + 39.1 + 14.1 + 72.3) = 645.5 \\\\\n\nSS_\\text{residual} &= 4 * (0.25 + 0.06 + 0 + 0.06) = 1.5\n\\end{align}\\]\nPutting this information into the ANOVA table gives us Table 1.\n\n\n\n\nTable 1: Sums of squares\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n46225.0\n\n\n\n\n\nIntersection (row)\n3\n2850.5\n\n\n\n\n\nTime of day (column)\n3\n133.5\n\n\n\n\n\nAlgorithm (treatment)\n3\n645.5\n\n\n\n\n\nResidual Error\n6\n1.5\n\n\n\n\n\nTotal\n16\n49856.0\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can verify that we have successfully partitioned out the SS_total, try adding the sum of squares for all the factors together. The result should be equal to the sum of squares you got by squaring the observed values and summing them.\nThe next step is to covert the total variability (sum of squares) to an average variability per factor (mean squares). To create an average from a total, you must divide by the number of unique pieces of information that were summed to create the total, in this case the degrees of freedom. The mean squares can be thought of as the sample variance between factor level means.\nObtain the mean squares for each factor by dividing its sum of squares by its degrees of freedom.\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n46225.0\n46225.00\n\n\n\n\nIntersection (row)\n3\n2850.5\n950.17\n\n\n\n\nTime of day (column)\n3\n133.5\n44.50\n\n\n\n\nAlgorithm (treatment)\n3\n645.5\n215.17\n\n\n\n\nResidual Error\n6\n1.5\n0.25\n\n\n\n\nTotal\n16\n49856.0\n3116.00\n\n\n\n\n\n\n\n\n\nThe objective of the study was to evaluate differences in timing algorithms of traffic lights. The intersection and time of day factors were simply nuisance factors we blocked on to better isolate the effect of timing algorithm. For that reason, we will only show the hypothesis test of the treatment factor (algorithm) here, though a similar test could be done for the blocking factors (intersection and time of day).\nIn Equation 1, \\(\\gamma\\) represents the effect of algorithm. Our hypotheses therefore are\n\\[\nH_o: \\gamma_k = 0 \\text{, for all } k\n\\]\n\\[\nH_a: \\gamma_k \\ne 0 \\text{, for some } k\n\\]\nTo test the hypothesis, we need to compare the mean square (MS) for algorithm to the mean square for residual error (abbreviated as MSE). This ratio of variances is called an F statistic.\n\\[\n\\text{F statistic} = \\frac{MS_{algorithm}}{MS_{error}} = \\frac{215.1\\overline{6}}{0.25} = 860.\\overline{6}\n\\]\nThis F statistic has 3 and 6 degrees of freedom, written as \\(F_{3,6} = 860.\\overline{6}\\). This is a huge F statistic.\nThe associated p-value is approximately zero as calculated in Excel with the function = f.dist.rt(860.6667, 3, 6).\n\n\n\n\n\nSource\ndf\nSS\nMS\nFvalue\npvalue\n\n\n\n\nGrand Mean\n1\n46225.0\n46225.00\n\n\n\n\nIntersection (row)\n3\n2850.5\n950.17\n\n\n\n\nTime of day (column)\n3\n133.5\n44.50\n\n\n\n\nAlgorithm (treatment)\n3\n645.5\n215.17\n860.667\n0\n\n\nResidual Error\n6\n1.5\n0.25\n\n\n\n\nTotal\n16\n49856.0\n3116.00\n\n\n\n\n\n\n\n\n\nWe can conclude from these results that at least one of the timing algorithms has a statistically significant effect on the number of cars flowing through an intersection. As calculated earlier, Algorithm D had the largest positive effect on throughput at an intersection and it seems reasonable to recommend this algorithm to those in charge of traffic lights."
  },
  {
    "objectID": "latin_square.html#check-assumptions",
    "href": "latin_square.html#check-assumptions",
    "title": "Latin Square",
    "section": "Check Assumptions",
    "text": "Check Assumptions\nFor a more detailed explanation of the code, output, and theory behind these assumptions visit the Assumptions page.\n\nConstant Variance of Residuals\nThe residuals need to demonstrate constant variance, regardless of the fitted or predicted value. We use a residual plot to check this assumption.\n\n\nCode\nplot(my_ls_aov, which = 1)\n\n\n\n\n\nFigure 8: Checking constant variance\n\n\n\n\n\n\nIgnore the red line in this plot\nThe x-axis of Figure 8 shows the fitted. Fitted values, also called predicted values, is the sum of the effects contributing to a datapoint. It includes all effects except for the residual effect. The residual is plotted on the y-axis.\nThe points in the plot do not show any increase (or decreasing) in vertical spread as we move along the x-axis. Therefore, we conclude this requirement is met.\n\n\nNormally Distributed Residuals\nWe check the assumption that residuals are normally distributed in Figure 9. All the points are in the shaded region.\n\n\nCode\ncar::qqPlot(my_ls_aov$residuals, id = FALSE)\n\n\n\n\n\nFigure 9: Checking normality of residuals\n\n\n\n\n\n\nIndependent Residuals\nThe dataset we are analyzing does not include information about the order in which the data was collected. In fact, it is possible some conditions of the experiment were run simultaneously and there is no specific order. From what we know, there is no reason to think there is a potential order bias."
  },
  {
    "objectID": "latin_square.html#summary",
    "href": "latin_square.html#summary",
    "title": "Latin Square",
    "section": "Summary",
    "text": "Summary\nThe ANOVA model assumptions all appear to be met. We can trust the p-values in the ANOVA summary table. Thus we conclude algorithm has a significant effect on throughput. To gain further insight, pairwise comparisons for the algorithm levels could be run."
  },
  {
    "objectID": "latin_square.html#footnotes",
    "href": "latin_square.html#footnotes",
    "title": "Latin Square",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nA carry-over effect occurs when the effect of a treatment applied to block spreads beyond the borders of the block. For example, a fertilizer applied to a particular area is carried by wind or water to some adjacent area that is supposed to be receiving a different treatment.\nIn the case of temporal (rather than spatial) blocks, a carry-over effect occurs when the effect of the previous treatment influences the outcome for a particular subject even after the subject has begun a new phase of the experiment under a different treatment condition.\nCarry over effects also include when effects of repetition (such as learning or fatigue) are mixed with effects of the treatment, and the two become confounded.↩︎\nBailey, R. & Cameron, Peter & Connelly, R.. (2008). Sudoku, Gerechte Designs, Resolutions, Affine Space, Spreads, Reguli, and Hamming Codes. American Mathematical Monthly. 115. 10.1080/00029890.2008.11920542.↩︎\nSince this sequence is randomly generated, running the same code on your machine will give a different sequence each time you run it. You can create the sequence by first running set.seed(6), and then sample(1:4). If sample(1:4) command is run again without resetting the random seed or doing any other random sampling, the result will be the sequence which was obtained for the columns in step 2.↩︎\nSince this sequence is randomly generated, running the same code on your machine will give a different sequence each time you run it. You can create the sequence by first running set.seed(6), and then sample(1:4). If sample(1:4) command is run again without resetting the random seed or doing any other random sampling, the result will be the sequence which was obtained for the columns in step 2.↩︎\nDeciding whether the treatment factor is inside or outside of another factor is a little unusual since the partitions for treatment are not contiguous. However, the definition of outside or inside is still the same. Let’s look at the relationship between treatment at grand mean.\n\nTreatment A fits nicely inside of the Grand Mean partition. The partitions for the other treatment levels also fit in Grand Mean; so Treatment is “inside” of Grand Mean.\nTreatment and the Column Factor can also be investigated. In this case, level A of Treatment does not fit nicely inside of the column factor. In fact, one level of Treatment spans all 4 levels of the column factor. Treatment is certainly not inside of the Column Factor.\n\nWe can also see that the Column Factor partitions do not fit inside of Treatment.\n\nThe factors are crossed since each level of Treatment appears in combination with each level of the Column Factor. A similar process can be carried out to determine that Treatment and the Row Factor are also crossed.↩︎\nThe counting free numbers approach of determining degrees of freedom for residuals may be less clear to apply than it was in other designs due to the non-continuous partitions of the treatment factor. There are 3 structural factors: rows, columns, and treatments. (In the traffic example, that corresponds to intersections, times of day, and timing algorithm respectively). The residuals in each of these partitions must sum to zero.\nFor the treatment, all the residuals for observations from Treatment A must sum to zero. Similarly, the observations from Treatment B will have residuals that sum to zero. And so on for each treatment. It is not obvious in the factor diagram which observation should be chosen as “locked” and which ones we can count as free to vary. But consider for a moment that in any row, each of the treatments appears. We will select a row (let’s use the top row for convenience), and say that each of those residuals is “locked”. This essentially reduces the residual factor from a 4x4 table of free values, to a 3x4 table.\n\nNow apply the fact that in order to sum to zero across rows, the last value in each row is “locked”. Similarly, the sum of the residuals in each column of the remaining 3x4 table of free values must also sum to zero. Therefore, the last (bottom) residual of each column is also “locked”.\n\nThis leads to a general result for finding residual degrees of freedom for a Latin Square: (# rows – 1) x (# columns – 2).↩︎"
  },
  {
    "objectID": "contrast.html",
    "href": "contrast.html",
    "title": "Contrasts",
    "section": "",
    "text": "The ANOVA F test is considered an omnibus test, meaning it tests all the factor levels of a factor at once. If the test suggests the null hypothesis should be rejected it seems to give rise to more questions than answers. Specifically, you will want to know which factor levels are significantly different from which other factor levels.\nUsually during the design of an experiment, the researcher has specific comparisons in mind that are of particular interest. For example, they may be interested in comparing treatment effects for two dosing levels. These pre-planned comparisons usually drive the experimental design. When it comes time for analysis, an omnibus F-test test may be skipped entirely in favor of jumping directly to the planned comparisons. Or, if the F-test finds statistical significance, the researcher may follow-up with focused post-hoc tests of specific factor levels.\nWhen one factor level mean is compared to another, it is called a pairwise comparison, or simple contrasts. For example, in our toothbrush experiment we may be interested in comparing the oscillating brush to the control group (manual brush). Or we may be especially interested in comparing sonic to ultra sonic.\nLess commonly, the comparison of interest may involve averages of two or more factor level means. This is most likely to occur when the factor levels lend themselves to natural groupings that may be of particular interest to compare. For example, we may want to compare the mean of the sonic and ultrasonic groups to the mean of the oscillating group. Another example might include a comparison of the average of all the “treatment” toothbrushes vs. the control group (manual). When an average across groups is involved, this is called a complex comparison, or linear contrast.\nWe can represent the null hypotheses of these 4 example contrasts as:\n\n\nThough contrast and comparison are technically synonomous, “comparison” most often refers to simple, pairwise comparisons; and “contrast” refers to complex comparisons.\n\n\n\n\nVenn Diagram\n\n\n\n\\(\\begin{aligned} H_0: \\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\nThe above hypotheses can all be expressed as a sum, where each factor level mean is multiplied by a coefficient. When a factor level is not a part of the hypotheses, it has a coefficient of zero.\n\n\nTable 1: Expanded Hypotheses\n\n\n\n\n\n\nFour Null Hypotheses\nLeft Hand Side of Hypotheses Expressed as a Sum of Means and Coefficients\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(-1*\\mu_\\text{man} + 1*\\mu_\\text{osc} + 0*\\mu_\\text{sonic} + 0*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 0*\\mu_\\text{osc} + 1*\\mu_\\text{sonic} + -1*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 1*\\mu_\\text{osc} + -\\frac{1}{2}*\\mu_\\text{sonic} + -\\frac{1}{2}*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\n\\(1*\\mu_\\text{man} + -\\frac{1}{3}*\\mu_\\text{osc} + -\\frac{1}{3}*\\mu_\\text{sonic} + -\\frac{1}{3}*\\mu_\\text{ultra}\\)\n\n\n\n\nThe contents in the right column of Table 1 are referred to as contrasts. We will use the symbol \\(\\psi\\) to represent the contrast. A contrast is formed by multiplying each factor level mean by a coefficient. Simply put, it is a weighted sum. The above hypotheses are all examples of valid contrasts. To be considered a valid contrast, the only restriction is that the sum of the coefficients must be zero. We will often write coefficients used in a contrast as a set, in curly braces as shown in Table 2. Thinking of a contrast in terms of its set of coefficients is helpful for identifying orthogonality of contrasts. Also, when calculating/testing a contrast with software, you are required to input the set (or vector) of coefficients to define the contrast.\n\n\nTable 2: Contrast Coefficients\n\n\n\n\n\n\n\n\\(H_0\\)\nContrast (\\(\\psi\\)) Tested in \\(H_0\\)\nSet of Contrast Coefficients\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(-1*\\mu_\\text{man} + 1*\\mu_\\text{osc} + 0*\\mu_\\text{sonic} + 0*\\mu_\\text{ultra}\\)\n\\(\\{ -1, 1, 0, 0 \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 0*\\mu_\\text{osc} + 1*\\mu_\\text{sonic} + -1*\\mu_\\text{ultra}\\)\n\\(\\{ 0, 0, 1, -1 \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 1*\\mu_\\text{osc} + -\\frac{1}{2}*\\mu_\\text{sonic} + -\\frac{1}{2}*\\mu_\\text{ultra}\\)\n\\(\\{ 0, 1, -\\frac{1}{2}, -\\frac{1}{2} \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\n\\(1*\\mu_\\text{man} + -\\frac{1}{3}*\\mu_\\text{osc} + -\\frac{1}{3}*\\mu_\\text{sonic} + -\\frac{1}{3}*\\mu_\\text{ultra}\\)\n\\(\\{ 1, -\\frac{1}{3}, -\\frac{1}{3}, -\\frac{1}{3} \\}\\)\n\n\n\n\nThere are an infinite number of contrasts that could be tested. Realistically though, the contrasts that make sense to test are generally obvious and depend on your understanding/context of the experiment. Testing pairwise comparisons (i.e. simple contrasts where the coefficients are either -1, 0, or 1) is quite common; averaging across certain factor level means as part of the comparison is less common, but is still something you should be prepared to do. Contrasts can get quite complicated, especially for experiments with complicated designs. In this class though we will stick to relatively simple situations."
  },
  {
    "objectID": "contrast.html#what-is-a-contrast",
    "href": "contrast.html#what-is-a-contrast",
    "title": "Contrasts",
    "section": "",
    "text": "The ANOVA F test is considered an omnibus test, meaning it tests all the factor levels of a factor at once. If the test suggests the null hypothesis should be rejected it seems to give rise to more questions than answers. Specifically, you will want to know which factor levels are significantly different from which other factor levels.\nUsually during the design of an experiment, the researcher has specific comparisons in mind that are of particular interest. For example, they may be interested in comparing treatment effects for two dosing levels. These pre-planned comparisons usually drive the experimental design. When it comes time for analysis, an omnibus F-test test may be skipped entirely in favor of jumping directly to the planned comparisons. Or, if the F-test finds statistical significance, the researcher may follow-up with focused post-hoc tests of specific factor levels.\nWhen one factor level mean is compared to another, it is called a pairwise comparison, or simple contrasts. For example, in our toothbrush experiment we may be interested in comparing the oscillating brush to the control group (manual brush). Or we may be especially interested in comparing sonic to ultra sonic.\nLess commonly, the comparison of interest may involve averages of two or more factor level means. This is most likely to occur when the factor levels lend themselves to natural groupings that may be of particular interest to compare. For example, we may want to compare the mean of the sonic and ultrasonic groups to the mean of the oscillating group. Another example might include a comparison of the average of all the “treatment” toothbrushes vs. the control group (manual). When an average across groups is involved, this is called a complex comparison, or linear contrast.\nWe can represent the null hypotheses of these 4 example contrasts as:\n\n\nThough contrast and comparison are technically synonomous, “comparison” most often refers to simple, pairwise comparisons; and “contrast” refers to complex comparisons.\n\n\n\n\nVenn Diagram\n\n\n\n\\(\\begin{aligned} H_0: \\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(\\begin{aligned} H_0: \\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\nThe above hypotheses can all be expressed as a sum, where each factor level mean is multiplied by a coefficient. When a factor level is not a part of the hypotheses, it has a coefficient of zero.\n\n\nTable 1: Expanded Hypotheses\n\n\n\n\n\n\nFour Null Hypotheses\nLeft Hand Side of Hypotheses Expressed as a Sum of Means and Coefficients\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(-1*\\mu_\\text{man} + 1*\\mu_\\text{osc} + 0*\\mu_\\text{sonic} + 0*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 0*\\mu_\\text{osc} + 1*\\mu_\\text{sonic} + -1*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 1*\\mu_\\text{osc} + -\\frac{1}{2}*\\mu_\\text{sonic} + -\\frac{1}{2}*\\mu_\\text{ultra}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\n\\(1*\\mu_\\text{man} + -\\frac{1}{3}*\\mu_\\text{osc} + -\\frac{1}{3}*\\mu_\\text{sonic} + -\\frac{1}{3}*\\mu_\\text{ultra}\\)\n\n\n\n\nThe contents in the right column of Table 1 are referred to as contrasts. We will use the symbol \\(\\psi\\) to represent the contrast. A contrast is formed by multiplying each factor level mean by a coefficient. Simply put, it is a weighted sum. The above hypotheses are all examples of valid contrasts. To be considered a valid contrast, the only restriction is that the sum of the coefficients must be zero. We will often write coefficients used in a contrast as a set, in curly braces as shown in Table 2. Thinking of a contrast in terms of its set of coefficients is helpful for identifying orthogonality of contrasts. Also, when calculating/testing a contrast with software, you are required to input the set (or vector) of coefficients to define the contrast.\n\n\nTable 2: Contrast Coefficients\n\n\n\n\n\n\n\n\\(H_0\\)\nContrast (\\(\\psi\\)) Tested in \\(H_0\\)\nSet of Contrast Coefficients\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} = 0 \\end{aligned}\\)\n\\(-1*\\mu_\\text{man} + 1*\\mu_\\text{osc} + 0*\\mu_\\text{sonic} + 0*\\mu_\\text{ultra}\\)\n\\(\\{ -1, 1, 0, 0 \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 0*\\mu_\\text{osc} + 1*\\mu_\\text{sonic} + -1*\\mu_\\text{ultra}\\)\n\\(\\{ 0, 0, 1, -1 \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} = 0 \\end{aligned}\\)\n\\(0*\\mu_\\text{man} + 1*\\mu_\\text{osc} + -\\frac{1}{2}*\\mu_\\text{sonic} + -\\frac{1}{2}*\\mu_\\text{ultra}\\)\n\\(\\{ 0, 1, -\\frac{1}{2}, -\\frac{1}{2} \\}\\)\n\n\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3} = 0 \\end{aligned}\\)\n\\(1*\\mu_\\text{man} + -\\frac{1}{3}*\\mu_\\text{osc} + -\\frac{1}{3}*\\mu_\\text{sonic} + -\\frac{1}{3}*\\mu_\\text{ultra}\\)\n\\(\\{ 1, -\\frac{1}{3}, -\\frac{1}{3}, -\\frac{1}{3} \\}\\)\n\n\n\n\nThere are an infinite number of contrasts that could be tested. Realistically though, the contrasts that make sense to test are generally obvious and depend on your understanding/context of the experiment. Testing pairwise comparisons (i.e. simple contrasts where the coefficients are either -1, 0, or 1) is quite common; averaging across certain factor level means as part of the comparison is less common, but is still something you should be prepared to do. Contrasts can get quite complicated, especially for experiments with complicated designs. In this class though we will stick to relatively simple situations."
  },
  {
    "objectID": "contrast.html#testing-a-contrast",
    "href": "contrast.html#testing-a-contrast",
    "title": "Contrasts",
    "section": "Testing a Contrast",
    "text": "Testing a Contrast\n\nt-test for Pairwise Comparisons\nPairwise comparisons (i.e. simple contrasts) of means using a t-test is something you are probably familiar with from previous statistics classes. The procedure was most likely called something like, “independent samples t-test of two means”. We can build on that understanding to come up with a more general approach that will allow us to test any contrast.\nRecall, that a t-test for one sample has the general form:\n\\[\nt = \\frac{\\bar{y} - \\mu_0}{s_\\bar{y}}\n\\]\nWhere \\(\\bar{y}\\) is the sample mean, \\(\\mu_0\\) is the value from the null hypothesis, and \\(s_\\bar{y}\\) is the standard error of the mean. We can expand this to test whether a difference of two means is zero, in other words an independent samples t-test of two means. Recall, that in ANOVA we assume constant variance across factor levels. (This is a slightly different assumption, resulting in a slightly different calculation than the independent samples t-tests presented in Math221 and Math3251).\n\n\nStandard error of the mean is equal to standard deviation of the individual observations divided by square root of the sample size, \\(s_\\bar{y} = \\frac{s_y}{\\sqrt{n}}\\). See Math221 text for review.\nIn our toothbrush experiment, if we want to test whether the mean of manual brushes is equal to the mean of oscillating brushes we have for our null hypothesis:\n\\[\nH_0: \\mu_\\text{man} - \\mu_\\text{osc} = 0\n\\]\nWe use a t statistic:\n\\[\nt = \\frac{(\\bar{y}_\\text{man} - \\bar{y}_\\text{osc})}{\\sqrt{s^2_p*(\\frac{1}{n_1} + \\frac{1}{n_2})}}\n\\tag{1}\\]\nThe difference in the numerator is calculated directly from the contrast (multiplying the set of coefficients by their respective factor level mean). In the denominator, the pooled variance (\\(s^2_p\\)) is identical to the mean squared error from the ANOVA summary table. The degrees of freedom for this test statistic are equivalent to the residual degrees of freedom.\n\n\n\n\n\n\nNote, by using the MSE from the ANOVA summary table we are taking advantage of information about residual errors contained in the observations of sonic and ultrasonic brushes as well as the observations from manual and oscillating. This leads to a better estimate of the size of random error.\n\n\n\nFor our study on toothbrushes we have the model:\n\\[\ny_\\text{ij} = \\mu + \\alpha_i + \\epsilon_\\text{ij}\n\\tag{2}\\]\nWhere\n\n\\(y_\\text{ij}\\) is an observation\n\\(\\mu\\) is the grand mean\n\\(\\alpha_i\\) represents the effect of factor level \\(i\\)\n\\(\\epsilon_\\text{ij}\\) is the residual error for the \\(j^\\text{th}\\) observation in factor level \\(i\\)\n\nBelow is the table of factor level means and the ANOVA summary table.\n\n\nCode\n```{r}\n#| label: tbl-brush_analysis\n#| message: false\n#| tbl-cap: \"Toothbrush Experiment Results\"\n#| tbl-subcap:\n#| - \"Factor Level Means\"\n#| - \"ANOVA Summary Table\"\n#| layout-ncol: 2\n#| code-fold: true\n\nbf2 &lt;- read_csv(\"data/toothpaste_BF2.csv\") \n\nmeans_tbl &lt;- bf2 |&gt; group_by(Brush) |&gt; summarise(mean = mean(Plaque),\n                                    `sample size` = n())\nmeans_tbl |&gt; pander::pander()\n\n\nbrush_aov &lt;- aov(Plaque~Brush, data = bf2)\nsummary(brush_aov) |&gt; pander::pander()\n\n#These lines store values in variables so that I can write them in\n#the latex equation below programmatically rather than hardcoding them\nmean_man &lt;- means_tbl[[1,2]]\nmean_osc &lt;- means_tbl[[2,2]]\nnsize &lt;- means_tbl[[1,3]]\nmse &lt;- summary(brush_aov)[[1]][2,3] #This gets the number from the summary table\ntstat &lt;- (mean_man - mean_osc)/sqrt(mse*(1/nsize + 1/nsize))\npprob &lt;- pt(q=tstat, df=brush_aov$df.resid, lower.tail=FALSE) * 2\n```\n\n\n\nTable 3: Toothbrush Experiment Results\n\n\n\n\n(a) Factor Level Means\n\n\n\n\n\n\n\nBrush\nmean\nsample size\n\n\n\n\nManual\n23.09\n6\n\n\nOscillating\n19.98\n6\n\n\nSonic\n22.67\n6\n\n\nUltrasonic\n25.31\n6\n\n\n\n\n\n\n(b) ANOVA Summary Table\n\n\n\n\n\n\n\n\n\n\n \nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nBrush\n3\n86.31\n28.77\n3.822\n0.02583\n\n\nResiduals\n20\n150.6\n7.528\nNA\nNA\n\n\n\n\n\n\n\nPlugging the values from Table 3 into Equation 1 we can calculate the t statistic:\n\\[\nt = \\frac{ 3.11 }{\\sqrt{ 7.53 * (\\frac{1}{ 6 } + \\frac{1}{ 6 })}} = 1.97\n\\tag{3}\\]\nA t statistic of 1.97 leads to a p-value of 0.063. Since the p-value is greater than our traditional alpha of 0.05, we fail to reject the null hypothesis of equality. In other words, there is insufficient evidence to claim that the manual brush and the oscillating brush have different mean values for percent area of teeth with plaque.\n\n\nt-test for Any Contrast\nThis same t-test approach can be extended so that we can test any contrast, not just pairwise comparisons. To extend the approach, recognize that the \\(1's\\) in Equation 3 appearing directly above each sample size actually represent the squared coefficient of the contrast (see Table 1). Thus, Equation 1 used to compare two factor level means, is actually just a special case of a more general formula, Equation 4, which allows us to perform a hypothesis test of any contrast. This equation continues with the general structure of a t statistic: the numerator contains a sample estimate of the difference, the denominator is the standard error of that difference.\n\\[\nt = \\frac{\\hat{\\psi}}{s_\\hat{\\psi}} = \\frac{\\hat{\\psi}}{\\sqrt{MSE * \\sum(c^2_j / n_j)}}\n\\tag{4}\\]\nWhere,\n\n\\(\\hat{\\psi}\\) is an estimate of the contrast, obtained by multiplying each factor level mean by its respective contrast coefficient. For a simple pairwise comparison, it is just the difference in means.\n\\(MSE\\) is the mean squares of residuals obtained from the ANOVA summary table\n\\(c_j\\) is the squared coefficient for the \\(j^\\text{th}\\) factor level and\n\\(n_j\\) is the sample size of the \\(j^\\text{th}\\) factor level.\n\nThe degrees of freedom for \\(t\\) will be equal to the degrees of freedom for residual error in the ANOVA summary table.\nLet’s use this more general approach in Equation 4 to test the fourth hypothesis contained in Table Table 1. Our alternative hypothesis will be the contrast is not equal to zero. Though you can use directional (i.e. 1-tailed) tests of a contrast, the default is to use a two-tailed alternative hypothesis of “not equal to zero”.\nPlugging the values from Table 3 into Equation 4 we can calculate the t statistic:\nNumerator: \\[\n\\hat{\\psi} = 1 * 23.09 + -\\frac{1}{3} * 19.98 + -\\frac{1}{3} * 22.67 + -\\frac{1}{3} * 25.31 = 0.438\n\\]\nDenominator: \\[\ns_\\hat{\\psi} = \\sqrt{MSE * \\sum(c^2_j / n_j)} = \\sqrt{ 7.53 * \\left( \\frac{1^2}{6} + \\frac{-\\frac{1}{3}^2}{6} + \\frac{-\\frac{1}{3}^2}{6} + \\frac{-\\frac{1}{3}^2}{6} \\right) } = 1.294\n\\]\nt statistic: \\[\nt = \\frac{\\hat{\\psi}}{s_\\hat{\\psi}} = \\frac{0.438}{1.294} = .34\n\\tag{5}\\]\nA test statistic \\(t_\\text{20} = .34\\) is not large enough to be significant.\n\n\n\n\n\n\nCaution\n\n\n\nActually, it does not make a lot of sense to compare the control group (manual brush) to the average of the other three brushes. For a contrast of the control mean vs. average of the treatments to make sense, the treatments would need to have more commonality. For example, if there were two treatments and both used oscillating toothbrushes: one oscillated in a clockwise fashion and the other oscillated in a counter-clockwise. In that case it would make sense to combine the treatment factor levels since they could be interpreted generally as “oscillating brush”. Then you could compare the average of the oscillating groups against the average of the control group (manual brush).\n\n\n\n\nF-test vs. t-test\nWe could have reached exactly the same conclusions by conducting an appropriate F test for the contrast instead of a t-test2. It can be shown that \\(F = t^2\\). When t is based on the degrees of freedom for residuals, and F has \\(df_\\text{numerator}\\) = 1 and \\(df_\\text{denominator} = df_\\text{residuals}\\) , the two tests given identical p-values and thus lead to the same conclusion.\n\n\nR Instructions\nThis section illustrates just one way to test custom contrasts in R. There are many packages, each with their unique syntax, for computing and testing contrasts. As you work more in the field, you may find another package better suits your needs.\nThere are sets of comparisons (a.k.a. contrasts) that are commonly done in practice. The calculation of these sets can be obtained with simpler code than what is shown here but may require other R packages. In addition, when testing multiple contrasts simultaneously there are potentially other adjustments that should be made. Please read “Multiple Comparisons” to understand what other adjustments to consider as well as the R code for conducting these common sets of comparisons.\n\nCaution, the contrasts() function from the stats package in base R will produce the correct p-value for the test of a contrast, but without extra work will not produce the correct estimate of the contrast itself. For this reason, we illustrate estimating and testing the contrast with the emmeans package, which stands for “estimated marginal means”.\nThe first step is to create the model. Then use the emmeans() command to create a grid of factor level summary statistics, including: means, standard deviations, standard error, degrees of freedom associated with the standard error estimate, and confidence intervals around the mean. Unlike a summarize() or favstats() command, emmeans() has the output structured so that it can easily be used in the next step. Store the grid of means into a new object.\n\nmyaov &lt;- aov(Y ~ X, data = df)\nmymeans &lt;- emmeans(myaov, \"X\")\n\n\nmyaov is some name you come up with to store the results of the aov() model.\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\ndf is the name of your data set.\nmymeans is some name you come up with to store the results of the emmeans() command.\n\nDefine the contrasts you are interested in testing inside the contrast() function, which returns the hypothesis test results. You can also feed the result into a confint() function if you prefer confidence intervals over p-values.\n\ncontrast(mymeans,list(name_of_contrast1 = coefficient vector,\n                       name_of_contrast2 = another coefficient vector))) \n\nname_of_contrast are descriptive names you should give to the contrast to help you remember what it represents. The coefficient vector is how you define the contrast.\nWe will repeat the contrasts we did by hand in the sections above, but this time using R.\nExample Code Using Toothbrush Experiment:\n\n\n df The name you want for your dataset  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv(“../data/toothpaste_BF2.csv”) A tidyverse command to read the data in from the specified path  plaque_aov Name you want for your ANOVA model  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  brush_means The name you want for the output of the emmeans command  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left   emmeans(  Function to calculate stats about marginal means  plaque_aov, aov model created in previous step  “Brush” Factor for whose levels you want to calculate means  ) Functions always end with a closing parenthesis  contrast_results Name you want to store contrast results in  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  contrast( Function to define and test contrasts  brush_means, Grid of stats about marginal means you named in the previous step list( create a list object, which allows you to pass multiple contrast coefficient vectors  man_v_osc = A descriptive name to help you remember what the contrast represents  c(1,-1,0,0) Vector of coefficients used to define the contrast  , Seperator to allow additional inputs to the list     man_v_others = A descriptive name to help you remember what the contrast represents  c(1,-(1/3),-(1/3),-(1/3)) Vector of coefficients used to define the contrast  ), A list is closed with a parenthesis  adjust = Specify what type of adjustment (if any) to make for multiple testing. Default is “none” if this argument is not included.  “none” Read help at ?summary.emmGrid for other acceptable values  ) Functions always end with a closing parenthesis  contrast_results View the test results stored in this object in the previous step  confint( Function to create confidence intervals around contrasts  contrast_results Name of object where you stored contrasts  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n contrast     estimate   SE df t.ratio p.value\n man_v_osc       3.117 1.58 20   1.967  0.0632\n man_v_others    0.438 1.29 20   0.339  0.7382\n\n\n\n\n contrast     estimate   SE df lower.CL upper.CL\n man_v_osc       3.117 1.58 20   -0.188     6.42\n man_v_others    0.438 1.29 20   -2.260     3.14\n\nConfidence level used: 0.95"
  },
  {
    "objectID": "contrast.html#othogonal-contrast",
    "href": "contrast.html#othogonal-contrast",
    "title": "Contrasts",
    "section": "Othogonal Contrast",
    "text": "Othogonal Contrast\nStay tuned…Under Construction"
  },
  {
    "objectID": "contrast.html#footnotes",
    "href": "contrast.html#footnotes",
    "title": "Contrasts",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nt-tests of pairwise comparisons with non-constant variance would result in the independent samples t-test presented in Math221 and Math325. More complicated contrasts assuming non-constant variance is explained in Design and Analysis: A Researcher’s Handbook by Keppel, G. and Wickens T.D. (2004, Pearson), starting on page 156.↩︎\nThe appropriate F-test consists of calculating the mean squares of the contrast and dividing by the mean squared error. In most cases, the contrast has 1 degree of freedom, so the contrast sum of squares is equal to the contrast mean squares. The formula to calculate a contrast sum of squares is\n\\[\nSS_{\\psi} = \\frac{n*\\hat{\\psi}^2}{\\sum{c_j^2}}\n\\]\nThe contrast has just 1 degree of freedom because it compares just two sets of observations. This is true even for complex comparisons: each set of observations may come from one factor level, or from a combination of factor levels.↩︎"
  },
  {
    "objectID": "hoveRmd/contrast_R_instructions.html",
    "href": "hoveRmd/contrast_R_instructions.html",
    "title": "Math326 Notebook",
    "section": "",
    "text": "Caution, the contrasts() function from the stats package in base R will produce the correct p-value for the test of a contrast, but without extra work will not produce the correct estimate of the contrast itself. For this reason, we illustrate estimating and testing the contrast with the emmeans package, which stands for “estimated marginal means”.\nThe first step is to create the model. Then use the emmeans() command to create a grid of factor level summary statistics, including: means, standard deviations, standard error, degrees of freedom associated with the standard error estimate, and confidence intervals around the mean. Unlike a summarize() or favstats() command, emmeans() has the output structured so that it can easily be used in the next step. Store the grid of means into a new object.\n\nmyaov &lt;- aov(Y ~ X, data = df)\nmymeans &lt;- emmeans(myaov, \"X\")\n\n\nmyaov is some name you come up with to store the results of the aov() model.\nY must be a “numeric” vector of the quantitative response variable.\nX is a qualitative variable (should have class(X) equal to factor or character. If it does not, use factor(X) inside the aov(Y ~ factor(X),...) command.\ndf is the name of your data set.\nmymeans is some name you come up with to store the results of the emmeans() command.\n\nDefine the contrasts you are interested in testing inside the contrast() function, which returns the hypothesis test results. You can also feed the result into a confint() function if you prefer confidence intervals over p-values.\n\ncontrast(mymeans,list(name_of_contrast1 = coefficient vector,\n                       name_of_contrast2 = another coefficient vector))) \n\nname_of_contrast are descriptive names you should give to the contrast to help you remember what it represents. The coefficient vector is how you define the contrast.\nWe will repeat the contrasts we did by hand in the sections above, but this time using R.\nExample Code Using Toothbrush Experiment:\n\n\n df The name you want for your dataset  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  read_csv(“../data/toothpaste_BF2.csv”) A tidyverse command to read the data in from the specified path  plaque_aov Name you want for your ANOVA model  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  aov( A function to define the model  Plaque The response, or y, variable in the model. It is numeric.  ~ The ~ is like an equal sign in the model. Items on the left of ~ represent y, on the right you define independent factors (i.e. x’s).  Brush, The independent variable containing the names for the 4 types of toothbrushes.  data = df Tell the model to look in the dataset named “df” for Plaque and Brush variables  ) Functions always end with a closing parenthesis  brush_means The name you want for the output of the emmeans command  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left   emmeans(  Function to calculate stats about marginal means  plaque_aov, aov model created in previous step  “Brush” Factor for whose levels you want to calculate means  ) Functions always end with a closing parenthesis  contrast_results Name you want to store contrast results in  &lt;- The assignment operator. The result to the right of it gets stored in an object specified on the left  contrast( Function to define and test contrasts  brush_means, Grid of stats about marginal means you named in the previous step list( create a list object, which allows you to pass multiple contrast coefficient vectors  man_v_osc = A descriptive name to help you remember what the contrast represents  c(1,-1,0,0) Vector of coefficients used to define the contrast  , Seperator to allow additional inputs to the list     man_v_others = A descriptive name to help you remember what the contrast represents  c(1,-(1/3),-(1/3),-(1/3)) Vector of coefficients used to define the contrast  ), A list is closed with a parenthesis  adjust = Specify what type of adjustment (if any) to make for multiple testing. Default is “none” if this argument is not included.  “none” Read help at ?summary.emmGrid for other acceptable values  ) Functions always end with a closing parenthesis  contrast_results View the test results stored in this object in the previous step  confint( Function to create confidence intervals around contrasts  contrast_results Name of object where you stored contrasts  ) Functions always end with a closing parenthesis  Toggle output Toggle Output. \n\n\n\n\n\n contrast     estimate   SE df t.ratio p.value\n man_v_osc       3.117 1.58 20   1.967  0.0632\n man_v_others    0.438 1.29 20   0.339  0.7382\n\n\n\n\n contrast     estimate   SE df lower.CL upper.CL\n man_v_osc       3.117 1.58 20   -0.188     6.42\n man_v_others    0.438 1.29 20   -2.260     3.14\n\nConfidence level used: 0.95"
  },
  {
    "objectID": "contrast.html#othogonal-contrasts",
    "href": "contrast.html#othogonal-contrasts",
    "title": "Contrasts",
    "section": "Othogonal Contrasts",
    "text": "Othogonal Contrasts\nIn ANOVA, the variability in a dataset is decomposed, or allocated, to the various factors contributing to that variance. This total variability is called Sums of Squares. The Sums of Squares for a particular factor can further be decomposed, or allocated. Most of the time the variability is allocated to simple contrasts (i.e. a comparison of factor level means). Sometimes however, there is a desire to create a more complex contrast as we have seen above. When two contrasts do not share any information, or have any overlap in how their sums of squares are calculated, they are said to be orthogonal. Stated another way, the variability in one contrast is not correlated with the variability in another. This means that the information gained from one contrast is completely independent of the information gained in another, orthogonal contrast.\nYou can use a set of orthogonal contrasts to split the Sums of Squares for a factor into pieces, one piece for each contrast. There is a limit to how many contrasts can be tested for a given factor. That limit is the factor’s degrees of freedom. Testing sets of non-orthogonal contrasts can effect your Type I family error rate because the information contained in the contrasts is not independent.\n\nAssess Orthogonality\nTwo contrasts are orthogonal if the dot product of the coefficient vectors equals zero. The term “dot product” means that corresponding elements of a vector are multiplied, and then those products are summed together.\nLet’s determine if the contrasts listed in Table 2 are orthogonal to one another. On the right hand side of Table 2 the coefficient vector of the contrast is listed. We will investigate 2 of the 6 pairs of contrasts.\nFirst, we will assess whether the contrast \\(\\mu_{osc} - \\mu_{man}\\) is orthogonal to \\(\\mu_{sonic}- \\mu_{ultra}\\).\n\n\nTable 4: First Pair of Contrasts\n\n\n\n\n\n\n\n\n\n\nContrast\nSet of Contrast Coefficients\nman. coef.\nosc. coef.\nsonic coef.\nultra coef.\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} \\end{aligned}\\)\n\\(\\{ -1, 1, 0, 0 \\}\\)\n-1\n1\n0\n0\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra} \\end{aligned}\\)\n\\(\\{ 0, 0, 1, -1 \\}\\)\n0\n0\n1\n-1\n\n\n\nProduct of Coefficients\n\\(-1 \\times 1 = 0\\)\n\\(1 \\times 0 = 0\\)\n\\(0 \\times 1 = 0\\)\n\\(0 \\times -1 = 0\\)\n\n\n\n\nIn the last row of Table 4, the product of the elements of the coefficient vectors are calculated. The sum of these products \\(0 + 0 + 0 + 0 = 0\\). Because the sum of the products is zero, we conclude the first two contrasts listed in Table 2 are orthogonal.\nNext, we will assess whether the contrast \\(\\mu_{osc} - \\mu_{man}\\) is orthogonal to \\(\\mu_{osc}- \\frac{\\mu_{sonic} + \\mu_{ultra}}{2}\\).\n\n\nTable 5: Comparing a Different Set of Contrasts\n\n\n\n\n\n\n\n\n\n\nContrast\nSet of Contrast Coefficients\nman. coef.\nosc. coef.\nsonic coef.\nultra coef.\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man} \\end{aligned}\\)\n\\(\\{ -1, 1, 0, 0 \\}\\)\n-1\n1\n0\n0\n\n\n\\(\\begin{aligned}\\mu_{osc}- \\frac{\\mu_{sonic} + \\mu_{ultra}}{2} \\end{aligned}\\)\n{ 0, 1, \\(-\\frac{1}{2}\\), \\(-\\frac{1}{2}\\) }\n0\n1\n\\(-\\frac{1}{2}\\)\n\\(-\\frac{1}{2}\\)\n\n\n\nProduct of Coefficients\n\\(-1 \\times 0 = 0\\)\n\\(1 \\times 1 = 1\\)\n\\(0 \\times -\\frac{1}{2} = 0\\)\n\\(0 \\times -\\frac{1}{2} = 0\\)\n\n\n\n\nIn Table 5 the product of the elements of the coefficient vectors are calculated in the last row. The sum of these products is \\(0 + 1 + 0 + 0 = 1\\). Because the sum of the products is NOT zero, we conclude that these two contrasts are NOT orthogonal.\nIt has been shown how to determine orthogonality for the contrasts contained in first two rows of Table 6 below. The orthogonality of the other contrast pairs is left to the reader to work through. However, the answers are displayed so that you may check your work.\n\n\nTable 6: Orthogonality of Contrasts from Table 2\n\n\n\n\n\n\n\nContrast Row #’s from Table 2\n\nOrthogonality\n\n\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man}\\end{aligned}\\)\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra}\\end{aligned}\\)\northogonal\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man}\\end{aligned}\\)\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} \\end{aligned}\\)\nnot orthogonal\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\mu_\\text{man}\\end{aligned}\\)\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3}\\end{aligned}\\)\nnot orthogonal\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra}\\end{aligned}\\)\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} \\end{aligned}\\)\northogonal\n\n\n\\(\\begin{aligned}\\mu_\\text{sonic} - \\mu_\\text{ultra}\\end{aligned}\\)\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3}\\end{aligned}\\)\northogonal\n\n\n\\(\\begin{aligned}\\mu_\\text{osc} - \\frac{\\mu_\\text{sonic} + \\mu_\\text{ultra}}{2} \\end{aligned}\\)\n\\(\\begin{aligned}\\mu_\\text{man} - \\frac{\\mu_\\text{osc} + \\mu_\\text{sonic} + \\mu_\\text{ultra}}{3}\\end{aligned}\\)\nnot orthogonal"
  },
  {
    "objectID": "multiple_comparisons.html",
    "href": "multiple_comparisons.html",
    "title": "Multiple Comparison",
    "section": "",
    "text": "In this page, the approach to dealing with multiple contrasts is explained. Specifically, whether and how to adjust the tests of multiple contrasts to account for an inflated family wise error rate. A few techniques are described, with a focus on when to use which technique. Lastly, instructions and example code is provided for carrying out each technique in R.\nIn most good experiments, researchers are interested in more than just one contrast. Conducting multiple tests on the levels of a factor can inflate the family wise Type I error rate, as illustrated in the “Multiple T-tests” section of the ANOVA page. There is considerable disagreement among statisticians about how to approach the issue of multiple tests. The debate primarily focuses on whether to proactively take steps that will mitigate the inflated family wise error rate or not. To further complicate matters, if an adjustment is desired, there are multiple techniques to choose from. An exhaustive presentation of the arguments on either side is not attempted in this text. Though, a few of the key ideas will naturally emerge as the different approaches are discussed.\n\n\nThe terms “contrast” and “comparison” are treated here as synonymous. Comparison is used more often to refer to testing a difference in factor level means. Read Contrasts for more explanation of these terms."
  },
  {
    "objectID": "multiple_comparisons.html#bonferroni",
    "href": "multiple_comparisons.html#bonferroni",
    "title": "Multiple Comparison",
    "section": "Bonferroni",
    "text": "Bonferroni\nThe Bonferroni adjustment is best for a handful of pre-planned contrasts. As the number of contrasts grows, the adjustment quickly becomes too conservative (i.e. makes it too hard to find significance). In that case, other methods may strike a better balance between Type I and Type II errors.\n\n\nType I error occurs when a true hypothesis is rejected. Type II error occurs when a false hypothesis is not rejected.\nIt can be shown that in order to not exceed a desired family wise error rate of \\(\\alpha_\\text{fw}\\), for a set of \\(k\\) contrasts, each individual contrast should be tested at a significance level of \\(\\frac{\\alpha_\\text{fw}}{k}\\). For example, if we desire a family wise error rate of 0.05 and plan to do 5 tests, each individual contrast must have a p-value less than \\(\\frac{0.05}{5} = 0.01\\) to be considered significant. The test itself has not changed, only the benchmark p-value for claiming significance. This adjustment is easy to understand and to calculate."
  },
  {
    "objectID": "multiple_comparisons.html#scheffé",
    "href": "multiple_comparisons.html#scheffé",
    "title": "Multiple Comparison",
    "section": "Scheffé",
    "text": "Scheffé\nUsing experimental results to suggest which contrasts to test is often referred to as “data snooping” or exploratory analysis. For example, you may look at graphical and numerical summaries to see which means (or combinations of means) will be promising to test. The problem with this approach is that you have essentially done a quick, informal test of many differences when you looked at descriptive statistics and plots. In other words, you have already tested the means and combinations of the means in your mind. The Type I error rate of the contrasts will be different (higher) than stated because you are only formally applying the test to those that look significant already.\nScheffé’s method is most useful when many contrasts are tested, especially when going beyond pairwise comparisons of factor level means to test combined factor levels (i.e. complex comparisons). In data exploration, there are theoretically an infinite number of contrasts you could test. This is not a problem for Scheffé’s adjustment because, unlike other adjustment techniques, Scheffé’s adjustment does not depend on the number of comparisons to be made. Rather, it is determined only by the number of factor levels and the number of observations.\nThe F statistic used to test a contrast in Scheffé’s adjustment is related to the omnibus F test for the factor itself, and is given by:\n\\[\nF_\\text{Scheffé} = (k-1)*F\n\\]\nWhere \\(F\\) is the statistic for the F test of the factor as usual. \\(k\\) is the number of levels in that factor. \\(F_\\text{Scheffé}\\) has \\(df_\\text{numerator} = k-1\\) and \\(df_\\text{denominator} = df_\\text{residual}\\). Scheffé’s test output is often in terms of a t test. Recall that the t statistic is simply the square root of the F statistic.\nIf you are interested in only a specific set of hypotheses (all pairwise comparisons, or all treatment levels vs. control, or all levels compared to the “best” level, etc.) there may be another adjustment technique that will provide better statistical power. Two of which are mentioned below."
  },
  {
    "objectID": "multiple_comparisons.html#methods-designed-for-all-pairwise-comparisons",
    "href": "multiple_comparisons.html#methods-designed-for-all-pairwise-comparisons",
    "title": "Multiple Comparison",
    "section": "Methods Designed for All Pairwise Comparisons",
    "text": "Methods Designed for All Pairwise Comparisons\nWhether it is an exploratory analysis or a pre-planned set of contrasts, many researchers want to test all factor level means against each other. This is usually referred to as testing all pairwise comparisons. Because this situation is so common, two approaches are described below.\n\nTukey’s HSD\nIf a multiple comparison adjustment is desired for testing all pairwise comparisons, a standard approach is to apply Tukey’s Honest Significant Difference (HSD) technique. Occasionally, in the case of few factor levels, Bonferroni’s adjustment may result in more significant findings. If that is the case, use Bonferroni’s correction instead.\nThe calculation for this test is based on the distribution of \\(Q\\). The test statistic \\(Q\\) is sometimes called the studentized range distribution. “Range” is a reference to the numerator where the difference between a maximum and a minimum is calculated. “Studentized” because we are dividing by the estimated standard error, a technique for standardizing famously employed by Student’s (a.k.a. William Gossett) t test. \\(Q\\) is calculated as:\n\\[\nQ = \\frac{max(T_i) - min(T_i)}{\\sqrt{\\frac{MSE}{n}}}\n\\tag{1}\\]\n\n\\(MSE\\) is an estimate of the random error variance\n\\(n\\) is the number of replicates at each factor level. For unequal sample sizes the formula changes somewhat and the result of this test may have a lower Type I error rate than claimed\nThe observations for each level are generated by a different random variable: \\(k\\) variables total, one for each level. Each random variable is normally distributed with mean zero and standard deviation estimated by the denominator of Equation 1. \\(max(T_i)\\) is the maximum value of the \\(k\\) random variables, \\(min(T_i)\\) is the minimum.\nThe distribution of \\(Q\\) will depend on the number of treatments being compared, \\(k\\), and the number of degrees of freedom for error.\n\n\n\nFisher’s LSD\nMaking adjustments for multiple contrasts is a conservative approach, meaning it is more difficult to claim significance compared to when no adjustment is made. Though these adjustments prevent understating the probability of Type I error, they increase the probability of Type II error for each individual contrast. In exploratory analysis where you are looking for hints of what to study further, a Type II error may be a greater concern than Type I.\nFor example, consider a screening study intended to narrow down the number of factors studied in a future experiment. In this case, accidentally ruling out something early on that actually does have a significant impact on the response is more egregious than letting a non-significant factor through to the next experiment where it’s non-significance will be discovered.\nFisher’s Least Significant Difference (LSD) employs no adjustment at all to the pairwise comparisons. However, before proceeding to test pairwise comparisons, the F test for the factor must be significant. Using the less powerful F test as a gatekeeper to the more powerful pairwise t tests serves as a partial protection against extreme Type I errors inflation.\nIn summary, Fisher’s LSD is a two step process. First, verify the F test for the factor is significant. Second, if it is, proceed with all pairwise comparisons without any adjustment. Fisher’s LSD tends to be used in studies where many factors are present, especially screening/exploratory studies."
  },
  {
    "objectID": "multiple_comparisons.html#bonferonni",
    "href": "multiple_comparisons.html#bonferonni",
    "title": "Multiple Comparison",
    "section": "Bonferonni",
    "text": "Bonferonni\nThere are two ways to implement the Bonferroni adjustment illustrated below using the contrasts that were tested in the R Instructions section of the Contrast page.\n\nRecalculate an Alpha Level by Hand\nFirst, the Bonferroni adjustment is shown using output provided for a test of contrasts without adjustment. The code and output from the R Instructions section of the Contrast page is provided again here for convenience. These two contrasts test the mean of the manual brush against the oscillating brush mean, as well as the manual brush mean against the mean of all the other brushes combined.\n\n\nCode\ncontrast_results &lt;- contrast(brush_means,\n                             list(man_v_osc = c(1,-1,0,0),\n                                  man_v_others = c(1,-(1/3),-(1/3),-(1/3))), \n                             adjust=\"none\")\n\n#kable commands are for formatting the output\ncontrast_results |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nman_v_osc\n3.12\n1.58\n20\n1.97\n0.06\n\n\nman_v_others\n0.44\n1.29\n20\n0.34\n0.74\n\n\n\n\n\n\n\n\nA new alpha level against which to compare the p-values can be calculated by hand. Since there are two tests, if the intent was to keep the family wise error rate of 0.05, the alpha level for each individual test is \\(\\frac{0.05}{2} = 0.025\\). To be considered significant, the contrast’s p-value must be less than 0.025.\nman_v_osc has a p-value of 0.06; man_v_others has a p-value of 0.74. Since neither contrast has a p-value less than 0.025 we conclude that the contrasts are not statistically significant.\n\n\nMake the Adjustment in R\nSecond, the Bonferroni adjustment is applied by changing the value of the adjust = argument in the contrast() function from “none” to “bon”.\n\n\nCode\nbon_results &lt;- contrast(brush_means,\n                        list(man_v_osc = c(1,-1,0,0),\n                             man_v_others = c(1,-(1/3),-(1/3),-(1/3))), \n                        adjust=\"bon\")\n\n#kable commands are for formatting the output\nbon_results |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nman_v_osc\n3.12\n1.58\n20\n1.97\n0.13\n\n\nman_v_others\n0.44\n1.29\n20\n0.34\n1.00\n\n\n\n\n\n\n\n\nIn these results the p-values have simply been multiplied by 2 because there were 2 contrasts in the set being tested. Each test can be compared to our desired family wise error rate as usual. Since each test has a p-value greater than 0.05 we conclude that the contrasts are not statistically significant.\nNote, for man_v_others the p-value is capped at 1.00 since a p-value cannot exceed 1.00."
  },
  {
    "objectID": "multiple_comparisons.html#scheffé-1",
    "href": "multiple_comparisons.html#scheffé-1",
    "title": "Multiple Comparison",
    "section": "Scheffé",
    "text": "Scheffé\nSimilar to how the Bonferroni adjustment was applied, to apply a Scheffé adjustment, change the value of the adjust = argument in the contrast() function from “none” to “scheffe”.\n\n\nCode\ncontrast(brush_means, \n         list(man_v_osc = c(1,-1,0,0),\n              man_v_others = c(1,-(1/3),-(1/3),-(1/3))),\n         adjust=\"scheffe\") |&gt; \n\n  #kable commands are for formatting the output\n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nman_v_osc\n3.12\n1.58\n20\n1.97\n0.17\n\n\nman_v_others\n0.44\n1.29\n20\n0.34\n0.94\n\n\n\n\n\n\n\n Each contrast’s p-value can be compared to our desired family wise error rate of 0.05. Since each test has a p-value greater than 0.05 we conclude that the contrasts are not statistically significant. Notice the p-values with Scheffé’s adjustment are higher than the p-values with Bonferroni’s adjustment. This will always be the case if the number of contrasts being tested is small."
  },
  {
    "objectID": "multiple_comparisons.html#tukey",
    "href": "multiple_comparisons.html#tukey",
    "title": "Multiple Comparison",
    "section": "Tukey",
    "text": "Tukey\nIn our toothbrush example, if we want to compare each factor level mean to the other we can apply Tukey’s HSD (Honest Significant Different) adjustment. To do this, instead of inputting custom contrasts to the contrast() command in R, we alter the method argument to be pairwise. We also need to change the adjust argument to tukey. The output provides an estimate of each pairwise comparison, as well as adjusted p-values.\n\n\nFor Tukey adjustment to all pairwise comparisons, this base R shortcut can also be used. The arguments to the function are the name of the model and the name of the factor whose factor level means should be tested.\n\nTukeyHSD(plaque_aov, \"Brush\")\n\n\n\nCode\ncontrast(brush_means, method = \"pairwise\", adjust = \"tukey\")\n\n\n contrast                 estimate   SE df t.ratio p.value\n Manual - Oscillating        3.117 1.58 20   1.967  0.2332\n Manual - Sonic              0.418 1.58 20   0.264  0.9933\n Manual - Ultrasonic        -2.220 1.58 20  -1.401  0.5130\n Oscillating - Sonic        -2.698 1.58 20  -1.703  0.3480\n Oscillating - Ultrasonic   -5.337 1.58 20  -3.369  0.0149\n Sonic - Ultrasonic         -2.638 1.58 20  -1.666  0.3670\n\nP value adjustment: tukey method for comparing a family of 4 estimates \n\n\nWith a p-value of 0.0149, only the Ultrasonic-Oscillating contrast is significant at the 0.05 level. This significance is driven by the large difference in means between the two levels, Ultrasonic’s mean is 5.337 higher than Oscillating. All other pairwise comparisons have p-values greater than 0.05 and so are not considered significant.\n\n\n\n\n\n\nConfidence Intervals Instead of p-values\n\n\n\nIf confidence intervals are desired instead of p-values, the output of the contrast() command can be saved to an object, which then becomes the input to the confint() command. This is true for ANY contrasts computed with emmeans::contrast(), not just Tukey and not just pairwise comparisons. The adjustment specified in contrast() is then applied to the confidence interval as well.\n\n\nCode\nfor_ci &lt;- contrast(brush_means, method = \"pairwise\", adjust = \"tukey\") \nconfint(for_ci)\n\n\n contrast                 estimate   SE df lower.CL upper.CL\n Manual - Oscillating        3.117 1.58 20    -1.32    7.550\n Manual - Sonic              0.418 1.58 20    -4.02    4.852\n Manual - Ultrasonic        -2.220 1.58 20    -6.65    2.214\n Oscillating - Sonic        -2.698 1.58 20    -7.13    1.735\n Oscillating - Ultrasonic   -5.337 1.58 20    -9.77   -0.903\n Sonic - Ultrasonic         -2.638 1.58 20    -7.07    1.795\n\nConfidence level used: 0.95 \nConf-level adjustment: tukey method for comparing a family of 4 estimates"
  },
  {
    "objectID": "multiple_comparisons.html#sec-fisher",
    "href": "multiple_comparisons.html#sec-fisher",
    "title": "Multiple Comparison",
    "section": "Fisher",
    "text": "Fisher\nFirst, look at the ANOVA summary table to see if the F test for brush is significant.\n\n\nCode\nsummary(plaque_aov)\n\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThe p-value for Brush is significant at the 0.05 level. You can then proceed with an un-adjusted test of all pairwise comparisons for the Brush factor. The adjustment argument in the contrast() command in this case is none.\n\n\nCode\ncontrast(brush_means, method = \"pairwise\", adjust = \"none\")\n\n\n contrast                 estimate   SE df t.ratio p.value\n Manual - Oscillating        3.117 1.58 20   1.967  0.0632\n Manual - Sonic              0.418 1.58 20   0.264  0.7944\n Manual - Ultrasonic        -2.220 1.58 20  -1.401  0.1764\n Oscillating - Sonic        -2.698 1.58 20  -1.703  0.1040\n Oscillating - Ultrasonic   -5.337 1.58 20  -3.369  0.0031\n Sonic - Ultrasonic         -2.638 1.58 20  -1.666  0.1114\n\n\n The p-value for Oscillating - Ultrasonic is 0.0031 and is the only significant pairwise comparison at the 0.05 level; though Manual - Oscillating is close, with a p-value of 0.0632."
  },
  {
    "objectID": "z_multiple_comparisons.html",
    "href": "z_multiple_comparisons.html",
    "title": "Multiple Comparison",
    "section": "",
    "text": "In this page, the approach to dealing with multiple contrasts is explained. Specifically, whether and how to adjust the tests of multiple contrasts to account for an inflated family wise error rate. A few techniques are described, with a focus on when to use which technique. Lastly, instructions and example code is provided for carrying out each technique in R.\nIn most good experiments, researchers are interested in more than just one contrast. Conducting multiple tests on the levels of a factor can inflate the family wise Type I error rate, as illustrated in the “Multiple T-tests” section of the ANOVA page. There is considerable disagreement among statisticians about how to approach the issue of multiple tests. The debate primarily focuses on whether to proactively take steps that will mitigate the inflated family wise error rate or not. To further complicate matters, if an adjustment is desired, there are multiple techniques to choose from. An exhaustive presentation of the arguments on either side is not attempted in this text. Though, a few of the key ideas will naturally emerge as the different approaches are discussed.\n\n\nThe terms “contrast” and “comparison” are treated here as synonymous. Comparison is used more often to refer to testing a difference in factor level means. Read Contrasts for more explanation of these terms."
  },
  {
    "objectID": "z_multiple_comparisons.html#bonferroni",
    "href": "z_multiple_comparisons.html#bonferroni",
    "title": "Multiple Comparison",
    "section": "Bonferroni",
    "text": "Bonferroni\nThe Bonferroni adjustment is best for a handful of pre-planned contrasts. As the number of contrasts grows, the adjustment quickly becomes too conservative (i.e. makes it too hard to find significance). In that case, other methods may strike a better balance between Type I and Type II errors.\n\n\nType I error occurs when a true hypothesis is rejected. Type II error occurs when a false hypothesis is not rejected.\nIt can be shown that in order to not exceed a desired family wise error rate of \\(\\alpha_\\text{fw}\\), for a set of \\(k\\) contrasts, each individual contrast should be tested at a significance level of \\(\\frac{\\alpha_\\text{fw}}{k}\\). For example, if we desire a family wise error rate of 0.05 and plan to do 5 tests, each individual contrast must have a p-value less than \\(\\frac{0.05}{5} = 0.01\\) to be considered significant. The test itself has not changed, only the benchmark p-value for claiming significance. This adjustment is easy to understand and to calculate."
  },
  {
    "objectID": "z_multiple_comparisons.html#scheffé",
    "href": "z_multiple_comparisons.html#scheffé",
    "title": "Multiple Comparison",
    "section": "Scheffé",
    "text": "Scheffé\nUsing experimental results to suggest which contrasts to test is often referred to as “data snooping” or exploratory analysis. For example, you may look at graphical and numerical summaries to see which means (or combinations of means) will be promising to test. The problem with this approach is that you have essentially done a quick, informal test of many differences when you looked at descriptive statistics and plots. In other words, you have already tested the means and combinations of the means in your mind. The Type I error rate of the contrasts will be different (higher) than stated because you are only formally applying the test to those that look significant already.\nScheffé’s method is most useful when many contrasts are tested, especially when going beyond pairwise comparisons of factor level means to test combined factor levels (i.e. complex comparisons). In data exploration, there are theoretically an infinite number of contrasts you could test. This is not a problem for Scheffé’s adjustment because, unlike other adjustment techniques, Scheffé’s adjustment does not depend on the number of comparisons to be made. Rather, it is determined only by the number of factor levels and the number of observations.\nThe F statistic used to test a contrast in Scheffé’s adjustment is related to the omnibus F test for the factor itself, and is given by:\n\\[\nF_\\text{Scheffé} = (k-1)*F\n\\]\nWhere \\(F\\) is the statistic for the F test of the factor as usual. \\(k\\) is the number of levels in that factor. \\(F_\\text{Scheffé}\\) has \\(df_\\text{numerator} = k-1\\) and \\(df_\\text{denominator} = df_\\text{residual}\\). Scheffé’s test output is often in terms of a t test. Recall that the t statistic is simply the square root of the F statistic.\nIf you are interested in only a specific set of hypotheses (all pairwise comparisons, or all treatment levels vs. control, or all levels compared to the “best” level, etc.) there may be another adjustment technique that will provide better statistical power. Two of which are mentioned below."
  },
  {
    "objectID": "z_multiple_comparisons.html#methods-designed-for-all-pairwise-comparisons",
    "href": "z_multiple_comparisons.html#methods-designed-for-all-pairwise-comparisons",
    "title": "Multiple Comparison",
    "section": "Methods Designed for All Pairwise Comparisons",
    "text": "Methods Designed for All Pairwise Comparisons\nWhether it is an exploratory analysis or a pre-planned set of contrasts, many researchers want to test all factor level means against each other. This is usually referred to as testing all pairwise comparisons. Because this situation is so common, two approaches are described below.\n\nTukey’s HSD\nIf a multiple comparison adjustment is desired for testing all pairwise comparisons, a standard approach is to apply Tukey’s Honest Significant Difference (HSD) technique. Occasionally, in the case of few factor levels, Bonferroni’s adjustment may result in more significant findings. If that is the case, use Bonferroni’s correction instead.\nThe calculation for this test is based on the distribution of \\(Q\\). The test statistic \\(Q\\) is sometimes called the studentized range distribution. “Range” is a reference to the numerator where the difference between a maximum and a minimum is calculated. “Studentized” because we are dividing by the estimated standard error, a technique for standardizing famously employed by Student’s (a.k.a. William Gossett) t test. \\(Q\\) is calculated as:\n\\[\nQ = \\frac{max(T_i) - min(T_i)}{\\sqrt{\\frac{MSE}{n}}}\n\\tag{1}\\]\n\n\\(MSE\\) is an estimate of the random error variance\n\\(n\\) is the number of replicates at each factor level. For unequal sample sizes the formula changes somewhat and the result of this test may have a lower Type I error rate than claimed\nThe observations for each level are generated by a different random variable: \\(k\\) variables total, one for each level. Each random variable is normally distributed with mean zero and standard deviation estimated by the denominator of Equation 1. \\(max(T_i)\\) is the maximum value of the \\(k\\) random variables, \\(min(T_i)\\) is the minimum.\nThe distribution of \\(Q\\) will depend on the number of treatments being compared, \\(k\\), and the number of degrees of freedom for error.\n\n\n\nFisher’s LSD\nMaking adjustments for multiple contrasts is a conservative approach, meaning it is more difficult to claim significance compared to when no adjustment is made. Though these adjustments prevent understating the probability of Type I error, they increase the probability of Type II error for each individual contrast. In exploratory analysis where you are looking for hints of what to study further, a Type II error may be a greater concern than Type I.\nFor example, consider a screening study intended to narrow down the number of factors studied in a future experiment. In this case, accidentally ruling out something early on that actually does have a significant impact on the response is more egregious than letting a non-significant factor through to the next experiment where it’s non-significance will be discovered.\nFisher’s Least Significant Difference (LSD) employs no adjustment at all to the pairwise comparisons. However, before proceeding to test pairwise comparisons, the F test for the factor must be significant. Using the less powerful F test as a gatekeeper to the more powerful pairwise t tests serves as a partial protection against extreme Type I errors inflation.\nIn summary, Fisher’s LSD is a two step process. First, verify the F test for the factor is significant. Second, if it is, proceed with all pairwise comparisons without any adjustment. Fisher’s LSD tends to be used in studies where many factors are present, especially screening/exploratory studies."
  },
  {
    "objectID": "z_multiple_comparisons.html#bonferonni",
    "href": "z_multiple_comparisons.html#bonferonni",
    "title": "Multiple Comparison",
    "section": "Bonferonni",
    "text": "Bonferonni\nThere are two ways to implement the Bonferroni adjustment illustrated below using the contrasts that were tested in the R Instructions section of the Contrast page.\n\n\nSee R instructions for Fisher’s LSD for a shortcut to apply Bonferroni adjustment to all pairwise comparisons.\n\nRecalculate an Alpha Level by Hand\nFirst, the Bonferroni adjustment is shown using output provided for a test of contrasts without adjustment. The code and output from the R Instructions section of the Contrast page is provided again here for convenience. These two contrasts test the mean of the manual brush against the oscillating brush mean, as well as the manual brush mean against the mean of all the other brushes combined.\n\n\nCode\nbrush_means &lt;- emmeans(plaque_aov, \"Brush\")\ncontrast_results &lt;- contrast(brush_means,\n                             list(man_v_osc = c(1,-1,0,0),\n                                  man_v_others = c(1,-(1/3),-(1/3),-(1/3))), \n                             adjust=\"none\")\n\n#kable commands are for formatting the output\ncontrast_results |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nman_v_osc\n3.12\n1.58\n20\n1.97\n0.06\n\n\nman_v_others\n0.44\n1.29\n20\n0.34\n0.74\n\n\n\n\n\n\n\n\nA new alpha level against which to compare the p-values can be calculated by hand. Since there are two tests, if the intent was to keep the family wise error rate of 0.05, the alpha level for each individual test is \\(\\frac{0.05}{2} = 0.025\\). To be considered significant, the contrast’s p-value must be less than 0.025.\nman_v_osc has a p-value of 0.06; man_v_others has a p-value of 0.74. Since neither contrast has a p-value less than 0.025 we conclude that the contrasts are not statistically significant.\n\n\nMake the Adjustment in R\nSecond, the Bonferroni adjustment is applied by changing the value of the adjust = argument in the contrast() function from “none” to “bon”.\n\n\nCode\nbon_results &lt;- contrast(brush_means,\n                        list(man_v_osc = c(1,-1,0,0),\n                             man_v_others = c(1,-(1/3),-(1/3),-(1/3))), \n                        adjust=\"bon\")\n\n#kable commands are for formatting the output\nbon_results |&gt; \n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nman_v_osc\n3.12\n1.58\n20\n1.97\n0.13\n\n\nman_v_others\n0.44\n1.29\n20\n0.34\n1.00\n\n\n\n\n\n\n\n\nIn these results the p-values have simply been multiplied by 2 because there were 2 contrasts in the set being tested. Each test can be compared to our desired family wise error rate as usual. Since each test has a p-value greater than 0.05 we conclude that the contrasts are not statistically significant.\nNote, for man_v_others the p-value is capped at 1.00 since a p-value cannot exceed 1.00."
  },
  {
    "objectID": "z_multiple_comparisons.html#scheffé-1",
    "href": "z_multiple_comparisons.html#scheffé-1",
    "title": "Multiple Comparison",
    "section": "Scheffé",
    "text": "Scheffé\nSimilar to how the Bonferroni adjustment was applied, to apply a Scheffé adjustment, change the value of the adjust = argument in the contrast() function from “none” to “scheffe”.\n\n\nCode\ncontrast(brush_means, \n         list(man_v_osc = c(1,-1,0,0),\n              man_v_others = c(1,-(1/3),-(1/3),-(1/3))),\n         adjust=\"scheffe\") |&gt; \n\n  #kable commands are for formatting the output\n  kable(digits = 2) |&gt; \n  kable_styling(full_width = TRUE)\n\n\n\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nman_v_osc\n3.12\n1.58\n20\n1.97\n0.17\n\n\nman_v_others\n0.44\n1.29\n20\n0.34\n0.94\n\n\n\n\n\n\n\n Each contrast’s p-value can be compared to our desired family wise error rate of 0.05. Since each test has a p-value greater than 0.05 we conclude that the contrasts are not statistically significant. Notice the p-values with Scheffé’s adjustment are higher than the p-values with Bonferroni’s adjustment. This will always be the case if the number of contrasts being tested is small."
  },
  {
    "objectID": "z_multiple_comparisons.html#tukey",
    "href": "z_multiple_comparisons.html#tukey",
    "title": "Multiple Comparison",
    "section": "Tukey",
    "text": "Tukey\nIn our toothbrush example, if we want to compare each factor level mean to the other we can apply Tukey’s HSD adjustment using a base R function. The arguments to the function are the name of the model and the name of the factor whose means should be tested. Notice the emmeans grid does not have to be created and the contrast coefficients do not explicitly need to be input. The output provides an estimate of each pairwise comparison, as well as adjusted simultaneous confidence intervals and p-values.\n\n\nCode\nTukeyHSD(plaque_aov, \"Brush\") |&gt; pander()\n\n\n\nBrush:\n\n\n\n\n\n\n\n\n\n\n \ndiff\nlwr\nupr\np adj\n\n\n\n\nOscillating-Manual\n-3.117\n-7.55\n1.317\n0.2332\n\n\nSonic-Manual\n-0.4183\n-4.852\n4.015\n0.9933\n\n\nUltrasonic-Manual\n2.22\n-2.214\n6.654\n0.5129\n\n\nSonic-Oscillating\n2.698\n-1.735\n7.132\n0.348\n\n\nUltrasonic-Oscillating\n5.337\n0.9029\n9.77\n0.01487\n\n\nUltrasonic-Sonic\n2.638\n-1.795\n7.072\n0.367\n\n\n\n\n\n\n\nWith a p-value of 0.01, only the Ultrasonic-Oscillating contrast is significant. This significance is driven by the large difference in means between the two levels, Ultrasonic’s mean is 5.337 higher than Oscillating. All other pairwise comparisons have p-values greater than 0.05 and so are not considered significant."
  },
  {
    "objectID": "z_multiple_comparisons.html#sec-fisher",
    "href": "z_multiple_comparisons.html#sec-fisher",
    "title": "Multiple Comparison",
    "section": "Fisher",
    "text": "Fisher\nFirst, look at the ANOVA summary table to see if the F test for brush is significant.\n\n\nCode\nsummary(plaque_aov)\n\n\n            Df Sum Sq Mean Sq F value Pr(&gt;F)  \nBrush        3  86.31  28.769   3.822 0.0258 *\nResiduals   20 150.56   7.528                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nThe p-value for Brush is significant at the 0.05 level. You can then proceed with an unadjusted test of all pairwise comparisons for the Brush factor. The syntax for this function is a bit different. You do not have to create the model first.\nIt requires the response vector as the first argument, the factor vector as the 2nd argument, and an adjustment for multiple comparisons (if any) as the 3rd argument.\n\n\nCode\npairwise.t.test(df$Plaque, df$Brush, p.adjust.method = \"none\") |&gt; \n  pander()\n\n\n\nmethod: t tests with pooled SD\n\ndata.name: df\\(Plaque and df\\)Brush\np.value:\n\n\n\n\n\n\n\n\n\n \nManual\nOscillating\nSonic\n\n\n\n\nOscillating\n0.06315\nNA\nNA\n\n\nSonic\n0.7944\n0.104\nNA\n\n\nUltrasonic\n0.1764\n0.003052\n0.1114\n\n\n\np.adjust.method: none\n\n\n\n\n\n The output is a triangular matrix of p-values. The p-value for Ultrasonic vs. Oscillating is 0.0031 and is the only significant pairwise comparison at the 0.05 level; though Oscillating vs. Manual is close, with a p-value of 0.0632.\n\n\n\n\n\n\nNote\n\n\n\nThe pairwise.t.test() can receive “bon” as an input to the p.adjust.method = argument, which will perform all pairwise comparisons and apply the Bonferroni adjustment. When the number of factor levels is small Bonferroni is preferred over the Tukey’s HSD because it provides more statistical power."
  },
  {
    "objectID": "multiple_comparisons.html#bonus-estimating-and-testing-effect-sizes",
    "href": "multiple_comparisons.html#bonus-estimating-and-testing-effect-sizes",
    "title": "Multiple Comparison",
    "section": "Bonus: Estimating and Testing Effect Sizes",
    "text": "Bonus: Estimating and Testing Effect Sizes\nIf no custom contrasts are provided to the contrast() command, and no argument for method is provided, the default output is an estimate (and test) of each factor level effect, as seen below!\n\n\nCode\n(effect_sizes &lt;- contrast(brush_means)) \n\n\n contrast           estimate   SE df t.ratio p.value\n Manual effect        0.3287 0.97 20   0.339  0.9273\n Oscillating effect  -2.7879 0.97 20  -2.874  0.0323\n Sonic effect        -0.0896 0.97 20  -0.092  0.9273\n Ultrasonic effect    2.5488 0.97 20   2.627  0.0323\n\nP value adjustment: fdr method for 4 tests \n\n\n\n\nNote the behavior of the defaults is a little different than what might be expected. “fdr” stands for “false detection rate”. It makes adjustments to keep the overall proportion of Type I errors fixed (e.g. 5% of tests will be a Type I error). This is somewhat less stringent than keeping the family-wise Type I error rate fixed.\nYou can use confint() to get confidence intervals for the effects (with or without adjustments) as well.\n\n\nCode\nconfint(effect_sizes)\n\n\n contrast           estimate   SE df lower.CL upper.CL\n Manual effect        0.3287 0.97 20   -2.333    2.991\n Oscillating effect  -2.7879 0.97 20   -5.450   -0.126\n Sonic effect        -0.0896 0.97 20   -2.752    2.573\n Ultrasonic effect    2.5488 0.97 20   -0.113    5.211\n\nConfidence level used: 0.95 \nConf-level adjustment: bonferroni method for 4 estimates"
  }
]